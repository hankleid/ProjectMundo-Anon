<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/ProjectMundo/style/jats-html.xsl"?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     L'apprentissage sans exemple permet une débruitage et une super-résolution instantanés en microscopie à fluorescence optique
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Résumé
    </title>
    <p id="Par1">
     Les méthodes de super-résolution computationnelles, notamment les algorithmes analytiques conventionnels et les modèles d'apprentissage profond, ont considérablement amélioré la microscopie optique. Parmi eux, les réseaux de neurones profonds supervisés ont démontré des performances exceptionnelles, cependant, ils exigent des données de formation de haute qualité abondantes, qui sont laborieuses et même impraticables à acquérir en raison de la dynamique élevée des cellules vivantes. Ici, nous développons des réseaux de déconvolution sans exemple (ZS-DeconvNet) qui améliorent instantanément la résolution des images de microscope de plus de 1,5 fois par rapport à la limite de diffraction avec 10 fois moins de fluorescence que les conditions d'imagerie à super-résolution ordinaires, de manière non supervisée sans nécessité de vérités de base ou d'acquisition de données supplémentaires. Nous démontrons l'applicabilité polyvalente de ZS-DeconvNet sur plusieurs modalités d'imagerie, notamment la microscopie à fluorescence par réflexion interne totale, la microscopie à champ large tridimensionnelle, la microscopie confocale, la microscopie à deux photons, la microscopie à feuille de lumière à lattice et la microscopie à illumination structurée multimodale, qui permet l'imagerie à super-résolution 2D/3D à long terme et multicolore des bioprocédés sous-cellulaires des cellules unicellulaires mitotiques aux embryons multicellulaires de souris et de
     <italic>
      C. elegans
     </italic>
     .
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    Introduction
   </title>
   <p id="Par3">
    La microscopie à fluorescence optique est un outil essentiel pour la recherche biologique. Les développements récents des techniques de super-résolution (SR) offrent une résolvabilité sans précédent pour visualiser les structures dynamiques fines des divers bioprocessus
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
    </sup>
    . Cependant, le gain en résolution spatiale via toute méthode SR se traduit par des compromis sur d'autres métriques d'imagerie, par exemple la durée ou la vitesse, qui sont également importantes pour disséquer les bioprocessus
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
    </sup>
    . Récemment, les méthodes de SR computationnelles ont gagné une attention considérable pour leur capacité à améliorer instantanément la résolution d'image in silico, permettant ainsi une mise à niveau significative des systèmes de microscopie à fluorescence existants et une extension de leur domaine d'application
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    .
   </p>
   <p id="Par4">
    En général, les méthodes de SR computationnelles existantes peuvent être classées en deux catégories : les méthodes basées sur des modèles analytiques, telles que les algorithmes de déconvolution, et les méthodes basées sur l'apprentissage profond, par exemple les réseaux de neurones SR
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . La première catégorie emploie souvent des modèles analytiques qui préscrivent certaines hypothèses sur l'échantillon et les propriétés d'image, par exemple la parcimonie et la symétrie locale, pour améliorer la résolution d'image avec plusieurs paramètres ajustables. L'ajustement des paramètres dépend de l'expérience et est fastidieux, et les sorties des modèles analytiques dépendent fortement des ensembles de paramètres
    <sup>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     ,
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    . De plus, dans les expériences pratiques, les modèles conçus avec certaines hypothèses ne peuvent pas répondre à la complexité statistique totale de l'imagerie microscopique, ce qui les rend peu robustes et les rend propices à générer des artefacts, en particulier dans des conditions de faible rapport signal/bruit (SNR)
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    . En revanche, les méthodes de SR basées sur l'apprentissage profond (DLSR) ont obtenu un succès remarquable dans l'apprentissage de la relation de transformation d'image de bout en bout selon de grandes quantités de données exemplaires sans nécessiter de modèle analytique explicite
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Notamment, le schéma d'inversion basé sur les données via l'apprentissage profond peut approximer non seulement la fonction pseudoinverse du processus de dégradation d'image mais également les caractéristiques stochastiques des solutions SR. Cependant, la formation de modèles DLSR nécessite l'acquisition de grandes quantités d'images de faible résolution et d'images de référence SR de haute qualité, ce qui est extrêmement fastidieux et parfois même impraticable en raison de la dynamique rapide ou du faible SNR de fluorescence dans les échantillons biologiques
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . En outre, les performances des méthodes DLSR dépendent fortement de la qualité et de la quantité des données de formation
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Ces facteurs entravent considérablement l'application large des méthodes DLSR dans les expériences d'imagerie quotidienne, malgré leurs performances SR convaincantes par rapport aux méthodes basées sur des modèles analytiques
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    .
   </p>
   <p id="Par5">
    Nous présentons ici un cadre de réseau de neurones profonds de déconvolution à zéro coupure (ZS-DeconvNet) capable de former un réseau DLSR de manière non supervisée en utilisant au plus une seule image plane ou un seul empilement d'images de faible résolution et de faible SNR, ce qui aboutit à une mise en œuvre à zéro coupure
    <sup>
     <xref ref-type="bibr" rid="CR18">
      18
     </xref>
    </sup>
    . Ainsi, par rapport aux méthodes DLSR de pointe, le ZS-DeconvNet peut s'adapter à des circonstances d'imagerie biologique diverses, où les bioprocessus sont trop dynamiques, trop sensibles à la lumière pour acquérir des images SR de référence, ou le processus d'acquisition d'images est affecté par des facteurs inconnus et non idéaux. Nous avons caractérisé que le ZS-DeconvNet peut améliorer la résolution de plus de 1,5 fois par rapport aux limites de diffraction avec une grande fidélité et une quantifiabilité, même lorsqu'il est formé sur une seule image de faible SNR et sans nécessiter de réglage de paramètres spécifiques à l'image
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     ,
     <xref ref-type="bibr" rid="CR19">
      19
     </xref>
     ,
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
     ,
     <xref ref-type="bibr" rid="CR21">
      21
     </xref>
     ,
     <xref ref-type="bibr" rid="CR22">
      22
     </xref>
     ,
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
    </sup>
    . Nous avons démontré que le ZS-DeconvNet formé correctement peut inférer l'image à haute résolution à l'échelle des millisecondes, réalisant ainsi une imagerie SR 2D/3D à long terme et à haut débit de multiples interactions d'organites, de dynamiques cytosquelettiques et organellaires pendant les processus sensibles à la lumière de migration et de mitose, ainsi que des structures et dynamiques sous-cellulaires dans les embryons de
    <italic>
     C. elegans
    </italic>
    et de souris en développement. En outre, pour permettre au ZS-DeconvNet d'être largement accessible à la communauté de recherche biologique, nous avons créé une boîte à outils de plugin Fiji et une page d'accueil de tutoriel pour les méthodes ZS-DeconvNet
    <sup>
     <xref ref-type="bibr" rid="CR24">
      24
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    Résultats
   </title>
   <sec id="Sec3">
    <title>
     Développement et caractérisation de ZS-DeconvNet
    </title>
    <p id="Par6">
     Le concept de ZS-DeconvNet repose sur le solveur de problème inverse non supervisé informé par le modèle d'imagerie optique avant :
     <disp-formula id="Equ1">
      <label>
       1
      </label>
      <alternatives>
       <math id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <msubsup>
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\arg }}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\Big|\Big|{{{{{{\bf{y}}}}}}-{\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{\bf{y}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }{\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     où
     <bold>
      y
     </bold>
     désigne l'image de faible résolution bruyante, PSF est la fonction d'étalement de points (PSF),
     <inline-formula id="IEq1">
      <alternatives>
       <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     représente un réseau de neurones profonds (DNN) avec des paramètres formables
     <bold>
      θ
     </bold>
     , et
     <inline-formula id="IEq2">
      <alternatives>
       <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     indique l'opération de sous-échantillonnage. Si le DNN est formé directement via la fonction d'objectif ci-dessus, il amplifiera indésirablement le bruit photonique contenu dans les images biologiques, ce qui contaminera considérablement les informations réelles de l'échantillon à des conditions de faible SNR (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      1a
     </xref>
     ). Pour améliorer la robustesse au bruit du ZS-DeconvNet tout en maintenant sa caractéristique non supervisée, nous avons adopté un schéma de recorruption d'images qui génère deux images recorrompues indépendantes du bruit à partir de l'image originale, qui sont ensuite utilisées comme entrées et images de référence dans la formation du réseau (Méthodes). Nous avons démontré théoriquement la validité de l'approximation gaussienne au modèle de bruit mixte de Poisson-Gauss pour les images sCMOS ordinaires et prouvé la convergence de l'intégration du schéma de recorruption dans le solveur de problème inverse non supervisé (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). En outre, nous avons introduit le terme de régularisation de Hessian, qui a été démontré comme étant utile pour atténuer les artefacts de reconstruction dans les images de microscopie, pour réguler la convergence du réseau (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b–e
     </xref>
     ). Pris ensemble, la fonction d'objectif globale du ZS-DeconvNet peut être formulée comme :
     <disp-formula id="Equ2">
      <label>
       2
      </label>
      <alternatives>
       <math id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfrac>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </mfrac>
        <msubsup>
         <mrow>
          <mo mathsize="big">
           ∑
          </mo>
         </mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </msubsup>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msup>
           <mrow>
            <mi>
             D
            </mi>
           </mrow>
           <mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </msup>
          <mi mathvariant="bold">
           g
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi>
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   i
                  </mi>
                 </mrow>
                </msub>
                <mi mathvariant="bold-italic">
                 +
                </mi>
                <mi>
                 D
                </mi>
                <mi mathvariant="bold">
                 g
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mi>
               i
              </mi>
             </mrow>
            </msub>
            <mi mathvariant="bold-italic">
             +
            </mi>
            <mi>
             D
            </mi>
            <mi mathvariant="bold">
             g
            </mi>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{arg}}}}}}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\frac{1}{N}{\sum }_{i=1}^{N}{{{{{\mathcal{L}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}-{D}^{-1}{{{{{\bf{g}}}}}},{\left({f}_{\theta }\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }\right)+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     où
     <italic>
      N
     </italic>
     est le nombre total d'images à traiter,
     <inline-formula id="IEq3">
      <alternatives>
       <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
       </math>
       <tex-math id="IEq3_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq3.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est une matrice de contrôle de bruit inversible qui peut être calculée en fonction des niveaux de signal et de bruit (Méthodes), et
     <bold>
      g
     </bold>
     est une carte de bruit aléatoire échantillonnée à partir d'une distribution normale standard. Nous faisons référence à la première partie de la fonction d'objectif comme le terme de dégradation, qui rend compte de la fidélité d'inférence, et la deuxième partie comme le terme de régularisation, qui rationalise les sorties SR
     <sup>
      <xref ref-type="bibr" rid="CR25">
       25
      </xref>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
      <xref ref-type="bibr" rid="CR27">
       27
      </xref>
      ,
      <xref ref-type="bibr" rid="CR28">
       28
      </xref>
     </sup>
     .
    </p>
    <p id="Par7">
     Après avoir défini la fonction d'objectif, nous avons adopté une architecture de DNN à deux étapes composée de deux U-Nets connectés séquentiellement comme colonne vertébrale simple mais efficace pour le ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig1">
      1a, b
     </xref>
     et Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2a
     </xref>
     ). La première étape sert de débruiteur pour générer des images sans bruit selon la perte de débruitage (Méthodes), et la deuxième étape améliore la résolution d'image selon la perte de déconvolution non supervisée décrite ci-dessus. Nous avons constaté empiriquement que l'architecture à deux étapes et la fonction de perte régulée par le modèle physique stabilisent les procédures de formation et confèrent une interprétabilité au modèle de réseau global
     <sup>
      <xref ref-type="bibr" rid="CR29">
       29
      </xref>
     </sup>
     .
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="fr">
       <title>
        Réseaux de déconvolution sans tir.
       </title>
       <p>
        <bold>
         a
        </bold>
        L'architecture à deux étages de ZS-DeconvNet et le schéma de sa phase d'entraînement.
        <bold>
         b
        </bold>
        Le schéma de la phase d'inférence de ZS-DeconvNet.
        <bold>
         c
        </bold>
        Images SR représentatives de Lyso et MT reconstruites par déconvolution RL (deuxième colonne), déconvolution éparsse (troisième colonne) et ZS-DeconvNet (quatrième colonne). Les images WF claires sont affichées pour référence.
        <bold>
         d
        </bold>
        Comparaisons statistiques de la déconvolution RL, de la déconvolution éparsse et de ZS-DeconvNet en termes de PSNR et de résolution (
        <italic>
         n
        </italic>
        = 100 régions d'intérêt).
        <bold>
         e
        </bold>
        Comparaisons de la largeur à mi-hauteur (FWHM) des images WF claires et des images traitées via déconvolution RL, déconvolution éparsse et ZS-DeconvNet (
        <italic>
         n
        </italic>
        = 30 microtubules). La limite de diffraction théorique est étiquetée avec la ligne pointillée grise pour référence.
        <bold>
         f
        </bold>
        Comparaison du temps de test entre la déconvolution éparsse basée sur GPU et ZS-DeconvNet (moyenne de 25 images de test de 1024 × 1024 pixels). Ligne centrale, médianes ; limites, 75% et 25% ; whiskers, la plus grande valeur entre le point de données le plus élevé et les 75e percentiles plus 1,5 × la plage interquartile (IQR), et la plus petite valeur entre le point de données le plus petit et les 25e percentiles moins 1,5 × l'IQR ; outliers, points de données supérieurs à la whisker supérieure ou inférieurs à la whisker inférieure. Les données sources sont fournies sous forme de fichier Source Data. Barre d'échelle, 1,5 μm (
        <bold>
         a
        </bold>
        ), 5 μm (
        <bold>
         c
        </bold>
        ), 2 μm (régions de zoom dans (
        <bold>
         c
        </bold>
        )).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig1_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par8">
     Pour caractériser et évaluer ZS-DeconvNet, nous avons simulé les images de microscopie de structures ponctuelles et tubulaires contaminées par un bruit gaussien-poisson à des niveaux de signal croissants de 5 à 25 comptes de photons moyens, ce qui nous a permis de tester systématiquement comment les paramètres d'hypercorruption à différents conditions d'imagerie influencent les sorties finales (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      2
     </xref>
     ). Nous avons constaté que les hyperparamètres optimaux sont théoriquement indépendants du contenu et des niveaux de signal des images (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      5
     </xref>
     ), ce qui permet une application robuste de ZS-DeconvNet sur divers spécimens biologiques et configurations d'imagerie (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ). Ensuite, nous avons comparé les performances des modèles ZS-DeconvNet formés avec des données augmentées par recorruption d'une seule image bruyante avec des algorithmes de déconvolution analytiques ou des modèles formés avec des nombres d'images simulées ou acquises de manière indépendante. Pour ce faire, nous avons utilisé le mode d'illumination de fluorescence interne totale (TIRF) de notre microscopie à illumination structurée multimodale (Multi-SIM) pour acquérir ~20 ensembles d'images TIRF limitées par la diffraction à faible et haute SNR pour chaque structure sous-cellulaire de lysosomes (Lyso) et de microtubules (MTs), dont les images à faible SNR ont été utilisées pour la formation et le test, tandis que leurs homologues à haute SNR ont servi de référence (Méthodes). Nous avons constaté que le rapport signal/bruit (PSNR) et la résolution des images ZS-DeconvNet étaient substantiellement meilleurs que ceux générés par des algorithmes analytiques, tels que le classique Richardson-Lucy (RL) et la déconvolution éparsée la plus récente (Fig.
     <xref ref-type="fig" rid="Fig1">
      1c–e
     </xref>
     ) et le taux de débit d'un ZS-DeconvNet bien formé est &gt;100 fois supérieur à celui de l'algorithme de déconvolution épars (Fig.
     <xref ref-type="fig" rid="Fig1">
      1f
     </xref>
     ). En particulier, même si le ZS-DeconvNet a été formé avec des données augmentées à partir d'une seule image d'entrée, la qualité perceptive et les métriques quantifiées de ses images de sortie étaient comparables à celles des images du modèle formé avec de plus grandes quantités de données (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      6
     </xref>
     ). En outre, nous avons validé l'amélioration de la résolution, la quantifiabilité et la capacité de généralisation de ZS-DeconvNet (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      7
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      10
     </xref>
     ), et les avons comparés avec le modèle DFCAN supervisé (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      11
     </xref>
     ) sur des données synthétiques et expérimentales. Ces caractérisations démontrent que ZS-DeconvNet est capable de générer des images DLSR de haute qualité avec une amélioration de la résolution de 1,5 fois par rapport à la limite de diffraction tout en utilisant les moins de données de formation, ce qui présente un grand potentiel pour améliorer les performances d'imagerie de divers systèmes de microscope et étendre leur applicabilité à une large variété de bioprocédés qui sont difficiles pour les méthodes conventionnelles
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     Observation à long terme de bioprocédés sensibles à la phototoxicité
    </title>
    <p id="Par9">
     L'adhésion et la migration cellulaires sont essentielles dans les processus morphogénétiques et contribuent à de nombreuses maladies
     <sup>
      <xref ref-type="bibr" rid="CR31">
       31
      </xref>
     </sup>
     . La visualisation de la dynamique du cytosquelette à haute résolution pendant le processus d'adhésion/migration est critique pour élucider le mécanisme sous-jacent. Cependant, en raison d'une photosensibilité sévère, les processus d'adhésion et de migration cellulaires sont généralement enregistrés à des taux d'images faibles, c'est-à-dire plusieurs secondes par image, et à des intensités de lumière faibles
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR32">
       32
      </xref>
     </sup>
     . Dans ces conditions d'imagerie, soit la déconvolution RL, soit l'apprentissage auto-supervisé basé sur la continuité temporelle (Méthodes) échoue à récupérer et à affiner la structure complexe de F-actine et de myosine-II (Fig.
     <xref ref-type="fig" rid="Fig2">
      2a
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      12
     </xref>
     , et Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM4">
      1
     </xref>
     ). En revanche, le modèle ZS-DeconvNet améliore efficacement à la fois le rapport signal/bruit et la résolution des enregistrements temporels à deux couleurs de la dynamique cellulaire
     <sup>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
     </sup>
     .
     <fig id="Fig2" position="float">
      <label>
       Fig. 2
      </label>
      <caption xml:lang="fr">
       <title>
        Imagerie SR à long terme de bioprocédés rapides et photosensibles via ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Images SR représentatives reconstruites par ZS-DeconvNet du cytosquelette d'actine F et de la myosine-II dans une cellule COS-7 co-exprimant mEmerald-lifeact et mCherry-myosin-IIA. Les comparaisons de l'image TIRF brute et des images traitées par déconvolution RL, déconvolution basée sur DeepCAD et ZS-DeconvNet sont affichées.
        <bold>
         b
        </bold>
        Images SR à deux couleurs et à balayage temporel améliorées via ZS-DeconvNet montrant la dynamique coordonnée de l'actine F (cyan) et de la myosine-II (jaune) pendant tout le processus d'étalage après avoir placé une cellule COS-7 sur une couverture (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM5">
         2
        </xref>
        ).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Images SR à deux couleurs et à balayage temporel améliorées via ZS-DeconvNet de l'actine F et de la myosine-II dans une cellule COS-7 en train de ramper, montrant que la myosine-II se concentre de préférence à l'arrière de la cellule (délimitée par des lignes pointillées jaunes dans
        <bold>
         d
        </bold>
        ), opposée à la direction de rampe (indiquée par les flèches blanches dans
        <bold>
         d
        </bold>
        ) (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM6">
         3
        </xref>
        ).
        <bold>
         e
        </bold>
        Image SR représentative générée via ZS-DeconvNet des endosomes de recyclage (RE, vert) et des endosomes tardifs (LE, magenta) dans une cellule SUM-159 éditée par le génome et exprimant de manière endogène EGFP-Rab11 et mCherry-Lamp1 (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM7">
         4
        </xref>
        ).
        <bold>
         f
        </bold>
        Trajectoires typiques des mouvements de RE (haut) et de LE (bas) montrant la motilité directionnelle rapide de RE et la nature bidirectionnelle de LE.
        <bold>
         g
        </bold>
        Comparaisons de la vitesse, du déplacement et du temps de trajet entre Lyso/LE et RE, et quantification du temps de résidence des RE près de leurs sites d'exocytose avant de fusionner avec la membrane plasmique (
        <italic>
         n
        </italic>
        = 505 trajectoires pour RE et
        <italic>
         n
        </italic>
        = 230 trajectoires pour LE). Un petit nombre de points de données dépassant le temps de transport de 150 s ou le déplacement de 60 μm n'a pas été affiché pour une meilleure présentation des distributions. Ligne centrale, médianes ; limites, 75% et 25%. La signification statistique a été déterminée à l'aide d'un test de Mann-Whitney non apparié (p =
        <inline-formula id="IEq4">
         <alternatives>
          <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            1,38
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              7
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq4_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1,38\times {10}^{-7}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq4.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ,
        <inline-formula id="IEq5">
         <alternatives>
          <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            5,65
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              35
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq5_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$5,65\times {10}^{-35}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq5.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        , et
        <inline-formula id="IEq6">
         <alternatives>
          <math id="IEq6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            6,26
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              40
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq6_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$6,26\times {10}^{-40}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq6.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        pour les tests de la vitesse de déplacement, du temps de transport et du déplacement, respectivement). ****
        <italic>
         p
        </italic>
        &lt; 0,0001. Les données sources sont fournies sous forme de fichier Source Data.
        <bold>
         h
        </bold>
        Les images à balayage temporel illustrent le mouvement directionnel d'un RE en forme de bâtonnet, et la fusion ultérieure avec la membrane plasmique.
        <bold>
         i
        </bold>
        Les images à balayage temporel illustrent trois LE qui s'accrochent les uns aux autres et co-migrent sur une certaine distance avant de se diviser en LE individuels. Barre d'échelle, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 2 μm (régions de zoom dans
        <bold>
         a
        </bold>
        ), 8 μm (
        <bold>
         b
        </bold>
        ), 3 μm (
        <bold>
         e
        </bold>
        ), 0,5 μm (région de zoom dans
        <bold>
         e
        </bold>
        ), 1 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         f
        </bold>
        ,
        <bold>
         i
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig2_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par10">
     des processus de dispersion cellulaires après avoir déposé une cellule coexprimant mEmerald-Lifeact et mCherry-myosin- IIA sur une plaque de couverture (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     et Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Intriguamment, nous avons observé que dans certaines substances, les cellules rampaient autour du site de contact pour explorer le voisinage avant de se disperser et d'adhérer (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     et Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). La migration cellulaire a été précédée par l'accumulation polarisée de myosine-II à l'arrière de la cellule, conduisant à une migration cellulaire dans la direction opposée, entraînée par la contractilité de myosine-II postérieure. En outre, la direction de migration pouvait être rapidement modifiée en réponse à la redistribution dynamique de myosine-II à l'intérieur de la cellule (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Ces résultats démontrent que la cinétique de l'adhésion et de la migration cellulaire peut être fidèlement enregistrée par l'imagerie assistée par ZS-DeconvNet sans perturber ce processus long et vulnérable.
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     Visualisation de la dynamique rapide du système endolysosomial
    </title>
    <p id="Par11">
     Le système endolysosomal comprend divers types de vésicules qui fonctionnent de manière dynamique et bien organisée. Bien que l'imagerie de fluorescence en cellules vivantes ait considérablement amélioré notre compréhension du système endolysosomal, la plupart des études ont dû surexprimer les protéines d'intérêt pour enregistrer leur dynamique rapide, ce qui a souvent résulté en morphologies ou comportements artificiels. Avec ZS-DeconvNet, nous avons pu imager la lignée cellulaire SUM-159 édité par knock-in, exprimant de manière endogène EGFP-Rab11 et mCherry-Lamp1, pendant 1 500 images à une résolution d'environ 150 nm et 3 images par seconde en deux couleurs (Fig.
     <xref ref-type="fig" rid="Fig2">
      2e
     </xref>
     et Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM7">
      4
     </xref>
     ), ce qui nous a permis de visualiser et de suivre le mouvement rapide des endosomes de recyclage (RE) et des lysosomes ou des endosomes tardifs (LE) sur une échelle spatiotemporelle plus fine et une fenêtre d'observation plus longue que celles précédemment atteintes
     <sup>
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR34">
       34
      </xref>
     </sup>
     . Comme le montre la Fig.
     <xref ref-type="fig" rid="Fig2">
      2f–h
     </xref>
     , nous avons constaté que la majorité des RE (n = 505 trajectoires) ont subi un mouvement directionnel, avec un déplacement total de 6,7 ± 5,4 µm à une vitesse élevée de 2,2 ± 1,2 µm/s (vitesse instantanée dépassant 5,3 µm/s), avec une pause intermédiaire rare, puis s'est arrêtée à des sites spécifiques pendant une période de 13,5 ± 10,3 s avant de fusionner avec la membrane plasmique. Cette observation suggère que les RE pourraient être transportés de manière efficace sur de longues distances vers des régions proches de la membrane plasmique pour faciliter l'exocytose ultérieure. De manière inattendue, ZS-DeconvNet a capturé plusieurs événements de fission des RE positifs pour Rab11, dans lesquels les deux RE séparés ont subi une exocytose séquentielle (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      13a
     </xref>
     ) ou un RE s'est éloigné (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      13b
     </xref>
     ). Cette observation indique que les RE positifs pour Rab11 hautement spécialisés pourraient être soumis à un tri de cargaison supplémentaire juste avant l'exocytose.
    </p>
    <p id="Par12">
     En revanche, les mouvements des LE étaient généralement discontinus et se sont déroulés de manière bidirectionnelle, par à-coups, à une vitesse relativement lente de 1,6 ± 0,6 µm/s (n = 230 trajectoires) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2f, g, i
     </xref>
     ). Bien que le transport des LE ait semblé inefficace, les LE ont souvent persisté pendant une longue période de 91,8 s avec un déplacement total aussi long que 23,6 µm (moyenne de n = 230 trajectoires) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2h
     </xref>
     ). Intéressamment, nous avons remarqué que deux LE ou plus ont parfois tendance à s'accrocher les uns aux autres de manière « kiss-and-stay » et à migrer sur une certaine distance avant de se séparer à nouveau en LE individuels (Fig.
     <xref ref-type="fig" rid="Fig2">
      2i
     </xref>
     et Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      13c
     </xref>
     ), ce qui pourrait faciliter le mouvement directionnel des LE sans adaptateurs de protéines motrices suffisants pour le transport à longue distance. Ces dynamiques complexes des LE suggèrent que leur positionnement et leur mobilité sont délicatement régulés par de multiples facteurs, tels que les moteurs MT et les contacts de membrane.
    </p>
   </sec>
   <sec id="Sec6">
    <title>
     3D ZS-DeconvNet pour la microscopie à feuille de lumière lattice
    </title>
    <p id="Par13">
     L'imagerie à cellules vivantes en volume transmet plus d'informations biologiques que les observations 2D ; cependant, elle est soumise à une phototoxicité, une photoblanchiment et une contamination de fluorescence hors de focus beaucoup plus graves. Pour étendre la capacité supérieure de ZS-DeconvNet à l'imagerie SR en volume, nous avons amélioré l'architecture du réseau en dual-stage en 3D RCAN, qui a été démontré comme étant adapté pour la restauration d'images en volume (Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     et Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ). Ensuite, nous avons intégré notre schéma d'apprentissage auto-supervisé spatiallement intercalé précédemment proposé avec le solveur inverse auto-supervisé informé par modèle physique pour construire le 3D ZS-DeconvNet. Le 3D ZS-DeconvNet avec schéma auto-supervisé spatiallement intercalé suit une procédure d'augmentation de données plus simple (Méthodes), tout en atteignant des performances comparables ou même meilleures que la stratégie basée sur la recorruption (Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="fr">
       <title>
        Caractérisations et démonstrations de 3D ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        L'architecture du réseau de 3D ZS-DeconvNet et le schéma de sa phase d'entraînement.
        <bold>
         b
        </bold>
        Le schéma de la phase d'inférence de 3D ZS-DeconvNet.
        <bold>
         c
        </bold>
        Images SR de projection d'intensité maximale (MIP) représentatives de F-actine, de la membrane externe de Mito et de l'ER reconstruites par déconvolution éparse (deuxième colonne), 3D ZS-DeconvNet (troisième colonne) et LLS-SIM (quatrième colonne). Les comptes sCMOS moyens des 1% de pixels les plus élevés pour les images raw avant traitement sont étiquetés en haut à droite.
        <bold>
         d
        </bold>
        Comparaisons statistiques de la déconvolution RL, de la déconvolution éparse et de ZS-DeconvNet en termes de PSNR et de résolution sur différents spécimens (
        <italic>
         n
        </italic>
        = 40 régions d'intérêt). La résolution a été mesurée par analyse de corrélation de ring de Fourier
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        avec des piles d'images de F-actine. Ligne centrale, médianes ; limites, 75% et 25% ; moustaches, maximum et minimum. Les données sources sont fournies sous forme de fichier de données source.
        <bold>
         e
        </bold>
        Images 3D de rendu temporel reconstruites via 3D ZS-DeconvNet de l'ER, de H2B et de Mito, montrant leurs transformations en morphologie et en distribution ainsi que la dynamique d'interaction pendant la mitose (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ).
        <bold>
         f
        </bold>
        Images à trois couleurs représentatives obtenues avec LLSM conventionnel (première colonne), déconvolution éparse (deuxième colonne), déconvolution basée sur DeepCAD (troisième colonne) (Méthodes) et 3D ZS-DeconvNet (quatrième colonne). Les comparaisons sont effectuées sur deux points temporels typiques des données de rendu temporel montrées en (
        <bold>
         e
        </bold>
        ). Barre d'échelle, 5 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         e
        </bold>
        ,
        <bold>
         f
        </bold>
        ), 1,5 μm (régions de zoom de
        <bold>
         c
        </bold>
        ), 2 μm (régions de zoom de
        <bold>
         f
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     Nous avons évalué systématiquement le modèle 3D ZS-DeconvNet avec des jeux de données de trois spécimens biologiques différents acquis via notre microscope à illumination structurale à feuille de lumière à lattice (LLS-SIM) maison, dans lequel les données à limite de diffraction acquises par le mode de microscopie à feuille de lumière à lattice (LLSM) ont été utilisées pour l'entraînement, tandis que les contreparties SR acquises par le mode LLS-SIM ont servi de références (Méthodes). Nous avons constaté que le 3D ZS-DeconvNet a réussi à reconstruire les filaments élaborés de F-actine, la structure creuse de la membrane externe mitochondriale (Mito) et les réseaux complexes du réticulum endoplasmique (ER) avec une grande fidélité et une résolution comparable aux images LLS-SIM acquises dans des conditions de haute SNR (Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ). Les quantifications du PSNR et de la résolution illustrent que le modèle 3D ZS-DeconvNet surpasse de manière significative les approches basées sur des modèles analytiques conventionnels dans divers spécimens biologiques (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ). Nous démontrons que, en s'entraînant avec les piles d'images bruyantes elles-mêmes, le 3D ZS-DeconvNet à double étape ne génère pas seulement des résultats débruités comparables aux techniques de débruitage auto-supervisées de pointe (Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ), mais fournit également des piles d'images super-résolues avec une amélioration significative de la résolution d'environ 1,5 fois à la fois latéralement (Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ) et axialement (Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ). De plus, en intégrant séquentiellement des méthodes d'amélioration de la résolution axiale basées sur l'apprentissage auto-supervisé, la résolution axiale peut être améliorée davantage (Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     Imagerie à super-résolution volumétrique à long terme ermöglichte par 3D ZS-DeconvNet
    </title>
    <p id="Par15">
     L'observation en volume de la division cellulaire à haute résolution spatio-temporelle est d'une importance vitale pour explorer les mécanismes biologiques liés à la mitose, tels que le mécanisme qui alloue les nombreuses organites distinctes dans le cytoplasme à chaque cellule fille
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
      ,
      <xref ref-type="bibr" rid="CR42">
       42
      </xref>
     </sup>
     . En raison de la sensibilité extrême à la lumière et de la vulnérabilité des cellules en mitose, les précédentes imageries SR en volume de ce processus ont reposé sur le système LLS-SIM à faible lumière et la reconstruction SR basée sur l'apprentissage supervisé
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     . Cependant, la collecte de données d'entraînement de haute qualité est extrêmement laborieuse et parfois impraticable, car la morphologie et la distribution des organites subissent généralement des changements dramatiques au cours de la mitose
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
     </sup>
     . Ici, nous démontrons que le modèle 3D ZS-DeconvNet auto-supervisé peut être généralement appliqué pour super-résoudre les structures sous-cellulaires fines de l'ER, du Mito et des chromosomes à partir de volumes LLSM bruyants sans nécessiter de données d'entraînement supplémentaires, permettant ainsi une observation SR en volume rapide et à long terme de plusieurs organites pour 1 000 points de temps à des intervalles de 10 secondes dans une cellule HeLa en mitose (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e
     </xref>
     et Vidéo supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM8">
      5
     </xref>
     ). De plus, la propriété auto-supervisée de ZS-DeconvNet nous permet d'intégrer une stratégie d'adaptation d'apprentissage au moment du test pour exploiter pleinement le contenu structurel de chaque volume bruyant, ce qui a donné les meilleures performances SR 3D (Méthodes). En revanche, l'algorithme de déconvolution classique basé sur des priorités et la méthode d'apprentissage auto-supervisé intercalé dans le temps ont tous deux échoué à restaurer les détails à haute fréquence des spécimens en raison de la faible condition de SNR et de la faible cohérence temporelle entre les points de temps adjacents (Fig.
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     et Méthodes). De plus, selon la faible invasivité fournie par le 3D ZS-DeconvNet, un groupe de cellules HeLa en mitose marquées de H2B-mCherry et HeLa-mEmerald-SC35 ont été imaged dans un grand champ de vision (FOV) de 100×50×25 μm pour plus de 300 points de temps, enregistrant ainsi l'ensemble des processus de désassemblage et de réassemblage des speckles nucléaires à une résolution spatio-temporelle élevée (Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     et Vidéo supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM9">
      6
     </xref>
     ). En bref, le 3D ZS-DeconvNet permet aux biologistes d'explorer facilement divers processus biologiques sensibles à la lumière avec une faible invasivité à une résolution spatio-temporelle nettement supérieure sans nécessiter de jeux de données ou de modifications de configuration optique supplémentaires
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      ,
      <xref ref-type="bibr" rid="CR44">
       44
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet pour la microscopie confocale et à champ large
    </title>
    <p id="Par16">
     Le ZS-DeconvNet repose sur l'aléatoire des bruits et le caractère de filtre passe-bas des microscopes optiques, qui sont courants pour divers types de modalités de microscopie. Sur cette base, nous attendons que le ZS-DeconvNet puisse être généralement appliqué à tous les microscopes, par exemple, les microscopes à balayage les plus couramment utilisés et la microscopie à champ large (WF). Pour étudier les performances du 3D ZS-DeconvNet sur les données de confocal, nous avons utilisé notre microscope à confocal maison pour acquérir un volume à quatre couleurs de l'embryon de souris précoce immunomarqué pour le microtubule, les chromosomes, l'actine et le domaine apical (Méthodes), qui jouent des rôles clés dans la première décision de destin cellulaire et sont critiques pour le développement de l'embryon
     <sup>
      <xref ref-type="bibr" rid="CR45">
       45
      </xref>
      ,
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
      ,
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
     </sup>
     . Nous avons ensuite entraîné des modèles 3D ZS-DeconvNet sur ce seul volume bruyant et traité les données originales avec les modèles entraînés. Comme le montrent les Figs.
     <xref ref-type="fig" rid="Fig4">
      4a, b
     </xref>
     , le 3D ZS-DeconvNet améliore de manière significative le SNR, le contraste et la résolution du volume de données de confocal et résout les structures fines des ponts de microtubules et des anneaux d'actine (Fig.
     <xref ref-type="fig" rid="Fig4">
      4c, d
     </xref>
     , Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      19
     </xref>
     et Vidéo supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM10">
      7
     </xref>
     ). Ces résultats indiquent que le ZS-DeconvNet permet une résolution spatiale plus élevée à un budget de photons plus faible pour la microscopie à confocal dans l'imagerie d'échantillons à grande échelle, par exemple, les embryons de souris précoces, ce qui est critique pour la recherche sur la polarité cellulaire, le transport intracellulaire et la formation de blastocyste
     <sup>
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
     </sup>
     .
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="fr">
       <title>
        Généralisation de ZS-DeconvNet à plusieurs modalités d'imagerie.
       </title>
       <p>
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        Images représentatives de confocal (en haut à gauche), de déconvolution éparse (en bas à gauche) et de 3D ZS-DeconvNet améliorées (à droite) d'un embryon de souris précoce immunomarqué pour la microtubule (cyan), les chromosomes (orange), les anneaux d'actine (magenta) et le domaine apical (vert).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Régions agrandies des ponts de microtubules (c) et des anneaux d'actine (d) étiquetés avec des boîtes à traits blancs en (
        <bold>
         a
        </bold>
        ) et (
        <bold>
         b
        </bold>
        ) acquises via la microscopie confocale, la déconvolution éparse et 3D ZS-DeconvNet.
        <bold>
         e
        </bold>
        Images représentatives de WF (région centrale) et de 3D ZS-DeconvNet améliorées (région environnante) d'un embryon de
        <italic>
         C. elegans
        </italic>
        avec jonction apicale, membrane cellulaire (cyan) et lysosomes (rouge) étiquetés.
        <bold>
         f
        </bold>
        ,
        <bold>
         g
        </bold>
        Canal de lysosome de la région centrale en (
        <bold>
         e
        </bold>
        ) codé en couleur pour la distance par rapport au substrat. Les images WF (
        <bold>
         f
        </bold>
        ) et les images traitées 3D ZS-DeconvNet (
        <bold>
         g
        </bold>
        ) sont montrées pour comparaison.
        <bold>
         h
        </bold>
        Images de rendu temporel améliorées 3D ZS-DeconvNet montrant le processus de fusion cellulaire hypodermique (flèches rouges) pendant le développement d'un embryon de
        <italic>
         C. elegans
        </italic>
        . Barre d'échelle, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        ,
        <bold>
         e
        </bold>
        ), 2 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 3 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         h
        </bold>
        ), 1 μm (région de zoom de
        <bold>
         g
        </bold>
        ). Valeur gamma, 0,7 pour la cytomembrane et les lysosomes dans l'embryon de
        <italic>
         C. elegans
        </italic>
        .
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17">
     Nous avons ensuite imprimé des embryons de Caenorhabditis elegans avec des jonctions apicales, des membranes cellulaires et des lysosomes marqués en utilisant le mode 3D WF de notre système Multi-SIM (Méthodes). Pour nous assurer que le développement de l'embryon de
     <italic>
      C. elegans
     </italic>
     n'était pas perturbé, nous avons acquis des piles d'images raw à une excitation lumineuse relativement faible à des intervalles de 30 secondes pour plus de 200 points de temps. Cependant, dans de telles conditions, les images WF sont fortement contaminées par un bruit de fond hors de focus et un bruit (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, f
     </xref>
     ). Même dans cette situation difficile, les images 3D ZS-DeconvNet ont présenté une suppression considérable du bruit et du bruit de fond tout en améliorant la résolution spatiale des détails sous-cellulaires (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, g
     </xref>
     et Vidéo supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM11">
      8
     </xref>
     ), permettant ainsi d'étudier le processus élaboré du développement embryonnaire, par exemple, la fusion des cellules hypodermiques (Fig.
     <xref ref-type="fig" rid="Fig4">
      4h
     </xref>
     ), même via un simple microscope à champ large
     <sup>
      <xref ref-type="bibr" rid="CR48">
       48
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     Dénodification et amélioration de la résolution en images SIM multimodales
    </title>
    <p id="Par18">
     Parmi les différentes formes de microscopie SR, la microscopie à illumination structurée (SIM) est souvent reconnue comme une option équilibrée pour la microscopie à cellules vivantes SR car elle nécessite moins de dix images raw modulées pour fournir une amélioration twofold de la résolution spatiale
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     . Cependant, la SIM conventionnelle a deux limitations critiques : premièrement, une amélioration supplémentaire de la résolution nécessite considérablement plus de données raw, c'est-à-dire qu'au moins 25 images raw sont nécessaires pour la SIM non linéaire pour obtenir une résolution sub-80 nm ; deuxièmement, la postreconstruction des images SIM nécessite généralement des images raw avec un SNR élevé pour éliminer les artefacts de reconstruction induits par le bruit, ce qui gêne ainsi la microscopie à cellules vivantes rapide, à faible lumière et à long terme
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     . Des études récentes ont exploré des approches d'apprentissage supervisé en débruitant les images SIM ou en reconstruisant directement des images SR SIM à partir d'images raw bruyantes pour atteindre une reconstruction SIM à faible lumière ; cependant, ces méthodes nécessitent des données d'entraînement abondantes et n'améliorent pas davantage la résolution. Compte tenu de la capacité de débruitage et de SR superb de ZS-DeconvNet, nous avons intégré le schéma d'apprentissage zero-shot avec l'algorithme de reconstruction SIM conventionnel, et avons théoriquement prouvé que ZS-DeconvNet est adapté pour traiter les images SR-SIM (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Nous avons conçu le modèle ZS-DeconvNet amélioré SIM (ZS-DeconvNet-SIM) pour débruirer et affiner simultanément les images SR SIM de manière non supervisée (Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     , et Methods). En recourant à l'amélioration remarquable du SNR et de la résolution fournie par ZS-DeconvNet-SIM (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ), la structure creuse des pits revêtus de clathrine (CCPs) dans une cellule SUM-159 et les cytosquelettes densement entrelacés dans une cellule COS-7, qui sont indiscernables dans les images WF et SIM conventionnelles, ont été clairement résolus (Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ). De plus, nous avons démontré que ZS-DeconvNet-SIM peut être appliqué en modalité 3D-SIM pour débruirer et affiner simultanément les images 3D-SIM dans les deux axes latéraux et axiaux (Methods, Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     .
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="fr">
       <title>
        Dénodage et amélioration de résolution sans supervision dans les données SIM multimodales.
       </title>
       <p>
        <bold>
         a
        </bold>
        Schéma de la procédure d'entraînement de ZS-DeconvNet pour SIM.
        <bold>
         b
        </bold>
        Progression de l'amélioration du SNR et de la résolution à travers les CCP dans une cellule SUM-159, à partir d'images SIM raw (gauche), d'images SIM conventionnelles (droite) et d'images SIM améliorées par ZS-DeconvNet (milieu).
        <bold>
         c
        </bold>
        Progression de l'amélioration du SNR et de la résolution à travers les microtubules dans une cellule COS-7, à partir d'images SIM raw (gauche), d'images SIM conventionnelles (droite) et d'images SIM améliorées par ZS-DeconvNet (milieu).
        <bold>
         d
        </bold>
        Images MIP représentatives de F-actine dans une cellule HeLa obtenues via LLSM, LLS-SIM et LLS-SIM amélioré par 3D ZS-DeconvNet dans les trois dimensions.
        <bold>
         e
        </bold>
        , Images MIP représentatives de la membrane externe mitochondriale étiquetée avec TOMM20 dans une cellule 293 T obtenues via LLSM, LLS-SIM et LLS-SIM amélioré par 3D ZS-DeconvNet dans les trois dimensions. Barre d'échelle, 1 μm (
        <bold>
         a
        </bold>
        ), 2 μm (
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 0,5 μm (régions de zoom en
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 3 μm (
        <bold>
         d
        </bold>
        ,
        <bold>
         e
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig5_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par19">
     De plus, nous avons intégré 3D ZS-DeconvNet avec LLS-SIM pour développer la modalité 3D ZS-DeconvNet-SIM (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ). En incorporant la PSF anisotrope de la LLS-SIM conventionnelle dans le processus d'entraînement, 3D ZS-DeconvNet LLS-SIM n'améliore pas seulement la contraste et la résolution dans les trois dimensions, mais fournit également une résolution latérale approximativement isotrope de ~150 nm (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     , et Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ). Ces applications réussies de ZS-DeconvNet à des systèmes SIM multimodaux démontrent sa capacité à étendre davantage la bande passante de résolution spatiotemporelle des techniques SR existantes
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     .
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    Discussion
   </title>
   <p id="Par20">
    L'objectif ultime de l'imagerie en direct est de collecter le maximum d'informations spatiotemporelles sur les bioprocédés avec le minimum d'invasivité pour les spécimens biologiques. Cependant, les restrictions mutuelles entre la vitesse d'imagerie, la durée, la résolution et le SNR en microscopie à fluorescence résultent en une limitation de bande passante spatiotemporelle, qui limite l'amélioration synergique de tous ces aspects. Par exemple, pour obtenir une résolution spatiale plus élevée, les techniques SR conventionnelles doivent s'appuyer sur des acquisitions répétitives ou une excitation supplémentaire, ce qui aggrave la phototoxicité et la photoblanchiment, empêchant ainsi les observations rapides et à long terme des bioprocédés. Pour résoudre les limitations de bande passante spatiotemporelle en microscopie, nous avons effectué une analyse approfondie de la propagation du bruit dans le modèle d'imagerie optique et la reconstruction SIM (Supplementary Note
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ), prouvé la convergence de la fonction de perte auto-supervisée intégrée à la recorruption dans les scénarios ordinaires et SIM sur la base de la linéarité de la convolution PSF, et proposé le cadre ZS-DeconvNet polyvalent, qui peut être incorporé à divers microscopes à fluorescence optique pour améliorer instantanément le SNR et la résolution des images sans compromettre les autres propriétés d'imagerie. Nous soulignons que l'application de ZS-DeconvNet est robuste aux hyperparamètres du processus de recorruption d'images (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ) et que ZS-DeconvNet peut être bien entraîné avec une seule tranche ou pile d'images raw (Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ) sans utiliser des hypothèses de parcimonie structurale et de continuité temporelle
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    . Les évaluations qualitatives et quantitatives sur les données simulées et expérimentales montrent que nos méthodes améliorent considérablement la qualité et la résolution des images d'un facteur supérieur à 1,5 avec une grande fidélité et quantifiabilité même dans des conditions de faible lumière, permettant ainsi des observations à résolution supérieure rapides et à long terme de multiples dynamiques sous-cellulaires.
   </p>
   <p id="Par21">
    La méthode ZS-DeconvNet proposée a une fonctionnalité étendue pour divers types de modalités d'imagerie, des microscopies à balayage, par exemple la microscopie confocale et la microscopie à deux photons (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     25
    </xref>
    ), aux microscopies à détection à champ large, par exemple la microscopie TIRF, la microscopie 3D WF, la microscopie LLSM et la microscopie SIM multimodale. Nous démontrons ses capacités avec plus de 10 spécimens fixes ou vivants distincts imprimés via six ensembles de configuration de microscopie différents, notamment l'imagerie planaire et volumétrique de multiples organites dans des cellules uniques, l'observation de la dynamique et des interactions sous-cellulaires pendant la mitose cellulaire, et l'imagerie 3D multicolore des embryons de souris et des embryons de
    <italic>
     C. elegans
    </italic>
    . Pour rendre nos méthodes plus accessibles et plus pratiques, nous avons intégré ZS-DeconvNet et 3D ZS-DeconvNet dans un plugin Fiji convivial (Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     26
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     27
    </xref>
    , Supplementary Notes
    <xref ref-type="supplementary-material" rid="MOESM1">
     3
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     4
    </xref>
    , et Supplementary Video
    <xref ref-type="supplementary-material" rid="MOESM12">
     9
    </xref>
    ), permettant aux utilisateurs, même sans expérience en apprentissage profond, de former facilement leurs propres modèles ZS-DeconvNet et d'améliorer les images de microscopie ouvertes dans Fiji en quelques clics de souris. La fonctionnalité et la commodité de ZS-DeconvNet démontrent son grand potentiel pour améliorer les performances de la microscopie optique existante.
   </p>
   <p id="Par22">
    Malgré sa robustesse et son applicabilité générales, les utilisateurs de ZS-DeconvNet doivent considérer soigneusement l'apparition potentielle d'hallucinations et ses limites. Premièrement, ZS-DeconvNet peut confondre des signaux de fluorescence extrêmement faibles avec du bruit photonique, affaiblissant ainsi ces signaux dans les images de sortie (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     28a
    </xref>
    ). Ce type d'erreurs pourrait être détecté dans une certaine mesure via des outils de contrôle de la qualité d'image tels que SQUIRREL
    <sup>
     <xref ref-type="bibr" rid="CR54">
      54
     </xref>
    </sup>
    . Deuxièmement, si un modèle ZS-DeconvNet bien entraîné est appliqué au traitement d'images significativement différentes des données d'entraînement, par exemple acquises avec une modalité d'imagerie différente, il peut y avoir une dégradation notable des performances et un risque plus élevé de génération d'hallucinations (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     28b
    </xref>
    ). Troisièmement, les modèles ZS-DeconvNet doivent être entraînés en utilisant des PSF correspondant aux données, sinon un entraînement inapproprié avec des PSF non correspondants peut aboutir à une amélioration de résolution peu notable ou à des artefacts de ring
    <sup>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
    </sup>
    (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     28c
    </xref>
    ). Enfin, nous n'attendons pas que le ZS-DeconvNet non supervisé génère des images SR aussi bonnes que les modèles DLSR supervisés entraînés avec un jeu de données de haute qualité (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     11
    </xref>
    ). Cependant, dans les expériences d'imagerie où un tel jeu de données n'est pas disponible, ZS-DeconvNet sera un outil puissant et pratique pour résoudre les détails biologiques aussi fins que possible.
   </p>
   <p id="Par23"/>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    Méthodes
   </title>
   <sec id="Sec12">
    <title>
     Système Multi-SIM
    </title>
    <p id="Par24"/>
   </sec>
   <sec id="Sec13">
    <title>
     Système LLS-SIM
    </title>
    <p id="Par25"/>
   </sec>
   <sec id="Sec14">
    <title>
     Système confocal
    </title>
    <p id="Par26"/>
   </sec>
   <sec id="Sec15">
    <title>
     Architectures et fonctions objectives de ZS-DeconvNet
    </title>
    <p id="Par27"/>
    <p id="Par28"/>
    <p id="Par29">
     Il est important de noter que puisque la base théorique de ZS-DeconvNet est agnostique au modèle, les deux U-Net et RCAN ne sont pas les seuls modèles de réseau de neurones applicables, mais plutôt les modèles les plus largement adoptés et efficaces. Équiper ZS-DeconvNet d'autres architectures de réseau de neurones d'état de l'art, par exemple DFCAN et RLN, peut améliorer davantage ses capacités de débruitage et de SR
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     Mise en œuvre de 2D ZS-DeconvNet
    </title>
    <p id="Par30">
     Les paires d'images
     <inline-formula id="IEq21">
      <alternatives>
       <math id="IEq21_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq21_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq21.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     utilisées pour l'entraînement des modèles 2D ZS-DeconvNet ont été générées en suivant un schéma modifié de la stratégie de recorruption originale sous l'hypothèse de distributions de bruit mixte de Poisson-Gauss, où trois hyperparamètres
     <inline-formula id="IEq22">
      <alternatives>
       <math id="IEq22_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq22_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq22.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq23">
      <alternatives>
       <math id="IEq23_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq23_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq23.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq24">
      <alternatives>
       <math id="IEq24_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq24_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq24.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     devaient être prédéterminés. La procédure de recorruption à partir d'une seule image bruyante
     <italic>
      y
     </italic>
     peut être représentée sous forme matricielle comme :
     <disp-formula id="Equ9">
      <label>
       9
      </label>
      <alternatives>
       <math id="Equ9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̂
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         +
        </mo>
        <mi>
         D
        </mi>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ9_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}+D{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ10">
      <label>
       10
      </label>
      <alternatives>
       <math id="Equ10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mo>
          ̃
         </mo>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         −
        </mo>
        <msup>
         <mrow>
          <mi>
           D
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           1
          </mi>
         </mrow>
        </msup>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ10_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}-{D}^{-{{{{{\bf{1}}}}}}}{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     où
     <inline-formula id="IEq25">
      <alternatives>
       <math id="IEq25_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
        <mo>
         =
        </mo>
        <mi>
         α
        </mi>
        <mi>
         I
        </mi>
       </math>
       <tex-math id="IEq25_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\alpha I$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq25.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est une matrice inversible définie comme une matrice d'unité agrandie par un facteur de
     <inline-formula id="IEq26">
      <alternatives>
       <math id="IEq26_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         α
        </mi>
       </math>
       <tex-math id="IEq26_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq26.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , qui contrôle la grandeur globale des bruits ajoutés, et
     <inline-formula id="IEq27">
      <alternatives>
       <math id="IEq27_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="IEq27_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq27.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est une carte de bruit aléatoire échantillonnée à partir d'une distribution gaussienne de moyenne nulle :
     <disp-formula id="Equ11">
      <label>
       11
      </label>
      <alternatives>
       <math id="Equ11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
        <mo>
         ~
        </mo>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         N
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           0
          </mn>
          <mo>
           ,
          </mo>
          <msup>
           <mrow>
            <mi>
             σ
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mi>
           I
          </mi>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ11_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}} \sim {{{{{\mathcal{N}}}}}}\left(0,{\sigma }^{2}I\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ12">
      <label>
       12
      </label>
      <alternatives>
       <math id="Equ12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msup>
         <mrow>
          <mi>
           σ
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msup>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
        <mi>
         H
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="Equ12_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }^{2}={\beta }_{1}H\left({{{{{\bf{y}}}}}}-{{{{{\bf{b}}}}}}\right)+{\beta }_{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     où
     <inline-formula id="IEq28">
      <alternatives>
       <math id="IEq28_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq28_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq28.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est le facteur de Poisson qui affecte la variance du bruit de tir aléatoire dépendant du signal, et
     <inline-formula id="IEq29">
      <alternatives>
       <math id="IEq29_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq29_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq29.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est le facteur gaussien qui représente la variance des bruits gaussiens additifs.
     <inline-formula id="IEq30">
      <alternatives>
       <math id="IEq30_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         b
        </mi>
       </math>
       <tex-math id="IEq30_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{b}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq30.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est le fond, approximativement considéré comme une valeur fixe liée à l'appareil photo, en soustrayant laquelle nous avons extrait les signaux de fluorescence de l'échantillon.
     <inline-formula id="IEq31">
      <alternatives>
       <math id="IEq31_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         H
        </mi>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq31_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq31.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est un filtre passe-bas linéaire utilisé pour lisser préliminairement l'image et réduire le bruit, et nous avons adopté un filtre de moyenne avec une taille de 5 pixels dans nos expériences
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     .
    </p>
    <p id="Par31">
     Comme le prouve la Note supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     , la valeur théoriquement optimale de
     <inline-formula id="IEq32">
      <alternatives>
       <math id="IEq32_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq32_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq32.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     et
     <inline-formula id="IEq33">
      <alternatives>
       <math id="IEq33_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq33_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq33.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     est 1, tandis que
     <inline-formula id="IEq34">
      <alternatives>
       <math id="IEq34_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq34_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq34.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     dépend de l'appareil photo et peut être estimé à partir de la région sans échantillon de l'image elle-même ou pré-étalonné en suivant les protocoles standard
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
     </sup>
     . Les évaluations sur les données simulées ont montré que les meilleures performances de débruitage et de SR sont obtenues aux valeurs théoriquement optimales de ces hyperparamètres, quelle que soit la structure et le rapport signal/bruit des images de test (Figures supplémentaires
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ).
    </p>
   </sec>
   <sec id="Sec17">
    <title>
     Mise en œuvre de 3D ZS-DeconvNet
    </title>
    <p id="Par32">
     Le schéma d'entraînement de 3D ZS-DeconvNet intègre le schéma d'auto-apprentissage auto-intercalé avec le solveur de problème inverse auto-supervisé. Dans le processus d'entraînement, chaque pile d'images bruyantes a été divisée en tranches impaires et paires, qui ont ensuite été utilisées comme entrée et cibles, respectivement, après augmentation par rotation aléatoire, recadrage et retournement. Pour modifier l'écart d'attente entre les tranches impaires et paires, nous avons introduit le terme de régularisation de correction d'écart (GAR) dans les pertes de débruitage et de déconvolution, qui a été calculé avec la pile débruitée (étiquetée avec la boîte rouge dans Fig.
     <xref ref-type="fig" rid="Fig3">
      3a
     </xref>
     ), les tranches paires bruyantes et les sorties du réseau (détail dans la Note supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec18">
    <title>
     Mise en œuvre de 2D/3D ZS-DeconvNet-SIM
    </title>
    <p id="Par33">
     Pour les implémentations de ZS-DeconvNet-SIM sur 2D-SIM et 3D-SIM, chaque ensemble d'images raw SIM a été augmenté en deux ensembles d'images raw recorrompues via l'équation 9 et 10, et reconstruites en une paire d'images SIM SR via l'algorithme de reconstruction SIM conventionnel. Les paires d'images SIM générées ont ensuite été utilisées pour l'entraînement auto-supervisé d'une manière similaire à l'entraînement des modèles ZS-DeconvNet. Pour 3D ZS-DeconvNet-SIM appliqué sur LLS-SIM (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     ), les données de simulation volumétrique post-reconstruites au lieu des images raw ont été échantillonnées axialement en deux piles SIM contenant respectivement des tranches impaires et paires, qui ont été utilisées dans les procédures d'entraînement ultérieures des modèles 3D ZS-DeconvNet avec des fonctions de perte décrites dans l'équation 6-8. Le flux de travail schématique de ZS-DeconvNet-SIM est montré dans Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     et Figure supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      20
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec19">
    <title>
     Utilisation et génération de PSF
    </title>
    <p id="Par34">
     Dans la procédure d'entraînement de ZS-DeconvNet, nous avons utilisé des PSF acquis expérimentalement ou simulés (avec le plugin PSF Generator Fiji licencié par EPFL) qui correspondent aux configurations d'imagerie. Des modèles ZS-DeconvNet indépendants ont été entraînés pour chaque structure biologique et chaque longueur d'onde d'émission pour une performance optimale.
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     Entraînement de modèle et adaptation au moment du test
    </title>
    <p id="Par35">
     Dans ce travail, les modèles ZS-DeconvNet ont été entraînés sur un PC avec un processeur Intel Core i7-11700 et une carte graphique RTX 3090 (NVIDIA) dans l'environnement logiciel de TensorFlow 2.5.0 et python 3.9.7. Avant l'entraînement, les images d'entrée/GT appariées ont été augmentées en plusieurs paires de patches via un recadrage aléatoire, un flip horizontal/vertical et une transformation de rotation pour enrichir davantage le jeu de données d'entraînement, ce qui a finalement généré ~20 000 paires de patches 2D (128
     <inline-formula id="IEq35">
      <alternatives>
       <math id="IEq35_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq35_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq35.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     128 pixels) ou ~10 000 paires de patches 3D (64
     <inline-formula id="IEq36">
      <alternatives>
       <math id="IEq36_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq36_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq36.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     64
     <inline-formula id="IEq37">
      <alternatives>
       <math id="IEq37_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq37_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq37.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     13 voxels). L'entraînement a été effectué avec l'optimiseur Adam et un taux d'apprentissage initial de
     <inline-formula id="IEq38">
      <alternatives>
       <math id="IEq38_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mn>
         0.5
        </mn>
        <mo>
         ×
        </mo>
        <msup>
         <mrow>
          <mn>
           10
          </mn>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           4
          </mn>
         </mrow>
        </msup>
       </math>
       <tex-math id="IEq38_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times {10}^{-4}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq38.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , qui diminuait d'un facteur de 0,5 tous les 10 000 itérations. La taille du lot d'entraînement était de 4 pour les images 2D et de 3 pour les piles 3D. Le processus d'entraînement complet a nécessité 50 000 itérations pour les images 2D et 10 000 itérations pour les piles 3D. Le temps écoulé pour l'entraînement de 50 000 itérations pour les modèles 2D et de 10 000 itérations pour les modèles 3D était d'environ 1 heure et 2 heures, respectivement. Comme c'est souvent le cas avec la plupart des méthodes basées sur l'apprentissage profond, l'entraînement de ZS-DeconvNet est une procédure unique dans la plupart des cas d'imagerie en direct, où les utilisateurs entraînent le modèle ZS-DeconvNet avec toutes les trames, puis les modèles bien entraînés sont applicables à toutes les données du même spécimen biologique à une vitesse de traitement élevée. Pour éliminer les artefacts de bord induits par la déconvolution, nous avons généralement ajouté 2 tranches vides au sommet et au bas des piles 3D et une marge de 8 pixels pour chaque tranche xy dans les processus d'entraînement et d'inférence (Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      30a
     </xref>
     ). En particulier, lors du traitement des données de time-lapsing de la mitose cellulaire (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     ), la propriété non supervisée de ZS-DeconvNet a permis une stratégie d'adaptation en temps de test dans laquelle nous avons d'abord entraîné un modèle général pour chaque structure biologique avec des données de l'ensemble du processus, puis affiné le modèle pré-entraîné pour chaque point de temps avec un petit nombre d'étapes d'entraînement (généralement 50 itérations prenant ~1 minute) pour exploiter pleinement les informations structurelles des données brutes et obtenir la performance SR optimale. Il est à noter que l'adaptation en temps de test n'est pas nécessaire, mais une technique optionnelle pour améliorer la performance de ZS-DeconvNet, en particulier dans les circonstances où il y a de grands changements morphologiques sur les spécimens biologiques pendant la fenêtre d'observation, par exemple, les chromosomes pendant la mitose (Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      31
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     Post-traitement des données et évaluation des images à super-résolution
    </title>
    <p id="Par36">
     Pour les modalités d'imagerie utilisant la détection à champ large, telles que LLSM, le bruit de motif fixe (FPN) qui est induit par la non-uniformité de la sensibilité des pixels de la caméra ne peut pas être supprimé par les schémas basés sur noise2noise
     <sup>
      <xref ref-type="bibr" rid="CR62">
       62
      </xref>
     </sup>
     . Dans notre implémentation de ZS-DeconvNet, le FPN serait renforcé dans la phase de déconvolution et deviendrait non négligeable, en particulier dans des conditions d'imagerie à SNR extrêmement faible. Pour les capteurs sCMOS, qui sont les plus couramment utilisés en microscopie à fluorescence, le motif fixe présente généralement une apparence régulière de bandes horizontales ou verticales attribuée à l'amplificateur de colonne. À cette fin, nous avons simplement appliqué un masque d'apodisation dans le domaine de Fourier pour supprimer les artefacts striés tout en préservant les autres composantes fréquentielles des échantillons (Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      30b
     </xref>
     ). Il est à noter que le bruit de motif fixe peut également être fondamentalement supprimé par une étalonnage préalable des images brutes acquises avant de les envoyer dans le modèle de réseau suivant les procédures bien établies
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
      ,
      <xref ref-type="bibr" rid="CR63">
       63
      </xref>
      ,
      <xref ref-type="bibr" rid="CR64">
       64
      </xref>
     </sup>
     .
    </p>
    <p id="Par37">
     Les autres approches de SR computationnelles comparées dans ce travail, à savoir la déconvolution sparse, la déconvolution basée sur DeepCAD et SRRF, sont mises en œuvre suivant les instructions des articles originaux. Plus précisément, nous avons essayé de sélectionner les hyperparamètres optimaux pour la déconvolution sparse pour obtenir une image reconstruite avec le moins d'artefacts et la résolution la plus élevée. Et la déconvolution basée sur DeepCAD (Fig.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a et
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     ) a été effectuée en intégrant le schéma d'échantillonnage temporel dans notre cadre ZS-DeconvNet, c'est-à-dire en utilisant des images échantillonnées temporellement à partir des données de time-lapsing pour l'entraînement de nos modèles de réseau à deux étages, en garantissant la même taille de modèle et le même coût computationnel pour une comparaison équitable
     <sup>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      <xref ref-type="bibr" rid="CR13">
       13
      </xref>
     </sup>
     .
    </p>
    <p id="Par38"/>
    <p id="Par39">
     La transformation linéaire est appliquée à toutes les méthodes pour une comparaison équitable ; (3) Calcul de la PSNR entre l'image GT normalisée
     <bold>
      x
     </bold>
     et l'image transformée linéairement
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     .
    </p>
    <p id="Par40">
     Pour l'évaluation de la PSNR de 3D ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ), nous avons directement utilisé les images LLS-SIM comme référence, car les deux LLS-SIM et notre 3D ZS-DeconvNet ont fourni une amélioration de résolution d'environ 1,5 fois théoriquement. Le processus de calcul global est similaire aux cas 2D, à l'exception que les piles SR n'ont pas été convoluées et que la PSNR n'a été calculée que dans les régions de fonctionnalité uniquement avec un seuil de 0,02 pour éviter d'obtenir une valeur anormalement élevée de PSNR.
    </p>
    <p id="Par41">
     Pour fournir un meilleur contraste et une meilleure visualisation, nous avons effectué une normalisation par percentile pour les images de déconvolution générées par la déconvolution RL, la déconvolution sparse et ZS-DeconvNet, qui est formulée comme :
     <disp-formula id="Equ15">
      <label>
       15
      </label>
      <alternatives>
       <math id="Equ15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="normal">
           Norm
          </mi>
         </mrow>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             l
            </mi>
            <mi>
             o
            </mi>
            <mi>
             w
            </mi>
           </mrow>
          </msub>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             h
            </mi>
            <mi>
             i
            </mi>
            <mi>
             g
            </mi>
            <mi>
             h
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               h
              </mi>
              <mi>
               i
              </mi>
              <mi>
               g
              </mi>
              <mi>
               h
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
        <mo>
         ,
        </mo>
       </math>
       <tex-math id="Equ15_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{Norm}}}}}}}_{p}\left({{{{{\bf{Y}}}}}},{p}_{{low}},{p}_{{high}}\right)=\frac{{{{{{\bf{Y}}}}}}-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)}{{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{high}}\right)-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)},$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ15.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     où percentile(
     <bold>
      Y,
     </bold>
     <italic>
      p
     </italic>
     ) donne la valeur d'intensité classée
     <italic>
      p
     </italic>
     % dans l'image
     <bold>
      Y
     </bold>
     <sup/>
     .
     <inline-formula id="IEq40">
      <alternatives>
       <math id="IEq40_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           l
          </mi>
          <mi>
           o
          </mi>
          <mi>
           w
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq40_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{low}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq40.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     et
     <inline-formula id="IEq41">
      <alternatives>
       <math id="IEq41_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           h
          </mi>
          <mi>
           i
          </mi>
          <mi>
           g
          </mi>
          <mi>
           h
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq41_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{high}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq41.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     sont généralement définis comme 3 et 100 dans nos figures et vidéos.
    </p>
   </sec>
   <sec id="Sec22">
    <title>
     Culture cellulaire, transfection et coloration
    </title>
    <p id="Par42">
     Les cellules Cos7, HeLa, 293 T ainsi que leurs lignées cellulaires stables ont été cultivées dans du DMEM (Gibco, n° de cat. 11965092), supplémenté avec 10 % de sérum fœtal de bovin (Gibco, n° de cat. 10099141 C) et 1 × pénicilline-streptomycine (Thermo Fisher, 15140122) à 37 °C dans un incubateur CO
     <sub>
      2
     </sub>
     Heracell 150i de Thermo Scientific. Les cellules SUM159 ont été cultivées dans un milieu DMEM/F12K supplémenté avec 5 % de sérum fœtal de bovin (FBS) et 1 % de solution de pénicilline-streptomycine.
    </p>
    <p id="Par43">
     Pour l'imagerie de cellules vivantes, les couvercles en verre de 35 mm ont été pré-coatés avec 50 μg ml de collagène et 1 × 10 cellules ont été semées sur les couvercles. Pour la transfection transitoire, les cellules ont été transfectées avec des plasmides à l'aide de Lipofectamine 3000 (Invitrogen, n° de cat. L3000150) selon le protocole du fabricant 12 h après le repiquage. Les cellules ont été imagées 12 h après la transfection. Lorsqu'indiqué, les cellules transfectées avec des plasmides Halo Tag ont été marquées avec 10 nM de ligand JF549 pendant 15 min selon le protocole publié
     <sup>
      <xref ref-type="bibr" rid="CR65">
       65
      </xref>
     </sup>
     . Les cellules ont été rincées avec un milieu frais pour éliminer le ligand non lié et imagées immédiatement après. Les plasmides utilisés pour la transfection transitoire incluent Lifeact-mEmerald, Clathrin-mEmerald, 3 × mEmerald-Ensconsin, Lamp1-Halo, 2 × mEmerald-Tomm20, Myosin2-Halo, KDEL-mCherry et Halo-Calnexin.
    </p>
    <p id="Par44">
     Pour le conditionnement des lentiviruses, 1 μg d'ADN de vecteur de transfert lentiviral, ainsi que 0,5 μg de psPAX2 d'emballage et 0,5 μg de plasmide d'enveloppe pMD2.G, ont été co-transférés à des cellules HEK293T à 90 % de confluence dans une boîte de Petri de 6 cm en utilisant Lipofectamine 3000 suivant le protocole du fabricant. Après 2 jours, le surnageant a été récolté et filtré avec un filtre à 0,22 μm (Millipore). Pour la construction de cellules stables, des cellules HeLa et Cos7 ont été infectées avec des lentiviruses codant le marqueur du réticulum endoplasmique Calnexin-mEmerald et le marqueur F-actine Lifeact-mEmerald
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     . Quarante-huit heures après, les cellules ont été enrichies par cytomètre de flux (FACSAria III, BD Biosciences) et ensuite placées une cellule par puits dans des plaques de 96 puits, des cellules monoclonales ont été utilisées pour nos expériences. Plus précisément, Lifeact-mEmerald pour COS7 utilisé dans les Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     et
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     ; Calnexin-mEmerald, Mito-dsRed et Halo-H2B pour les cellules HeLa utilisées dans la Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ; H2B-mCherry pour HeLa-mEmerald-SC35 utilisé dans la Fig. supplémentaire
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     Lignées cellulaires éditées par le génome
    </title>
    <p id="Par45">
     Les cellules SUM159 ont été éditées génétiquement de manière séquentielle pour incorporer l'EGFP à l'extrémité N-terminale de Rab11A, puis Halo à l'extrémité C-terminale de Lamp1 en utilisant l'approche CRISPR/Cas9
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     . Les séquences cibles de l'ARN guide unique (sgRNA) sont 5'-TCGCTCCTCGGCCGCGCAAT-3' pour RAB11A et 5'-CTATCTAGCCTGGTGCACGC-3' pour LAMP1. Les cellules SUM159 ont été transfectées avec le plasmide donneur EGFP-Rab11A, le plasmide codant pour la spCas9 et le produit PCR libre contenant la séquence cible sgRNA en utilisant Lipofectamin 3000 (Invitrogen) suivant les instructions du fabricant. Les cellules exprimant l'EGFP ont été enrichies par tri de cellules à activation de fluorescence (FACS) (FACSAria II, BD Biosciences), et ensuite soumises à un tri de cellules uniques dans des plaques de 96 puits. Les cellules monoclonales avec incorporation réussie d'EGFP ont été identifiées par dépistage PCR en utilisant la polymérase GoTaq (Promega). Les cellules clonales SUM159 exprimant EGFP-Rab11A +/+ ont été soumises à un deuxième tour d'édition génétique pour incorporer Lamp1-Halo dans le génome comme décrit ci-dessus. Les cellules transfectées ont été teintes avec 10 nM de ligands HaloTag Janelia Fluor 646 (Promega) pendant 15 minutes. Pour éliminer le colorant non lié, les échantillons ont été rincés avec un milieu frais, puis enrichis par FACS. Les cellules monoclonales SUM159 exprimant à la fois EGFP-Rab11A +/+ et Lamp1-Halo +/+ ont été confirmées par analyse PCR et Western blot.
    </p>
    <p id="Par46">
     Les cellules SUM159 ont été éditées génétiquement pour incorporer l'EGFP à l'extrémité C-terminale de la chaîne légère de la clathrine A (clathrine-EGFP) en utilisant l'approche TALEN
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     . Les cellules exprimant la clathrine-EGFP ont été enrichies par deux séries de tri en vrac.
    </p>
    <p id="Par47">
     Les lignées cellulaires HeLa ont été éditées génétiquement pour incorporer le mEmerald à l'extrémité C-terminale du génome humain SC35 en utilisant le système d'édition génétique CRISPR-Cas9. La séquence cible de l'ARN guide unique (sgRNA) est 5'-CGAGCAGCACTCCTAATGAT-3', et l'ARN guide unique a été ligé au plasmide pX330A-1×2 (Addgene, 58766). Le plasmide résultant a été nommé pX330-SC35-gRNA. Pour construire le vecteur donneur p-SC35-doner, le mEmerald entouré d'environ 1800 pb d'ailes d'homologie complémentaires au codon stop du locus génomique humain SC35 a été ligé au plasmide pEASY-blunt (Transgene, CB101). 2 × 10 cellules HeLa cultivées dans une boîte de Petri de 6 cm ont été transfectées avec 1,2 μg de pX330-SC35-gRNA et 0,4 μg de p-SC35-doner. 48 heures post-transfection, les cellules positives pour le mEmerald ont été triées en utilisant FACS (FACSAria III, BD Biosciences). Après une semaine, les lentiviruses H2B-mCherry ont été infectés aux cellules triées, puis des cellules uniques ont été semées dans des plaques de 96 puits. Après deux semaines, l'ADN génomique de différents clones de cellules uniques a été extrait et validé par PCR et Western blot. Les cellules knock-in SC35 homozygotes ont été sélectionnées pour l'étude. Le knock-in SC35 réussi a été vérifié par analyse PCR et Western blot
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     Préparation de l'embryon de
     <italic>
      C. elegans
     </italic>
    </title>
    <p id="Par48">
     <italic>
      C. elegans
     </italic>
     a été cultivé à 20 °C sur des plaques de milieu de croissance des nématodes (NGM) ensemencées avec OP50 suivant les protocoles standard
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     . TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ;
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ;
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     a été utilisé dans cette étude. Le plasmide
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     a été construit suivant le système de clonage PCR In-Fusion de Clontech et micro-injecté à
     <italic>
      jcIs1;qxIs257
     </italic>
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     . L'array extrachromosomique
     <italic>
      wyEx51119
     </italic>
     a marqué la membrane cellulaire épidermique.
     <italic>
      jcIs1
     </italic>
     a marqué le domaine de jonction apicale de
     <italic>
      C. elegans
     </italic>
     .
     <italic>
      qxIs257
     </italic>
     a marqué les lysosomes dans les cellules épidermiques
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     .
    </p>
    <p id="Par49">
     Environ 50 vers transgéniques de stade L4 ont été placés sur des plaques NGM avec du OP50 frais 48 à 60 heures avant les expériences. Les œufs transgéniques ont été collectés sous un microscope fluorescent de dissection (Olympus MVX10) et montés sur des coussinets d'agarose à 3 %. Les embryons de stade Lima bean à 2 plis ont ensuite été imprimés à l'aide du mode 3D WF de notre système Multi-SIM.
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     Préparation de l'embryon de souris
    </title>
    <p id="Par50">
     Les souris utilisées dans cette étude étaient de souche C57BL/6 J. Toutes les expériences animales ont été approuvées par les comités de soins et d'utilisation des animaux (IACUC) de l'Institut de biophysique, Académie chinoise des sciences, Pékin, Chine. Les embryons pré-implantatoires ont été isolés de femelles âgées de 5-6 semaines, superovulées par injection intrapéritonéale de 5 unités internationales (UI) de sérum gonadotropique de jument enceinte (PMSG ; LEE BIOSOLUTIONS) et 5 UI de gonadotropine chorionique humaine (hCG ; Millipore) 48 heures plus tard, et accouplées avec des souris mâles. Les zygotes ont été récupérés à E0,5 dans un milieu M2 (Millipore) et cultivés dans un milieu KSOM (Millipore) dans un incubateur CO2 (Thermo Scientific) à 37 °C avec 5 % de CO2 jusqu'au stade 8-cellules tardif.
    </p>
    <p id="Par51">
     Pour l'immunofluorescence, les embryons ont été fixés avec du paraformaldéhyde à 4 % dans du PBS pendant 30 min à température ambiante (RT) et lavés avec du PBS trois fois. Les embryons ont ensuite été perméabilisés dans du TritonX-100 à 0,5 % (Sigma) dans du PBS pendant 20 min à RT, lavés dans du PBS trois fois, bloqués dans du sérum albumine bovine à 1 % dans du PBS pendant 1 heure à RT et incubés avec un anticorps anti-pERM (Abcam, ab76247), un anticorps anti-alpha-tubuline-FITC (Sigma, F2168-.2 ML) et de la phalloidine-rhodamine (Molecular Probes, R415) pendant la nuit à 4 °C. Ensuite, les embryons ont été lavés dans du PBS trois fois, incubés avec des anticorps secondaires (Life technologies) pendant 1 heure à RT, colorés avec du Hoescht 33342 (Thermo) pendant 15 min à RT, lavés dans du PBS trois fois et imprimés à l'aide du microscope confocal construit sur place.
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     Visualisation d'images 3D
    </title>
    <p id="Par52">
     Les images de lysosomes codées par couleur axiale présentées dans la Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     ont été générées avec Fiji. Les images de rendu 3D de la cellule de mitose et des embryons de souris présentées dans la Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     ont été visualisées et générées à l'aide du logiciel commercial Amira.
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     Statistiques et reproductibilité
    </title>
    <p id="Par53">
     Les expériences présentées dans les Fig.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i,
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f,
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     , et
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     ont été répétées de manière indépendante avec au moins 3 spécimens, c'est-à-dire des cellules ou des embryons, tous ayant obtenu des résultats similaires.
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     Résumé de rapport
    </title>
    <p id="Par54">
     Des informations supplémentaires sur la conception de la recherche sont disponibles dans le
     <xref ref-type="supplementary-material" rid="MOESM13">
      Résumé de la collection Nature Portfolio
     </xref>
     lié à cet article.
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Remerciements
   </title>
   <p>
    Les auteurs remercient T. Kirchhausen pour les plasmides donneurs utilisés pour l'édition du génome et pour avoir aidé à générer les lignées cellulaires éditées du génome, et remercient le professeur Xiaochen Wang et le Dr Kangmin He pour les souches de
    <italic>
     C. elegans
    </italic>
    et les lignées cellulaires éditées du génome SUM159. Ce travail a été soutenu par des subventions de la Fondation nationale des sciences naturelles de Chine (32125024, 32271513, 62071271 et 62088102) ; du Ministère des Sciences et de la Technologie (2021YFA1300303 et 2020AA0105500) ; de l'Académie chinoise des sciences (ZDBS-LY-SM004 et XDA16021401) ; du Fonds de recherche collaborative de l'Institut chinois pour la recherche sur le cerveau, Beijing (2021-NKX-XM-03) ; de la Fondation de la science postdoctorale de Chine (2022M721842, 2023T160365) ; de la Nouvelle fondation Cornerstone ; du programme de chercheurs Shuimu Tsinghua (2022SM035) ; de la Fondation naturelle de Beijing (JQ21012).
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Contributions des auteurs
   </title>
   <p>
    Q.D. et Dong Li ont supervisé la recherche. Q.D., Dong Li et C.Q. ont conçu et initié ce projet. C.Q. a conçu les implementations détaillées sous les instructions de Q.D. et Dong Li. Y.Z, C.Q. et X.C ont développé le code python, ont effectué des simulations et ont traité les données d'imagerie pertinentes. H.C., C.Q. et Y.Z. ont développé le plugin Fiji. T.J., R.W, C.Q, H.L., W.F., Di Li et J.G. ont préparé des échantillons et ont effectué des expériences d'imagerie. C.Q., Y.Z., X.C. et Q.M. ont analysé les données avec des conseils conceptuels de Q.D., Dong Li, J.W, Y.W. et H.Q. C.Q., Y.Z et Q.M. ont composé les figures et les vidéos, ont créé la page d'accueil du tutoriel sous la supervision de Q.D. et Dong Li. Q.D., Dong Li et C.Q. ont rédigé le manuscrit, avec des contributions de tous les auteurs. Tous les auteurs ont discuté des résultats et ont commenté le manuscrit.
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Évaluation par les pairs
   </title>
   <sec id="FPar1">
    <title>
     Information sur l'évaluation par les pairs
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilité des données
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilité du code
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Intérêts concurrents
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    Références
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      Informations supplémentaires
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      Données sources
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Informations supplémentaires
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
