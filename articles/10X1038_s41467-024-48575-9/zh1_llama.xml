<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/ProjectMundo/style/jats-html.xsl"?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     零样本学习实现光学荧光显微镜的即时去噪和超分辨率
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     摘要
    </title>
    <p id="Par1">
     计算超分辨率方法，包括传统的分析算法和深度学习模型，已经大大改进了光学显微镜。其中，监督深度神经网络已经展示了卓越的性能，但是需要大量高质量的训练数据，这些数据由于活细胞的高动态性而难以获取。这里，我们开发了零样本去卷积网络（ZS-DeconvNet），它可以即时提高显微镜图像的分辨率，超过衍射极限1.5倍，且比普通超分辨率成像条件的荧光强度低10倍，在无需地真实值或额外数据采集的情况下，以无监督的方式工作。我们展示了ZS-DeconvNet在多种成像模式下的多功能应用，包括全内反射荧光显微镜、三维宽场显微镜、共焦显微镜、两光子显微镜、格子光片显微镜和多模态结构照明显微镜，这使得从有丝分裂单细胞到小鼠和
     <italic>
      C. elegans
     </italic>
     多细胞胚胎的亚细胞生物过程可以进行多色、长期、超分辨率2D/3D成像。
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    介绍
   </title>
   <p id="Par3">
    光学荧光显微镜是生物研究的必备工具。最近的超分辨率（SR）技术的发展为可视化多种生物过程的精细动态结构提供了前所未有的分辨率。然而，通过任何SR方法获得的空间分辨率提高都伴随着其他成像度量的权衡，例如持续时间或速度，这些对于解析生物过程同样重要。最近，计算SR方法因其能够在silico中即时提高图像分辨率而受到关注，从而显著升级现有的荧光显微镜系统并扩展其应用范围。计算SR方法可以分为两类：基于分析模型的方法，例如去卷积算法，以及基于深度学习的方法，例如SR神经网络。前者通常采用分析模型，假设标本和图像具有某些性质，例如稀疏性和局部对称性，以提高图像分辨率，并具有多个可调参数。参数调优依赖于经验且耗时，分析模型的输出极大地依赖于参数集。此外，在实际实验中，具有某些假设的手工模型无法解决显微镜成像的全部统计复杂性，因此缺乏鲁棒性，容易产生artifact，特别是在低信噪比（SNR）条件下。另一方面，基于深度学习的SR（DLSR）方法在学习端到端图像转换关系方面取得了惊人的成功，无需显式的分析模型。值得注意的是，通过深度学习的数据驱动逆算可以近似图像退化过程的伪逆函数以及SR解决方案的随机特性。然而，训练DLSR模型需要大量的配对低分辨率输入图像和高质量的ground truth（GT）SR图像，这在生物标本中由于快速动态或低荧光SNR而极其耗时，有时甚至不切实际。此外，DLSR方法的性能极大地依赖于训练数据的质量和数量。这些因素严重阻碍了DLSR方法在日常成像实验中的广泛应用，尽管其SR性能比基于分析模型的方法更具吸引力。
   </p>
   <p id="Par4">
    一般来说，现有的计算SR方法可以分为两类：基于分析模型的方法，例如去卷积算法，以及基于深度学习的方法，例如SR神经网络。前者通常采用分析模型，假设标本和图像具有某些性质，例如稀疏性和局部对称性，以提高图像分辨率，并具有多个可调参数。参数调优依赖于经验且耗时，分析模型的输出极大地依赖于参数集。此外，在实际实验中，具有某些假设的手工模型无法解决显微镜成像的全部统计复杂性，因此缺乏鲁棒性，容易产生artifact，特别是在低信噪比（SNR）条件下。另一方面，基于深度学习的SR（DLSR）方法在学习端到端图像转换关系方面取得了惊人的成功，无需显式的分析模型。值得注意的是，通过深度学习的数据驱动逆算可以近似图像退化过程的伪逆函数以及SR解决方案的随机特性。然而，训练DLSR模型需要大量的配对低分辨率输入图像和高质量的ground truth（GT）SR图像，这在生物标本中由于快速动态或低荧光SNR而极其耗时，有时甚至不切实际。此外，DLSR方法的性能极大地依赖于训练数据的质量和数量。这些因素严重阻碍了DLSR方法在日常成像实验中的广泛应用，尽管其SR性能比基于分析模型的方法更具吸引力。
   </p>
   <p id="Par5">
    这里，我们提出了一种零样本去卷积深度神经网络（ZS-DeconvNet）框架，可以在无监督的方式下使用仅一个低分辨率和低SNR的单平面图像或体积图像栈来训练DLSR网络，从而实现零样本实现。与最先进的DLSR方法相比，ZS-DeconvNet可以适应多种生物成像环境，其中生物过程太动态，太敏感到光，无法获取ground-truth SR图像，或者图像获取过程受到未知和非理想因素的影响。我们表明，ZS-DeconvNet可以在仅使用一个低SNR输入图像和无需图像特定参数调优的情况下，以高保真度和可量化性提高分辨率超过1.5倍的衍射极限。我们证明了正确训练的ZS-DeconvNet可以在毫秒时间尺度上推断高分辨率图像，实现多个细胞器相互作用、细胞骨架和细胞器动力学的高速、长期、超分辨率2D/3D成像，以及在发育中的
    <italic>
     C. elegans
    </italic>
    和小鼠胚胎中子细胞结构和动力学的成像。此外，为了使ZS-DeconvNet更容易被生物研究社区使用，我们建立了一个Fiji插件工具箱和一个ZS-DeconvNet方法的教程主页。
   </p>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    结果
   </title>
   <sec id="Sec3">
    <title>
     ZS-DeconvNet的开发和特征
    </title>
    <p id="Par6">
     ZS-DeconvNet的概念基于光学成像前向模型的无监督逆问题求解器：
     <disp-formula id="Equ1">
      <label>
       1
      </label>
      <alternatives>
       <math id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <msubsup>
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\arg }}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\Big|\Big|{{{{{{\bf{y}}}}}}-{\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{\bf{y}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }{\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     ，其中
     <bold>
      y
     </bold>
     表示噪声低分辨率图像，PSF是点扩散函数，
     <inline-formula id="IEq1">
      <alternatives>
       <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     表示具有可训练参数
     <bold>
      θ
     </bold>
     的深度神经网络，
     <inline-formula id="IEq2">
      <alternatives>
       <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     表示下采样操作。如果直接通过上述目标函数训练DNN，它将不必要地放大生物图像中的光子噪声，这将在低SNR条件下严重污染真实标本信息（补充Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      1a
     </xref>
     ）。为了提高ZS-DeconvNet的噪声鲁棒性，同时保持其无监督特性，我们采用了一种图像重污染方案，从原始图像生成两个噪声独立的重污染图像，然后将其用作网络训练的输入和GT（方法）。我们在补充Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     中理论证明了普通sCMOS图像中混合泊松-高斯噪声模型的高斯近似有效性，并证明了将重污染方案纳入无监督逆问题求解器的收敛性。此外，我们引入了Hessian正则化项，它已被证明对减轻显微镜图像中的重构artifact有用（补充Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b–e
     </xref>
     ）。总的来说，ZS-DeconvNet的总目标函数可以公式化为：
     <disp-formula id="Equ2">
      <label>
       2
      </label>
      <alternatives>
       <math id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfrac>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </mfrac>
        <msubsup>
         <mrow>
          <mo mathsize="big">
           ∑
          </mo>
         </mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </msubsup>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msup>
           <mrow>
            <mi>
             D
            </mi>
           </mrow>
           <mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </msup>
          <mi mathvariant="bold">
           g
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi>
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   i
                  </mi>
                 </mrow>
                </msub>
                <mi mathvariant="bold-italic">
                 +
                </mi>
                <mi>
                 D
                </mi>
                <mi mathvariant="bold">
                 g
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mi>
               i
              </mi>
             </mrow>
            </msub>
            <mi mathvariant="bold-italic">
             +
            </mi>
            <mi>
             D
            </mi>
            <mi mathvariant="bold">
             g
            </mi>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{arg}}}}}}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\frac{1}{N}{\sum }_{i=1}^{N}{{{{{\mathcal{L}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}-{D}^{-1}{{{{{\bf{g}}}}}},{\left({f}_{\theta }\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }\right)+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     ，其中
     <italic>
      N
     </italic>
     是要处理的图像总数，
     <inline-formula id="IEq3">
      <alternatives>
       <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
       </math>
       <tex-math id="IEq3_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq3.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是根据信号和噪声水平计算的可逆噪声控制矩阵，
     <bold>
      g
     </bold>
     是从标准正态分布中采样的随机噪声图。我们将目标函数的第一部分称为退化项，负责推断保真度，将第二部分称为正则化项，合理化SR输出。
    </p>
    <p id="Par7">
     定义了目标函数后，我们采用了一种双阶段DNN架构，由两个顺序连接的U-Net组成，作为ZS-DeconvNet的简单但有效的骨架（Fig.
     <xref ref-type="fig" rid="Fig1">
      1a, b
     </xref>
     和补充Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2a
     </xref>
     ）。第一阶段作为去噪器，根据去噪损失生成无噪图像（方法），第二阶段根据上述无监督去卷积损失提高图像分辨率。我们经验性地发现，双阶段架构和物理模型调节的损失函数稳定了训练过程，并为整个网络模型赋予了可解释性。
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="zh-CN">
       <title>
        零样本去卷积网络。
       </title>
       <p>
        <bold>
         a
        </bold>
        ZS-DeconvNet的双阶段架构及其训练阶段的示意图。
        <bold>
         b
        </bold>
        ZS-DeconvNet的推理阶段的示意图。
        <bold>
         c
        </bold>
        通过RL去卷积（第二列）、稀疏去卷积（第三列）和ZS-DeconvNet（第四列）重构的Lyso和MTs的代表性SR图像。 为参考，显示了清晰的WF图像。
        <bold>
         d
        </bold>
        RL去卷积、稀疏去卷积和ZS-DeconvNet在PSNR和分辨率方面的统计比较（
        <italic>
         n
        </italic>
        = 100个感兴趣区域）。
        <bold>
         e
        </bold>
        清晰的WF图像和通过RL去卷积、稀疏去卷积和ZS-DeconvNet处理的图像的全宽半高（FWHM）比较（
        <italic>
         n
        </italic>
        = 30个微管）。 为参考，灰色虚线标记了理论衍射极限。
        <bold>
         f
        </bold>
        GPU-based稀疏去卷积和ZS-DeconvNet之间的测试时间比较（平均25个测试图像，1024 × 1024像素）。 中心线，中位数；限制，75%和25%；须状线，最大数据点和75百分位数之和的1.5倍，以及最小数据点和25百分位数之差的1.5倍；异常值，数据点大于上须状线或小于下须状线。 源数据作为源数据文件提供。 标尺，1.5 μm（
        <bold>
         a
        </bold>
        ），5 μm（
        <bold>
         c
        </bold>
        ），2 μm（
        <bold>
         c
        </bold>
        中的放大区域）。
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig1_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par8">
     为了表征和评估ZS-DeconvNet，我们首先模拟了被高斯-泊松噪声污染的点状和管状结构的显微镜图像，信号水平从5到25个平均光子计数不等，这使我们能够系统地测试不同成像条件下重腐蚀超参数设置如何影响最终输出（补充说明2）。我们发现，最佳超参数在理论上与图像内容和信号水平无关（补充图3-5），因此可以将ZS-DeconvNet鲁棒地应用于各种生物样本和成像配置（补充说明4）。接下来，我们比较了使用单个噪声图像重腐蚀数据训练的ZS-DeconvNet模型与使用分析性解卷积算法或使用多个模拟或独立采集的图像训练的模型的性能。为此，我们使用了我们自主构建的多模态结构照明显微镜（Multi-SIM）的全内反射荧光（TIRF）照明模式，获得了每个细胞内溶酶体（Lyso）和微管（MTs）结构的低信噪比和高信噪比的约20组衍射极限TIRF图像，其中低信噪比图像用于训练和测试，而高信噪比的对应图像作为参考（方法）。我们发现，ZS-DeconvNet图像的峰值信噪比（PSNR）和分辨率明显优于分析算法生成的图像，例如经典的Richardson-Lucy（RL）和最新开发的稀疏解卷积（图1c-e），并且一个良好训练的ZS-DeconvNet的吞吐量比稀疏解卷积算法高出100倍以上（图1f）。特别是，即使ZS-DeconvNet是使用单个输入图像的增强数据训练的，其输出图像的感知质量和量化指标也与使用大量数据训练的模型的图像相当（补充图6）。此外，我们验证了ZS-DeconvNet的分辨率改进、量化和泛化能力（补充图7-10），并将其与监督DFCAN模型（补充图11）在合成和实验数据上进行了比较。这些表征表明，ZS-DeconvNet能够生成高质量的DLSR图像，相对于衍射极限，分辨率改进了1.5倍，同时使用最少的训练数据，这有望升级各种显微镜系统的成像性能，并将其应用范围扩展到传统方法难以处理的广泛生物过程中。
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     对光毒性敏感的生物过程的长期观察
    </title>
    <p id="Par9">
     细胞粘附和迁移在形态发生过程中至关重要，并且对许多疾病做出了贡献。高分辨率成像细胞粘附/迁移过程中的细胞骨架动力学对于阐明其潜在机制至关重要。然而，由于严重的光敏性，细胞粘附和迁移的整个过程通常以低帧率（即每帧几秒）和低光强记录。 在这些成像条件下，经典的Richardson-Lucy（RL）解卷积或基于时间连续性的自监督学习（方法）都无法恢复和锐化F-actin和肌动蛋白-II的复杂结构（图2a，补充图12和补充视频1）。相比之下，ZS-DeconvNet模型有效地提高了两色时间序列记录的信噪比和分辨率，该记录显示了在涂片上滴落共表达mEmerald-Lifeact和mCherry-myosin-IIA的COS-7细胞的扩散过程（图2b和补充视频2）。令人着迷的是，我们观察到在某些物质中，细胞会在扩散和粘附之前在接触位点周围爬行以探索邻域（图2c和补充视频3）。细胞爬行是在细胞后部肌动蛋白-II的极化积累之后发生的，导致了由后部肌动蛋白-II收缩驱动的细胞迁移与相反方向。另外，迁移方向可以迅速响应细胞内肌动蛋白-II的动态重新分布而改变（图2d）。这些结果表明，ZS-DeconvNet辅助成像可以在不干扰这种漫长而脆弱的过程的情况下忠实地记录细胞粘附和迁移的动力学。
     <fig id="Fig2" position="float">
      <label>
       Fig. 2
      </label>
      <caption xml:lang="zh-CN">
       <title>
        通过ZS-DeconvNet进行长期SR成像的快速和光敏生物过程。
       </title>
       <p>
        <bold>
         a
        </bold>
        ZS-DeconvNet重构的COS-7细胞中F-actin骨架和肌动蛋白-II的代表性SR图像，该细胞共表达mEmerald-lifeact和mCherry-myosin-IIA。 显示了原始噪声TIRF图像和通过RL去卷积、DeepCAD-based去卷积和ZS-DeconvNet处理的图像的比较。
        <bold>
         b
        </bold>
        通过ZS-DeconvNet增强的两色时间序列SR图像，显示了F-actin（青色）和肌动蛋白-II（黄色）在整个扩散过程中的协调动态，扩散过程发生在将COS-7细胞放在盖玻片上之后（补充视频
        <xref ref-type="supplementary-material" rid="MOESM5">
         2
        </xref>
        ）。
        <bold>
         c
        </bold>
        ，
        <bold>
         d
        </bold>
        通过ZS-DeconvNet增强的两色时间序列SR图像，显示了F-actin和肌动蛋白-II在爬行的COS-7细胞中的动态，肌动蛋白-II偏向于集中在细胞的后部（
        <bold>
         d
        </bold>
        中用黄色虚线标记），与爬行方向相反（
        <bold>
         d
        </bold>
        中用白色箭头标记）（补充视频
        <xref ref-type="supplementary-material" rid="MOESM6">
         3
        </xref>
        ）。
        <bold>
         e
        </bold>
        通过ZS-DeconvNet生成的回收内体（REs，绿色）和晚期内体（LEs，洋红色）的代表性SR图像，在基因编辑的SUM-159细胞中内源性表达EGFP-Rab11和mCherry-Lamp1（补充视频
        <xref ref-type="supplementary-material" rid="MOESM7">
         4
        </xref>
        ）。
        <bold>
         f
        </bold>
        RE（上）和LE（下）运动的典型轨迹，显示了RE的快速定向运动和LE的双向运动。
        <bold>
         g
        </bold>
        Lyso/LEs和REs之间的速度、位移和旅行时间的比较，以及REs在与质膜融合之前在其外排_sites附近的驻留时间的量化（
        <italic>
         n
        </italic>
        = 505条RE轨迹和
        <italic>
         n
        </italic>
        = 230条LE轨迹）。 为更好地展示分布，未显示超过150秒的运输时间或60 μm的位移的少数数据点。 中心线，中位数；限制，75%和25%。 使用无配对Mann-Whitney测试确定统计显著性（
        <italic>
         p
        </italic>
        =
        <inline-formula id="IEq4">
         <alternatives>
          <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            1.38
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              7
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq4_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.38\times {10}^{-7}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq4.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ，
        <inline-formula id="IEq5">
         <alternatives>
          <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            5.65
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              35
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq5_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$5.65\times {10}^{-35}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq5.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ，和
        <inline-formula id="IEq6">
         <alternatives>
          <math id="IEq6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            6.26
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              40
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq6_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$6.26\times {10}^{-40}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq6.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ，分别用于移动速度、运输时间和位移的测试）。 ****
        <italic>
         p
        </italic>
        &lt; 0.0001。 源数据作为源数据文件提供。
        <bold>
         h
        </bold>
        时间序列图像显示了RE的定向运动和随后的与质膜融合。
        <bold>
         i
        </bold>
        时间序列图像显示了三个LEs相互连接并在一定距离上共同移动，然后分裂成单个LEs。 标尺，5 μm（
        <bold>
         a
        </bold>
        ，
        <bold>
         c
        </bold>
        ，
        <bold>
         d
        </bold>
        ），2 μm（
        <bold>
         a
        </bold>
        中的放大区域），8 μm（
        <bold>
         b
        </bold>
        ），3 μm（
        <bold>
         e
        </bold>
        ），0.5 μm（
        <bold>
         e
        </bold>
        中的放大区域），1 μm（
        <bold>
         g
        </bold>
        ，
        <bold>
         f
        </bold>
        ，
        <bold>
         i
        </bold>
        ）。
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig2_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par10">
     扩散过程后，将共表达mEmerald-Lifeact和mCherry-myosin-IIA的COS-7细胞滴落在涂片上（图2b和补充视频2）。令人着迷的是，我们观察到在某些物质中，细胞会在扩散和粘附之前在接触位点周围爬行以探索邻域（图2c和补充视频3）。细胞爬行是在细胞后部肌动蛋白-II的极化积累之后发生的，导致了由后部肌动蛋白-II收缩驱动的细胞迁移与相反方向。另外，迁移方向可以迅速响应细胞内肌动蛋白-II的动态重新分布而改变（图2d）。这些结果表明，ZS-DeconvNet辅助成像可以在不干扰这种漫长而脆弱的过程的情况下忠实地记录细胞粘附和迁移的动力学。
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     可视化内体系统的快速动态
    </title>
    <p id="Par11">
     内体系统包括多种类型的囊泡，这些囊泡以高度动态但又高度有序的方式发挥作用。虽然活细胞荧光成像已经显著改善了我们对内体系统的理解，但大多数研究都需要过表达感兴趣的蛋白质来记录其快速动力学，这通常会导致伪影形态或行为。使用ZS-DeconvNet，我们能够成像内源性表达EGFP-Rab11和mCherry-Lamp1的SUM-159细胞系，成像时间长达1500帧，分辨率约为150nm，两色成像帧率为3帧/秒（图2e和补充视频4），从而使我们能够在比以前成像时间窗口更长、空间时间尺度更细的条件下可视化和跟踪回收内体（REs）和溶酶体或晚期内体（LEs）的快速运动。如图2f-h所示，我们发现大多数REs（n=505条轨迹）经历了方向运动，总位移为6.7±5.4μm，速度为2.2±1.2μm/s（瞬时速度超过5.3μm/s），中间暂停很少，然后在特定位点停留13.5±10.3秒后与细胞膜融合。这种观察表明，REs可能被高效地运输到靠近细胞膜的区域，以便于随后的外吐作用。出乎意料的是，ZS-DeconvNet捕捉到了Rab11阳性REs的多个裂解事件，其中两个分离的REs顺序地经历了外吐作用（补充图13a），或者一个RE移动走了（补充图13b）。这种观察表明，高度专门化的Rab11阳性REs可能会在外吐作用之前经历进一步的货物排序。
    </p>
    <p id="Par12">
     相比之下，LEs的运动通常是断续的，以相对较慢的速度1.6±0.6μm/s（n=230条轨迹）进行（图2f、g、i）。虽然LEs的运输似乎效率低下，但LEs通常会在91.8秒的时间内持续存在，总位移长达23.6μm（平均值来自n=230条轨迹）（图2h）。有趣的是，我们注意到两个或多个LEs有时会以“亲吻-停留”的方式相互连接，并在一定距离上共同迁移，然后再分裂成单个LEs（图2i和补充图13c），这可能有助于LEs在没有足够的motor-protein-adaptors进行长距离运输的情况下进行方向运动。LEs的这些复杂动力学表明，其定位和移动是由多种因素精细调节的，例如MT-based motors和膜接触。
    </p>
   </sec>
   <sec id="Sec6">
    <title>
     用于光格子光片显微镜的3D ZS-DeconvNet
    </title>
    <p id="Par13">
     体积活细胞成像比2D观察提供了更多的生物信息；然而，它受到更严重的光毒性、光漂白和非焦点荧光污染的影响。为了扩展ZS-DeconvNet的体积超分辨率成像能力，我们将双阶段网络架构的骨干升级为3D RCAN，它已被证明适用于体积图像恢复（Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     和Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ）。接下来，我们将之前提出的空间交错自监督学习方案与物理模型信息自监督逆问题求解器相结合，构建了3D ZS-DeconvNet。具有空间交错自监督方案的3D ZS-DeconvNet遵循更简单的数据增强过程（方法），同时实现了与重构策略相似的或更好的性能（Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     ）
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     。
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="zh-CN">
       <title>
        3D ZS-DeconvNet 的特征和示例。
       </title>
       <p>
        <bold>
         a
        </bold>
        3D ZS-DeconvNet 的网络架构及其训练阶段的示意图。
        <bold>
         b
        </bold>
        3D ZS-DeconvNet 的推理阶段的示意图。
        <bold>
         c
        </bold>
        代表性的最大强度投影（MIP）SR 图像，展示了 F-actin、Mito 外膜和 ER 经过稀疏去卷积（第二列）、3D ZS-DeconvNet（第三列）和 LLS-SIM（第四列）重构的结果。原始图像前处理中最高 1% 像素的平均 sCMOS 计数在右上角标注。
        <bold>
         d
        </bold>
        比较了 RL 去卷积、稀疏去卷积和 ZS-DeconvNet 在不同标本（
        <italic>
         n
        </italic>
        = 40 个感兴趣区域）上的 PSNR 和分辨率。分辨率通过 F-actin 图像栈的傅里叶环相关分析
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        测量。中位数，中位数；限制，75% 和 25%；须状线，最大值和最小值。源数据作为源数据文件提供。
        <bold>
         e
        </bold>
        通过 3D ZS-DeconvNet 重构的 ER、H2B 和 Mito 的时间序列三色 3D 渲染图像，展示了它们在有丝分裂过程中的形态和分布变化以及相互作用动力学（补充视频
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ）。
        <bold>
         f
        </bold>
        通过传统 LLSM（第一列）、稀疏去卷积（第二列）、DeepCAD 基于去卷积（第三列）（方法）和 3D ZS-DeconvNet（第四列）获得的代表性三色图像。比较是在时间序列数据（
        <bold>
         e
        </bold>
        ）的两个典型时间点上进行的。比例尺，5 μm（
        <bold>
         c
        </bold>
        ，
        <bold>
         e
        </bold>
        ，
        <bold>
         f
        </bold>
        ），1.5 μm（
        <bold>
         c
        </bold>
        的放大区域），2 μm（
        <bold>
         f
        </bold>
        的放大区域）。
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     我们系统地评估了3D ZS-DeconvNet模型，使用了通过我们自建的格子光片结构照明显微镜（LLS-SIM）获得的三个不同生物样本的数据集，其中通过格子光片显微镜（LLSM）模式获得的衍射极限数据用于训练，而通过LLS-SIM模式获得的超分辨率对应数据作为参考（方法）。我们发现3D ZS-DeconvNet成功地重构了F-actin的精细丝、线粒体（Mito）外膜的空心结构和内质网（ER）的复杂网络，具有与在高信噪比条件下获得的LLS-SIM图像相似的高保真度和分辨率（Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ）。PSNR和分辨率的量化结果表明，3D ZS-DeconvNet模型在多种生物样本中比传统的基于分析模型的方法有了显著的改进（Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ）。我们证明，通过训练噪声图像堆栈本身，双阶段3D ZS-DeconvNet不仅生成了与最先进的自监督去噪技术相似的去噪结果（Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ），还提供了具有显著分辨率改进的超分辨率图像堆栈，改进了1.5倍以上的横向（Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ）和轴向（Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ）分辨率。此外，通过顺序整合自学习基于轴向分辨率增强方法，轴向分辨率可以进一步改进（Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     ）
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     。
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     3D ZS-DeconvNet实现的长期体积超分辨率成像
    </title>
    <p id="Par15">
     体积观察细胞分裂在高时空分辨率下对于探索有丝分裂相关的生物机制至关重要，例如将细胞质中众多不同的细胞器分配到每个子细胞中的机制
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
      ,
      <xref ref-type="bibr" rid="CR42">
       42
      </xref>
     </sup>
     。由于有丝分裂细胞的极端光敏性和脆弱性，之前的体积超分辨率成像依赖于低光LLS-SIM系统和基于监督学习的超分辨率重构
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     。然而，收集高质量的训练数据极其耗时，有时甚至不切实际，因为有丝分裂过程中细胞器的形态和分布通常会发生戏剧性的变化
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
     </sup>
     。在这里，我们证明了自监督的3D ZS-DeconvNet模型可以被广泛应用于从噪声LLSM体积中超分辨率细化ER、Mito和染色体的细微亚细胞结构，而无需额外的训练数据，从而实现了在有丝分裂HeLa细胞中1000个时间点、每10秒间隔的快速和长期体积超分辨率观察（Fig.
     <xref ref-type="fig" rid="Fig3">
      3e
     </xref>
     和Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM8">
      5
     </xref>
     ）。此外，ZS-DeconvNet的自监督特性允许我们整合测试时适应学习策略，以充分利用每个噪声体积中的结构内容，从而获得最佳的3D超分辨率性能（方法）。相比之下，传统的先验依赖的去卷积算法和时间交错自监督学习方法都未能恢复样本的高频细节，因为低信噪比条件和相邻时间点之间的弱时间一致性（Fig.
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     和方法）。此外，根据3D ZS-DeconvNet提供的低侵入性，一组有丝分裂HeLa细胞被标记为H2B-mCherry和HeLa-mEmerald-SC35，在100×50×25 μm的大视野（FOV）中成像超过300个时间点，从而以高时空分辨率记录了整个核斑的解聚和重聚过程（Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     和Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM9">
      6
     </xref>
     ）。简而言之，3D ZS-DeconvNet允许生物学家轻松以低侵入性和更高的时空分辨率探索各种光敏生物过程，而无需任何额外的数据集或光学设置修改
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      ,
      <xref ref-type="bibr" rid="CR44">
       44
      </xref>
     </sup>
     。
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet用于共焦和广场场显微镜
    </title>
    <p id="Par16">
     ZS-DeconvNet依赖于噪声的随机性和光学显微镜的低通滤波特性，这些特性在各种类型的显微镜模式中都很常见。基于此，我们期望ZS-DeconvNet可以被广泛应用于所有显微镜，例如最常用的共焦显微镜和宽场（WF）显微镜。为了研究3D ZS-DeconvNet在共焦数据上的性能，我们使用自建的共焦显微镜获得了小鼠早期胚胎的四色体积图像，图像中微管、染色体、肌动蛋白和顶端域都被免疫标记（方法），这些结构在第一次细胞命运决定中起着关键作用，并且对于胚胎发育至关重要
     <sup>
      <xref ref-type="bibr" rid="CR45">
       45
      </xref>
      ,
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
      ,
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
     </sup>
     。然后，我们在这个单个噪声体积上训练了3D ZS-DeconvNet模型，并使用训练好的模型处理原始数据。如Fig.
     <xref ref-type="fig" rid="Fig4">
      4a, b
     </xref>
     所示，3D ZS-DeconvNet显著提高了共焦数据体积的信噪比、对比度和分辨率，并解析了微管桥和肌动蛋白环的精细结构（Fig.
     <xref ref-type="fig" rid="Fig4">
      4c, d
     </xref>
     、Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      19
     </xref>
     和Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM10">
      7
     </xref>
     ）。这些结果表明ZS-DeconvNet能够在大尺度上实现共焦显微镜的更高空间分辨率和更低的光子预算，例如小鼠早期胚胎，这对于研究细胞 polarity、细胞内运输和囊胚形成至关重要
     <sup>
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
     </sup>
     。
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="zh-CN">
       <title>
        ZS-DeconvNet 在多种成像模式下的泛化。
       </title>
       <p>
        <bold>
         a
        </bold>
        ，
        <bold>
         b
        </bold>
        代表性的共焦（左上）、稀疏去卷积（左下）和 3D ZS-DeconvNet 增强（右）的图像，展示了早期小鼠胚胎的微管（青色）、染色体（橙色）、肌动蛋白环（洋红色）和顶端域（绿色）的免疫荧光染色。
        <bold>
         c
        </bold>
        ，
        <bold>
         d
        </bold>
        微管桥（c）和肌动蛋白环（d）的放大区域，分别通过共焦显微镜、稀疏去卷积和 3D ZS-DeconvNet 获得。这些区域在（
        <bold>
         a
        </bold>
        ）和（
        <bold>
         b
        </bold>
        ）中用白色虚线框标注。
        <bold>
         e
        </bold>
        代表性的广场场（中心区域）和 3D ZS-DeconvNet 增强（周围区域）的图像，展示了带有顶端连接、细胞膜（青色）和溶酶体（红色）标记的
        <italic>
         C. elegans
        </italic>
        胚胎。
        <bold>
         f
        </bold>
        ，
        <bold>
         g
        </bold>
        (
        <bold>
         e
        </bold>
        ) 中心区域的溶酶体通道，根据距基材的距离进行颜色编码。广场场（
        <bold>
         f
        </bold>
        ）和 3D ZS-DeconvNet 处理的图像（
        <bold>
         g
        </bold>
        ）均用于比较。
        <bold>
         h
        </bold>
        时间序列 3D ZS-DeconvNet 增强图像，展示了
        <italic>
         C. elegans
        </italic>
        胚胎发育过程中的皮质细胞融合过程（红色箭头）。比例尺，5 μm（
        <bold>
         a
        </bold>
        ，
        <bold>
         b
        </bold>
        ，
        <bold>
         e
        </bold>
        ），2 μm（
        <bold>
         c
        </bold>
        ，
        <bold>
         d
        </bold>
        ），3 μm（
        <bold>
         g
        </bold>
        ，
        <bold>
         h
        </bold>
        ），1 μm（
        <bold>
         g
        </bold>
        的放大区域）。Gamma 值，
        <italic>
         C. elegans
        </italic>
        胚胎的细胞膜和溶酶体为 0.7。
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17">
     我们接着使用Multi-SIM系统的3D WF模式成像了具有顶端连接、细胞膜和溶酶体标记的线虫胚胎（方法）。为了确保线虫胚胎的发育不受干扰，我们在30秒的间隔内以相对较低的光照激发获得了原始图像堆栈，共超过200个时间点。然而，在这种条件下，WF图像受到非焦点背景和噪声的严重污染（Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, f
     </xref>
     ）。即使在这种具有挑战性的情况下，3D ZS-DeconvNet图像也表现出显著的噪声和背景抑制，同时提高了亚细胞细节的空间分辨率（Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, g
     </xref>
     和Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM11">
      8
     </xref>
     ），从而使我们能够研究胚胎发育的精细过程，例如皮层细胞融合（Fig.
     <xref ref-type="fig" rid="Fig4">
      4h
     </xref>
     ），即使使用简单的WF显微镜
     <sup>
      <xref ref-type="bibr" rid="CR48">
       48
      </xref>
     </sup>
     。
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     多模态SIM图像中的ZS去噪和分辨率增强
    </title>
    <p id="Par18">
     在各种超分辨率（SR）显微镜中，结构照明显微镜（SIM）通常被认为是超分辨率活细胞成像的平衡选择，因为它需要不到十张原始调制图像就可以提供两倍的空间分辨率提高
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     。然而，传统的SIM有两个关键限制：首先，进一步提高分辨率需要大量原始数据，例如，非线性SIM需要至少25张原始图像才能获得低于80纳米的分辨率；第二，SIM图像的后处理通常需要原始图像具有高信噪比（SNR）以消除噪声诱导的重建伪影，从而阻碍快速、低光、长时间的活细胞成像
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     。最近的研究探索了使用监督学习方法来降噪SIM图像或直接从原始图像重建SR SIM图像以实现低光SIM重建；然而，这些方法需要大量的训练数据，并且不能进一步提高分辨率。在ZS-DeconvNet的出色降噪和SR能力的基础上，我们将零样本学习方案与传统的SIM重建算法相结合，并从理论上证明了ZS-DeconvNet适用于处理SR-SIM图像（补充说明
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ）。我们设计了ZS-DeconvNet增强SIM（ZS-DeconvNet-SIM）模型，以无监督的方式同时降噪和增强SR SIM图像（图
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     ，补充图
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     ，和方法）。借助ZS-DeconvNet-SIM提供的SNR和分辨率的显著提高（补充图
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ，
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ），SUM-159细胞中的夹层结构和COS-7细胞中的密集交错的细胞骨架，在WF和传统SIM图像中无法区分，变得清晰可见（图
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ）。此外，我们证明了ZS-DeconvNet-SIM可以应用于3D-SIM模式，以同时降噪和增强3D-SIM图像在横向和轴向上的分辨率（方法，补充图
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     ）
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     。
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="zh-CN">
       <title>
        SIM 数据的零样本去噪和分辨率增强。
       </title>
       <p>
        <bold>
         a
        </bold>
        ZS-DeconvNet 用于 SIM 的训练过程示意图。
        <bold>
         b
        </bold>
        SUM-159 细胞中 CCP 的信噪比和分辨率改进过程，分别从原始 SIM 图像（左）、传统 SIM 图像（右）和 ZS-DeconvNet 增强的 SIM 图像（中）可见。
        <bold>
         c
        </bold>
        COS-7 细胞中微管的信噪比和分辨率改进过程，分别从原始 SIM 图像（左）、传统 SIM 图像（右）和 ZS-DeconvNet 增强的 SIM 图像（中）可见。
        <bold>
         d
        </bold>
        代表性的最大强度投影（MIP）图像，展示了 HeLa 细胞中 F-actin 经过 LLSM、LLS-SIM 和 3D ZS-DeconvNet 增强的 LLS-SIM 获得的结果，跨三个维度。
        <bold>
         e
        </bold>
        ，代表性的最大强度投影（MIP）图像，展示了 293 T 细胞中用 TOMM20 标记的线粒体外膜，分别通过 LLSM、LLS-SIM 和 3D ZS-DeconvNet 增强的 LLS-SIM 获得的结果，跨三个维度。比例尺，1 μm（
        <bold>
         a
        </bold>
        ），2 μm（
        <bold>
         b
        </bold>
        ，
        <bold>
         c
        </bold>
        ），0.5 μm（
        <bold>
         b
        </bold>
        和
        <bold>
         c
        </bold>
        的放大区域），3 μm（
        <bold>
         d
        </bold>
        ，
        <bold>
         e
        </bold>
        ）。
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig5_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par19">
     此外，我们将3D ZS-DeconvNet与激光光片结构照明显微镜（LLS-SIM）相结合，开发了3D ZS-DeconvNet-SIM模式（补充图
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ）。通过将传统LLS-SIM的各向异性点扩散函数（PSF）纳入训练过程，3D ZS-DeconvNet LLS-SIM不仅显著提高了三个维度的对比度和分辨率，而且提供了约150纳米的等向横向分辨率（图
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     ，和补充图
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ）。这些成功应用ZS-DeconvNet到多模态SIM系统的结果，证明了其进一步扩展现有SR技术的时空分辨率带宽的能力
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     。
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    讨论
   </title>
   <p id="Par20">
    活细胞成像的最终目标是以最小的侵入性收集生物过程的最多时空信息。然而，荧光显微镜中的成像速度、持续时间、分辨率和信噪比之间的相互限制，导致了时空带宽限制，这限制了所有这些方面的协同改进。例如，为了获得更高的空间分辨率，传统的SR技术必须依赖重复采集或额外的激发，这加剧了光毒性和光漂白，阻碍了快速、长时间的生物过程观察。为了解决显微镜中的时空带宽限制，我们对光学成像模型和SIM重建中的噪声传播进行了深入分析（补充说明
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ），证明了在普通和SIM场景中，基于PSF卷积线性的重构-集成自监督损失函数的收敛性，并提出了通用的ZS-DeconvNet框架，该框架可以与各种光学荧光显微镜相结合，瞬间提高图像信噪比和分辨率，而不损害其他成像特性。我们强调ZS-DeconvNet对图像重构过程中的超参数具有鲁棒性（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ），并且ZS-DeconvNet可以仅使用一张或一组原始图像进行良好的训练（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ，
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ），而无需使用结构稀疏性和时间连续性的假设
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    。在模拟和实验数据上的定量和定性评估表明，我们的方法显著提高了图像质量和分辨率，超过1.5倍，具有高保真度和可量化性，即使在低光条件下，也可以实现快速、长时间的超分辨率观察多个亚细胞动态过程。
   </p>
   <p id="Par21">
    提出的ZS-DeconvNet方法适用于各种类型的成像模态，从扫描基显微镜（例如，共焦显微镜和二光子显微镜，补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     25
    </xref>
    ），到宽场检测基显微镜（例如，TIRF，3D WF显微镜，LLSM和多模态SIM）。我们通过六种不同的显微镜设置，对十多种不同的固定或活体标本进行了成像，包括单细胞中多个细胞器的平面和体积成像，细胞分裂过程中亚细胞动态和相互作用的观察，以及早期小鼠胚胎和
    <italic>
     C. elegans
    </italic>
    胚胎的多色3D成像。为了使我们的方法更容易使用和方便，我们将ZS-DeconvNet和3D ZS-DeconvNet集成到一个用户友好的Fiji插件中（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     26
    </xref>
    ，
    <xref ref-type="supplementary-material" rid="MOESM1">
     27
    </xref>
    ，补充说明
    <xref ref-type="supplementary-material" rid="MOESM1">
     3
    </xref>
    ，
    <xref ref-type="supplementary-material" rid="MOESM1">
     4
    </xref>
    ，和补充视频
    <xref ref-type="supplementary-material" rid="MOESM12">
     9
    </xref>
    ），允许用户即使没有深度学习经验，也可以轻松训练自己的ZS-DeconvNet模型，并在Fiji中以鼠标点击的方式增强显微镜图像。ZS-DeconvNet的功能和便捷性表明其在升级现有光学显微镜性能方面具有巨大的潜力。
   </p>
   <p id="Par22">
    尽管ZS-DeconvNet具有普遍的鲁棒性和适用性，但用户应该仔细考虑其潜在的虚假现象和局限性。首先，ZS-DeconvNet可能将极低的荧光信号误认为是光子噪声，从而在输出图像中削弱它们（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     28a
    </xref>
    ）。这种错误可以通过图像质量检查工具（如SQUIRREL）
    <sup>
     <xref ref-type="bibr" rid="CR54">
      54
     </xref>
    </sup>
    在一定程度上被检测到。第二，如果一个训练良好的ZS-DeconvNet模型被应用于处理与训练数据明显不同的图像（例如，使用不同的成像模态），可能会出现明显的性能下降和更高的虚假现象风险（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     28b
    </xref>
    ）。第三，ZS-DeconvNet模型应该使用与数据集匹配的PSF进行训练，否则使用不匹配的PSF进行训练可能会导致分辨率提高不明显或出现环形伪影（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     28c
    </xref>
    ）。最后，我们不期望无监督的ZS-DeconvNet能够生成与使用高质量数据集训练的监督DLSR模型相当的SR图像（补充图
    <xref ref-type="supplementary-material" rid="MOESM1">
     11
    </xref>
    ）。然而，在无法获得此类数据集的成像实验中，ZS-DeconvNet将是一个强大且方便的工具，用于解析生物细节以达到可能的最细程度。
   </p>
   <p id="Par23"/>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    方法
   </title>
   <sec id="Sec12">
    <title>
     多模态SIM系统
    </title>
    <p id="Par24"/>
   </sec>
   <sec id="Sec13">
    <title>
     光格子光片显微镜系统
    </title>
    <p id="Par25"/>
   </sec>
   <sec id="Sec14">
    <title>
     共焦系统
    </title>
    <p id="Par26"/>
   </sec>
   <sec id="Sec15">
    <title>
     ZS-DeconvNet的架构和目标函数
    </title>
    <p id="Par27"/>
    <p id="Par28"/>
    <p id="Par29">
     值得注意的是，自从ZS-DeconvNet的理论基础是模型无关的，U-Net和RCAN不仅是唯一适用的骨干模型，而且也是广泛采用的高效模型。装备ZS-DeconvNet以其他最先进的网络架构，例如DFCAN和RLN，可能会进一步提高其去噪和SR能力
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     。
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     2D ZS-DeconvNet的实现
    </title>
    <p id="Par30">
     用于训练2D ZS-DeconvNet模型的图像对
     <inline-formula id="IEq21">
      <alternatives>
       <math id="IEq21_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq21_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq21.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是按照修改的策略从原始的重腐蚀到重腐蚀的策略生成的，假设混合了泊松-高斯噪声分布，其中三个超参数
     <inline-formula id="IEq22">
      <alternatives>
       <math id="IEq22_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq22_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq22.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq23">
      <alternatives>
       <math id="IEq23_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq23_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq23.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq24">
      <alternatives>
       <math id="IEq24_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq24_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq24.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     需要预先确定。从单个噪声图像
     <italic>
      y
     </italic>
     的重腐蚀过程可以用矩阵形式表示为：
     <disp-formula id="Equ9">
      <label>
       9
      </label>
      <alternatives>
       <math id="Equ9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̂
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         +
        </mo>
        <mi>
         D
        </mi>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ9_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}+D{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ10">
      <label>
       10
      </label>
      <alternatives>
       <math id="Equ10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mo>
          ̃
         </mo>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         −
        </mo>
        <msup>
         <mrow>
          <mi>
           D
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           1
          </mi>
         </mrow>
        </msup>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ10_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}-{D}^{-{{{{{\bf{1}}}}}}}{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     其中
     <inline-formula id="IEq25">
      <alternatives>
       <math id="IEq25_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
        <mo>
         =
        </mo>
        <mi>
         α
        </mi>
        <mi>
         I
        </mi>
       </math>
       <tex-math id="IEq25_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\alpha I$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq25.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是一个可逆矩阵，定义为一个通过
     <inline-formula id="IEq26">
      <alternatives>
       <math id="IEq26_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         α
        </mi>
       </math>
       <tex-math id="IEq26_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq26.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     因子放大的单位矩阵，它控制添加噪声的总幅度，而
     <inline-formula id="IEq27">
      <alternatives>
       <math id="IEq27_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="IEq27_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq27.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是一个从零均值的高斯分布中采样的随机噪声图：
     <disp-formula id="Equ11">
      <label>
       11
      </label>
      <alternatives>
       <math id="Equ11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
        <mo>
         ~
        </mo>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         N
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           0
          </mn>
          <mo>
           ,
          </mo>
          <msup>
           <mrow>
            <mi>
             σ
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mi>
           I
          </mi>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ11_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}} \sim {{{{{\mathcal{N}}}}}}\left(0,{\sigma }^{2}I\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ12">
      <label>
       12
      </label>
      <alternatives>
       <math id="Equ12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msup>
         <mrow>
          <mi>
           σ
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msup>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
        <mi>
         H
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="Equ12_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }^{2}={\beta }_{1}H\left({{{{{\bf{y}}}}}}-{{{{{\bf{b}}}}}}\right)+{\beta }_{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     其中
     <inline-formula id="IEq28">
      <alternatives>
       <math id="IEq28_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq28_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq28.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是泊松噪声的方差因子，
     <inline-formula id="IEq29">
      <alternatives>
       <math id="IEq29_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq29_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq29.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是高斯噪声的方差因子，
     <inline-formula id="IEq30">
      <alternatives>
       <math id="IEq30_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         b
        </mi>
       </math>
       <tex-math id="IEq30_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{b}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq30.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是背景，近似地被认为是一个与相机相关的固定值，通过减去它，我们从样本中提取了荧光信号。
     <inline-formula id="IEq31">
      <alternatives>
       <math id="IEq31_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         H
        </mi>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq31_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq31.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     是一个线性低通滤波器，用于预先平滑图像并降低噪声，我们在实验中采用了一个5像素大小的平均滤波器
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     。
    </p>
    <p id="Par31">
     如Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     所证明的，
     <inline-formula id="IEq32">
      <alternatives>
       <math id="IEq32_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq32_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq32.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     和
     <inline-formula id="IEq33">
      <alternatives>
       <math id="IEq33_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq33_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq33.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     的理论最优值是1，而
     <inline-formula id="IEq34">
      <alternatives>
       <math id="IEq34_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq34_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq34.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     依赖于相机，可以从图像本身的无样本区域估计或按照标准协议预先校准
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
     </sup>
     。在模拟数据上的评估表明，无论测试图像的结构和信噪比如何，在这些超参数的理论最优值处都能获得最佳的去噪和SR性能（Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ）。
    </p>
   </sec>
   <sec id="Sec17">
    <title>
     3D ZS-DeconvNet的实现
    </title>
    <p id="Par32">
     3D ZS-DeconvNet的训练方案将空间交错的自监督学习方案与自监督逆问题求解器相结合。在训练过程中，每个噪声图像堆栈被分成奇数切片和偶数切片，然后在随机旋转、裁剪和翻转的增强后，分别用作输入和目标。为了修正奇数切片和偶数切片之间的期望差距，我们在去噪损失和去卷积损失中引入了间隙修正正则化（GAR）项，它是用去噪堆栈（在Fig.
     <xref ref-type="fig" rid="Fig3">
      3a
     </xref>
     中用红色框标记）、噪声偶数切片和网络输出计算的（详见Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b
     </xref>
     ）
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     。
    </p>
   </sec>
   <sec id="Sec18">
    <title>
     2D/3D ZS-DeconvNet-SIM的实现
    </title>
    <p id="Par33">
     对于2D-SIM和3D-SIM的ZS-DeconvNet-SIM实现，每组原始SIM图像首先通过公式9和10增强成两组重腐蚀的原始图像，然后通过传统的SIM重构算法重构成一对SR SIM图像。生成的SIM图像对然后用于与训练ZS-DeconvNet模型类似的自监督训练方式。对于在LLS-SIM（Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     ）上应用的3D ZS-DeconvNet-SIM，原始图像不是raw图像，而是后重构的体积SIM数据，轴向采样成两个分别包含奇数切片和偶数切片的SIM堆栈，然后用于3D ZS-DeconvNet模型的后续训练过程，损失函数如公式6-8所述。ZS-DeconvNet-SIM的示意性工作流程如Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     和Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20
     </xref>
     所示
     <sup/>
     。
    </p>
   </sec>
   <sec id="Sec19">
    <title>
     点扩散函数的使用和生成
    </title>
    <p id="Par34">
     在ZS-DeconvNet的训练过程中，我们使用实验获取或模拟的PSF（使用Fiji插件PSF Generator，获得自EPFL），这些PSF与成像配置相对应。我们为每个生物结构和发射波长训练独立的ZS-DeconvNet模型，以获得最佳性能。
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     模型训练和测试时适应
    </title>
    <p id="Par35">
     在这项工作中，ZS-DeconvNet模型是在一台配备Intel Core i7-11700处理器和NVIDIA RTX 3090图形处理卡的PC上训练的，使用TensorFlow 2.5.0和python 3.9.7。在训练之前，成对的输入/GT图像首先通过随机裁剪、水平/垂直翻转和旋转变换增强成多个patch对，以进一步丰富训练数据集，最终生成~20,000对2D patch（128×128像素）或~10,000对3D patch（64×64×13体素）。训练通常使用Adam优化器和初始学习率0.5×10^-4进行，学习率每10,000次迭代衰减0.5倍。2D图像的训练批大小为4，3D栈的训练批大小为3。整个训练过程通常需要50,000次迭代用于2D图像和10,000次迭代用于3D栈。训练50,000次迭代的2D模型和10,000次迭代的3D模型所需的时间分别约为1小时和2小时。与大多数深度学习方法一样，ZS-DeconvNet的训练通常是在大多数活细胞成像情况下是一次性的过程，其中用户使用所有帧训练ZS-DeconvNet模型，然后使用训练好的模型以高处理速度处理同一生物样本的所有数据。为了消除由去卷积引起的边缘artifact，我们通常在3D栈的顶部和底部添加2个空白切片，并在训练和推理过程中为每个xy切片添加8像素的边缘（补充图30a）。特别是，当处理细胞有丝分裂的时间序列数据（图3e，f）时，ZS-DeconvNet的无监督性质使我们能够采用测试时适应学习策略，即首先使用整个过程的数据训练一个通用模型，然后使用少量训练步骤（通常为50次迭代，耗时约1分钟）对每个时间点的预训练模型进行微调，以充分利用原始数据的结构信息并获得最佳的超分辨率性能。需要注意的是，测试时适应不是必需的，但是一种可选的技术，用于在生物样本在观察窗口期间发生巨大形态变化的情况下改善ZS-DeconvNet的性能，例如有丝分裂期间的染色体（补充图31）
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
     </sup>
     。
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     数据后处理和超分辨率图像评估
    </title>
    <p id="Par36">
     对于使用宽场检测的成像模式，例如LLSM，相机像素灵敏度非均匀性引起的固定模式噪声（FPN）不能通过噪声2噪声方案去除
     <sup>
      <xref ref-type="bibr" rid="CR62">
       62
      </xref>
     </sup>
     。在我们的ZS-DeconvNet实现中，FPN将在去卷积阶段被增强，特别是在极低SNR的成像条件下变得不可忽略。对于sCMOS传感器，它们是荧光显微镜中最常用的，固定模式通常表现为由列放大器引起的水平或垂直条纹。为此，我们简单地在傅里叶域中应用了一个apodization掩膜，以抑制条纹artifact，同时保留样本的其他频率成分（补充图30b）。需要注意的是，固定模式噪声也可以通过对获取的原始图像进行预校准基本上去除，方法是遵循成熟的程序
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
      ,
      <xref ref-type="bibr" rid="CR63">
       63
      </xref>
      ,
      <xref ref-type="bibr" rid="CR64">
       64
      </xref>
     </sup>
     。
    </p>
    <p id="Par37">
     本工作中比较的其他计算超分辨率方法，即稀疏去卷积、DeepCAD基于去卷积和SRRF，是按照原始论文的指示实现的。特别是，我们尽量选择稀疏去卷积的最佳超参数，以获得重构图像中artifact最少和分辨率最高。DeepCAD基于去卷积（图2a和图3f）是通过将时间采样方案集成到我们的ZS-DeconvNet框架中实现的，即使用从时间序列数据中采样的图像训练我们的双阶段网络模型，确保与比较的方法具有相同的模型大小和计算成本
     <sup>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      <xref ref-type="bibr" rid="CR13">
       13
      </xref>
     </sup>
     。
    </p>
    <p id="Par38"/>
    <p id="Par39">
     线性变换适用于所有方法，以便进行公平的比较；（3）计算归一化的GT图像
     <bold>
      x
     </bold>
     和线性变换后的图像
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     。
    </p>
    <p id="Par40">
     对于3D ZS-DeconvNet（Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ）的PSNR评估，我们直接利用LLS-SIM图像作为参考，因为LLS-SIM和我们的3D ZS-DeconvNet都提供了1.5倍的分辨率改进。整个计算过程与2D情况类似，除了SR栈没有进行卷积，PSNR仅在特征区域内计算，阈值为0.02，以避免获得异常高的PSNR值。
    </p>
    <p id="Par41">
     为了提供更好的对比度和可视化，我们对RL解卷积、稀疏解卷积和ZS-DeconvNet生成的解卷积图像进行了百分位归一化，公式如下：
     <disp-formula id="Equ15">
      <label>
       15
      </label>
      <alternatives>
       <math id="Equ15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="normal">
           Norm
          </mi>
         </mrow>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             l
            </mi>
            <mi>
             o
            </mi>
            <mi>
             w
            </mi>
           </mrow>
          </msub>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             h
            </mi>
            <mi>
             i
            </mi>
            <mi>
             g
            </mi>
            <mi>
             h
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               h
              </mi>
              <mi>
               i
              </mi>
              <mi>
               g
              </mi>
              <mi>
               h
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
        <mo>
         ,
        </mo>
       </math>
       <tex-math id="Equ15_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{Norm}}}}}}}_{p}\left({{{{{\bf{Y}}}}}},{p}_{{low}},{p}_{{high}}\right)=\frac{{{{{{\bf{Y}}}}}}-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)}{{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{high}}\right)-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)},$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ15.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     ，其中percentile（
     <bold>
      Y
     </bold>
     ，
     <italic>
      p
     </italic>
     ）输出图像
     <bold>
      Y
     </bold>
     中排名
     <italic>
      p
     </italic>
     %的强度值。
     <inline-formula id="IEq40">
      <alternatives>
       <math id="IEq40_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           l
          </mi>
          <mi>
           o
          </mi>
          <mi>
           w
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq40_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{low}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq40.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     和
     <inline-formula id="IEq41">
      <alternatives>
       <math id="IEq41_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           h
          </mi>
          <mi>
           i
          </mi>
          <mi>
           g
          </mi>
          <mi>
           h
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq41_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{high}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq41.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     通常分别设置为3和100，在我们的图像和视频中。
    </p>
   </sec>
   <sec id="Sec22">
    <title>
     细胞培养、转染和染色
    </title>
    <p id="Par42">
     Cos7、HeLa、293T细胞及其稳定细胞株在DMEM（Gibco，cat. no. 11965092）中培养，补充10%胎牛血清（Gibco，cat. no. 10099141 C）和1×青霉素-链霉素（Thermo Fisher，15140122），在37°C的Thermo Scientific™ Heracell™ 150i CO
     <sub>
      2
     </sub>
     孵育器中。SUM159细胞在DMEM/F12K培养基中补充5%胎牛血清（FBS）和1%青霉素-链霉素溶液中培养。
    </p>
    <p id="Par43">
     对于活细胞成像，35mm盖玻片预先涂覆50 μg/ml的胶原蛋白和1×10个细胞。对于暂时转染，细胞使用Lipofectamine 3000（Invitrogen，cat. no. L3000150）按照制造商的协议在接种后12小时进行转染。细胞在转染后12小时进行成像。如有指示，转染Halo Tag质粒的细胞用10 nM JF549配体按照已发表的协议进行标记。细胞用新鲜培养基洗去未结合的配体，并立即进行成像。用于暂时转染的质粒包括Lifeact-mEmerald、Clathrin-mEmerald、3×mEmerald-Ensconsin、Lamp1-Halo、2×mEmerald-Tomm20、Myosin2-Halo、KDEL-mCherry和Halo-Calnexin。
    </p>
    <p id="Par44">
     对于病毒包装，1 μg 病毒转移载体 DNA 与 0.5 μg psPAX2 包装和 0.5 μg pMD2.G 外壳质粒 DNA 一起转染到 90% 凝集的 HEK293T 细胞中，使用 Lipofectamine 3000 按照制造商的协议进行。两天后，收集并用 0.22-μm 滤器（Millipore）过滤上清液。为了构建稳定细胞，HeLa 和 Cos7 细胞被感染以编码内质网标记物 Calnexin-mEmerald 和 F-actin 标记物 Lifeact-mEmerald 的病毒
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     。48 小时后，细胞被流式细胞仪（FACSAria III，BD Biosciences）富集，然后每个孔中放置一个细胞，放入 96 孔板中。单克隆细胞用于我们的实验。具体来说，COS7 中的 Lifeact-mEmerald 用于 Figs.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     和
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     ；HeLa 细胞中使用的 Calnexin-mEmerald、Mito-dsRed 和 Halo-H2B 用于 Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ；HeLa-mEmerald-SC35 中的 H2B-mCherry 用于补充 Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     。
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     基因编辑细胞株
    </title>
    <p id="Par45">
     SUM159 细胞被顺序基因编辑以将 EGFP 融合到 Rab11A 的 N-端，然后将 Halo 融合到 Lamp1 的 C-端，使用 CRISPR/Cas9 方法
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     。单导向 RNA（sgRNA）靶序列为 RAB11A 的 5'-TCGCTCCTCGGCCGCGCAAT-3' 和 LAMP1 的 5'-CTATCTAGCCTGGTGCACGC-3'。SUM159 细胞被转染以 EGFP-Rab11A donnee 质粒、编码 spCas9 的质粒和含有 sgRNA 靶序列的自由 PCR 产物，使用 Lipofectamin 3000（Invitrogen）按照制造商的说明进行。表达 EGFP 的细胞被富集使用流式细胞仪（FACS）（FACSAria II，BD Biosciences），然后进行单细胞排序到 96 孔板中。单克隆细胞中成功融合 EGFP 的细胞被 PCR 筛选使用 GoTaq 聚合酶（Promega）识别。表达 EGFP-Rab11A +/+ 的 SUM159 单克隆细胞被进行第二轮基因编辑以将 Lamp1-Halo 融合到基因组中，如上所述。转染的细胞被 10 nM Janelia Fluor 646 HaloTag Ligands（Promega）染色 15 分钟。为了洗去未结合的染料，样品被用新鲜介质冲洗，然后被 FACS 富集。单克隆 SUM159 细胞同时表达 EGFP-Rab11A +/+ 和 Lamp1-Halo +/+ 被 PCR 和 Western blot 分析确认。
    </p>
    <p id="Par46">
     SUM159 细胞被基因编辑以将 EGFP 融合到轻链 A（clathrin-EGFP）的 C-端，使用 TALEN 基础方法
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     。表达 clathrin-EGFP 的细胞被两次顺序 bulk 排序富集。
    </p>
    <p id="Par47">
     HeLa 细胞系被基因编辑以将 mEmerald 融合到人类基因组 SC35 的 C-端，使用 CRISPR-Cas9 基因编辑系统。sgRNA 靶序列为 5'-CGAGCAGCACTCCTAATGAT-3'，并被连接到 pX330A-1×2（Addgene，58766）中。得到的质粒被命名为 pX330-SC35-gRNA。为了构建 donnee 质粒 p-SC35-doner，mEmerald 被 flank 以约 1800bp 的同源臂，同源臂与人类基因组 SC35 位点的停止密码子互补，被连接到 pEASY-blunt（Transgene，CB101）中。2 × 10^5 HeLa 细胞在 6 cm 容器中被转染以 1.2 μg 的 pX330-SC35-gRNA 和 0.4 μg 的 p-SC35-doner。48 小时后，mEmerald 阳性细胞被 FACS（FACSAria III，BD Biosciences）排序。一个星期后，H2B-mCherry 病毒被感染排序的细胞，然后单细胞被种植到 96 孔板中。两个星期后，不同单细胞克隆的基因组 DNA 被提取并被 PCR 和 Western blot 验证。同源 SC35 knock-in 细胞被选用进行研究。成功的 SC35 knock-in 被 PCR 和 Western blot 分析验证
     <sup/>
     。
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     <italic>
      C. elegans
     </italic>
     胚胎制备
    </title>
    <p id="Par48">
     <italic>
      C. elegans
     </italic>
     菌株在 20 °C 的 nematode 生长介质（NGM）板上培养，板上撒有 OP50，按照标准协议
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     进行。TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ；
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ；
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     被用在本研究中。质粒
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     被按照 Clontech In-Fusion PCR 克隆系统构建，并被微注射到
     <italic>
      jcIs1;qxIs257
     </italic>
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     中。外显子数组
     <italic>
      wyEx51119
     </italic>
     标记了表皮细胞膜。
     <italic>
      jcIs1
     </italic>
     标记了
     <italic>
      C. elegans
     </italic>
     的顶端连接域。
     <italic>
      qxIs257
     </italic>
     标记了表皮细胞中的溶酶体
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     。
    </p>
    <p id="Par49">
     大约50个L4阶段的转基因蠕虫被放在NGM平板上，新鲜的OP50被添加在48至60小时之前。转基因卵在解剖型荧光显微镜（Olympus MVX10）下被收集，并安装在3%的琼脂糖垫上。利马豆到2倍体阶段的胚胎随后使用我们的Multi-SIM系统的3D WF模式成像。
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     小鼠胚胎制备
    </title>
    <p id="Par50">
     本研究中使用的小鼠属于C57BL/6 J背景。所有动物实验均获得了中国科学院生物物理研究所动物护理和使用委员会（IACUC）的批准。超排卵的5-6周龄雌性小鼠通过腹腔注射5国际单位（IU）的妊娠马血清促性腺激素（PMSG；LEE BIOSOLUTIONS）和5 IU的人绒毛膜促性腺激素（hCG；Millipore），48小时后与雄性小鼠交配。受精卵在E0.5时在M2培养基（Millipore）中回收，并在CO2孵育器（Thermo Scientific）中以37°C和5% CO2的条件下培养在KSOM培养基（Millipore）中，直到晚期8细胞阶段。
    </p>
    <p id="Par51">
     对于免疫荧光，胚胎被固定在4%的多聚甲醛中，PBS中，30分钟，在室温（RT）下，并洗涤了三次PBS。胚胎随后被渗透在0.5%的TritonX-100（Sigma）中，PBS中，20分钟，在室温（RT）下，洗涤了三次PBS，封闭在1%的牛血清白蛋白中，PBS中，1小时，在室温（RT）下，并孵育过夜在4°C下，使用抗pERM抗体（Abcam，ab76247），抗α-管蛋白-FITC（Sigma，F2168-.2 ML）和菲罗定-罗丹明（Molecular Probes，R415）。然后，胚胎被洗涤三次PBS，孵育1小时在室温（RT）下，使用二级抗体（Life technologies），染色15分钟在室温（RT）下，使用Hoescht 33342（Thermo），洗涤三次PBS，并使用自制的共焦显微镜成像。
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     3D图像可视化
    </title>
    <p id="Par52">
     Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     中显示的溶酶体的轴向色彩编码图像是使用Fiji生成的。Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     中显示的有丝分裂细胞和小鼠胚胎的3D渲染图像是使用商业软件Amira生成的。
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     统计和重复性
    </title>
    <p id="Par53">
     Fig.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i，
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f，
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     和
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     中的实验均独立重复进行了至少3次标本，即细胞或胚胎，都获得了类似的结果。
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     报告摘要
    </title>
    <p id="Par54">
     有关研究设计的进一步信息，请参阅本文链接的
     <xref ref-type="supplementary-material" rid="MOESM13">
      Nature Portfolio Reporting Summary
     </xref>
     。
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    致谢
   </title>
   <p>
    作者感谢T. Kirchhausen提供用于基因编辑的供体质粒和帮助生成基因编辑细胞株，并感谢王晓晨教授和何康民博士提供
    <italic>
     C. elegans
    </italic>
    菌株和基因编辑SUM159细胞株。本工作得到了中国国家自然科学基金（32125024、32271513、62071271和62088102）、科学技术部（2021YFA1300303和2020AA0105500）、中国科学院（ZDBS-LY-SM004和XDA16021401）、中国科学院北京脑科学研究所合作研究基金（2021-NKX-XM-03）、中国博士后科学基金（2022M721842、2023T160365）、新基石科学基金、清华大学树木学者计划（2022SM035）和北京市自然科学基金（JQ21012）的资助。
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    作者贡献
   </title>
   <p>
    邱东和李冬指导了研究。邱东、李冬和常强提出并启动了这个项目。常强在邱东和李冬的指导下设计了详细的实施方案。张洋、常强和陈昕开发了python代码，进行了模拟，并处理了相关的成像数据。胡晨、常强和张洋开发了Fiji插件。田佳、王睿、常强、李航、付伟、李迪和贾刚准备了样本并进行了成像实验。常强、张洋、陈昕和乔琦分析了数据，在邱东、李冬、王军、王勇和胡强的概念建议下。常强、张洋和乔琦组装了图表和视频，并在邱东和李冬的监督下制作了教程主页。邱东、李冬和常强撰写了稿件，并得到了所有作者的意见。所有作者讨论了结果并对稿件进行了评论。
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    同行评议
   </title>
   <sec id="FPar1">
    <title>
     同行评议信息
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    数据可用性
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    代码可用性
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     竞争利益
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    参考文献
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      补充信息
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      源数据
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    补充信息
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
