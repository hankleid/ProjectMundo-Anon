<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/ProjectMundo/style/jats-html.xsl"?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     Aprendizaje de tiro cero habilita la reducción de ruido y super-resolución instantánea en microscopía de fluorescencia óptica
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Resumen
    </title>
    <p id="Par1">
     Los métodos de super-resolución computacional, incluyendo algoritmos analíticos convencionales y modelos de aprendizaje profundo, han mejorado sustancialmente la microscopía óptica. Entre ellos, las redes neuronales profundas supervisadas han demostrado un rendimiento sobresaliente, sin embargo, requieren una gran cantidad de datos de entrenamiento de alta calidad, lo cual es laborioso y a veces incluso impráctico de obtener debido a la alta dinámica de las células vivas. Aquí, desarrollamos redes de deconvolución de tiro cero (ZS-DeconvNet) que mejoran instantáneamente la resolución de las imágenes microscópicas en más de 1.5 veces sobre el límite de difracción con 10 veces menos fluorescencia que las condiciones de imagen de super-resolución ordinarias, de manera no supervisada sin la necesidad de verdades terrestres o adquisición de datos adicionales. Demostramos la aplicabilidad versátil de ZS-DeconvNet en múltiples modalidades de imagen, incluyendo microscopía de reflexión total interna de fluorescencia, microscopía de campo amplio tridimensional, microscopía confocal, microscopía de dos fotones, microscopía de lámina de luz en reja y microscopía de iluminación estructurada multimodal, lo que permite la imagen 2D/3D de alta resolución, multicolor y a largo plazo de procesos biológicos subcelulares, desde células mitóticas individuales hasta embriones multicelulares de ratón y
     <italic>
      C. elegans
     </italic>
     .
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    Introducción
   </title>
   <p id="Par3">
    La microscopía de fluorescencia óptica es una herramienta esencial para la investigación biológica. Los recientes avances en técnicas de super-resolución (SR) proporcionan una resolvencia sin precedentes para visualizar las finas estructuras dinámicas de diversos procesos biológicos
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
    </sup>
    . Sin embargo, la ganancia en resolución espacial mediante cualquier método SR conlleva compensaciones en otras métricas de imagen, por ejemplo, duración o velocidad, que son igualmente importantes para desentrañar procesos biológicos
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
    </sup>
    . Recientemente, los métodos computacionales de SR han ganado considerable atención por su capacidad para mejorar instantáneamente la resolución de las imágenes en silico, lo que permite una mejora significativa de los sistemas de microscopía de fluorescencia existentes y una extensión de su rango de aplicaciones
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    .
   </p>
   <p id="Par4">
    En general, los métodos computacionales de SR existentes se pueden clasificar en dos categorías: métodos basados en modelos analíticos, como algoritmos de deconvolución, y métodos basados en aprendizaje profundo, por ejemplo, redes neuronales de SR
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . La primera categoría a menudo emplea modelos analíticos que prescriben ciertas suposiciones sobre el espécimen y las propiedades de la imagen, por ejemplo, la escasez y la simetría local, para mejorar la resolución de la imagen con múltiples parámetros ajustables. El ajuste de parámetros es dependiente de la experiencia y consume tiempo, y las salidas de los modelos analíticos dependen en gran medida de los conjuntos de parámetros
    <sup>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     ,
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    . Además, en experimentos prácticos, los modelos elaborados con ciertas suposiciones no pueden abordar la complejidad estadística completa de la imagen microscópica, por lo que carecen de robustez y son propensos a generar artefactos, especialmente en condiciones de baja relación señal-ruido (SNR)
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    . Por otro lado, los métodos de SR basados en aprendizaje profundo (DLSR) han logrado un éxito asombroso en aprender la relación de transformación de imagen de extremo a extremo según grandes cantidades de datos ejemplares sin la necesidad de un modelo analítico explícito
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Cabe destacar que el esquema de inversión basado en datos a través del aprendizaje profundo puede aproximar no solo la función pseudoinversa del proceso de degradación de la imagen, sino también las características estocásticas de las soluciones de SR. Sin embargo, el entrenamiento de modelos DLSR requiere adquirir grandes cantidades de imágenes de entrada de baja resolución y de alta calidad y sus correspondientes imágenes de verdad terrestre (GT) de SR, lo cual es extremadamente laborioso y a veces incluso impráctico debido a la dinámica rápida o la baja SNR de fluorescencia en especímenes biológicos
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Además, el rendimiento de los métodos DLSR depende fuertemente de la calidad y cantidad de datos de entrenamiento
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Estos factores dificultan significativamente la amplia aplicación de los métodos DLSR en experimentos de imagen diarios, a pesar de su rendimiento de SR convincente en comparación con los métodos basados en modelos analíticos
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    .
   </p>
   <p id="Par5"/>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    Resultados
   </title>
   <sec id="Sec3">
    <title>
     Desarrollo y caracterización de ZS-DeconvNet
    </title>
    <p id="Par6"/>
    <p id="Par7">
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="es">
       <title>
        Redes de deconvolución de tiro cero.
       </title>
       <p>
        <bold>
         a
        </bold>
        La arquitectura de dos etapas de ZS-DeconvNet y el esquema de su fase de entrenamiento.
        <bold>
         b
        </bold>
        El esquema de la fase de inferencia de ZS-DeconvNet.
        <bold>
         c
        </bold>
        Imágenes representativas de SR de Lisos y MTs reconstruidas por deconvolución RL (segunda columna), deconvolución dispersa (tercera columna) y ZS-DeconvNet (cuarta columna). Las imágenes WF claras se muestran como referencia.
        <bold>
         d
        </bold>
        Comparaciones estadísticas de deconvolución RL, deconvolución dispersa y ZS-DeconvNet en términos de PSNR y resolución (
        <italic>
         n
        </italic>
        = 100 regiones de interés).
        <bold>
         e
        </bold>
        Comparaciones de ancho a media altura (FWHM) de imágenes WF claras y imágenes procesadas mediante deconvolución RL, deconvolución dispersa y ZS-DeconvNet (
        <italic>
         n
        </italic>
        = 30 microtúbulos). El límite teórico de difracción se etiqueta con una línea punteada gris para referencia.
        <bold>
         f
        </bold>
        Comparación de tiempo de prueba entre deconvolución dispersa basada en GPU y ZS-DeconvNet (promedio de 25 imágenes de prueba de 1024 × 1024 píxeles). Línea central, medianas; límites, 75% y 25%; bigotes, el valor más grande entre el punto de datos más grande y el percentil 75 más 1.5× el rango intercuartil (IQR), y el valor más pequeño entre el punto de datos más pequeño y el percentil 25 menos 1.5× el IQR; valores atípicos, puntos de datos mayores que el bigote superior o menores que el bigote inferior. Los datos de origen se proporcionan como un archivo de datos de origen. Barra de escala, 1.5 μm (
        <bold>
         a
        </bold>
        ), 5 μm (
        <bold>
         c
        </bold>
        ), 2 μm (regiones ampliadas en (
        <bold>
         c
        </bold>
        )).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig1_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par8">
     Para caracterizar y evaluar ZS-DeconvNet, primero simulamos las imágenes microscópicas de estructuras puntuales y tubulares contaminadas por ruido Gaussiano-Poisson a niveles de señal crecientes desde 5 hasta 25 cuentas de fotones promedio, lo que nos permitió probar sistemáticamente cómo los ajustes de los hiperparámetros de recorrupción en diferentes condiciones de imagen influyen en las salidas finales (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      2
     </xref>
     ). Encontramos que los hiperparámetros óptimos son teóricamente independientes del contenido de la imagen y los niveles de señal (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      5
     </xref>
     ), lo que permite una aplicación robusta de ZS-DeconvNet en diversos especímenes biológicos y configuraciones de imagen (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ). A continuación, comparamos el rendimiento de los modelos ZS-DeconvNet entrenados con datos aumentados mediante la recorrupción de una sola imagen ruidosa con algoritmos de deconvolución analítica o modelos entrenados con múltiples imágenes simuladas o adquiridas de manera independiente. Para hacerlo, empleamos el modo de iluminación de reflexión total interna de fluorescencia (TIRF) de nuestra microscopía de iluminación estructurada multimodal (Multi-SIM) para adquirir ~20 conjuntos de imágenes TIRF limitadas por difracción a baja y alta SNR para cada estructura subcelular de lisosomas (Lyso) y microtúbulos (MTs), de las cuales las imágenes de baja SNR se utilizaron para entrenamiento y prueba, mientras que sus contrapartes de alta SNR sirvieron como referencia (Methods). Encontramos que la relación señal-ruido pico (PSNR) y la resolución de las imágenes ZS-DeconvNet fueron sustancialmente mejores que las generadas por algoritmos analíticos, como el clásico Richardson-Lucy (RL) y la deconvolución dispersa más reciente (Fig.
     <xref ref-type="fig" rid="Fig1">
      1c–e
     </xref>
     ) y la tasa de throughput de un ZS-DeconvNet bien entrenado es &gt;100 veces mayor que la del algoritmo de deconvolución dispersa (Fig.
     <xref ref-type="fig" rid="Fig1">
      1f
     </xref>
     ). En particular, incluso si ZS-DeconvNet se entrenó con datos aumentados a partir de una sola imagen de entrada, la calidad perceptual y las métricas cuantificadas de sus imágenes de salida fueron comparables con las imágenes del modelo entrenado con cantidades mayores de datos (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      6
     </xref>
     ). Además, validamos la mejora de la resolución, la cuantificabilidad y la capacidad de generalización de ZS-DeconvNet (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      7
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      10
     </xref>
     ), y lo comparamos con el modelo supervisado DFCAN (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      11
     </xref>
     ) en datos sintéticos y experimentales. Estas caracterizaciones demuestran que ZS-DeconvNet es capaz de generar imágenes DLSR de alta calidad con una mejora de resolución de 1.5 veces en relación con el límite de difracción mientras utiliza la menor cantidad de datos de entrenamiento, lo que tiene un gran potencial para mejorar el rendimiento de imagen de diversos sistemas microscópicos y extender su aplicabilidad a una amplia variedad de procesos biológicos que son desafiantes para los métodos convencionales
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     Observación a largo plazo de procesos biológicos sensibles a la fototoxicidad
    </title>
    <p id="Par9">
     La adhesión y migración celular son esenciales en los procesos morfogenéticos y contribuyen a muchas enfermedades
     <sup>
      <xref ref-type="bibr" rid="CR31">
       31
      </xref>
     </sup>
     . Visualizar la dinámica del citoesqueleto a alta resolución durante el proceso de adhesión/migración es crucial para esclarecer el mecanismo subyacente. Sin embargo, debido a la alta fotosensibilidad, los procesos completos de adhesión y migración celular se registran típicamente a bajas tasas de cuadros, es decir, varios segundos por cuadro, y a intensidades de luz bajas
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR32">
       32
      </xref>
     </sup>
     . Bajo estas condiciones de imagen, ya sea la deconvolución RL o el aprendizaje supervisado basado en la continuidad temporal (Methods) fallan en recuperar y afilar la estructura intrincada del F-actina y la miosina-II (Fig.
     <xref ref-type="fig" rid="Fig2">
      2a
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      12
     </xref>
     , y Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM4">
      1
     </xref>
     ). En contraste, el modelo ZS-DeconvNet mejora eficazmente tanto la SNR como la resolución de las grabaciones de tiempo-lapse de dos colores del proceso de expansión celular
     <sup>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
     </sup>
     .
    </p>
    <p id="Par10">
     de expansión celular después de depositar una célula que coexpresa mEmerald-Lifeact y mCherry-myosin-IIA sobre un cubrecristal (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     y Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Intrigantemente, observamos que en ciertas sustancias, las células se arrastraban alrededor del sitio de contacto para explorar el entorno antes de expandirse y adherirse (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     y Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). El arrastre celular se precedía por la acumulación polarizada de miosina-II en la parte posterior de la célula, lo que llevaba a la migración celular en la dirección opuesta impulsada por la contracción posterior de la miosina-II. Además, la dirección de migración podía cambiar rápidamente en respuesta a la redistribución dinámica de la miosina-II dentro de la célula (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Estos resultados demuestran que la cinética de la adhesión y migración celular puede registrarse fielmente mediante la imagen asistida por ZS-DeconvNet sin perturbar este proceso largo y vulnerable.
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     Visualización de la dinámica rápida del sistema endolisisomal
    </title>
    <p id="Par11"/>
    <p id="Par12"/>
   </sec>
   <sec id="Sec6">
    <title>
     3D ZS-DeconvNet para microscopía de lámina de luz en reja
    </title>
    <p id="Par13">
     La imagen tridimensional de células vivas transmite más información biológica que las observaciones 2D; sin embargo, está sujeta a una fototoxicidad, foto-bleaching y contaminación de fluorescencia fuera de enfoque mucho más severas. Para extender la capacidad superior de ZS-DeconvNet a la imagen de super-resolución tridimensional, mejoramos el núcleo de la arquitectura de red de dos etapas a un 3D RCAN, que se ha demostrado ser adecuado para la restauración de imágenes tridimensionales (Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     y Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ). A continuación, integramos nuestro esquema de aprendizaje auto-supervisado espacialmente entrelazado propuesto previamente con el solucionador de problemas inversos auto-supervisados informado por el modelo físico para construir el 3D ZS-DeconvNet. El 3D ZS-DeconvNet con el esquema auto-supervisado espacialmente entrelazado sigue un procedimiento de aumento de datos más simple (Métodos), mientras logra un rendimiento comparable o incluso mejor que la estrategia basada en recorruption (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="es">
       <title>
        Caracterizaciones y demostraciones de 3D ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        La arquitectura de la red 3D ZS-DeconvNet y el esquema de su fase de entrenamiento.
        <bold>
         b
        </bold>
        El esquema de la fase de inferencia de 3D ZS-DeconvNet.
        <bold>
         c
        </bold>
        Imágenes representativas de proyección de máxima intensidad (MIP) de SR de F-actina, membrana externa de mitocondrias y ER reconstruidas por deconvolución dispersa (segunda columna), 3D ZS-DeconvNet (tercera columna) y LLS-SIM (cuarta columna). Se etiquetan en la esquina superior derecha los conteos promedio de sCMOS de los píxeles del 1% más altos de las imágenes crudas antes del procesamiento.
        <bold>
         d
        </bold>
        Comparaciones estadísticas de la deconvolución RL, deconvolución dispersa y ZS-DeconvNet en términos de PSNR y resolución en diferentes especímenes (
        <italic>
         n
        </italic>
        = 40 regiones de interés). La resolución se midió mediante el análisis de correlación de anillos de Fourier
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        con pilas de imágenes de F-actina. Línea central, medianas; límites, 75% y 25%; bigotes, máximo y mínimo. Los datos de origen se proporcionan como un archivo de datos de origen.
        <bold>
         e
        </bold>
        Imágenes de renderizado 3D de tres colores reconstruidas a través de 3D ZS-DeconvNet de ER, H2B y mitocondrias, mostrando sus transformaciones en morfología y distribución, así como dinámicas de interacción durante la mitosis (Suplemento Video
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ).
        <bold>
         f
        </bold>
        Imágenes representativas de tres colores obtenidas con LLSM convencional (primera columna), deconvolución dispersa (segunda columna), deconvolución basada en DeepCAD (tercera columna) (Métodos), y 3D ZS-DeconvNet (cuarta columna). Las comparaciones se realizan en dos puntos de tiempo típicos de los datos de tiempo-lapse mostrados en (
        <bold>
         e
        </bold>
        ). Barra de escala, 5 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         e
        </bold>
        ,
        <bold>
         f
        </bold>
        ), 1.5 μm (regiones ampliadas de
        <bold>
         c
        </bold>
        ), 2 μm (regiones ampliadas de
        <bold>
         f
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     Evaluamos sistemáticamente el modelo 3D ZS-DeconvNet con conjuntos de datos de tres especímenes biológicos diferentes adquiridos mediante nuestra microscopía de iluminación estructurada de lámina de luz (LLS-SIM) de fabricación propia, en la cual los datos limitados por difracción adquiridos en el modo de microscopía de lámina de luz (LLSM) se utilizaron para el entrenamiento mientras que los contrapartes de SR adquiridos en el modo LLS-SIM sirvieron como referencias (Métodos). Encontramos que 3D ZS-DeconvNet reconstruyó con éxito los filamentos elaborados del actina F, la estructura hueca de la membrana externa mitocondrial (Mito) y las redes intrincadas del retículo endoplásmico (ER) con alta fidelidad y resolución comparable a las imágenes LLS-SIM adquiridas bajo condiciones de alta SNR (Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ). Las cuantificaciones de PSNR y resolución ilustran que el modelo 3D ZS-DeconvNet supera sustancialmente a los enfoques convencionales basados en modelos analíticos en diversos especímenes biológicos (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ). Demostramos que al entrenar con los propios volúmenes de imágenes ruidosas, el 3D ZS-DeconvNet de dos etapas no solo generó resultados desruidos comparables a las técnicas de desruido auto-supervisado de vanguardia (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ), sino que también proporcionó volúmenes de imágenes de super-resolución con una mejora significativa en la resolución de más de 1.5 veces tanto lateralmente (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ) como axialmente (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ). Además, al incorporar secuencialmente métodos de mejora de resolución axial basados en aprendizaje automático, la resolución axial puede mejorarse aún más (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     Imágenes de super-resolución volumétrica a largo plazo habilitadas por 3D ZS-DeconvNet
    </title>
    <p id="Par15"/>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet para microscopía confocal y de campo amplio
    </title>
    <p id="Par16">
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="es">
       <title>
        Generalización de ZS-DeconvNet a múltiples modalidades de imagen.
       </title>
       <p>
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        Imágenes representativas de confocal (superior izquierda), deconvolución dispersa (inferior izquierda) y mejoradas por 3D ZS-DeconvNet (derecha) de un embrión de ratón temprano inmunotintado para microtúbulos (cian), cromosomas (naranja), anillos de actina (magenta) y dominio apical (verde).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Regiones ampliadas de puentes de microtúbulos (c) y anillos de actina (d) etiquetados con cajas de puntos discontinuos blancos en (
        <bold>
         a
        </bold>
        ) y (
        <bold>
         b
        </bold>
        ) adquiridas mediante microscopía confocal, deconvolución dispersa y 3D ZS-DeconvNet.
        <bold>
         e
        </bold>
        Imágenes representativas de WF (región central) y mejoradas por 3D ZS-DeconvNet (región circundante) de un embrión de
        <italic>
         C. elegans
        </italic>
        con unión apical, membrana celular (cian) y lisosomas (rojos) etiquetados.
        <bold>
         f
        </bold>
        ,
        <bold>
         g
        </bold>
        Canal de lisosomas de la región central en (
        <bold>
         e
        </bold>
        ) codificado por color según la distancia desde el sustrato. Se muestran tanto las imágenes de WF (
        <bold>
         f
        </bold>
        ) como las procesadas por 3D ZS-DeconvNet (
        <bold>
         g
        </bold>
        ) para comparación.
        <bold>
         h
        </bold>
        Imágenes de tiempo-lapse mejoradas por 3D ZS-DeconvNet que muestran el proceso de fusión de células hipodérmicas (flechas rojas) durante el desarrollo de un embrión de
        <italic>
         C. elegans
        </italic>
        . Barra de escala, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        ,
        <bold>
         e
        </bold>
        ), 2 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 3 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         h
        </bold>
        ), 1 μm (región ampliada de
        <bold>
         g
        </bold>
        ). Valor gamma, 0.7 para la membrana celular y lisosomas en el embrión de
        <italic>
         C. elegans
        </italic>
        .
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17"/>
   </sec>
   <sec id="Sec9">
    <title>
     Reducción de ruido y mejora de resolución en imágenes SIM multimodales
    </title>
    <p id="Par18">
     Entre las diversas formas de microscopía de super-resolución (SR), la microscopía de iluminación estructurada (SIM) es a menudo reconocida como una opción equilibrada para la imagen de células vivas de SR, ya que necesita menos de diez imágenes moduladas en bruto para proporcionar una mejora de dos veces en la resolución espacial
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     . Sin embargo, la SIM convencional tiene dos limitaciones críticas: en primer lugar, una mayor mejora en la resolución requiere una cantidad considerablemente mayor de datos en bruto, es decir, se necesitan al menos 25 imágenes en bruto para la SIM no lineal para obtener una resolución sub-80 nm; en segundo lugar, la postreconstrucción de las imágenes de SIM generalmente requiere imágenes en bruto con un SNR alto para eliminar los artefactos de reconstrucción inducidos por el ruido, lo que perjudica la imagen rápida, de baja luz y a largo plazo de células vivas
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     . Estudios recientes han explorado enfoques de aprendizaje supervisado, ya sea para reducir el ruido de las imágenes de SIM o para reconstruir imágenes de SR de SIM directamente a partir de imágenes en bruto ruidosas para lograr la reconstrucción de SIM de baja luz; sin embargo, estos métodos requieren una gran cantidad de datos de entrenamiento y no mejoran aún más la resolución. A la luz de la excelente capacidad de reducción de ruido y SR de ZS-DeconvNet, integramos el esquema de aprendizaje de tiro cero con el algoritmo de reconstrucción de SIM convencional, y demostramos teóricamente que ZS-DeconvNet es adecuado para procesar las imágenes de SR-SIM (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Diseñamos el modelo ZS-DeconvNet mejorado SIM (ZS-DeconvNet-SIM) para reducir el ruido y mejorar simultáneamente las imágenes de SR SIM de manera no supervisada (Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     , y Métodos). Gracias a la notable mejora en SNR y resolución proporcionada por ZS-DeconvNet-SIM (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ), la estructura hueca de las cavidades revestidas de clathrin (CCPs) en una célula SUM-159 y los citoesqueletos densamente entrelazados en una célula COS-7, que son indistinguibles en las imágenes de WF y SIM convencionales, se resolvieron claramente (Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ). Además, demostramos que el ZS-DeconvNet-SIM puede aplicarse en la modalidad 3D-SIM para reducir el ruido y mejorar simultáneamente las imágenes de 3D-SIM en ambos ejes lateral y axial (Métodos, Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     .
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="es">
       <title>
        Supresión de ruido y mejora de resolución en datos de SIM multimodal.
       </title>
       <p>
        <bold>
         a
        </bold>
        Esquema del procedimiento de entrenamiento de ZS-DeconvNet para SIM.
        <bold>
         b
        </bold>
        Progresión de la mejora de SNR y resolución a través de los CCPs en una célula SUM-159, desde imágenes SIM crudas (izquierda), imagen SIM convencional (derecha) y imagen SIM mejorada por ZS-DeconvNet (centro).
        <bold>
         c
        </bold>
        Progresión de la mejora de SNR y resolución a través de los microtúbulos en una célula COS-7, desde imágenes SIM crudas (izquierda), imagen SIM convencional (derecha) y imagen SIM mejorada por ZS-DeconvNet (centro).
        <bold>
         d
        </bold>
        Imágenes representativas de proyección de máxima intensidad (MIP) de F-actina en una célula HeLa obtenidas mediante LLSM, LLS-SIM y LLS-SIM mejorada por 3D ZS-DeconvNet en tres dimensiones.
        <bold>
         e
        </bold>
        , Imágenes representativas de MIP de la membrana externa de mitocondrias etiquetada con TOMM20 en una célula 293 T obtenidas mediante LLSM, LLS-SIM y LLS-SIM mejorada por 3D ZS-DeconvNet en tres dimensiones. Barra de escala, 1 μm (
        <bold>
         a
        </bold>
        ), 2 μm (
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 0.5 μm (regiones ampliadas en
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 3 μm (
        <bold>
         d
        </bold>
        ,
        <bold>
         e
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig5_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par19">
     Además, integramos 3D ZS-DeconvNet con LLS-SIM para desarrollar la modalidad 3D ZS-DeconvNet-SIM (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ). Al incorporar la PSF anisotrópica de la LLS-SIM convencional en el proceso de entrenamiento, 3D ZS-DeconvNet LLS-SIM no solo mejoró notablemente el contraste y la resolución en las tres dimensiones, sino que también proporcionó una resolución lateral isotrópica de aproximadamente ~150 nm (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     , y Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ). Estas aplicaciones exitosas de ZS-DeconvNet en sistemas SIM multimodales demuestran su capacidad para ampliar aún más el ancho de banda de resolución espacio-temporal de las técnicas de SR existentes
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     .
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    Discusión
   </title>
   <p id="Par20">
    El objetivo final de la imagen en vivo es recopilar la mayor cantidad de información espacio-temporal sobre los procesos biológicos con la menor invasividad posible en los especímenes biológicos. Sin embargo, las restricciones mutuas entre la velocidad de imagen, la duración, la resolución y el SNR en la microscopía de fluorescencia resultan en una limitación del ancho de banda espacio-temporal, lo que limita la mejora sinérgica en todos estos aspectos. Por ejemplo, para obtener una mayor resolución espacial, las técnicas de SR convencionales deben basarse en adquisiciones repetitivas o en excitación adicional, lo cual agrava la fototoxicidad y la foto-bleaching, impidiendo observaciones rápidas y a largo plazo de los procesos biológicos. Para abordar las limitaciones del ancho de banda espacio-temporal en la microscopía, realizamos un análisis en profundidad de la propagación del ruido en el modelo de imagen óptica y la reconstrucción de SIM (Supplementary Note
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ), demostramos la convergencia de la función de pérdida auto-supervisada integrada con recorruption en ambos escenarios ordinarios y SIM basados en la linealidad de la convolución de PSF, y propusimos el marco ZS-DeconvNet versátil, que puede incorporarse a diversos microscopios de fluorescencia óptica para mejorar instantáneamente el SNR y la resolución de las imágenes sin comprometer otras propiedades de imagen. Enfatizamos que la aplicación de ZS-DeconvNet es robusta a los hiperparámetros en el proceso de recorruption de imágenes (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ) y que ZS-DeconvNet puede entrenarse bien con solo una rebanada o pila de imágenes en bruto (Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ) sin usar supuestos de escasez estructural y continuidad temporal
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    . Las evaluaciones cualitativas y cuantitativas tanto en datos simulados como experimentales muestran que nuestros métodos mejoran sustancialmente la calidad y la resolución de las imágenes en más de 1.5 veces con alta fidelidad y cuantificabilidad, incluso en condiciones de baja luz, lo que permite observaciones de alta resolución, rápidas y a largo plazo de múltiples dinámicas subcelulares.
   </p>
   <p id="Par21"/>
   <p id="Par22"/>
   <p id="Par23"/>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    Métodos
   </title>
   <sec id="Sec12">
    <title>
     Sistema Multi-SIM
    </title>
    <p id="Par24"/>
   </sec>
   <sec id="Sec13">
    <title>
     Sistema LLS-SIM
    </title>
    <p id="Par25"/>
   </sec>
   <sec id="Sec14">
    <title>
     Sistema confocal
    </title>
    <p id="Par26"/>
   </sec>
   <sec id="Sec15">
    <title>
     Arquitecturas y funciones objetivas de ZS-DeconvNet
    </title>
    <p id="Par27"/>
    <p id="Par28"/>
    <p id="Par29">
     Es importante destacar que, dado que la base teórica de ZS-DeconvNet es agnóstica al modelo, tanto U-Net como RCAN no son los únicos modelos de columna vertebral aplicables, sino los más adoptados y eficientes. Equipar ZS-DeconvNet con otras arquitecturas de red de vanguardia, como DFCAN y RLN, puede mejorar aún más su capacidad de reducción de ruido y super-resolución
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     Implementación de 2D ZS-DeconvNet
    </title>
    <p id="Par30"/>
    <p id="Par31"/>
   </sec>
   <sec id="Sec17">
    <title>
     Implementación de 3D ZS-DeconvNet
    </title>
    <p id="Par32"/>
   </sec>
   <sec id="Sec18">
    <title>
     Implementación de 2D/3D ZS-DeconvNet-SIM
    </title>
    <p id="Par33"/>
   </sec>
   <sec id="Sec19">
    <title>
     Uso y generación de PSF
    </title>
    <p id="Par34">
     En el procedimiento de entrenamiento de ZS-DeconvNet, utilizamos PSFs (funciones de dispersión puntual) adquiridas experimentalmente o simuladas (con el complemento PSF Generator de Fiji, licenciado por EPFL) que corresponden a las configuraciones de imagen. Se entrenaron modelos ZS-DeconvNet independientes para cada estructura biológica y longitud de onda de emisión para obtener el mejor rendimiento.
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     Entrenamiento de modelos y adaptación en tiempo de prueba
    </title>
    <p id="Par35">
     En este trabajo, los modelos ZS-DeconvNet se entrenaron en una PC con un procesador Intel Core i7-11700 y una tarjeta gráfica RTX 3090 (NVIDIA) bajo el entorno de software TensorFlow 2.5.0 y Python 3.9.7. Antes del entrenamiento, las imágenes de entrada/GT emparejadas se aumentaron en varios pares de parches mediante recorte aleatorio, volteo horizontal/vertical y transformación de rotación para enriquecer aún más el conjunto de datos de entrenamiento, lo que finalmente generó ~20,000 pares de parches 2D (128
     <inline-formula id="IEq35">
      <alternatives>
       <math id="IEq35_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq35_TeX">
        \documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym}\usepackage{amsfonts}\usepackage{amssymb}\usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq35.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     128 píxeles) o ~10,000 pares de parches 3D (64
     <inline-formula id="IEq36">
      <alternatives>
       <math id="IEq36_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq36_TeX">
        \documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym}\usepackage{amsfonts}\usepackage{amssymb}\usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq36.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     64
     <inline-formula id="IEq37">
      <alternatives>
       <math id="IEq37_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq37_TeX">
        \documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym}\usepackage{amsfonts}\usepackage{amssymb}\usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq37.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     13 voxels). El entrenamiento se realizó típicamente con el optimizador Adam y una tasa de aprendizaje inicial de
     <inline-formula id="IEq38">
      <alternatives>
       <math id="IEq38_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mn>
         0.5
        </mn>
        <mo>
         ×
        </mo>
        <msup>
         <mrow>
          <mn>
           10
          </mn>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           4
          </mn>
         </mrow>
        </msup>
       </math>
       <tex-math id="IEq38_TeX">
        \documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym}\usepackage{amsfonts}\usepackage{amssymb}\usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$0.5\times {10}^{-4}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq38.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , que decay con un factor de 0.5 cada 10,000 iteraciones. El tamaño del lote de entrenamiento fue 4 para imágenes 2D y 3 para pilas 3D. El proceso de entrenamiento completo generalmente requería 50,000 iteraciones para imágenes 2D y 10,000 iteraciones para pilas 3D. El tiempo transcurrido para entrenar 50,000 iteraciones para modelos 2D y 10,000 iteraciones para modelos 3D fue ~1 h y ~2 h, respectivamente. Como suele ser el caso con la mayoría de los métodos basados en aprendizaje profundo, el entrenamiento de ZS-DeconvNet es un procedimiento de una sola vez en la mayoría de los casos de imagen de células vivas, donde los usuarios entrenan el modelo ZS-DeconvNet con todos los marcos, y luego los modelos bien entrenados son aplicables a todos los datos del mismo especímen biológico a una alta velocidad de procesamiento. Para eliminar los artefactos de borde inducidos por la deconvolución, típicamente agregamos 2 rebanadas en blanco en la parte superior e inferior de las pilas 3D y un margen de 8 píxeles para cada rebanada xy en ambos procesos de entrenamiento e inferencia (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      30a
     </xref>
     ). Particularmente, al procesar los datos de tiempo-lapse de la mitosis celular (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     ), la propiedad no supervisada de ZS-DeconvNet permitió una estrategia de aprendizaje de adaptación en tiempo de prueba en la que primero entrenamos un modelo general para cada estructura biológica con datos del proceso completo y luego ajustamos el modelo pre-entrenado para cada punto de tiempo con un pequeño número de pasos de entrenamiento (típicamente 50 iteraciones que toman ~1 min) para aprovechar completamente la información estructural de los datos brutos y obtener el mejor rendimiento de SR. Cabe señalar que la adaptación en tiempo de prueba no es necesaria, sino una técnica opcional para mejorar el rendimiento de ZS-DeconvNet, especialmente en circunstancias en las que hay cambios morfológicos importantes en los especímenes biológicos durante la ventana de observación, por ejemplo, los cromosomas durante la mitosis (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      31
     </xref>
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
     </sup>
     ).
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     Post-procesamiento de datos y evaluación de imágenes de super-resolución
    </title>
    <p id="Par36"/>
    <p id="Par37"/>
    <p id="Par38"/>
    <p id="Par39">
     La transformación lineal se aplica a todos los métodos para una comparación justa; (3) Calculando el PSNR entre la imagen GT normalizada
     <bold>
      x
     </bold>
     y la imagen transformada linealmente
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym}\n\\usepackage{amsfonts}\n\\usepackage{amssymb}\n\\usepackage{amsbsy}\n\\usepackage{mathrsfs}\n\\usepackage{upgreek}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     .
    </p>
    <p id="Par40">
     Para la evaluación de PSNR de 3D ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ), utilizamos directamente las imágenes LLS-SIM como referencia, ya que tanto LLS-SIM como nuestro 3D ZS-DeconvNet proporcionan una mejora de resolución de ~1.5 veces teóricamente. El proceso de cálculo general es similar a los casos 2D, excepto que las pilas SR no se convolucionaron y el PSNR solo se calculó en las regiones de características con un umbral de 0.02 para evitar obtener un valor anormalmente alto de PSNR.
    </p>
    <p id="Par41"/>
   </sec>
   <sec id="Sec22">
    <title>
     Cultivo de células, transfección y tinción
    </title>
    <p id="Par42"/>
    <p id="Par43"/>
    <p id="Par44">
     Para el empaquetado de lentivirus, 1 μg de ADN del vector de transferencia de lentivirus, junto con 0.5 μg de ADN del plásmido de embalaje psPAX2 y 0.5 μg de ADN del plásmido de envoltura pMD2.G, fueron co-transfectados a células HEK293T en un 90% de confluencia en un plato de Petri de 6 cm usando Lipofectamine 3000 siguiendo el protocolo del fabricante. Después de 2 días, el sobrenadante fue recolectado y filtrado con un filtro de 0.22-μm (Millipore). Para la construcción de células estables, las células HeLa y Cos7 fueron infectadas con lentivirus que codifican el marcador del retículo endoplásmico Calnexin-mEmerald y el marcador de F-actina Lifeact-mEmerald
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     . Cuarenta y ocho horas después, las células fueron enriquecidas mediante citómetro de flujo (FACSAria III, BD Biosciences) y luego sembradas una célula por pozo en placas de 96 pozos. Las células monoclonales se utilizaron para nuestros experimentos. Específicamente, Lifeact-mEmerald para COS7 utilizada en Figs.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     y
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     ; Calnexin-mEmerald, Mito-dsRed y Halo-H2B para células HeLa utilizadas en Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ; H2B-mCherry para HeLa-mEmerald-SC35 utilizada en Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     Líneas celulares editadas genéticamente
    </title>
    <p id="Par45">
     Las células SUM159 fueron editadas genéticamente secuencialmente para incorporar EGFP al N-terminal de Rab11A y luego Halo al C-terminal de Lamp1 utilizando el enfoque CRISPR/Cas9
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     . Las secuencias de guía de ARN (sgRNA) de objetivo son 5’-TCGCTCCTCGGCCGCGCAAT-3’ para RAB11A y 5’-CTATCTAGCCTGGTGCACGC-3’ para LAMP1. Las células SUM159 fueron transfectadas con el plásmido donante EGFP-Rab11A, el plásmido que codifica spCas9 y el producto de PCR libre que contiene la secuencia de guía sgRNA utilizando Lipofectamin 3000 (Invitrogen) según las instrucciones del fabricante. Las células que expresan EGFP fueron enriquecidas mediante citometría de flujo activada por fluorescencia (FACS) (FACSAria II, BD Biosciences), y luego sometidas a clasificación de células individuales en placas de 96 pozos. Las células monoclonales con incorporación exitosa de EGFP fueron identificadas mediante cribado de PCR utilizando GoTaq Polymerase (Promega). Las células clonales SUM159 que expresan EGFP-Rab11A + /+ fueron sometidas a una segunda ronda de edición genómica para incorporar Lamp1-Halo en el genoma como se describe arriba. Las células transfectadas fueron teñidas con 10 nM de Janelia Fluor 646 HaloTag Ligands (Promega) durante 15 min. Para lavar el tinte no unido, las muestras fueron enjuagadas con medio fresco y luego enriquecidas mediante FACS. Las células monoclonales SUM159 que expresan tanto EGFP-Rab11A + /+ como Lamp1-Halo + /+ fueron confirmadas mediante PCR y análisis de Western blot.
    </p>
    <p id="Par46">
     Las células SUM159 fueron editadas genéticamente para incorporar EGFP al C-terminal de la cadena ligera A de clathrin (clathrin-EGFP) utilizando el enfoque basado en TALEN
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     . Las células que expresan clathrin-EGFP fueron enriquecidas mediante dos clasificaciones en bloque secuenciales.
    </p>
    <p id="Par47">
     Las líneas de células HeLa fueron editadas genéticamente para incorporar mEmerald al C-terminal del SC35 genómico humano utilizando el sistema de edición génica CRISPR-Cas9. La secuencia de guía de ARN (sgRNA) de objetivo es 5’-CGAGCAGCACTCCTAATGAT-3’, y el sgRNA fue ligado a pX330A-1×2 (Addgene, 58766). El plásmido resultante fue nombrado pX330-SC35-gRNA a partir de entonces. Para construir el vector donante p-SC35-doner, mEmerald flanqueado con aproximadamente 1800bp de brazos de homología complementarios al codón de stop del locus SC35 genómico humano fueron ligados a pEASY-blunt (Transgene, CB101). 2 × 10 células HeLa cultivadas en un plato de Petri de 6 cm fueron transfectadas con 1.2 μg de pX330-SC35-gRNA y 0.4 μg de p-SC35-doner. 48 h después de la transfección, las células positivas para mEmerald fueron clasificadas mediante FACS (FACSAria III, BD Biosciences). Después de una semana, las células clasificadas fueron infectadas con lentivirus H2B-mCherry y luego sembradas células individuales en placas de 96 pozos. Después de dos semanas, el ADN génico de diferentes clones de células individuales fue extraído y validado mediante PCR y Western blot. Las células knock-in homocigotas de SC35 fueron seleccionadas para el estudio. El knock-in exitoso de SC35 fue verificado mediante PCR y análisis de Western blot
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     <italic>
      C. elegans
     </italic>
     preparación de embriones
    </title>
    <p id="Par48">
     <italic>
      C. elegans
     </italic>
     cepas fueron cultivadas a 20 °C en placas de medio de crecimiento de nematodos (NGM) sembradas con OP50 siguiendo protocolos estándar
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     . TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ;
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ;
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     fue utilizado en este estudio. El plásmido
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     fue construido siguiendo el sistema de clonación PCR In-Fusion de Clontech y microinyectado en
     <italic>
      jcIs1;qxIs257
     </italic>
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     . El array extracromosómico
     <italic>
      wyEx51119
     </italic>
     marcó la membrana celular epitelial.
     <italic>
      jcIs1
     </italic>
     marcó el dominio de la unión apical de
     <italic>
      C. elegans
     </italic>
     <italic>
      . qxIs257
     </italic>
     marcó los lisosomas en las células epiteliales
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     .
    </p>
    <p id="Par49">
     Aproximadamente 50 gusanos transgénicos en la etapa L4 fueron colocados en placas NGM con OP50 fresco 48 a 60 h antes de los experimentos. Los huevos transgénicos fueron recolectados bajo el microscopio fluorescente de disección (Olympus MVX10) y montados en almohadillas de agarosa al 3%. Los embriones en la etapa de frijol de Lima a 2 veces fueron luego imagenados utilizando el modo 3D WF de nuestro sistema Multi-SIM.
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     Preparación de embriones de ratón
    </title>
    <p id="Par50">
     Los ratones utilizados en este estudio tenían un fondo C57BL/6 J. Todos los experimentos con animales fueron aprobados por los Comités de Cuidado y Uso de Animales (IACUC) del Instituto de Biología Física, Academia China de Ciencias, Beijing, China. Los embriones preimplantacionales fueron aislados de hembras de 5-6 semanas de edad, superovuladas mediante inyección intraperitoneal de 5 unidades internacionales (UI) de gonadotropina sérica de yeguas preñadas (PMSG; LEE BIOSOLUTIONS) y 5 UI de gonadotropina coriónica humana (hCG; Millipore) 48 h después, y apareadas con ratones machos. Los cigotos fueron recuperados a E0.5 en medio M2 (Millipore) y cultivados en medio KSOM (Millipore) en incubadora de CO2 (Thermo Scientific) a 37°C con 5% de CO2 hasta la etapa de 8 células tardía.
    </p>
    <p id="Par51">
     Para la inmunofluorescencia, los embriones fueron fijados con paraformaldehído al 4% en PBS durante 30 min a temperatura ambiente (RT) y lavados con PBS tres veces. Luego, los embriones fueron permeabilizados con TritonX-100 al 0.5% (Sigma) en PBS durante 20 min a RT, lavados con PBS tres veces, bloqueados con albúmina bovina al 1% en PBS durante 1 h a RT e incubados con anticuerpo anti-pERM (Abcam, ab76247), anti-alpha-tubulina-FITC (Sigma, F2168-.2 ML) y Fitaloidina-Rodamina (Molecular Probes, R415) durante la noche a 4°C. Luego, los embriones fueron lavados con PBS tres veces, incubados con anticuerpos secundarios (Life technologies) durante 1 h a RT, teñidos con Hoescht 33342 (Thermo) durante 15 min a RT, lavados con PBS tres veces e imagenados mediante el microscopio confocal de fabricación propia.
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     Visualización de imágenes 3D
    </title>
    <p id="Par52">
     Las imágenes codificadas por color axial de los lisosomas mostradas en Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     fueron generadas con Fiji. Las imágenes de renderizado 3D de la célula en mitosis y los embriones de ratón mostradas en Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     fueron visualizadas y generadas utilizando el software comercial Amira.
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     Estadísticas y reproducibilidad
    </title>
    <p id="Par53">
     Los experimentos en Figs.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i,
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f,
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     , y
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     se repitieron de manera independiente con al menos 3 especímenes, es decir, células o embriones, todos logrando resultados similares.
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     Resumen de informes
    </title>
    <p id="Par54">
     Más información sobre el diseño de la investigación está disponible en el
     <xref ref-type="supplementary-material" rid="MOESM13">
      Nature Portfolio Reporting Summary
     </xref>
     vinculado a este artículo.
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Agradecimientos
   </title>
   <p>
    Los autores agradecen a T. Kirchhausen por los plásmidos donantes utilizados para la edición del genoma y la ayuda en la generación de las líneas celulares editadas genéticamente, y agradecen a los profesores Xiaochen Wang y Dr. Kangmin He por las cepas de
    <italic>
     C. elegans
    </italic>
    y las líneas celulares editadas genéticamente SUM159. Este trabajo fue financiado por subvenciones de la Fundación Nacional de Ciencias Naturales de China (32125024, 32271513, 62071271 y 62088102); el Ministerio de Ciencia y Tecnología (2021YFA1300303 y 2020AA0105500); la Academia China de Ciencias (ZDBS-LY-SM004 y XDA16021401); el Fondo de Investigación Colaborativa del Instituto Chino de Investigación Cerebral, Beijing (2021-NKX-XM-03); la Fundación de Ciencia Postdoctoral de China (2022M721842, 2023T160365); la Fundación de Ciencia Nueva Esquina; el Programa de Becas Shuimu Tsinghua (2022SM035); la Fundación de Ciencias Naturales de Beijing (JQ21012).
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Contribuciones de los autores
   </title>
   <p>
    Q.D. y Dong Li supervisaron la investigación. Q.D., Dong Li y C.Q. concebieron e iniciaron este proyecto. C.Q. diseñó las implementaciones detalladas bajo la dirección de Q.D. y Dong Li. Y.Z, C.Q. y X.C desarrollaron el código python, realizaron simulaciones y procesaron datos de imagen relevantes. H.C., C.Q. y Y.Z. desarrollaron el complemento Fiji. T.J., R.W, C.Q, H.L., W.F., Di Li y J.G. prepararon muestras y realizaron experimentos de imagen. C.Q., Y.Z., X.C. y Q.M. analizaron los datos con el asesoramiento conceptual de Q.D., Dong Li, J.W, Y.W. y H.Q. C.Q., Y.Z y Q.M. compusieron las figuras y videos, crearon la página de inicio tutorial bajo la supervisión de Q.D. y Dong Li. Q.D., Dong Li y C.Q. escribieron el manuscrito, con aportes de todos los autores. Todos los autores discutieron los resultados y comentaron el manuscrito.
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Revisión por pares
   </title>
   <sec id="FPar1">
    <title>
     Información de revisión por pares
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilidad de datos
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilidad de código
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Intereses competidores
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    Referencias
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      Información suplementaria
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      Datos de origen
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Información suplementaria
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
