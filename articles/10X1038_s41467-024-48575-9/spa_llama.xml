<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/ProjectMundo/style/jats-html.xsl"?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     El aprendizaje de disparo cero permite el desenfoque instantáneo y la superresolución en la microscopía de fluorescencia óptica
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Resumen
    </title>
    <p id="Par1">
     Los métodos de superresolución computacional, incluidos los algoritmos analíticos convencionales y los modelos de aprendizaje profundo, han mejorado sustancialmente la microscopía óptica. Entre ellos, las redes neuronales profundas supervisadas han demostrado un rendimiento destacado, sin embargo, exigen una gran cantidad de datos de entrenamiento de alta calidad, lo que es laborioso y a veces impracticable de adquirir debido a la alta dinámica de las células vivas. Aquí, desarrollamos redes de desconvolución de disparo cero (ZS-DeconvNet) que mejoran instantáneamente la resolución de las imágenes del microscopio por más de 1,5 veces el límite de difracción con 10 veces menos fluorescencia que las condiciones de imagen de superresolución ordinarias, de manera no supervisada sin necesidad de verdades fundamentales o adquisición de datos adicionales. Demostramos la aplicabilidad versátil de ZS-DeconvNet en múltiples modalidades de imagen, incluyendo microscopía de fluorescencia de reflexión interna total, microscopía de campo amplio tridimensional, microscopía confocal, microscopía de dos fotones, microscopía de hoja de luz enrejada y microscopía de iluminación estructurada multimodal, lo que permite la imagen de superresolución 2D/3D a largo plazo y multicolor de bioprocesos subcelulares desde células individuales en mitosis hasta embriones multicelulares de ratón y
     <italic>
      C. elegans
     </italic>
     .
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    Introducción
   </title>
   <p id="Par3">
    La microscopía de fluorescencia óptica es una herramienta esencial para la investigación biológica. Los desarrollos recientes de técnicas de resolución superior (SR) proporcionan una resolubilidad sin precedentes para visualizar las estructuras dinámicas finas de diversos bioprocesos
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
    </sup>
    . Sin embargo, la ganancia en resolución espacial a través de cualquier método SR conlleva compensaciones en otras métricas de imagen, como la duración o la velocidad, que son igualmente importantes para diseccionar los bioprocesos
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
    </sup>
    . Recientemente, los métodos de SR computacionales han ganado considerable atención por su capacidad para mejorar instantáneamente la resolución de la imagen in silico, lo que permite una mejora significativa de los sistemas de microscopía de fluorescencia existentes y la extensión de su rango de aplicación
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    .
   </p>
   <p id="Par4">
    En general, los métodos de SR computacionales existentes se pueden clasificar en dos categorías: métodos basados en modelos analíticos, como algoritmos de deconvolución, y métodos basados en aprendizaje profundo, como redes neuronales SR
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . La primera categoría a menudo emplea modelos analíticos que prescriben ciertas suposiciones sobre las propiedades del espécimen y la imagen, como la esparsidad y la simetría local, para mejorar la resolución de la imagen con múltiples parámetros ajustables. La ajuste de parámetros es dependiente de la experiencia y consume tiempo, y las salidas de los modelos analíticos dependen en gran medida de los conjuntos de parámetros
    <sup>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     ,
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    . Además, en experimentos prácticos, los modelos diseñados a mano con ciertas suposiciones no pueden abordar la complejidad estadística completa de la imagen de microscopio, lo que les falta robustez y son propensos a generar artefactos, especialmente en condiciones de baja relación señaligeno (SNR)
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    . Por otro lado, los métodos de SR basados en aprendizaje profundo (DLSR) han logrado un éxito impresionante en el aprendizaje de la relación de transformación de imagen de extremo a extremo según grandes cantidades de datos ejemplares sin la necesidad de un modelo analítico explícito
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Cabe destacar que el esquema de inversión basado en datos a través del aprendizaje profundo puede aproximar no solo la función pseudoinversa del proceso de degradación de la imagen, sino también las características estocásticas de las soluciones SR. Sin embargo, el entrenamiento de los modelos DLSR requiere la adquisición de grandes cantidades de imágenes de entrada de baja resolución y imágenes de verdad de alta calidad SR, lo que es extremadamente laborioso y a veces incluso impráctico debido a la dinámica rápida o la baja SNR en los especímenes biológicos
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Además, el rendimiento de los métodos DLSR depende en gran medida de la calidad y cantidad de los datos de entrenamiento
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Estos factores obstaculizan significativamente la aplicación generalizada de los métodos DLSR en experimentos de imagen diarios a pesar de su rendimiento SR convincente en comparación con los métodos basados en modelos analíticos
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    .
   </p>
   <p id="Par5">
    Aquí presentamos un marco de red neuronal de deconvolución de disparo cero (ZS-DeconvNet) que puede entrenar una red DLSR de manera no supervisada utilizando como poco una sola imagen plana o una pila de imágenes de baja resolución y baja SNR, lo que resulta en una implementación de disparo cero
    <sup>
     <xref ref-type="bibr" rid="CR18">
      18
     </xref>
    </sup>
    . Como tal, en comparación con los métodos DLSR de última generación, ZS-DeconvNet puede adaptarse a diversas circunstancias de bioimagen, donde los bioprocesos son demasiado dinámicos, demasiado sensibles a la luz para adquirir imágenes SR de verdad, o el proceso de adquisición de imágenes está afectado por factores no ideales desconocidos. Caracterizamos que ZS-DeconvNet puede mejorar la resolución en más de 1,5 veces sobre los límites de difracción con alta fidelidad y cuantificabilidad, incluso cuando se entrena en una sola imagen de entrada de baja SNR y sin la necesidad de ajuste de parámetros específicos de la imagen
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     ,
     <xref ref-type="bibr" rid="CR19">
      19
     </xref>
     ,
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
     ,
     <xref ref-type="bibr" rid="CR21">
      21
     </xref>
     ,
     <xref ref-type="bibr" rid="CR22">
      22
     </xref>
     ,
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
    </sup>
    . Demostramos que la ZS-DeconvNet entrenada correctamente puede inferir la imagen de alta resolución en una escala de milisegundos, logrando una imagen SR 2D/3D de alta producción a largo plazo de múltiples interacciones de organelas, dinámica citoesquelética y organelar durante los procesos sensibles a la luz de migración y mitosis, y estructuras y dinámica subcelular en embriones de
    <italic>
     C. elegans
    </italic>
    y ratón en desarrollo. Además, para permitir que ZS-DeconvNet sea ampliamente accesible para la comunidad de investigación biológica, creamos una caja de herramientas de plugin de Fiji y una página de tutorial para los métodos ZS-DeconvNet
    <sup>
     <xref ref-type="bibr" rid="CR24">
      24
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    Resultados
   </title>
   <sec id="Sec3">
    <title>
     Desarrollo y caracterización de ZS-DeconvNet
    </title>
    <p id="Par6">
     El concepto de ZS-DeconvNet se basa en el modelo de imagen de microscopía óptica informado por el solucionador de problemas inversos no supervisado:
     <disp-formula id="Equ1">
      <label>
       1
      </label>
      <alternatives>
       <math id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <msubsup>
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\arg }}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\Big|\Big|{{{{{{\bf{y}}}}}}-{\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{\bf{y}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }{\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <bold>
      y
     </bold>
     denota la imagen de baja resolución ruidosa, PSF es la función de propagación de puntos (PSF),
     <inline-formula id="IEq1">
      <alternatives>
       <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     representa una red neuronal profunda (DNN) con parámetros entrenables
     <bold>
      θ
     </bold>
     , y
     <inline-formula id="IEq2">
      <alternatives>
       <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     indica la operación de muestreo descendente. Si la DNN se entrena directamente a través de la función de objetivo anterior, amplificará indeseablemente el ruido de fotones contenido en las imágenes biológicas, lo que contaminará sustancialmente la información real del espécimen en condiciones de baja SNR (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1a
     </xref>
     ). Para mejorar la robustez al ruido de ZS-DeconvNet mientras mantiene su característica no supervisada, adoptamos un esquema de recorrupción de imágenes que genera dos imágenes recorrompidas independientes del ruido desde la imagen original, que se utilizan como entradas y GT en el entrenamiento de la red (Métodos). Demostramos teóricamente la validez de la aproximación gaussiana al modelo de ruido mixto de Poisson-Gauss para imágenes sCMOS ordinarias y probamos la convergencia de la incorporación del esquema de recorrupción en el solucionador de problemas inversos no supervisado (Nota suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Además, introdujimos el término de regularización de Hessian, que ha demostrado ser útil para mitigar los artefactos de reconstrucción en imágenes de microscopio
     <sup>
      <xref ref-type="bibr" rid="CR25">
       25
      </xref>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
      <xref ref-type="bibr" rid="CR27">
       27
      </xref>
      ,
      <xref ref-type="bibr" rid="CR28">
       28
      </xref>
     </sup>
     , para regular la convergencia de la red (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b–e
     </xref>
     ). Tomados en conjunto, la función de objetivo general de ZS-DeconvNet se puede formular como:
     <disp-formula id="Equ2">
      <label>
       2
      </label>
      <alternatives>
       <math id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfrac>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </mfrac>
        <msubsup>
         <mrow>
          <mo mathsize="big">
           ∑
          </mo>
         </mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </msubsup>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msup>
           <mrow>
            <mi>
             D
            </mi>
           </mrow>
           <mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </msup>
          <mi mathvariant="bold">
           g
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi>
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   i
                  </mi>
                 </mrow>
                </msub>
                <mi mathvariant="bold-italic">
                 +
                </mi>
                <mi>
                 D
                </mi>
                <mi mathvariant="bold">
                 g
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mi>
               i
              </mi>
             </mrow>
            </msub>
            <mi mathvariant="bold-italic">
             +
            </mi>
            <mi>
             D
            </mi>
            <mi mathvariant="bold">
             g
            </mi>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{arg}}}}}}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\frac{1}{N}{\sum }_{i=1}^{N}{{{{{\mathcal{L}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}-{D}^{-1}{{{{{\bf{g}}}}}},{\left({f}_{\theta }\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }\right)+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <italic>
      N
     </italic>
     es el número total de imágenes que se van a procesar,
     <inline-formula id="IEq3">
      <alternatives>
       <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
       </math>
       <tex-math id="IEq3_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq3.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es una matriz de control de ruido invertible que se puede calcular según los niveles de señal y ruido (Métodos), y
     <bold>
      g
     </bold>
     es una mapa de ruido aleatorio que se muestrea desde una distribución normal estándar. Nos referimos a la primera parte de la función de objetivo como el término de degradación, que cuenta para la fidelidad de inferencia, y la segunda parte como el término de regularización, que racionaliza las salidas SR
     <sup>
      <xref ref-type="bibr" rid="CR25">
       25
      </xref>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
      <xref ref-type="bibr" rid="CR27">
       27
      </xref>
      ,
      <xref ref-type="bibr" rid="CR28">
       28
      </xref>
     </sup>
     .
    </p>
    <p id="Par7">
     Después de definir la función de objetivo, adoptamos una arquitectura de red neuronal profunda (DNN) de doble etapa compuesta por dos redes U-Net conectadas secuencialmente como una estructura de respaldo simple pero efectiva para ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig1">
      1a, b
     </xref>
     y Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2a
     </xref>
     ). La primera etapa sirve como un desenredador para generar imágenes libres de ruido según la pérdida de desenredo (Métodos), y la segunda etapa mejora la resolución de la imagen según la pérdida de deconvolución no supervisada descrita anteriormente. Encontramos empíricamente que la arquitectura de doble etapa y la función de pérdida regulada por el modelo físico estabilizan los procedimientos de entrenamiento y otorgan interpretabilidad para el modelo de red general
     <sup>
      <xref ref-type="bibr" rid="CR29">
       29
      </xref>
     </sup>
     .
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="es">
       <title>
        Redes de desconvolución de disparo cero.
       </title>
       <p>
        <bold>
         a
        </bold>
        La arquitectura de dos etapas de ZS-DeconvNet y el esquema de su fase de entrenamiento.
        <bold>
         b
        </bold>
        El esquema de la fase de inferencia de ZS-DeconvNet.
        <bold>
         c
        </bold>
        Imágenes SR representativas de Lyso y MTs reconstruidas por desconvolución RL (segunda columna), desconvolución esparsa (tercera columna) y ZS-DeconvNet (cuarta columna). Las imágenes WF claras se muestran como referencia.
        <bold>
         d
        </bold>
        Comparaciones estadísticas de desconvolución RL, desconvolución esparsa y ZS-DeconvNet en términos de PSNR y resolución (
        <italic>
         n
        </italic>
        = 100 regiones de interés).
        <bold>
         e
        </bold>
        Comparaciones de ancho completo a media altura (FWHM) de imágenes WF claras y procesadas a través de desconvolución RL, desconvolución esparsa y ZS-DeconvNet (
        <italic>
         n
        </italic>
        = 30 microtúbulos). El límite de difracción teórico está etiquetado con la línea discontinua gris de referencia.
        <bold>
         f
        </bold>
        Comparación del tiempo de prueba entre desconvolución esparsa basada en GPU y ZS-DeconvNet (promedio de 25 imágenes de prueba de 1024 × 1024 píxeles). Línea central, medianas; límites, 75% y 25%; bigotes, el valor más grande entre el punto de datos más grande y el percentil 75 más 1,5 veces el rango intercuartílico (IQR), y el valor más pequeño entre el punto de datos más pequeño y el percentil 25 menos 1,5 veces el IQR; valores atípicos, puntos de datos más grandes que el bigote superior o más pequeños que el bigote inferior. Los datos de origen se proporcionan como un archivo de datos de origen. Barra de escala, 1,5 μm (
        <bold>
         a
        </bold>
        ), 5 μm (
        <bold>
         c
        </bold>
        ), 2 μm (regiones de zoom en (
        <bold>
         c
        </bold>
        )).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig1_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par8">
     Para caracterizar y evaluar ZS-DeconvNet, primero simulamos las imágenes de microscopía de estructuras puntuales y tubulares contaminadas con ruido Gaussian-Poisson a niveles de señal de 5 a 25 cuentas de fotones promedio, lo que nos permitió probar sistemáticamente cómo los ajustes de hiperparámetros de recorrupción en diferentes condiciones de imagen influyen en las salidas finales (Nota suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2
     </xref>
     ). Encontramos que los hiperparámetros óptimos son teóricamente independientes del contenido de la imagen y los niveles de señal (Figs. suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      5
     </xref>
     ), lo que permite una aplicación robusta de ZS-DeconvNet en diversas muestras biológicas y configuraciones de imagen (Nota suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ). A continuación, comparamos el rendimiento de los modelos ZS-DeconvNet entrenados con datos aumentados por recorrupción de una sola imagen ruidosa con algoritmos de desconvolución analíticos o con modelos entrenados con números de imágenes simuladas o adquiridas de forma independiente. Para ello, empleamos el modo de iluminación de fluorescencia interna total (TIRF) de nuestro sistema de microscopía de iluminación estructurada multimodal (Multi-SIM) para adquirir ~20 conjuntos de imágenes TIRF limitadas por difracción a bajos y altos SNR para cada estructura subcelular de lisosomas (Lyso) y microtúbulos (MTs), de los cuales las imágenes de bajo SNR se utilizaron para entrenamiento y prueba, mientras que sus contrapartes de alto SNR sirvieron como referencia (Métodos). Encontramos que la relación señal a ruido pico (PSNR) y la resolución de las imágenes ZS-DeconvNet fueron sustancialmente mejores que las generadas por algoritmos analíticos, como el clásico Richardson-Lucy (RL) y la desconvolución esparsa más reciente desarrollada (Fig.
     <xref ref-type="fig" rid="Fig1">
      1c–e
     </xref>
     ) y la tasa de rendimiento de un ZS-DeconvNet bien entrenado es &gt;100 veces mayor que la de algoritmo de desconvolución esparsa (Fig.
     <xref ref-type="fig" rid="Fig1">
      1f
     </xref>
     ). En particular, incluso si el ZS-DeconvNet se entrenó con los datos aumentados de una sola imagen de entrada, la calidad perceptiva y las métricas cuantificadas de sus imágenes de salida fueron comparables con las imágenes del modelo entrenado con mayores cantidades de datos (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      6
     </xref>
     ). Además, validamos la mejora de resolución, la cuantificabilidad y la capacidad de generalización de ZS-DeconvNet (Figs. suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      7
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      10
     </xref>
     ), y lo comparamos con el modelo DFCAN supervisado (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      11
     </xref>
     ) en datos sintéticos y experimentales. Estas caracterizaciones demuestran que ZS-DeconvNet puede generar imágenes DLSR de alta calidad con una mejora de resolución de 1,5 veces relativa al límite de difracción mientras utiliza la menor cantidad de datos de entrenamiento, lo que tiene un gran potencial para mejorar el rendimiento de imagen de diversos sistemas de microscopio y ampliar su aplicabilidad a una amplia variedad de bioprocesos que son desafiantes para los métodos convencionales
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     Observación a largo plazo de bioprocesos sensibles a la fototoxicidad
    </title>
    <p id="Par9">
     La adhesión y migración celular son esenciales en los procesos morfogenéticos y contribuyen a muchas enfermedades
     <sup>
      <xref ref-type="bibr" rid="CR31">
       31
      </xref>
     </sup>
     . Visualizar la dinámica del citoesqueleto a alta resolución durante el proceso de adhesión/migración es crucial para elucidar el mecanismo subyacente. Sin embargo, debido a la fotosensibilidad severa, los procesos completos de adhesión y migración celular se registran típicamente a tasas de cuadros bajos, es decir, varios segundos por cuadro, y bajas intensidades de luz
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR32">
       32
      </xref>
     </sup>
     . En estas condiciones de imagen, ya sea la desconvolución RL o el aprendizaje auto-supervisado basado en la continuidad temporal (Métodos) no logra recuperar y afilar la estructura intrincada de F-actina y miosina-II (Fig.
     <xref ref-type="fig" rid="Fig2">
      2a
     </xref>
     , Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      12
     </xref>
     , y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM4">
      1
     </xref>
     ). En contraste, el modelo ZS-DeconvNet mejora efectivamente tanto la relación señal a ruido como la resolución de las grabaciones de tiempo de dos colores de los procesos de dispersión celular
     <sup>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
     </sup>
     .
     <fig id="Fig2" position="float">
      <label>
       Fig. 2
      </label>
      <caption xml:lang="es">
       <title>
        Imágenes SR a largo plazo de bioprocesos rápidos y fotosensibles a través de ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Imágenes SR representativas reconstruidas por ZS-DeconvNet de citosqueleto de actina F y miosina-II en una célula COS-7 que coexpresa mEmerald-actina y mCherry-miosina-IIA. Se muestran comparaciones de imagen TIRF ruidosa cruda y imágenes procesadas por desconvolución RL, desconvolución basada en DeepCAD y ZS-DeconvNet.
        <bold>
         b
        </bold>
        Imágenes SR de dos colores en tiempo real mejoradas a través de ZS-DeconvNet que muestran la dinámica coordinada de actina F (cyan) y miosina-II (amarillo) en todo el proceso de dispersión después de colocar una célula COS-7 en una cubierta (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM5">
         2
        </xref>
        ).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Imágenes SR de dos colores en tiempo real mejoradas a través de ZS-DeconvNet de actina F y miosina-II en una célula COS-7 que se arrastra, que muestra que la miosina-II se concentra preferentemente en la parte posterior de la célula (delimitada por líneas discontinuas amarillas en
        <bold>
         d
        </bold>
        ), opuesta a la dirección de arrastre (indicada por las flechas blancas en
        <bold>
         d
        </bold>
        ) (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM6">
         3
        </xref>
        ).
        <bold>
         e
        </bold>
        Imagen SR representativa generada a través de ZS-DeconvNet de endosomas de reciclaje (RE, verde) y endosomas tardíos (LE, magenta) en una célula SUM-159 editada genéticamente que expresa endógenamente EGFP-Rab11 y mCherry-Lamp1 (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM7">
         4
        </xref>
        ).
        <bold>
         f
        </bold>
        Trayectorias típicas de movimientos de RE (arriba) y LE (abajo) que muestran la motilidad direccional rápida de RE y la naturaleza bidireccional de LE.
        <bold>
         g
        </bold>
        Comparaciones de la velocidad, el desplazamiento y el tiempo de viaje entre Lyso/LE y RE, y cuantificación del tiempo de residencia de RE cerca de sus sitios de exocitosis antes de fusionarse con la membrana plasmática (
        <italic>
         n
        </italic>
        = 505 trayectorias para RE y
        <italic>
         n
        </italic>
        = 230 trayectorias para LE). Un pequeño número de puntos de datos que exceden el tiempo de transporte de 150 s o el desplazamiento de 60 μm no se muestran para una mejor presentación de las distribuciones. Línea central, medianas; límites, 75% y 25%. La significación estadística se determinó utilizando la prueba de Mann-Whitney no emparejada (p =
        <inline-formula id="IEq4">
         <alternatives>
          <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            1.38
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              7
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq4_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.38\times {10}^{-7}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq4.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ,
        <inline-formula id="IEq5">
         <alternatives>
          <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            5.65
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              35
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq5_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$5.65\times {10}^{-35}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq5.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        , y
        <inline-formula id="IEq6">
         <alternatives>
          <math id="IEq6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            6.26
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              40
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq6_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$6.26\times {10}^{-40}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq6.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        para pruebas de la velocidad de movimiento, el tiempo de transporte y el desplazamiento, respectivamente). ****
        <italic>
         p
        </italic>
        &lt; 0,0001. Los datos de origen se proporcionan como un archivo de datos de origen.
        <bold>
         h
        </bold>
        Imágenes en tiempo real que ilustran el movimiento direccional de un RE en forma de varilla, y la fusión posterior con la membrana plasmática.
        <bold>
         i
        </bold>
        Imágenes en tiempo real que ilustran tres LE que se unen entre sí y co-migran durante cierta distancia antes de dividirse en LE individuales. Barra de escala, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 2 μm (regiones de zoom en
        <bold>
         a
        </bold>
        ), 8 μm (
        <bold>
         b
        </bold>
        ), 3 μm (
        <bold>
         e
        </bold>
        ), 0,5 μm (región de zoom en
        <bold>
         e
        </bold>
        ), 1 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         f
        </bold>
        ,
        <bold>
         i
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig2_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par10">
     después de dejar caer una célula que coexpresa mEmerald-Lifeact y mCherry-miosina-IIA en una cubierta (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Curiosamente, observamos que en ciertas sustancias las células se arrastran alrededor del sitio de contacto para explorar el vecindario antes de adherirse y dispersarse (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). El arrastre celular fue precedido por la acumulación polarizada de miosina-II en la parte posterior de la célula, lo que lleva a la migración celular en la dirección opuesta impulsada por la contractilidad de miosina-II posterior. Además, la dirección de migración podría cambiar rápidamente en respuesta a la redistribución dinámica de miosina-II dentro de la célula (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Estos resultados demuestran que la cinética de la adhesión y migración celular puede registrarse fielmente mediante imágenes asistidas por ZS-DeconvNet sin perturbar este proceso largo y vulnerable.
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     Visualización de la dinámica rápida del sistema endolisosomal
    </title>
    <p id="Par11">
     El sistema endolisosomal incluye diversos tipos de vesículas que funcionan de manera altamente dinámica y bien organizada. Aunque la imagen de fluorescencia de células vivas ha mejorado notablemente nuestra comprensión del sistema endolisosomal, la mayoría de los estudios tuvieron que sobreexpresar las proteínas de interés para registrar sus dinámicas rápidas, lo que a menudo resultó en morfologías o comportamientos artefactuales. Con ZS-DeconvNet, pudimos imagenar la línea de células SUM-159 con knock-in que expresa endógenamente EGFP-Rab11 y mCherry-Lamp1 durante 1.500 cuadros a ~150 nm de resolución y 3 cuadros por segundo en dos colores (Fig.
     <xref ref-type="fig" rid="Fig2">
      2e
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM7">
      4
     </xref>
     ), lo que nos permitió visualizar y rastrear el movimiento rápido de endosomas de reciclaje (RE) y lisosomas o endosomas tardíos (LE) en una escala espacio-temporal más fina y una ventana de observación más larga que la lograda anteriormente
     <sup>
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR34">
       34
      </xref>
     </sup>
     . Como se ejemplifica en la Fig.
     <xref ref-type="fig" rid="Fig2">
      2f–h
     </xref>
     , encontramos que la mayoría de los RE (n = 505 trayectorias) experimentaron un movimiento direccional, con un desplazamiento total de 6,7 ± 5,4 µm a una velocidad alta de 2,2 ± 1,2 µm/s (velocidad instantánea que excede 5,3 µm/s), con una pausa intermedia rareza, y luego se detuvieron en sitios específicos durante un período de 13,5 ± 10,3 s antes de fusionarse con la membrana plasmática. Esta observación sugiere que los RE podrían ser transportados de manera eficiente a lo largo de distancias largas hasta regiones cercanas a la membrana plasmática para facilitar la exocitosis subsecuente. Inesperadamente, ZS-DeconvNet capturó múltiples eventos de fisión de los RE positivos para Rab11, en los que ambos RE separados se sometieron a exocitosis secuencialmente (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      13a
     </xref>
     ) o uno de los RE se alejó (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      13b
     </xref>
     ). Esta observación indica que los RE altamente especializados positivos para Rab11 pueden estar sujetos a una clasificación de carga adicional justo antes de la exocitosis.
    </p>
    <p id="Par12">
     En contraste, los movimientos de los LE fueron típicamente discontinuos y procedieron en una manera de stop-and-go bidireccional a una velocidad relativamente lenta de 1,6 ± 0,6 µm/s (n = 230 trayectorias) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2f, g, i
     </xref>
     ). Aunque el transporte de los LE parecía ineficiente, los LE a menudo persistieron durante un período largo de 91,8 s con un desplazamiento total tan largo como 23,6 µm (promediado desde n = 230 trayectorias) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2h
     </xref>
     ). Curiosamente, notamos que dos o más LE a veces tendían a unirse entre sí en una forma de beso y quedarse, y migrar durante una cierta distancia antes de dividirse en LE individuales nuevamente (Fig.
     <xref ref-type="fig" rid="Fig2">
      2i
     </xref>
     y Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      13c
     </xref>
     ), lo que podría facilitar el movimiento direccional de los LE sin adaptadores de proteínas motoras suficientes para el transporte a larga distancia. Estas dinámicas complejas de los LE sugieren que su posición y movilidad están reguladas de manera delicada por múltiples factores, como los motores basados en MT y los contactos de membrana.
    </p>
   </sec>
   <sec id="Sec6">
    <title>
     3D ZS-DeconvNet para microscopía de hoja de luz enrejada
    </title>
    <p id="Par13">
     La imagen de células vivas tridimensional proporciona más información biológica que las observaciones en 2D; sin embargo, está sujeta a una fototoxicidad, fotodegradación y contaminación de fluorescencia fuera de foco mucho más severas. Para extender la capacidad superior de ZS-DeconvNet a la imagen de resolución tridimensional, mejoramos la arquitectura de la red de doble etapa en un RCAN 3D, que se ha demostrado ser adecuado para la restauración de imágenes tridimensionales (Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     y Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ). A continuación, integraremos nuestro esquema de aprendizaje auto-supervisado espacialmente entrelazado previamente propuesto con el solucionador de problemas inversos auto-supervisado informado por el modelo físico para construir el 3D ZS-DeconvNet. El 3D ZS-DeconvNet con esquema auto-supervisado espacialmente entrelazado sigue un procedimiento de aumento de datos más simple (Métodos), mientras logra un rendimiento comparable o incluso mejor que la estrategia basada en recorrupción (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="es">
       <title>
        Caracterizaciones y demostraciones de 3D ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        La arquitectura de la red de 3D ZS-DeconvNet y el esquema de su fase de entrenamiento.
        <bold>
         b
        </bold>
        El esquema de la fase de inferencia de 3D ZS-DeconvNet.
        <bold>
         c
        </bold>
        Imágenes SR de proyección de intensidad máxima (MIP) representativas de F-actina, membrana externa de Mito y ER reconstruidas por desconvolución esparsa (segunda columna), 3D ZS-DeconvNet (tercera columna) y LLS-SIM (cuarta columna). Los recuentos promedio de sCMOS de los píxeles del 1% más alto para las imágenes raw antes del procesamiento se etiquetan en la esquina superior derecha.
        <bold>
         d
        </bold>
        Comparaciones estadísticas de desconvolución RL, desconvolución esparsa y ZS-DeconvNet en términos de PSNR y resolución en diferentes especímenes (
        <italic>
         n
        </italic>
        = 40 regiones de interés). La resolución se midió mediante análisis de correlación de anillo de Fourier
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        con pilas de imágenes de F-actina. Línea central, medianas; límites, 75% y 25%; bigotes, máximo y mínimo. Los datos de origen se proporcionan como un archivo de datos de origen.
        <bold>
         e
        </bold>
        Imágenes de renderizado 3D de tres colores en tiempo real reconstruidas a través de 3D ZS-DeconvNet de ER, H2B y Mito, que muestran sus transformaciones en morfología y distribución, así como dinámica de interacción durante la mitosis (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ).
        <bold>
         f
        </bold>
        Imágenes de tres colores representativas obtenidas con LLSM convencional (primera columna), desconvolución esparsa (segunda columna), desconvolución basada en DeepCAD (tercera columna) (Métodos) y 3D ZS-DeconvNet (cuarta columna). Las comparaciones se realizan en dos puntos de tiempo típicos de los datos de tiempo real mostrados en (
        <bold>
         e
        </bold>
        ). Barra de escala, 5 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         e
        </bold>
        ,
        <bold>
         f
        </bold>
        ), 1.5 μm (regiones de zoom de
        <bold>
         c
        </bold>
        ), 2 μm (regiones de zoom de
        <bold>
         f
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     Evaluar sistemáticamente el modelo 3D ZS-DeconvNet con conjuntos de datos de tres especímenes biológicos diferentes adquiridos a través de nuestra microscopía de iluminación estructurada de hoja de luz enrejada (LLS-SIM) de construcción casera, en el que los datos limitados por difracción adquiridos por el modo de microscopía de hoja de luz enrejada (LLSM) se utilizaron para el entrenamiento, mientras que los homólogos de resolución superiores adquiridos por el modo LLS-SIM sirvieron como referencias (Métodos). Encontramos que el 3D ZS-DeconvNet reconstruyó con éxito los filamentos elaborados de F-actina, la estructura hueca de la membrana externa mitocondrial (Mito) y las redes intrincadas del retículo endoplásmico (RE) con alta fidelidad y resolución comparable a las imágenes LLS-SIM adquiridas bajo condiciones de alta relación señaligeno (Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ). Las cuantificaciones de la relación señaligeno (PSNR) y la resolución ilustran que el modelo 3D ZS-DeconvNet supera sustancialmente los enfoques basados en modelos analíticos convencionales en diversos especímenes biológicos (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ). Demostramos que al entrenar con las pilas de imágenes ruidosas en sí, el 3D ZS-DeconvNet de doble etapa no solo generó resultados desenruidados comparables a las técnicas de desenruido auto-supervisadas de última generación (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ), sino que también proporcionó pilas de imágenes super-resueltas con una mejora significativa de resolución de más de 1,5 veces tanto lateral (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ) como axial (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ). Además, al incorporar secuencialmente métodos de mejora de resolución axial basados en auto-aprendizaje, se puede mejorar aún más la resolución axial (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     Imágenes de superresolución volumétrica a largo plazo habilitadas por 3D ZS-DeconvNet
    </title>
    <p id="Par15">
     La observación tridimensional de la división celular a alta resolución espaciotemporal es de vital importancia para explorar los mecanismos biológicos relacionados con la mitosis, como el mecanismo que asigna los numerosos organelos distintos en el citoplasma a cada célula hija
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
      ,
      <xref ref-type="bibr" rid="CR42">
       42
      </xref>
     </sup>
     . Debido a la extrema sensibilidad a la luz y vulnerabilidad de las células en mitosis, la imagen de resolución superiores tridimensional previa de este proceso ha dependido del sistema LLS-SIM de baja luz y la reconstrucción de resolución superiores basada en aprendizaje supervisado
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     . Sin embargo, recopilar datos de entrenamiento de alta calidad es extremadamente laborioso y sometimes impráctico porque la morfología y distribución de los organelos suelen experimentar cambios dramáticos durante la mitosis
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
     </sup>
     . Aquí, demostramos que el modelo 3D ZS-DeconvNet auto-supervisado se puede aplicar en general para super-resolver las estructuras subcelulares finas del RE, Mito y cromosomas a partir de volúmenes LLSM ruidosos sin necesidad de datos de entrenamiento adicionales, lo que permite una observación de resolución superiores tridimensional rápida y a largo plazo de múltiples organelos durante 1.000 puntos de tiempo a intervalos de 10 segundos en una célula HeLa en mitosis (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM8">
      5
     </xref>
     ). Además, la propiedad auto-supervisada de ZS-DeconvNet nos permite integrar una estrategia de aprendizaje de adaptación en el momento de la prueba para aprovechar al máximo el contenido estructural de cada volumen ruidoso, lo que produjo el mejor rendimiento de resolución superiores tridimensional (Métodos). En contraste, el algoritmo de desconvolución dependiente de prioridades convencional y el método de aprendizaje auto-supervisado entrelazado temporalmente no lograron restaurar los detalles de alta frecuencia de los especímenes debido a la condición de baja relación señaligeno y la débil consistencia temporal entre puntos de tiempo adyacentes (Fig.
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     y Métodos). Además, según la baja invasividad proporcionada por 3D ZS-DeconvNet, un grupo de células HeLa en mitosis etiquetadas con H2B-mCherry y HeLa-mEmerald-SC35 se imaginarán en un gran campo de visión (FOV) de 100×50×25 μm durante más de 300 puntos de tiempo, lo que registra los procesos completos de desensamblaje y reensamblaje de los gránulos nucleares a una alta resolución espaciotemporal (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM9">
      6
     </xref>
     ). En resumen, 3D ZS-DeconvNet permite a los biólogos explorar fácilmente varios bioprocesos sensibles a la luz con baja invasividad a una resolución espaciotemporal sustancialmente mayor sin necesidad de conjuntos de datos adicionales o modificaciones del montaje óptico
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      ,
      <xref ref-type="bibr" rid="CR44">
       44
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet para microscopía confocal y de campo amplio
    </title>
    <p id="Par16">
     ZS-DeconvNet se basa en la aleatoriedad de los ruidos y la característica de filtro de paso bajo de los microscopios ópticos, que son comunes para varios tipos de modalidades de microscopía. Sobre esta base, esperamos que ZS-DeconvNet se pueda aplicar en general a todos los microscopios, por ejemplo, la microscopía confocal y la microscopía de campo amplio (WF) más comúnmente utilizadas. Para investigar el rendimiento de 3D ZS-DeconvNet en datos confocales, empleamos nuestro microscopio confocal de construcción casera para adquirir un volumen de cuatro colores del embrión de ratón temprano inmunoteñido para el microtúbulo, cromosomas, actina y dominio apical (Métodos), que desempeñan papeles clave en la primera decisión del destino de la célula y son críticos para el desarrollo del embrión
     <sup>
      <xref ref-type="bibr" rid="CR45">
       45
      </xref>
      ,
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
      ,
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
     </sup>
     . Luego, entrenamos modelos 3D ZS-DeconvNet en este volumen ruidoso único y procesamos los datos originales con los modelos entrenados. Como se muestra en las Figs.
     <xref ref-type="fig" rid="Fig4">
      4a, b
     </xref>
     , 3D ZS-DeconvNet mejora significativamente la relación señaligeno, el contraste y la resolución del volumen de datos confocales y resuelve las estructuras finas de los puentes de microtúbulos y los anillos de actina (Fig.
     <xref ref-type="fig" rid="Fig4">
      4c, d
     </xref>
     , Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      19
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM10">
      7
     </xref>
     ). Estos resultados indican que ZS-DeconvNet permite una resolución espacial más alta a un presupuesto de fotones más bajo para la microscopía confocal en la imagen de especímenes a gran escala, por ejemplo, embriones de ratón temprano, lo que es crítico para la investigación sobre la polaridad de la célula, el transporte intracelular y la formación de blastocisto
     <sup>
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
     </sup>
     .
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="es">
       <title>
        Generalización de ZS-DeconvNet a múltiples modalidades de imagen.
       </title>
       <p>
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        Imágenes representativas de confocal (arriba a la izquierda), desconvolución esparsa (abajo a la izquierda) y 3D ZS-DeconvNet mejoradas (derecha) de un embrión de ratón temprano inmunoteñido para microtúbulos (cyan), cromosomas (naranja), anillos de actina (magenta) y dominio apical (verde).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Regiones ampliadas de puentes de microtúbulos (c) y anillos de actina (d) etiquetados con cuadros de líneas blancas en (
        <bold>
         a
        </bold>
        ) y (
        <bold>
         b
        </bold>
        ) adquiridos mediante microscopía confocal, desconvolución esparsa y 3D ZS-DeconvNet.
        <bold>
         e
        </bold>
        Imágenes representativas de WF (región central) y 3D ZS-DeconvNet mejoradas (región circundante) de un embrión de
        <italic>
         C. elegans
        </italic>
        con unión apical, membrana celular (cyan) y lisosomas (rojo) etiquetados.
        <bold>
         f
        </bold>
        ,
        <bold>
         g
        </bold>
        Canal de lisosoma de la región central en (
        <bold>
         e
        </bold>
        ) codificado por colores para la distancia desde el substrato. Se muestran tanto las imágenes WF (
        <bold>
         f
        </bold>
        ) como las imágenes procesadas por 3D ZS-DeconvNet (
        <bold>
         g
        </bold>
        ) para comparación.
        <bold>
         h
        </bold>
        Imágenes de tiempo real mejoradas por 3D ZS-DeconvNet que muestran el proceso de fusión de células hipodérmicas (flechas rojas) durante el desarrollo de un embrión de
        <italic>
         C. elegans
        </italic>
        . Barra de escala, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        ,
        <bold>
         e
        </bold>
        ), 2 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 3 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         h
        </bold>
        ), 1 μm (región de zoom de
        <bold>
         g
        </bold>
        ). Valor gamma, 0,7 para citomembrana y lisosomas en el embrión de
        <italic>
         C. elegans
        </italic>
        .
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17">
     A continuación, imaginarimos embriones de Caenorhabditis elegans con uniones apicales, membranas celulares y lisosomas marcados utilizando el modo 3D WF de nuestro sistema Multi-SIM (Métodos). Para asegurarnos de que el desarrollo del embrión de
     <italic>
      C. elegans
     </italic>
     no se viera perturbado, adquirimos pilas de imágenes raw a una excitación de luz relativamente baja en intervalos de 30 segundos durante más de 200 puntos de tiempo. Sin embargo, en tales condiciones, las imágenes WF están fuertemente contaminadas por el ruido de fondo y fuera de foco (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, f
     </xref>
     ). Incluso en esta situación desafiante, las imágenes 3D ZS-DeconvNet presentaron una supresión considerable del ruido y el fondo mientras mejoraban la resolución espacial de los detalles subcelulares (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, g
     </xref>
     y Video suplementario
     <xref ref-type="supplementary-material" rid="MOESM11">
      8
     </xref>
     ), lo que nos permite investigar el proceso elaborado del desarrollo embrionario, por ejemplo, la fusión de células hipodérmicas (Fig.
     <xref ref-type="fig" rid="Fig4">
      4h
     </xref>
     ), incluso mediante un microscopio WF simple
     <sup>
      <xref ref-type="bibr" rid="CR48">
       48
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     Reducción de ruido y mejora de resolución en imágenes SIM multimodales
    </title>
    <p id="Par18">
     Entre las diversas formas de microscopía SR, la microscopía de iluminación estructurada (SIM) es a menudo reconocida como una opción equilibrada para la imagen en vivo de células SR porque necesita menos de diez imágenes raw moduladas para proporcionar una mejora de dos veces en resolución espacial
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     . Sin embargo, la SIM convencional tiene dos limitaciones críticas: primero, una mayor mejora de la resolución requiere considerablemente más datos raw, es decir, al menos 25 imágenes raw son necesarias para la SIM no lineal para obtener una resolución sub-80 nm; segundo, la postreconstrucción de las imágenes SIM generalmente requiere imágenes raw con una alta relación señaligeno (SNR) para eliminar los artefactos reconstruidos inducidos por ruido, lo que impide la imagen en vivo rápida, de baja luz y a largo plazo
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     . Estudios recientes han explorado enfoques de aprendizaje supervisado mediante la denoising de imágenes SIM o la reconstrucción de imágenes SIM SR directamente desde imágenes raw ruidosas para lograr la reconstrucción SIM de baja luz; sin embargo, estos métodos requieren datos de entrenamiento abundantes y no mejoran aún más la resolución. A la luz de la capacidad de denoising y SR sobresaliente de ZS-DeconvNet, integramos el esquema de aprendizaje de zero-shot con el algoritmo de reconstrucción SIM convencional y demostramos teóricamente que ZS-DeconvNet es adecuado para procesar las imágenes SIM SR (Nota suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Diseñamos el modelo ZS-DeconvNet-SIM mejorado para denoising y afilado simultáneos de imágenes SIM SR de manera no supervisada (Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     , Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     y Métodos). Recurriendo a la mejora notable en SNR y resolución proporcionada por ZS-DeconvNet-SIM (Figuras suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ), la estructura hueca de las fosas recubiertas de clatrina (CCPs) en una célula SUM-159 y los citosqueletos interlaced densamente en una célula COS-7, que son indistinguibles en las imágenes WF y SIM convencionales, se resolvieron claramente (Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ). Además, demostramos que ZS-DeconvNet-SIM se puede aplicar en la modalidad 3D-SIM para denoising y afilado simultáneos de las imágenes 3D-SIM en ambos ejes laterales y axiales (Métodos, Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     .
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="es">
       <title>
        Reducción de ruido cero y mejora de resolución en datos de SIM multimodales.
       </title>
       <p>
        <bold>
         a
        </bold>
        Esquema del procedimiento de entrenamiento de ZS-DeconvNet para SIM.
        <bold>
         b
        </bold>
        Progresión de la mejora de la relación señaligeno y la resolución a través de los CCP en una célula SUM-159, desde imágenes SIM raw (izquierda), imagen SIM convencional (derecha) y imagen SIM mejorada por ZS-DeconvNet (medio).
        <bold>
         c
        </bold>
        Progresión de la mejora de la relación señaligeno y la resolución a través de los microtúbulos en una célula COS-7, desde imágenes SIM raw (izquierda), imagen SIM convencional (derecha) y imagen SIM mejorada por ZS-DeconvNet (medio).
        <bold>
         d
        </bold>
        Imágenes MIP representativas de F-actina en una célula HeLa obtenidas mediante LLSM, LLS-SIM y LLS-SIM mejoradas por 3D ZS-DeconvNet en tres dimensiones.
        <bold>
         e
        </bold>
        , Imágenes MIP representativas de la membrana externa mitocondrial etiquetada con TOMM20 en una célula 293 T obtenidas mediante LLSM, LLS-SIM y LLS-SIM mejoradas por 3D ZS-DeconvNet en tres dimensiones. Barra de escala, 1 μm (
        <bold>
         a
        </bold>
        ), 2 μm (
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 0.5 μm (regiones de zoom en
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 3 μm (
        <bold>
         d
        </bold>
        ,
        <bold>
         e
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig5_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par19">
     Además, integramos 3D ZS-DeconvNet con LLS-SIM para desarrollar la modalidad 3D ZS-DeconvNet-SIM (Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ). Al incorporar la PSF anisótropa de la LLS-SIM convencional en el proceso de entrenamiento, 3D ZS-DeconvNet LLS-SIM no solo mejoró notablemente el contraste y la resolución en las tres dimensiones, sino que también proporcionó una resolución lateral aproximadamente isotrópica de ~150 nm (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     , y Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ). Estas aplicaciones exitosas de ZS-DeconvNet a sistemas SIM multimodales demuestran su capacidad para ampliar aún más la banda de resolución espaciotemporal de las técnicas SR existentes
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     .
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    Discusión
   </title>
   <p id="Par20">
    El objetivo ultimate de la imagen en vivo es recopilar la mayor cantidad de información espaciotemporal sobre bioprocesos con la menor invasividad en las muestras biológicas. Sin embargo, las restricciones mutuas entre la velocidad de imagen, la duración, la resolución y la SNR en la microscopía de fluorescencia juntas resultan en la limitación de la banda espaciotemporal, que limita la mejora sinérgica en todos estos aspectos. Por ejemplo, para obtener una resolución espacial más alta, las técnicas SR convencionales deben basarse en adquisiciones repetitivas o en excitación adicional, lo que agrava la fototoxicidad y el fotoblanqueo, impidiendo observaciones rápidas y a largo plazo de bioprocesos. Para abordar las limitaciones de la banda espaciotemporal en la microscopía, realizamos un análisis en profundidad de la propagación del ruido en el modelo de imagen óptica y la reconstrucción SIM (Nota suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ), demostramos la convergencia de la función de pérdida auto-supervisada integrada con recorruption en escenarios SIM y ordinarios basados en la linealidad de la convolución PSF, y propusimos el marco versátil de ZS-DeconvNet, que se puede incorporar con varios microscopios de fluorescencia óptica para mejorar instantáneamente la SNR y la resolución de la imagen sin comprometer otras propiedades de imagen. Enfatizamos que la aplicación de ZS-DeconvNet es robusta a los hiperparámetros en el proceso de recorruption de la imagen (Figura suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ) y que ZS-DeconvNet se puede entrenar bien con solo una rebanada o pila de imágenes raw (Figuras suplementarias
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ) sin utilizar suposiciones de esparsidad estructural y continuidad temporal
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    . Las evaluaciones cualitativas y cuantitativas en datos simulados y experimentales muestran que nuestros métodos mejoran sustancialmente la calidad y la resolución de la imagen en más de 1,5 veces con alta fidelidad y cuantificabilidad incluso en condiciones de baja luz, lo que permite observaciones en vivo rápidas y a largo plazo de múltiples dinámicas subcelulares.
   </p>
   <p id="Par21">
    El método ZS-DeconvNet propuesto tiene una amplia funcionalidad para varios tipos de modalidades de imagen, desde la microscopía de exploración basada en la detección de campo amplio, como la microscopía confocal y la microscopía de dos fotones (Figura suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     25
    </xref>
    ), hasta la microscopía de detección de campo amplio, como la microscopía TIRF, la microscopía 3D WF, la microscopía LLSM y la microscopía SIM multimodal. Demostramos sus capacidades con más de 10 muestras fijas o en vivo distintas obtenidas mediante seis configuraciones de microscopía diferentes, incluyendo la imagen planar y volumétrica de múltiples organelos en células individuales, la observación de dinámicas y interacciones subcelulares durante la mitosis, y la imagen 3D multicolor de embriones de ratón y
    <italic>
     C. elegans
    </italic>
    tempranos. Para hacer que nuestros métodos sean más accesibles y fáciles de usar, integramos ZS-DeconvNet y 3D ZS-DeconvNet en un plugin de Fiji de fácil uso (Figuras suplementarias
    <xref ref-type="supplementary-material" rid="MOESM1">
     26
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     27
    </xref>
    , Notas suplementarias
    <xref ref-type="supplementary-material" rid="MOESM1">
     3
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     4
    </xref>
    y Video suplementario
    <xref ref-type="supplementary-material" rid="MOESM12">
     9
    </xref>
    ), lo que permite a los usuarios, incluso sin experiencia en aprendizaje profundo, entrenar fácilmente sus propios modelos ZS-DeconvNet y mejorar las imágenes de microscopía abiertas en Fiji en algunos clics del mouse. La funcionalidad y la conveniencia de ZS-DeconvNet demuestran su gran potencial para mejorar el rendimiento de la microscopía óptica existente.
   </p>
   <p id="Par22">
    A pesar de su robustez y aplicabilidad general, los usuarios de ZS-DeconvNet deben considerar cuidadosamente la posible aparición de alucinaciones y sus limitaciones. Primero, ZS-DeconvNet puede confundir las señales de fluorescencia extremadamente bajas con ruido de fotones, lo que debilita las imágenes de salida (Figura suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     28a
    </xref>
    ). Este tipo de errores podría detectarse en cierta medida mediante herramientas de control de calidad de imagen como SQUIRREL
    <sup>
     <xref ref-type="bibr" rid="CR54">
      54
     </xref>
    </sup>
    . Segundo, si un modelo ZS-DeconvNet bien entrenado se aplica a procesar imágenes significativamente diferentes de los datos de entrenamiento, por ejemplo, adquiridas con una modalidad de imagen diferente, puede haber una degradación del rendimiento notable y un mayor riesgo de generación de alucinaciones (Figura suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     28b
    </xref>
    ). Tercero, los modelos ZS-DeconvNet deben entrenarse utilizando PSF coincidentes con el conjunto de datos; de lo contrario, el entrenamiento inadecuado con PSF no coincidentes puede resultar en una mejora de resolución poco notable o artefactos de ringing (Figura suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     28c
    </xref>
    ). Finalmente, no esperamos que ZS-DeconvNet no supervisado genere imágenes SR tan buenas como los modelos DLSR supervisados entrenados con un conjunto de datos de alta calidad (Figura suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     11
    </xref>
    ). Sin embargo, en experimentos de imagen cuando dicho conjunto de datos no está disponible, ZS-DeconvNet será una herramienta poderosa y conveniente para resolver detalles biológicos lo más finos posible.
   </p>
   <p id="Par23"/>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    Métodos
   </title>
   <sec id="Sec12">
    <title>
     Sistema Multi-SIM
    </title>
    <p id="Par24"/>
   </sec>
   <sec id="Sec13">
    <title>
     Sistema LLS-SIM
    </title>
    <p id="Par25"/>
   </sec>
   <sec id="Sec14">
    <title>
     Sistema confocal
    </title>
    <p id="Par26"/>
   </sec>
   <sec id="Sec15">
    <title>
     Arquitecturas y funciones objetivos de ZS-DeconvNet
    </title>
    <p id="Par27"/>
    <p id="Par28"/>
    <p id="Par29">
     Es destacable que, dado que la base teórica de ZS-DeconvNet es agnóstica al modelo, tanto U-Net como RCAN no son los únicos modelos de backbone aplicables, sino que son ampliamente adoptados y eficientes. Equipar a ZS-DeconvNet con otras arquitecturas de red de estado de la técnica, como DFCAN y RLN, puede mejorar aún más su capacidad de desenruido y SR
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     Implementación de 2D ZS-DeconvNet
    </title>
    <p id="Par30">
     Las parejas de imágenes
     <inline-formula id="IEq21">
      <alternatives>
       <math id="IEq21_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq21_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq21.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     utilizadas para entrenar los modelos 2D ZS-DeconvNet se generaron siguiendo un esquema modificado del original de recorrupta a recorrupta bajo la suposición de distribuciones de ruido mixto de Poisson-Gauss, donde tres hiperparámetros
     <inline-formula id="IEq22">
      <alternatives>
       <math id="IEq22_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq22_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq22.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq23">
      <alternatives>
       <math id="IEq23_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq23_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq23.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq24">
      <alternatives>
       <math id="IEq24_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq24_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq24.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     necesitan ser pre-caracterizados. El procedimiento de recorrupta desde una sola imagen ruidosa
     <italic>
      y
     </italic>
     se puede representar en forma de matriz como:
     <disp-formula id="Equ9">
      <label>
       9
      </label>
      <alternatives>
       <math id="Equ9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̂
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         +
        </mo>
        <mi>
         D
        </mi>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ9_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}+D{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ10">
      <label>
       10
      </label>
      <alternatives>
       <math id="Equ10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mo>
          ̃
         </mo>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         −
        </mo>
        <msup>
         <mrow>
          <mi>
           D
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           1
          </mi>
         </mrow>
        </msup>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ10_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}-{D}^{-{{{{{\bf{1}}}}}}}{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <inline-formula id="IEq25">
      <alternatives>
       <math id="IEq25_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
        <mo>
         =
        </mo>
        <mi>
         α
        </mi>
        <mi>
         I
        </mi>
       </math>
       <tex-math id="IEq25_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\alpha I$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq25.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es una matriz invertible definida como una matriz unidad magnificada por un factor de
     <inline-formula id="IEq26">
      <alternatives>
       <math id="IEq26_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         α
        </mi>
       </math>
       <tex-math id="IEq26_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq26.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , que controla la magnitud general de los ruidos agregados, y
     <inline-formula id="IEq27">
      <alternatives>
       <math id="IEq27_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="IEq27_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq27.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es una mapa de ruido aleatorio muestreada desde una distribución Gaussiana con medias cero:
     <disp-formula id="Equ11">
      <label>
       11
      </label>
      <alternatives>
       <math id="Equ11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
        <mo>
         ~
        </mo>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         N
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           0
          </mn>
          <mo>
           ,
          </mo>
          <msup>
           <mrow>
            <mi>
             σ
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mi>
           I
          </mi>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ11_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}} \sim {{{{{\mathcal{N}}}}}}\left(0,{\sigma }^{2}I\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ12">
      <label>
       12
      </label>
      <alternatives>
       <math id="Equ12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msup>
         <mrow>
          <mi>
           σ
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msup>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
        <mi>
         H
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="Equ12_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }^{2}={\beta }_{1}H\left({{{{{\bf{y}}}}}}-{{{{{\bf{b}}}}}}\right)+{\beta }_{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <inline-formula id="IEq28">
      <alternatives>
       <math id="IEq28_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq28_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq28.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el factor de Poisson que afecta la varianza del ruido de disparo dependiente de la señal, y
     <inline-formula id="IEq29">
      <alternatives>
       <math id="IEq29_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq29_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq29.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el factor Gaussiano que representa la varianza de los ruidos Gaussianos adicionales.
     <inline-formula id="IEq30">
      <alternatives>
       <math id="IEq30_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         b
        </mi>
       </math>
       <tex-math id="IEq30_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{b}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq30.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el fondo, aproximadamente considerado como un valor fijo relacionado con la cámara, restando el cual extraemos las señales de fluorescencia de la muestra.
     <inline-formula id="IEq31">
      <alternatives>
       <math id="IEq31_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         H
        </mi>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq31_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq31.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es un filtro de paso bajo lineal utilizado para suavizar preliminarmente la imagen y reducir el ruido, y adoptamos un filtro de promedio con un tamaño de 5 píxeles en nuestros experimentos
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     .
    </p>
    <p id="Par31">
     Como se demuestra en la Nota suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     , el valor óptimo teórico de ambos
     <inline-formula id="IEq32">
      <alternatives>
       <math id="IEq32_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq32_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq32.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     y
     <inline-formula id="IEq33">
      <alternatives>
       <math id="IEq33_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq33_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq33.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es 1, mientras que
     <inline-formula id="IEq34">
      <alternatives>
       <math id="IEq34_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq34_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq34.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     depende de la cámara y se puede estimar desde la región libre de muestra de la imagen en sí o pre-calibrar siguiendo protocolos estándar
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
     </sup>
     . Las evaluaciones en datos simulados han demostrado que el mejor desenruido y rendimiento de SR se logran en los valores óptimos teóricos de estos hiperparámetros, independientemente de la estructura y la relación señal ruido de las imágenes de prueba (Figs. suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ).
    </p>
   </sec>
   <sec id="Sec17">
    <title>
     Implementación de 3D ZS-DeconvNet
    </title>
    <p id="Par32">
     El esquema de entrenamiento de 3D ZS-DeconvNet integra el esquema de aprendizaje auto-supervisado espacialmente entrelazado con el solucionador de problemas inversos auto-supervisado. En el proceso de entrenamiento, cada pila de imágenes ruidosas se dividió en rebanadas impares y pares, que se utilizaron como entrada y objetivos, respectivamente, después de la augmentación por rotación aleatoria, recorte y volteo. Para enmendar la brecha de expectativa entre rebanadas impares y pares, introdujimos el término de regularización de enmienda de brecha (GAR) en la pérdida de desenruido y la pérdida de deconvolución, que se calculó con la pila desenruidada (etiquetada con el cuadro rojo en Fig.
     <xref ref-type="fig" rid="Fig3">
      3a
     </xref>
     ), rebanadas pares ruidosas y salidas de la red (detallado en la Nota suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec18">
    <title>
     Implementación de 2D/3D ZS-DeconvNet-SIM
    </title>
    <p id="Par33">
     Para las implementaciones de ZS-DeconvNet-SIM en 2D-SIM y 3D-SIM, cada conjunto de imágenes raw SIM se augmentó primero en dos conjuntos de imágenes raw recorruptas a través de la Ecuación 9 y 10, y se reconstruyeron en una pareja de imágenes SIM de alta resolución a través del algoritmo de reconstrucción SIM convencional. Las parejas de imágenes SIM generadas se utilizaron luego para el entrenamiento auto-supervisado de manera similar al entrenamiento de los modelos ZS-DeconvNet. Para 3D ZS-DeconvNet-SIM aplicado en LLS-SIM (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     ), los datos SIM volumétricos post-reconstruidos en lugar de las imágenes raw se muestrearon axialmente en dos pilas SIM que contenían rebanadas impares y pares, respectivamente, que se utilizaron en los procedimientos de entrenamiento subsiguientes de los modelos 3D ZS-DeconvNet con funciones de pérdida descritas en la Ecuación 6-8. El flujo de trabajo esquemático de ZS-DeconvNet-SIM se muestra en la Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     y la Figura suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      20
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec19">
    <title>
     Uso y generación de PSF
    </title>
    <p id="Par34">
     En el procedimiento de entrenamiento de ZS-DeconvNet, utilizamos PSF adquiridos experimentalmente o simulados (con el plugin PSF Generator Fiji con licencia de EPFL) que corresponden a las configuraciones de imagen. Se entrenaron modelos ZS-DeconvNet independientes para cada estructura biológica y longitud de onda de emisión para obtener el mejor rendimiento.
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     Entrenamiento de modelos y adaptación en tiempo de prueba
    </title>
    <p id="Par35">
     En este trabajo, los modelos ZS-DeconvNet se entrenaron en una PC con un procesador Intel Core i7-11700 y una tarjeta gráfica RTX 3090 (NVIDIA) en un entorno de software de TensorFlow 2.5.0 y python 3.9.7. Antes del entrenamiento, las imágenes de entrada/GT emparejadas se aumentaron primero en varias parejas de patches a través de recortes aleatorios, volteos horizontales/verticales y transformaciones de rotación para enriquecer aún más el conjunto de datos de entrenamiento, lo que eventualmente generó ~20,000 parejas de patches 2D (128
     <inline-formula id="IEq35">
      <alternatives>
       <math id="IEq35_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq35_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq35.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     128 píxeles) o ~10,000 parejas de patches 3D (64
     <inline-formula id="IEq36">
      <alternatives>
       <math id="IEq36_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq36_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq36.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     64
     <inline-formula id="IEq37">
      <alternatives>
       <math id="IEq37_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq37_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq37.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     13 voxels). El entrenamiento se realizó típicamente con el optimizador Adam y una tasa de aprendizaje inicial de
     <inline-formula id="IEq38">
      <alternatives>
       <math id="IEq38_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mn>
         0.5
        </mn>
        <mo>
         ×
        </mo>
        <msup>
         <mrow>
          <mn>
           10
          </mn>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           4
          </mn>
         </mrow>
        </msup>
       </math>
       <tex-math id="IEq38_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times {10}^{-4}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq38.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , que disminuiría con un factor de 0,5 cada 10,000 iteraciones. El tamaño del lote de entrenamiento fue 4 para imágenes 2D y 3 para pilas 3D. Todo el proceso de entrenamiento requirió típicamente 50,000 iteraciones para imágenes 2D y 10,000 iteraciones para pilas 3D. El tiempo transcurrido para entrenar 50,000 iteraciones para modelos 2D y 10,000 iteraciones para modelos 3D fue ~1 hora y ~2 horas, respectivamente. Como sucede con la mayoría de los métodos basados en aprendizaje profundo, el entrenamiento de ZS-DeconvNet es un procedimiento de una sola vez en la mayoría de los casos de imagen de células vivas, donde los usuarios entrenan el modelo ZS-DeconvNet con todos los frames, luego los modelos bien entrenados son aplicables para todos los datos del mismo espécimen biológico a una alta velocidad de procesamiento. Para eliminar los artefactos de borde inducidos por la desconvolución, típicamente agregamos 2 slices en blanco en la parte superior e inferior de las pilas 3D y un margen de 8 píxeles para cada slice xy en ambos procesos de entrenamiento y inferencia (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      30a
     </xref>
     ). En particular, cuando se procesan los datos de tiempo de mitosis de la célula (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     ), la propiedad no supervisada de ZS-DeconvNet permite una estrategia de aprendizaje de adaptación en tiempo de prueba en la que primero entrenamos un modelo general para cada estructura biológica con datos de todo el proceso y luego ajustamos el modelo preentrenado para cada punto de tiempo con un pequeño número de pasos de entrenamiento (típicamente 50 iteraciones que toman ~1 min) para aprovechar al máximo la información estructural de los datos raw y obtener el rendimiento SR óptimo. Cabe destacar que la adaptación en tiempo de prueba no es necesaria, sino una técnica opcional para mejorar el rendimiento de ZS-DeconvNet, especialmente en circunstancias en las que hay cambios morfológicos importantes en los especímenes biológicos durante la ventana de observación, por ejemplo, los cromosomas durante la mitosis (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      31
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     Procesamiento de datos y evaluación de imágenes de superresolución
    </title>
    <p id="Par36">
     Para las modalidades de imagen que emplean detección de campo ancho, como LLSM, el ruido de patrón fijo (FPN) que se induce por la no uniformidad en la sensibilidad del píxel de la cámara no puede ser eliminado por esquemas basados en noise2noise
     <sup>
      <xref ref-type="bibr" rid="CR62">
       62
      </xref>
     </sup>
     . En nuestra implementación de ZS-DeconvNet, el FPN se realzaría en la etapa de desconvolución y se volvería no negligible, especialmente en condiciones de imagen de SNR extremadamente bajo. Para sensores sCMOS, que son los más comunes en microscopía de fluorescencia, el patrón fijo suele presentar una apariencia regular de franjas horizontales o verticales atribuidas al amplificador de columna. Para ello, simplemente aplicamos una máscara de apodización en el dominio de Fourier para suprimir los artefactos de franjas mientras se preservan otros componentes de frecuencia de las muestras (Fig. suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      30b
     </xref>
     ). Cabe destacar que el ruido de patrón fijo también puede ser eliminado fundamentalmente mediante una precalibración para las imágenes raw adquiridas antes de ser enviadas al modelo de red siguiendo los procedimientos bien establecidos
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
      ,
      <xref ref-type="bibr" rid="CR63">
       63
      </xref>
      ,
      <xref ref-type="bibr" rid="CR64">
       64
      </xref>
     </sup>
     .
    </p>
    <p id="Par37">
     Otros enfoques de SR computacional comparados en este trabajo, es decir, la desconvolución esparsa, la desconvolución basada en DeepCAD y SRRF se implementan siguiendo las instrucciones de los artículos originales. En particular, intentamos seleccionar los hiperparámetros óptimos para la desconvolución esparsa para obtener una imagen reconstruida con los menos artefactos y la mayor resolución. Y la desconvolución basada en DeepCAD (Figs.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a y
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     ) se realizó integrando el esquema de muestreo temporal en nuestro marco de trabajo ZS-DeconvNet, es decir, utilizando imágenes muestreadas temporalmente desde los datos de tiempo para entrenar nuestros modelos de red de dos etapas, asegurando el mismo tamaño de modelo y costo computacional para una comparación justa
     <sup>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      <xref ref-type="bibr" rid="CR13">
       13
      </xref>
     </sup>
     .
    </p>
    <p id="Par38"/>
    <p id="Par39">
     La transformación lineal se aplica a todos los métodos para una comparación justa; (3) Calculando el PSNR entre la imagen GT normalizada
     <bold>
      x
     </bold>
     y la imagen transformada linealmente
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     .
    </p>
    <p id="Par40">
     Para la evaluación del PSNR de 3D ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ), utilizamos directamente las imágenes LLS-SIM como referencia, ya que tanto LLS-SIM como nuestro 3D ZS-DeconvNet proporcionan una mejora de resolución de ~1,5 veces teóricamente. El proceso de cálculo general es similar a los casos 2D, excepto que las pilas SR no se convolucionaron y el PSNR se calculó solo dentro de las regiones con características con un umbral de 0,02 para evitar obtener un valor anormalmente alto de PSNR.
    </p>
    <p id="Par41">
     Para proporcionar un mejor contraste y visualización, realizamos una normalización por percentil para las imágenes de deconvolución generadas por RL deconvolución, deconvolución escasa y ZS-DeconvNet, que se formula como:
     <disp-formula id="Equ15">
      <label>
       15
      </label>
      <alternatives>
       <math id="Equ15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="normal">
           Norm
          </mi>
         </mrow>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             l
            </mi>
            <mi>
             o
            </mi>
            <mi>
             w
            </mi>
           </mrow>
          </msub>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             h
            </mi>
            <mi>
             i
            </mi>
            <mi>
             g
            </mi>
            <mi>
             h
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               h
              </mi>
              <mi>
               i
              </mi>
              <mi>
               g
              </mi>
              <mi>
               h
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
        <mo>
         ,
        </mo>
       </math>
       <tex-math id="Equ15_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{Norm}}}}}}}_{p}\left({{{{{\bf{Y}}}}}},{p}_{{low}},{p}_{{high}}\right)=\frac{{{{{{\bf{Y}}}}}}-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)}{{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{high}}\right)-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)},$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ15.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde percentile(
     <bold>
      Y,
     </bold>
     <italic>
      p
     </italic>
     ) produce el valor de intensidad que ocupa el
     <italic>
      p
     </italic>
     % en la imagen
     <bold>
      Y
     </bold>
     <sup/>
     .
     <inline-formula id="IEq40">
      <alternatives>
       <math id="IEq40_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           l
          </mi>
          <mi>
           o
          </mi>
          <mi>
           w
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq40_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{low}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq40.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     y
     <inline-formula id="IEq41">
      <alternatives>
       <math id="IEq41_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           h
          </mi>
          <mi>
           i
          </mi>
          <mi>
           g
          </mi>
          <mi>
           h
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq41_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{high}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq41.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     se establecen típicamente en 3 y 100 en nuestras figuras y videos.
    </p>
   </sec>
   <sec id="Sec22">
    <title>
     Cultivo de células, transfección y tinción
    </title>
    <p id="Par42">
     Las células Cos7, HeLa, 293 T, así como sus líneas celulares estables, se cultivaron en DMEM (Gibco, cat. no. 11965092), suplementado con 10% de suero fetal bovino (Gibco, cat. no. 10099141 C) y 1× penicilina-estreptomicina (Thermo Fisher, 15140122) a 37°C en incubadora de CO
     <sub>
      2
     </sub>
     Heracell 150i de Thermo Scientific. Las células SUM159 se cultivaron en medio DMEM/F12K suplementado con 5% de suero fetal bovino (FBS) y 1% de solución de penicilina-estreptomicina.
    </p>
    <p id="Par43">
     Para la imagen de células vivas, las cubiertas de 35 mm se precubrieron con 50 μg/ml de colágeno y se sembraron 1×10 células en las cubiertas. Para la transfección transitoria, las células se transfirieron con plásmidos utilizando Lipofectamine 3000 (Invitrogen, cat. no. L3000150) según el protocolo del fabricante 12 horas después del planteo. Las células se imaginarán durante 12 horas después de la transfección. Donde se indica, las células transfected con plásmidos Halo Tag se etiquetaron con 10 nM de ligando JF549 durante 15 minutos según el protocolo publicado
     <sup>
      <xref ref-type="bibr" rid="CR65">
       65
      </xref>
     </sup>
     . Las células se enjuagaron con medio fresco para eliminar el ligando no unido y se imaginarán inmediatamente después. Los plásmidos utilizados en la transfección transitoria incluyen Lifeact-mEmerald, Clathrin-mEmerald, 3×mEmerald-Ensconsin, Lamp1-Halo, 2×mEmerald-Tomm20, Myosin2-Halo, KDEL-mCherry y Halo-Calnexin.
    </p>
    <p id="Par44">
     Para el embalaje de lentivirus, 1 μg de ADN de vector de transferencia de lentivirus, junto con 0.5 μg de psPAX2 de embalaje y 0.5 μg de ADN de plasmido de envoltura pMD2.G, se transfirieron a células HEK293T con una confluencia del 90% en un plato de petri de 6 cm utilizando Lipofectamine 3000 siguiendo el protocolo del fabricante. Después de 2 días, se recolectó y filtró el sobrenadante con un filtro de 0,22 μm (Millipore). Para la construcción de células estables, las células HeLa y Cos7 se infectaron con lentivirus que codificaban el marcador de retículo endoplásmico Calnexin-mEmerald y el marcador de actina F-actina Lifeact-mEmerald
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     . Cuarenta y ocho horas después, las células se enriquecieron mediante un citómetro de flujo (FACSAria III, BD Biosciences) y luego se plantaron en placas de 96 pozos, una célula por pozo. Se utilizaron células monoclonales para nuestros experimentos. Específicamente, Lifeact-mEmerald para COS7 se utilizó en Figs.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     y
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     ; Calnexin-mEmerald, Mito-dsRed y Halo-H2B para células HeLa se utilizaron en Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ; H2B-mCherry para HeLa-mEmerald-SC35 se utilizó en Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     Líneas de células editadas genéticamente
    </title>
    <p id="Par45">
     Las células SUM159 se editaron genéticamente de forma secuencial para incorporar EGFP en el extremo N de Rab11A y luego Halo en el extremo C de Lamp1 utilizando el enfoque CRISPR/Cas9
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     . Las secuencias de ARN guía (sgRNA) que se dirigen a RAB11A y LAMP1 son 5'-TCGCTCCTCGGCCGCGCAAT-3' y 5'-CTATCTAGCCTGGTGCACGC-3', respectivamente. Las células SUM159 se transfirieron con el plasmido donador EGFP-Rab11A, el plasmido que codifica la enzima spCas9 y el producto de PCR libre que contiene la secuencia de ARN guía que se dirige a la secuencia utilizando Lipofectamin 3000 (Invitrogen) según las instrucciones del fabricante. Las células que expresaban EGFP se enriquecieron mediante citometría de flujo activada por fluorescencia (FACS) (FACSAria II, BD Biosciences) y luego se sometieron a una selección de células individuales en placas de 96 pozos. Las células monoclonales con incorporación exitosa de EGFP se identificaron mediante screening de PCR utilizando GoTaq Polymerase (Promega). Las células clonales SUM159 que expresaban EGFP-Rab11A +/+ se sometieron a una segunda ronda de edición genética para incorporar Lamp1-Halo en el genoma como se describió anteriormente. Las células transfirieron se tiñeron con 10 nM de ligandos de HaloTag Janelia Fluor 646 (Promega) durante 15 minutos. Para lavar el tinte no unido, las muestras se enjuagaron con medio fresco y luego se enriquecieron mediante FACS. Las células monoclonales SUM159 que expresaban tanto EGFP-Rab11A +/+ como Lamp1-Halo +/+ se confirmaron mediante análisis de PCR y Western blot.
    </p>
    <p id="Par46">
     Las células SUM159 se editaron genéticamente para incorporar EGFP en el extremo C de la cadena ligera de clatrina A (clatrina-EGFP) utilizando el enfoque basado en TALEN
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     . Las células que expresaban clatrina-EGFP se enriquecieron mediante dos selecciones de bulk secuenciales.
    </p>
    <p id="Par47">
     Las líneas de células HeLa se editaron genéticamente para incorporar mEmerald en el extremo C del genómico humano SC35 utilizando el sistema de edición de genes CRISPR-Cas9. La secuencia de ARN guía que se dirige a SC35 es 5'-CGAGCAGCACTCCTAATGAT-3', y el ARN guía se ligó al plasmido pX330A-1×2 (Addgene, 58766). El plasmido resultante se denominó pX330-SC35-gRNA. Para construir el vector donador p-SC35-doner, mEmerald flanqueado con aproximadamente 1800 pb de brazos de homología complementarios al codón de parada del locus genómico humano SC35 se ligó al plasmido pEASY-blunt (Transgene, CB101). 2 × 10 células HeLa crecidas en un plato de petri de 6 cm se transfirieron con 1,2 μg de pX330-SC35-gRNA y 0,4 μg de p-SC35-doner. 48 horas después de la transfección, las células que expresaban mEmerald se seleccionaron mediante FACS (FACSAria III, BD Biosciences). Después de una semana, el lentivirus H2B-mCherry se infectó a las células seleccionadas y luego se sembraron en placas de 96 pozos. Después de dos semanas, se extrajo y validó el ADN genómico de diferentes clones de células individuales mediante PCR y Western blot. Se seleccionaron células con knock-in de SC35 homocigoto para el estudio. El knock-in exitoso de SC35 se verificó mediante análisis de PCR y Western blot
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     Preparación de embriones de
     <italic>
      C. elegans
     </italic>
    </title>
    <p id="Par48">
     <italic>
      C. elegans
     </italic>
     se cultivaron a 20 °C en placas de medio de crecimiento de nematodos (NGM) sembradas con OP50 siguiendo protocolos estándar
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     . TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ;
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ;
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     se utilizó en este estudio. El plasmido
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     se construyó siguiendo el sistema de clonación de PCR In-Fusion de Clontech y se microinyectó en
     <italic>
      jcIs1;qxIs257
     </italic>
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     . El array extracromosómico
     <italic>
      wyEx51119
     </italic>
     marcó la membrana celular epidermal.
     <italic>
      jcIs1
     </italic>
     marcó el dominio de unión apical de
     <italic>
      C. elegans
     </italic>
     .
     <italic>
      qxIs257
     </italic>
     marcó los lisosomas en células epidermales
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     .
    </p>
    <p id="Par49">
     Aproximadamente 50 gusanos transgénicos en estadio L4 se colocaron en placas NGM con OP50 fresco 48 a 60 h antes de los experimentos. Los huevos transgénicos se recolectaron bajo el microscopio fluorescente de disección (Olympus MVX10) y se montaron en almohadillas de agarosa al 3%. Los embriones desde el estadio Lima bean hasta el estadio 2 se imagenaron utilizando el modo 3D WF de nuestro sistema Multi-SIM.
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     Preparación de embriones de ratón
    </title>
    <p id="Par50">
     Los ratones utilizados en este estudio fueron de fondo C57BL/6 J. Todos los experimentos con animales fueron aprobados por los Comités de Cuidado y Uso de Animales (IACUC) del Instituto de Biofísica, Academia China de Ciencias, Beijing, China. Los embriones preimplantacionales se aislaron de hembras de 5-6 semanas, superovuladas por inyección intraperitoneal de 5 unidades internacionales (UI) de gonadotropina de suero de yegua embarazada (PMSG; LEE BIOSOLUTIONS) y 5 UI de gonadotropina coriónica humana (hCG; Millipore) 48 h después, y se aparearon con ratones machos. Los zigotos se recuperaron en medio M2 (Millipore) en E0.5 y se cultivaron en medio KSOM (Millipore) en incubadora de CO2 (Thermo Scientific) a 37°C con 5% de CO2 hasta el estadio de 8 células tardío.
    </p>
    <p id="Par51">
     Para la inmunofluorescencia, los embriones se fijaron con paraformaldehído al 4% en PBS durante 30 min a temperatura ambiente (RT) y se lavaron con PBS tres veces. Los embriones se permeabilizaron luego en TritonX-100 al 0,5% (Sigma) en PBS durante 20 min a RT, se lavaron en PBS tres veces, se bloquearon en albúmina de suero bovino al 1% en PBS durante 1 h a RT y se incubaron con anticuerpo anti-pERM (Abcam, ab76247), anti-alpha-tubulina-FITC (Sigma, F2168-.2 ML) y Faloidina-Rodamina (Molecular Probes, R415) durante la noche a 4°C. Luego, los embriones se lavaron en PBS tres veces, se incubaron con anticuerpos secundarios (Life technologies) durante 1 h a RT, se tiñeron con Hoescht 33342 (Thermo) durante 15 min a RT, se lavaron en PBS tres veces y se imagenaron con el microscopio confocal de construcción propia.
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     Visualización de imágenes 3D
    </title>
    <p id="Par52">
     Las imágenes de lisosomas codificadas axialmente mostradas en Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     se generaron con Fiji. Las imágenes de renderizado 3D de la célula en mitosis y los embriones de ratón mostrados en Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     se visualizaron y generaron utilizando el software comercial Amira.
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     Estadísticas y reproducibilidad
    </title>
    <p id="Par53">
     Los experimentos en Figs.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i,
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f,
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     , y
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     se repitieron de forma independiente con al menos 3 especímenes, es decir, células o embriones, todos con resultados similares.
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     Resumen de informe
    </title>
    <p id="Par54">
     Más información sobre el diseño de la investigación está disponible en el
     <xref ref-type="supplementary-material" rid="MOESM13">
      Resumen de la cartera de Nature
     </xref>
     vinculado a este artículo.
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Agradecimientos
   </title>
   <p>
    Los autores agradecen a T. Kirchhausen por los plasmidos donantes utilizados para la edición del genoma y la ayuda en la generación de las líneas celulares editadas genéticamente, y agradecen al Prof. Xiaochen Wang y al Dr. Kangmin He por las cepas de
    <italic>
     C. elegans
    </italic>
    y las líneas celulares SUM159 editadas genéticamente. Este trabajo fue apoyado por subvenciones de la Fundación Nacional de Ciencias Naturales de China (32125024, 32271513, 62071271 y 62088102); el Ministerio de Ciencia y Tecnología (2021YFA1300303 y 2020AA0105500); la Academia China de Ciencias (ZDBS-LY-SM004 y XDA16021401); el Fondo de Investigación Colaborativa de la Institución China de Investigación del Cerebro, Beijing (2021-NKX-XM-03); la Fundación de Ciencia Postdoctoral de China (2022M721842, 2023T160365); la Nueva Fundación de Ciencia de Esquina; el Programa de Académico Shuimu de Tsinghua (2022SM035); la Fundación Natural de Beijing (JQ21012).
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Contribuciones de los autores
   </title>
   <p>
    Q.D. y Dong Li supervisaron la investigación. Q.D., Dong Li y C.Q. concibieron e iniciaron este proyecto. C.Q. diseñó las implementaciones detalladas bajo la instrucción de Q.D. y Dong Li. Y.Z, C.Q. y X.C desarrollaron el código de python, realizaron simulaciones y procesaron los datos de imagen relevantes. H.C., C.Q. y Y.Z. desarrollaron el plugin de Fiji. T.J., R.W, C.Q, H.L., W.F., Di Li y J.G. prepararon muestras y realizaron experimentos de imagen. C.Q., Y.Z., X.C. y Q.M. analizaron los datos con asesoramiento conceptual de Q.D., Dong Li, J.W, Y.W. y H.Q. C.Q., Y.Z, y Q.M. compusieron las figuras y videos, crearon la página de tutorial bajo la supervisión de Q.D. y Dong Li. Q.D., Dong Li y C.Q. escribieron el manuscrito, con aportes de todos los autores. Todos los autores discutieron los resultados y comentaron el manuscrito.
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Revisión por pares
   </title>
   <sec id="FPar1">
    <title>
     Información de revisión por pares
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilidad de datos
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilidad de código
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Intereses en conflicto
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    Referencias
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      Información suplementaria
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      Datos de origen
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Información suplementaria
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
