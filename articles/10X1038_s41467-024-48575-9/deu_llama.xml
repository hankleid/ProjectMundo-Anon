<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/ProjectMundo/style/jats-html.xsl"?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     Zero-Shot-Lernen ermöglicht instantane Entrauschung und Superauflösung in optischer Fluoreszenzmikroskopie
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Zusammenfassung
    </title>
    <p id="Par1">
     Computergestützte Superauflösungsmethoden, einschließlich konventioneller analytischer Algorithmen und Deep-Learning-Modellen, haben die optische Mikroskopie erheblich verbessert. Unter ihnen haben überwachte tiefe neuronale Netze eine herausragende Leistung gezeigt, jedoch erfordern sie reichlich hochwertige Trainingsdaten, die aufgrund der hohen Dynamik lebender Zellen mühsam und sogar unmöglich zu beschaffen sind. Hier entwickeln wir Zero-Shot-Deconvolutionsnetzwerke (ZS-DeconvNet), die die Auflösung von Mikroskopaufnahmen sofort um mehr als 1,5-fach über die Beugungsgrenze hinaus verbessern, mit 10-fach geringerer Fluoreszenz als bei herkömmlichen Superauflösungsbildgebungsbedingungen, auf unsupervisierte Weise ohne die Notwendigkeit von Ground-Truths oder zusätzlicher Datenerfassung. Wir demonstrieren die vielseitige Anwendbarkeit von ZS-DeconvNet auf multiple Bildgebungsmodalitäten, einschließlich Total-Internal-Reflection-Fluoreszenzmikroskopie, dreidimensionaler Weitfeldmikroskopie, Konfokalmikroskopie, Zwei-Photonen-Mikroskopie, Gitter-Lichtblatt-Mikroskopie und multimodaler strukturierter Beleuchtungsmikroskopie, die es ermöglicht, multikolorierte, langfristige, superauflösende 2D/3D-Bilder von subzellulären Bioprozessen von mitotischen Einzelzellen bis hin zu mehrzelligen Embryonen von Maus und
     <italic>
      C. elegans
     </italic>
     zu erstellen.
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    Einführung
   </title>
   <p id="Par3">
    Die optische Fluoreszenzmikroskopie ist ein wesentliches Werkzeug für die biologische Forschung. Die recenten Entwicklungen von Super-Auflösung (SR)-Techniken bieten eine unvergleichliche Auflösbarkeit, um die feinen dynamischen Strukturen von verschiedenen Bioprozessen zu visualisieren
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
    </sup>
    . Allerdings kommt der Gewinn an räumlicher Auflösung durch jede SR-Methode mit Kompromissen in anderen Bildmetriken, z. B. Dauer oder Geschwindigkeit, die für die Zerlegung von Bioprozessen gleich wichtig sind
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
    </sup>
    . In letzter Zeit haben rechnergestützte SR-Methoden erhebliche Beachtung für ihre Fähigkeit erhalten, die Bildauflösung sofort in silico zu verbessern, wodurch bestehende Fluoreszenzmikroskopiesysteme erheblich verbessert und ihr Anwendungsbereich erweitert werden können
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    .
   </p>
   <p id="Par4">
    Im Allgemeinen können bestehende rechnergestützte SR-Methoden in zwei Kategorien eingeteilt werden: analytische modellbasierte Methoden, wie z. B. Deconvolutionsalgorithmen, und tiefenlernbasierte Methoden, wie z. B. SR-Neuronale Netze
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Die erste Kategorie verwendet oft analytische Modelle, die bestimmte Annahmen über das Präparat und die Bildmerkmale treffen, z. B. Spärlichkeit und lokale Symmetrie, um die Bildauflösung mit mehreren einstellbaren Parametern zu verbessern. Die Parameteranpassung ist erfahrungsbasiert und zeitaufwendig, und die Ausgaben der analytischen Modelle hängen stark von den Parametersätzen ab
    <sup>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     ,
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    . Darüber hinaus können in praktischen Experimenten handgefertigte Modelle mit bestimmten Annahmen die volle statistische Komplexität der Mikroskopie nicht berücksichtigen, wodurch sie an Robustheit verlieren und anfällig für Artefakte sind, insbesondere unter Bedingungen mit niedrigem Signal-Rausch-Verhältnis (SNR)
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    . Andererseits haben tiefenlernbasierte SR-Methoden (DLSR) einen atemberaubenden Erfolg bei der Erforschung der end-to-end-Bildtransformationbeziehung nach großen Mengen an exemplarischen Daten ohne die Notwendigkeit eines expliziten analytischen Modells erzielt
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Es ist zu beachten, dass das datengetriebene Inversionsverfahren über tiefes Lernen nicht nur die Pseudoinverse-Funktion des Bildverschlechterungsprozesses approximieren kann, sondern auch die stochastischen Eigenschaften der SR-Lösungen. Allerdings erfordert die Schulung von DLSR-Modellen die Beschaffung großer Mengen an gepaarten Bildern mit niedriger Auflösung und hochwertigen Ground-Truth-SR-Bildern, was extrem zeitaufwendig und manchmal sogar unmöglich ist aufgrund der schnellen Dynamik oder des niedrigen Fluoreszenz-SNR in biologischen Proben
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Darüber hinaus hängt die Leistung von DLSR-Methoden stark von der Qualität und Quantität der Trainingsdaten ab
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Diese Faktoren behindern die weite Anwendung von DLSR-Methoden in täglichen Bildgebungsexperimenten, trotz ihrer überzeugenden SR-Leistung im Vergleich zu analytischen modellbasierten Methoden
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    .
   </p>
   <p id="Par5">
    Hier stellen wir ein Zero-Shot-Deconvolutions-Neuronales-Netzwerk (ZS-DeconvNet) vor, das in der Lage ist, ein DLSR-Netzwerk auf unsupervisierte Weise mit nur einem einzigen planaren Bild oder einem volumetrischen Bildstapel mit niedriger Auflösung und niedrigem SNR zu trainieren, was zu einer Zero-Shot-Implementierung führt
    <sup>
     <xref ref-type="bibr" rid="CR18">
      18
     </xref>
    </sup>
    . Als solches kann ZS-DeconvNet im Vergleich zu state-of-the-art-DLSR-Methoden an verschiedene bioimaging-Umgebungen angepasst werden, in denen die Bioprozesse zu dynamisch, zu lichtempfindlich sind, um Ground-Truth-SR-Bilder zu beschaffen, oder der Bildakquisitionsprozess von unbekannten und nicht idealen Faktoren beeinflusst wird. Wir haben festgestellt, dass ZS-DeconvNet die Auflösung um mehr als 1,5-fach über die Beugungsgrenze hinaus verbessern kann, mit hoher Treue und Quantifizierbarkeit, sogar wenn es auf einem einzigen Bild mit niedrigem SNR trainiert wird und ohne die Notwendigkeit von bildspezifischer Parameteranpassung
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     ,
     <xref ref-type="bibr" rid="CR19">
      19
     </xref>
     ,
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
     ,
     <xref ref-type="bibr" rid="CR21">
      21
     </xref>
     ,
     <xref ref-type="bibr" rid="CR22">
      22
     </xref>
     ,
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
    </sup>
    . Wir haben gezeigt, dass das ordnungsgemäß trainierte ZS-DeconvNet in der Lage ist, das hochauflösende Bild auf Millisekundenskala zu inferieren, wodurch eine hohe Durchsatzrate und lange SR-2D/3D-Bildgebung von mehreren Organelle-Interaktionen, zytoskelettalen und organellaren Dynamiken während der lichtempfindlichen Prozesse der Migration und Mitose sowie subzellularen Strukturen und Dynamiken in entwickelnden
    <italic>
     C. elegans
    </italic>
    und Maus-Embryonen erreicht wird. Darüber hinaus haben wir, um ZS-DeconvNet für die biologische Forschungsgemeinschaft leicht zugänglich zu machen, ein Fiji-Plugin-Toolbox und eine Tutorial-Homepage für ZS-DeconvNet-Methoden erstellt
    <sup>
     <xref ref-type="bibr" rid="CR24">
      24
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    Ergebnisse
   </title>
   <sec id="Sec3">
    <title>
     Entwicklung und Charakterisierung von ZS-DeconvNet
    </title>
    <p id="Par6">
     Das Konzept von ZS-DeconvNet basiert auf dem optischen Bildgebungsvorwärtsmodell informierten unsupervisierten inversen Problemlöser:
     <disp-formula id="Equ1">
      <label>
       1
      </label>
      <alternatives>
       <math id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <msubsup>
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\arg }}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\Big|\Big|{{{{{{\bf{y}}}}}}-{\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{\bf{y}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }{\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     wo
     <bold>
      y
     </bold>
     das verrauschte Bild mit niedriger Auflösung darstellt, PSF die Punktverbreitungsfunktion (PSF) ist,
     <inline-formula id="IEq1">
      <alternatives>
       <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ein tiefes Neuronales Netzwerk (DNN) mit trainierbaren Parametern
     <bold>
      θ
     </bold>
     darstellt und
     <inline-formula id="IEq2">
      <alternatives>
       <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     die Downsampling-Operation angibt. Wenn das DNN direkt über die obige Ziel Funktion trainiert wird, wird es unerwünschterweise das Photonrauschen in den biologischen Bildern verstärken, was die reale Probeninformation bei niedrigem SNR-Bedingungen erheblich kontaminieren wird (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      1a
     </xref>
     ). Um die Rauschrobustheit von ZS-DeconvNet zu verbessern, während seine unsupervisierte Eigenschaft beibehalten wird, haben wir ein Bild-Recorrupting-Verfahren verwendet, das zwei rauschunabhängige recorrupte Bilder aus dem ursprünglichen Bild generiert, die dann als Eingaben und Ground-Truths in der Netzwerktrainierung verwendet werden (Methods). Wir haben theoretisch die Gültigkeit der Gaussian-Näherung für das gemischte Poisson-Gaussian-Rauschen-Modell für gewöhnliche sCMOS-Bilder nachgewiesen und die Konvergenz der Integration des Recorrupting-Verfahrens in den unsupervisierten inversen Problemlöser bewiesen (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Darüber hinaus haben wir den Hessian-Regulierungsterm eingeführt, der sich als nützlich für die Minderung von Rekonstruktionsartefakten in Mikroskopiebildern erwiesen hat, um die Netzwerkkonvergenz zu regulieren (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b–e
     </xref>
     ). Insgesamt kann die Gesamtzweckfunktion von ZS-DeconvNet wie folgt formuliert werden:
     <disp-formula id="Equ2">
      <label>
       2
      </label>
      <alternatives>
       <math id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfrac>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </mfrac>
        <msubsup>
         <mrow>
          <mo mathsize="big">
           ∑
          </mo>
         </mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </msubsup>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msup>
           <mrow>
            <mi>
             D
            </mi>
           </mrow>
           <mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </msup>
          <mi mathvariant="bold">
           g
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi>
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   i
                  </mi>
                 </mrow>
                </msub>
                <mi mathvariant="bold-italic">
                 +
                </mi>
                <mi>
                 D
                </mi>
                <mi mathvariant="bold">
                 g
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </msub>
          <mo>
           +
          </mo>
          <mi>
           λ
          </mi>
          <msub>
           <mrow>
            <mi class="MJX-tex-caligraphic" mathvariant="script">
             R
            </mi>
           </mrow>
           <mrow>
            <mi>
             H
            </mi>
            <mi>
             e
            </mi>
            <mi>
             s
            </mi>
            <mi>
             s
            </mi>
            <mi>
             i
            </mi>
            <mi>
             a
            </mi>
            <mi>
             n
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               f
              </mi>
             </mrow>
             <mrow>
              <mi mathvariant="bold-italic">
               θ
              </mi>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
               <mrow>
                <mi>
                 i
                </mi>
               </mrow>
              </msub>
              <mi mathvariant="bold-italic">
               +
              </mi>
              <mi>
               D
              </mi>
              <mi mathvariant="bold">
               g
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
         </mrow>
         <tex-math id="Equ2_TeX">
          \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{arg}}}}}}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\frac{1}{N}{\sum }_{i=1}^{N}{{{{{\mathcal{L}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}-{D}^{-1}{{{{{\bf{g}}}}}},{\left({f}_{\theta }\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }\right)+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)\right)$$\end{document}
         </tex-math>
         <graphic href="41467_2024_48575_Article_Equ2.gif" mime-subtype="GIF" specific-use="web"/>
        </mfenced>
       </math>
       wo
       <italic>
        N
       </italic>
       die Gesamtzahl der zu verarbeitenden Bilder ist,
       <inline-formula id="IEq3">
        <alternatives>
         <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
          <mi>
           D
          </mi>
         </math>
         <tex-math id="IEq3_TeX">
          \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}
         </tex-math>
         <inline-graphic href="41467_2024_48575_Article_IEq3.gif" mime-subtype="GIF" specific-use="web"/>
        </alternatives>
       </inline-formula>
       eine invertierbare Rauschkontrollmatrix ist, die gemäß den Signal- und Rauschpegeln berechnet werden kann (Methods), und
       <bold>
        g
       </bold>
       eine zufällige Rauschmatrix ist, die aus einer Standardnormalverteilung stammt. Wir bezeichnen den ersten Teil der Zweckfunktion als Verschlechterungsterm, der für die Inferenztreue verantwortlich ist, und den zweiten Teil als Regulierungsterm, der die SR-Ausgaben rationalisiert
       <sup>
        <xref ref-type="bibr" rid="CR25">
         25
        </xref>
        <xref ref-type="bibr" rid="CR26">
         26
        </xref>
        <xref ref-type="bibr" rid="CR27">
         27
        </xref>
        ,
        <xref ref-type="bibr" rid="CR28">
         28
        </xref>
       </sup>
       .
      </alternatives>
     </disp-formula>
    </p>
    <p id="Par7">
     Nach der Definition der Zweckfunktion haben wir eine dual-stufige DNN-Architektur verwendet, die aus zwei sequenziell verbundenen U-Nets besteht, als einfache, aber effektive Grundlage für ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig1">
      1a, b
     </xref>
     und Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2a
     </xref>
     ). Die erste Stufe dient als Denoiser, um rauschfreie Bilder gemäß dem Denoising-Verlust zu generieren (Methods), und die zweite Stufe verbessert die Bildauflösung gemäß dem unsupervisierten Deconvolutions-Verlust, der oben beschrieben wurde. Wir haben empirisch festgestellt, dass die dual-stufige Architektur und die physikalisch modellregulierte Zweckfunktion die Trainingsverfahren stabilisieren und die Interpretierbarkeit für das gesamte Netzwerkmodell verleihen
     <sup>
      <xref ref-type="bibr" rid="CR29">
       29
      </xref>
     </sup>
     .
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="de">
       <title/>
      </caption>
      <p>
       <bold>
        a
       </bold>
       Die dual-stufige Architektur von ZS-DeconvNet und die schematische Darstellung seiner Trainingsphase.
       <bold>
        b
       </bold>
       Die schematische Darstellung der Inferenzphase von ZS-DeconvNet.
       <bold>
        c
       </bold>
       Repräsentative SR-Bilder von Lyso und MTs, die durch RL-Deconvolution (zweite Spalte), sparse Deconvolution (dritte Spalte) und ZS-DeconvNet (vierte Spalte) rekonstruiert wurden. Die klaren WF-Bilder werden als Referenz angezeigt.
       <bold>
        d
       </bold>
       Statistische Vergleiche von RL-Deconvolution, sparse Deconvolution und ZS-DeconvNet in Bezug auf PSNR und Auflösung (
       <italic>
        n
       </italic>
       = 100 Regionen von Interesse).
       <bold>
        e
       </bold>
       Vergleiche der vollen Breite bei halber Höhe (FWHM) von klaren WF-Bildern und verarbeiteten Bildern via RL-Deconvolution, sparse Deconvolution und ZS-DeconvNet (
       <italic>
        n
       </italic>
       = 30 Mikrotubuli). Die theoretische Beugungsgrenze ist mit einer grauen gestrichelten Linie als Referenz gekennzeichnet.
       <bold>
        f
       </bold>
       Vergleich der Testzeit zwischen GPU-basierter sparse Deconvolution und ZS-DeconvNet (Durchschnitt aus 25 Testbildern von 1024 × 1024 Pixeln). Mittellinie, Median; Grenzen, 75% und 25%; Whisker, der größere Wert zwischen dem größten Datenpunkt und dem 75. Perzentil plus 1,5-mal dem Interquartilsbereich (IQR) und der kleinere Wert zwischen dem kleinsten Datenpunkt und dem 25. Perzentil minus 1,5-mal dem IQR; Ausreißer, Datenpunkte, die größer sind als der obere Whisker oder kleiner als der untere Whisker. Quellendaten werden als Quelldaten-Datei bereitgestellt. Skalenzähler, 1,5 μm (
       <bold>
        a
       </bold>
       ), 5 μm (
       <bold>
        c
       </bold>
       ), 2 μm (Zoom-Bereiche in (
       <bold>
        c
       </bold>
       )).
      </p>
     </fig>
    </p>
    <p id="Par8">
     Um ZS-DeconvNet zu charakterisieren und zu bewerten, simulierten wir zunächst Mikroskopiebilder von punktförmigen und tubulären Strukturen, die mit Gauß-Poisson-Rauschen bei steigenden Signalpegeln von 5 bis 25 durchschnittlichen Photonenzahlen kontaminiert waren, was es uns ermöglichte, systematisch zu testen, wie die Einstellungen der Recorrupting-Hyperparameter unter verschiedenen Bildgebungsbedingungen die Endausgaben beeinflussen (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      2
     </xref>
     ). Wir fanden heraus, dass die optimalen Hyperparameter theoretisch unabhängig von den Bildinhalten und Signalpegeln sind (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      5
     </xref>
     ), was eine robuste Anwendung von ZS-DeconvNet auf verschiedene biologische Proben und BildgebungsKonfigurationen ermöglicht (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ). Als nächstes verglichen wir die Leistung der ZS-DeconvNet-Modelle, die mit Daten trainiert wurden, die durch Recorrupting eines einzelnen rauschigen Bildes augmentiert wurden, mit analytischen Deconvolutionsalgorithmen oder Modellen, die mit einer Reihe von simulierten oder unabhängig erworbenen Bildern trainiert wurden. Dazu verwendeten wir den totalen internen Reflexionsfluoreszenz-(TIRF)-Illuminationsmodus unseres selbstgebauten multimodalen strukturierten Beleuchtungsmikroskops (Multi-SIM), um etwa 20 Sätze von diffusionsbegrenzten TIRF-Bildern bei niedrigem und hohem SNR für jede subzelluläre Struktur von Lysosomen (Lyso) und Mikrotubuli (MTs) zu erfassen, von denen die Bildern mit niedrigem SNR für Training und Testen verwendet wurden, während ihre hoch-SNR-Gegenstücke als Referenz dienten (Methods). Wir fanden heraus, dass das Peak-Signal-Rausch-Verhältnis (PSNR) und die Auflösung der ZS-DeconvNet-Bilder erheblich besser waren als die von analytischen Algorithmen wie dem klassischen Richardson-Lucy (RL) und der neuesten entwickelten sparse Deconvolution (Fig.
     <xref ref-type="fig" rid="Fig1">
      1c–e
     </xref>
     ) und die Durchsatzrate eines gut trainierten ZS-DeconvNet ist &gt;100-mal höher als die der sparse Deconvolution-Algorithmen (Fig.
     <xref ref-type="fig" rid="Fig1">
      1f
     </xref>
     ). Insbesondere wenn das ZS-DeconvNet mit den augmentierten Daten aus einem einzelnen Eingabebild trainiert wurde, waren die wahrgenommene Qualität und die quantifizierten Metriken seiner Ausgabebilder vergleichbar mit den Bildern des Modells, das mit größeren Datenmengen trainiert wurde (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      6
     </xref>
     ). Darüber hinaus validierten wir die Auflösungsverbesserung, Quantifizierbarkeit und die Generalisierungsfähigkeit von ZS-DeconvNet (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      7
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      10
     </xref>
     ) und verglichen es mit dem überwachten DFCAN-Modell (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      11
     </xref>
     ) auf synthetischen und experimentellen Daten. Diese Charakterisierungen zeigen, dass ZS-DeconvNet in der Lage ist, hochwertige DLSR-Bilder mit einer 1,5-fachen Auflösungsverbesserung im Vergleich zur Beugungsgrenze zu erzeugen, während es die geringste Trainingsdatenmenge verwendet, was ein großes Potenzial zur Verbesserung der Bildgebungsleistung verschiedener Mikroskopsysteme und zur Erweiterung ihrer Anwendbarkeit auf eine breite Palette von Bioprozessen hat, die für herkömmliche Methoden herausfordernd sind
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     Langzeitbeobachtung von Bioprozessen, die empfindlich auf Phototoxizität reagieren
    </title>
    <p id="Par9">
     Zelladhäsion und -migration sind essentiell in morphogenetischen Prozessen und tragen zu vielen Krankheiten bei
     <sup>
      <xref ref-type="bibr" rid="CR31">
       31
      </xref>
     </sup>
     . Die Visualisierung von zytoskelettalen Dynamiken in hoher Auflösung während des Adhäsions-/Migrationsprozesses ist entscheidend für die Aufklärung des zugrunde liegenden Mechanismus. Allerdings werden die gesamten Prozesse der Zelladhäsion und -migration aufgrund der starken Photosensitivität typischerweise bei niedrigen Bildfrequenzen, d. h. mehreren Sekunden pro Bild, und niedrigen Lichtintensitäten aufgezeichnet
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR32">
       32
      </xref>
     </sup>
     . Unter diesen Bildgebungsbedingungen kann weder die RL-Deconvolution noch die temporal kontinuierliche selbstüberwachte Lernmethode (Methods) die feine Struktur von F-Aktin und Myosin-II wiederherstellen und schärfen (Fig.
     <xref ref-type="fig" rid="Fig2">
      2a
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      12
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM4">
      1
     </xref>
     ). Im Gegensatz dazu verbessert das ZS-DeconvNet-Modell sowohl das SNR als auch die Auflösung der zweifarbigen Zeitreihenaufnahmen von Zell
     <sup>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
     </sup>
     .
     <fig id="Fig2" position="float">
      <label>
       Fig. 2
      </label>
      <caption xml:lang="de">
       <title>
        Langzeit-SR-Bildgebung von schnellen und lichtempfindlichen Bioprozessen via ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Repräsentative SR-Bilder, die durch ZS-DeconvNet von F-Actin-Zytoskelett und Myosin-II in einer COS-7-Zelle rekonstruiert wurden, die mEmerald-Lifeact und mCherry-Myosin-IIA koexprimieren. Vergleiche von rohen, verrauschten TIRF-Bildern und Bildern, die durch RL-Deconvolution, DeepCAD-basierte Deconvolution und ZS-DeconvNet verarbeitet wurden, werden angezeigt.
        <bold>
         b
        </bold>
        Zwei-Farben-Zeitverlauf-SR-Bilder, die durch ZS-DeconvNet verstärkt wurden, zeigen die koordinierte Dynamik von F-Actin (cyan) und Myosin-II (gelb) während des gesamten Ausbreitungsprozesses nach dem Platzieren einer COS-7-Zelle auf einem Deckglas (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM5">
         2
        </xref>
        ).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Zwei-Farben-Zeitverlauf-SR-Bilder, die durch ZS-DeconvNet verstärkt wurden, von F-Actin und Myosin-II in einer kriechenden COS-7-Zelle, die zeigt, dass Myosin-II bevorzugt am hinteren Ende der Zelle konzentriert ist (mit gelben gestrichelten Linien in
        <bold>
         d
        </bold>
        umrandet), entgegengesetzt zur Kriechrichtung (durch weiße Pfeile in
        <bold>
         d
        </bold>
        angezeigt) (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM6">
         3
        </xref>
        ).
        <bold>
         e
        </bold>
        Repräsentatives SR-Bild, das durch ZS-DeconvNet von Recycling-Endosomen (RE, grün) und späten Endosomen (LE, magenta) in einer geneditierten SUM-159-Zelle generiert wurde, die EGFP-Rab11 und mCherry-Lamp1 endogen exprimiert (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM7">
         4
        </xref>
        ).
        <bold>
         f
        </bold>
        Typische Trajektoren von RE (oben) und LE (unten) Bewegungen, die die schnelle gerichtete Beweglichkeit von RE und die bidirektionale Natur von LE zeigen.
        <bold>
         g
        </bold>
        Vergleiche der Geschwindigkeit, Verschiebung und Reisezeit zwischen Lyso/LE und RE sowie Quantifizierung der Aufenthaltszeit von RE in der Nähe ihrer Exozytose-Sites vor der Fusion mit der Plasmamembran (
        <italic>
         n
        </italic>
        = 505 Trajektoren für RE und
        <italic>
         n
        </italic>
        = 230 Trajektoren für LE). Eine kleine Anzahl von Datenpunkten, die eine Reisezeit von 150 s oder eine Verschiebung von 60 μm überschreiten, werden nicht angezeigt, um eine bessere Darstellung der Verteilungen zu ermöglichen. Mittellinie, Median; Grenzen, 75% und 25%. Die statistische Signifikanz wurde unter Verwendung des unpaaren Mann-Whitney-Tests bestimmt (p =
        <inline-formula id="IEq4">
         <alternatives>
          <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            1.38
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              7
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq4_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.38\times {10}^{-7}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq4.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ,
        <inline-formula id="IEq5">
         <alternatives>
          <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            5.65
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              35
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq5_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$5.65\times {10}^{-35}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq5.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        , und
        <inline-formula id="IEq6">
         <alternatives>
          <math id="IEq6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            6.26
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              40
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq6_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$6.26\times {10}^{-40}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq6.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        für Tests der Bewegungsgeschwindigkeit, Reisezeit und Verschiebung. ****
        <italic>
         p
        </italic>
        &lt; 0,0001. Quellendaten werden als Quelldaten-Datei bereitgestellt.
        <bold>
         h
        </bold>
        Zeitverlauf-Bilder zeigen die gerichtete Bewegung eines RE in stangenförmiger Form und die anschließende Fusion mit der Plasmamembran.
        <bold>
         i
        </bold>
        Zeitverlauf-Bilder zeigen drei LE, die sich gegenseitig verbinden und für eine bestimmte Strecke zusammenwandern, bevor sie sich in einzelne LE aufteilen. Skalenzähler, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 2 μm (Zoom-Bereiche in
        <bold>
         a
        </bold>
        ), 8 μm (
        <bold>
         b
        </bold>
        ), 3 μm (
        <bold>
         e
        </bold>
        ), 0,5 μm (Zoom-Bereich in
        <bold>
         e
        </bold>
        ), 1 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         f
        </bold>
        ,
        <bold>
         i
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig2_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par10">
     Ausbreitungsprozessen nach dem Abfallen einer Zelle, die mEmerald-Lifeact und mCherry-Myosin-IIA koexprimiert, auf einen Deckglas (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Interessanterweise beobachteten wir, dass Zellen in bestimmten Substanzen um den Kontaktort herumkrochen, um die Umgebung zu erkunden, bevor sie sich ausbreiteten und adhärierten (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). Das Zellkriechen wurde von der polarisierten Accumulation von Myosin-II am Zellhinterteil vorangestellt, was zu einer Zellmigration in die entgegengesetzte Richtung führte, die durch die posteriore Myosin-II-Kontraktur angetrieben wurde. Darüber hinaus konnte die Migrationsrichtung schnell geändert werden als Reaktion auf die dynamische Umverteilung von Myosin-II innerhalb der Zelle (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Diese Ergebnisse zeigen, dass die Kinematik der Zelladhäsion und -migration durch ZS-DeconvNet-gestützte Bildgebung ohne Störung dieses langen und vulnerablen Prozesses treu aufgezeichnet werden kann.
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     Visualisierung der schnellen Dynamik des Endolysosom-Systems
    </title>
    <p id="Par11">
     Das Endolysosom-System umfasst verschiedene Arten von Vesikeln, die auf eine hochdynamische, aber gut organisierte Weise funktionieren. Obwohl die Live-Cell-Fluoreszenzmikroskopie unser Verständnis des Endolysosom-Systems erheblich verbessert hat, mussten die meisten Studien die Proteine von Interesse überexprimieren, um ihre schnellen Dynamiken aufzuzeichnen, was oft zu Artefakt-Morphologien oder -Verhaltensweisen führte. Mit ZS-DeconvNet konnten wir die knock-in-SUM-159-Zelllinie, die EGFP-Rab11 und mCherry-Lamp1 endogen exprimiert, für 1.500 Frames bei einer Auflösung von etwa 150 nm und 3 Frames pro Sekunde in zwei Farben abbilden (Fig.
     <xref ref-type="fig" rid="Fig2">
      2e
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM7">
      4
     </xref>
     ), was es uns ermöglichte, die schnelle Bewegung von Recycling-Endosomen (REs) und Lysosomen oder späten Endosomen (LEs) auf einer wesentlich feineren räumlich-zeitlichen Skala und längeren Beobachtungszeitfenster als zuvor zu visualisieren und zu verfolgen
     <sup>
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR34">
       34
      </xref>
     </sup>
     . Wie in Fig.
     <xref ref-type="fig" rid="Fig2">
      2f–h
     </xref>
     gezeigt, fanden wir heraus, dass die Mehrheit der REs (n = 505 Tracks) eine gerichtete Bewegung erlebte, mit einer Gesamtdisplacement von 6,7 ± 5,4 µm bei einer hohen Geschwindigkeit von 2,2 ± 1,2 µm/s (instantane Geschwindigkeit über 5,3 µm/s), mit einer seltenen Zwischenpause, dann an bestimmten Stellen für eine Periode von 13,5 ± 10,3 Sekunden vor der Fusion mit der Plasmamembran anhielten. Diese Beobachtung legt nahe, dass REs möglicherweise effizient über lange Strecken zu Regionen in der Nähe der Plasmamembran transportiert werden, um die nachfolgende Exocytose zu erleichtern. Überraschenderweise fing ZS-DeconvNet mehrere Fissionsereignisse der Rab11-positiven REs ein, bei denen beide getrennten REs sequenziell Exocytose durchführten (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      13a
     </xref>
     ) oder ein RE sich entfernte (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      13b
     </xref>
     ). Diese Beobachtung zeigt, dass die hochspezialisierten Rab11-positiven REs möglicherweise einer weiteren Cargo-Sortierung vor der Exocytose unterzogen werden.
    </p>
    <p id="Par12">
     Im Gegensatz dazu waren die Bewegungen von LEs typischerweise diskontinuierlich und verliefen in einer bidirektionalen Stop-and-Go-Manier bei einer relativ langsamen Geschwindigkeit von 1,6 ± 0,6 µm/s (n = 230 Tracks) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2f, g, i
     </xref>
     ). Obwohl der Transport von LEs ineffizient erschien, hielten die LEs oft für eine lange Periode von 91,8 Sekunden mit einer Gesamtdisplacement von bis zu 23,6 µm (im Durchschnitt von n = 230 Tracks) an (Fig.
     <xref ref-type="fig" rid="Fig2">
      2h
     </xref>
     ). Interessanterweise bemerkten wir, dass zwei oder mehr LEs manchmal tendenziell miteinander verbunden waren und für eine bestimmte Strecke migrierten, bevor sie sich in einzelne LEs wieder aufteilten (Fig.
     <xref ref-type="fig" rid="Fig2">
      2i
     </xref>
     und Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      13c
     </xref>
     ), was die gerichtete Bewegung von LEs ohne ausreichende Motor-Protein-Adaptoren für den Langstreckentransport erleichtern könnte. Diese komplexen Dynamiken von LEs legen nahe, dass ihre Positionierung und Mobilität von mehreren Faktoren wie MT-basierten Motoren und Membrankontakten fein abgestimmt werden.
    </p>
   </sec>
   <sec id="Sec6">
    <title>
     3D ZS-DeconvNet für Lichtgitter-Lichtscheiben-Mikroskopie
    </title>
    <p id="Par13">
     Das Volumen-Live-Cell-Imaging liefert mehr biologische Informationen als 2D-Beobachtungen; jedoch ist es viel stärkeren Phototoxizitäten, Photobleichungen und ausserfokussierter Fluoreszenzkontaminationen ausgesetzt. Um die überlegene Fähigkeit von ZS-DeconvNet auf Volumen-SR-Imaging auszudehnen, haben wir die Architektur des dualen Netzwerks in eine 3D-RCAN aufgerüstet, die sich als geeignet für die Wiederherstellung von Volumenbildern erwiesen hat (Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     und Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ). Als nächstes haben wir unser zuvor vorgeschlagenes räumlich-interleaved-Selbstlernverfahren mit dem physikalisch-modellinformierten Selbstlern-Inverse-Problemlöser kombiniert, um das 3D-ZS-DeconvNet zu konstruieren. Das 3D-ZS-DeconvNet mit räumlich-interleaved-Selbstlernverfahren folgt einem einfacheren Datenverstärkungsverfahren (Methods), während es eine vergleichbare oder sogar bessere Leistung als die recorruption-basierte Strategie erzielt (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="de">
       <title>
        Charakterisierungen und Demonstrationen von 3D ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Die Netzwerarchitektur von 3D ZS-DeconvNet und die schematische Darstellung seiner Trainingsphase.
        <bold>
         b
        </bold>
        Die schematische Darstellung der Inferenzphase von 3D ZS-DeconvNet.
        <bold>
         c
        </bold>
        Repräsentative Maximum-Intensitäts-Projektion (MIP) SR-Bilder von F-Actin, Mito-äußerer Membran und ER, die durch sparse Deconvolution (zweite Spalte), 3D ZS-DeconvNet (dritte Spalte) und LLS-SIM (vierte Spalte) rekonstruiert wurden. Die durchschnittlichen sCMOS-Zählungen der höchsten 1% Pixel für Rohbilder vor der Verarbeitung sind in der oberen rechten Ecke angegeben.
        <bold>
         d
        </bold>
        Statistische Vergleiche von RL-Deconvolution, sparse Deconvolution und ZS-DeconvNet in Bezug auf PSNR und Auflösung bei verschiedenen Proben (
        <italic>
         n
        </italic>
        = 40 Regionen von Interesse). Die Auflösung wurde durch Fourier-Ring-Korrelationsanalyse
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        mit F-Actin-Bildstapeln gemessen. Mittlere Linie, Median; Grenzen, 75% und 25%; Whisker, Maximum und Minimum. Quellendaten sind als Quelldaten-Datei verfügbar.
        <bold>
         e
        </bold>
        Zeitverlauf-3D-Rendering-Bilder, die durch 3D ZS-DeconvNet von ER, H2B und Mito rekonstruiert wurden, zeigen ihre Veränderungen in Morphologie und Verteilung sowie Interaktionsdynamik während der Mitose (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ).
        <bold>
         f
        </bold>
        Repräsentative dreifarbige Bilder, die mit konventionellem LLSM (erste Spalte), sparse Deconvolution (zweite Spalte), DeepCAD-basierten Deconvolution (dritte Spalte) (Methoden) und 3D ZS-DeconvNet (vierte Spalte) erhalten wurden. Die Vergleiche werden an zwei typischen Zeitpunkten des Zeitverlaufs-Datensatzes gezeigt, der in (
        <bold>
         e
        </bold>
        ) dargestellt ist. Skalenzähler, 5 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         e
        </bold>
        ,
        <bold>
         f
        </bold>
        ), 1,5 μm (Zoom-Bereiche von
        <bold>
         c
        </bold>
        ), 2 μm (Zoom-Bereiche von
        <bold>
         f
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     Wir haben das 3D-ZS-DeconvNet-Modell systematisch mit Datensätzen von drei verschiedenen biologischen Proben bewertet, die mittels unseres selbstgebauten Gitter-Lichtblatt-Struktur-Illuminationsmikroskops (LLS-SIM) erworben wurden, wobei die beugungsbegrenzten Daten, die im LLSM-Modus erworben wurden, für die Ausbildung verwendet wurden, während die SR-Gegenstücke, die im LLS-SIM-Modus erworben wurden, als Referenzen dienten (Methods). Wir fanden heraus, dass das 3D-ZS-DeconvNet die elaborierten Filamente von F-Aktin, die hohle Struktur der mitochondrialen (Mito) äußeren Membran und die feinen Netze des endoplasmatischen Retikulums (ER) mit hoher Treue und Auflösung, vergleichbar mit LLS-SIM-Bildern, die unter hoch-SNR-Bedingungen erworben wurden, erfolgreich rekonstruierte (Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ). Die Quantifizierungen von PSNR und Auflösung zeigen, dass das 3D-ZS-DeconvNet-Modell herkömmliche analytische modellbasierte Ansätze in verschiedenen biologischen Proben deutlich übertrifft (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ). Wir demonstrieren, dass durch die Ausbildung mit den verrauschten Bildstapeln selbst das dual-stufige 3D-ZS-DeconvNet nicht nur geräuschreduzierte Ergebnisse erzeugt, die mit denen von State-of-the-Art-Selbstlern-Verfahren vergleichbar sind (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ), sondern auch superauflösende Bildstapel mit signifikanter Auflösungsverbesserung um mehr als 1,5-fach sowohl lateral (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ) als auch axial (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ) bereitstellt. Darüber hinaus kann die axiale Auflösung durch sequenzielle Integration von selbstlernbasierten axialen Auflösungsverbesserungsverfahren weiter verbessert werden (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     Langzeit-Volumen-Superauflösungsbildgebung ermöglicht durch 3D ZS-DeconvNet
    </title>
    <p id="Par15">
     Die volumetrische Beobachtung der Zellteilung bei hoher räumlich-zeitlicher Auflösung ist von entscheidender Bedeutung für die Erforschung mitosebezogener biologischer Mechanismen, wie z.B. des Mechanismus, der die zahlreichen unterschiedlichen Organellen im Cytoplasma in jede Tochterzelle zuweist
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
      ,
      <xref ref-type="bibr" rid="CR42">
       42
      </xref>
     </sup>
     . Aufgrund der extremen Lichtempfindlichkeit und Verletzlichkeit von mitotischen Zellen hat die vorherige volumetrische SR-Imaging dieses Prozesses auf das Low-Light-LLS-SIM-System und die supervidierte Lernung basierende SR-Rekonstruktion zurückgegriffen
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     . Allerdings ist die Sammlung von hochwertigen Trainingsdaten extrem aufwändig und manchmal unmöglich, da die Morphologie und Verteilung der Organellen während der Mitose dramatische Veränderungen erfahren
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
     </sup>
     . Hier demonstrieren wir, dass das selbstlernende 3D-ZS-DeconvNet-Modell allgemein auf die Superauflösung der feinen subzellulären Strukturen von ER, Mito und Chromosomen aus verrauschten LLSM-Volumen ohne die Notwendigkeit zusätzlicher Trainingsdaten angewendet werden kann, wodurch eine schnelle und langfristige volumetrische SR-Beobachtung mehrerer Organellen für 1.000 Zeitpunkte bei 10-Sekunden-Abständen in einer mitotischen HeLa-Zelle ermöglicht wird (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM8">
      5
     </xref>
     ). Darüber hinaus ermöglicht die unsupervidierte Eigenschaft von ZS-DeconvNet die Integration einer Testzeit-Adaptionslernstrategie, um den strukturellen Inhalt in jedem verrauschten Volumen voll auszunutzen, was die beste 3D-SR-Leistung erbrachte (Methods). Im Gegensatz dazu scheiterten die herkömmliche priorabhängige Deconvolutionsalgorithmik und die zeitlich-interleaved-Selbstlernmethode daran, die hochfrequenten Details der Proben aufgrund der niedrigen SNR-Bedingung und der schwachen zeitlichen Konsistenz zwischen aufeinanderfolgenden Zeitpunkten wiederherzustellen (Fig.
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     und Methods). Weiterhin ermöglichte die geringe Invasivität, die durch 3D-ZS-DeconvNet bereitgestellt wird, die Abbildung einer Gruppe von mitotischen HeLa-Zellen, die mit H2B-mCherry und HeLa-mEmerald-SC35 markiert waren, in einem großen Feld der Sicht (FOV) von 100×50×25 μm für mehr als 300 Zeitpunkte, wodurch der gesamte Prozess der Desassembly und Reassembly von nuclear Speckles bei hoher räumlich-zeitlicher Auflösung aufgezeichnet werden konnte (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM9">
      6
     </xref>
     ). Insgesamt ermöglicht 3D-ZS-DeconvNet es Biologen, verschiedene lichtempfindliche biologische Prozesse mit geringer Invasivität bei wesentlich höherer räumlich-zeitlicher Auflösung ohne die Notwendigkeit zusätzlicher Datensätze oder optischer Aufbauänderungen zu untersuchen
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      ,
      <xref ref-type="bibr" rid="CR44">
       44
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet für Konfokal- und Weitfeld-Mikroskopie
    </title>
    <p id="Par16">
     Das ZS-DeconvNet basiert auf der Zufälligkeit von Rauschen und der Tiefpass-Filter-Eigenschaft von optischen Mikroskopen, die für verschiedene Arten von Mikroskop-Modalitäten gemeinsam sind. Auf dieser Grundlage erwarten wir, dass ZS-DeconvNet allgemein auf alle Mikroskop-Modalitäten anwendbar ist, z.B. die am häufigsten verwendete Konfokal-Mikroskopie und die Wide-Field-(WF)-Mikroskopie. Um die Leistung von 3D-ZS-DeconvNet auf Konfokal-Daten zu untersuchen, verwendeten wir unser selbstgebauten Konfokal-Mikroskop, um ein Vier-Farben-Volumen des frühen Maus-Embryos zu erwerben, das für Mikrotubuli, Chromosomen, Aktin und apikale Domäne immunmarkiert war (Methods), die eine wichtige Rolle bei der ersten Zell-Schicksals-Entscheidung spielen und für die Embryonal-Entwicklung kritisch sind
     <sup>
      <xref ref-type="bibr" rid="CR45">
       45
      </xref>
      ,
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
      ,
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
     </sup>
     . Wir trainierten dann 3D-ZS-DeconvNet-Modelle auf diesem einzelnen verrauschten Volumen und verarbeiteten die ursprünglichen Daten mit den trainierten Modellen. Wie in Figs.
     <xref ref-type="fig" rid="Fig4">
      4a, b
     </xref>
     gezeigt, verbessert 3D-ZS-DeconvNet das SNR, den Kontrast und die Auflösung des Konfokal-Daten-Volumens erheblich und löst die feinen Strukturen von Mikrotubuli-Brücken und Aktin-Ringen auf (Fig.
     <xref ref-type="fig" rid="Fig4">
      4c, d
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      19
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM10">
      7
     </xref>
     ). Diese Ergebnisse zeigen, dass ZS-DeconvNet eine höhere räumliche Auflösung bei einem geringeren Photon-Budget für die Konfokal-Mikroskopie bei der Abbildung von Proben im großen Maßstab, z.B. frühen Maus-Embryonen, ermöglicht, was für die Forschung auf Zell-Polarität, intrazellulären Transport und Blastozysten-Bildung kritisch ist
     <sup>
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
     </sup>
     .
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="de">
       <title>
        Verallgemeinerung von ZS-DeconvNet auf mehrere Bildgebungsmodalitäten.
       </title>
       <p>
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        Repräsentative konfokale (oben links), sparse Deconvolution (unten links) und 3D ZS-DeconvNet-verbesserte (rechts) Bilder eines frühen Maus-Embryos, der für Mikrotubuli (cyan), Chromosomen (orange), Aktin-Ringe (magenta) und apikale Domäne (grün) immunmarkiert wurde.
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Vergrößerte Bereiche von Mikrotubuli-Brücken (c) und Aktin-Ringen (d), die mit weißen gestrichelten Boxen in (
        <bold>
         a
        </bold>
        ) und (
        <bold>
         b
        </bold>
        ) markiert wurden, die durch konfokale Mikroskopie, sparse Deconvolution und 3D ZS-DeconvNet erhalten wurden.
        <bold>
         e
        </bold>
        Repräsentative WF- (Mittelpunkt) und 3D ZS-DeconvNet-verbesserte (Umgebung) Bilder eines
        <italic>
         C. elegans
        </italic>
        -Embryos mit apikaler Verbindung, Zellmembran (cyan) und Lysosomen (rot) markiert.
        <bold>
         f
        </bold>
        ,
        <bold>
         g
        </bold>
        Lysosomen-Kanal des zentralen Bereichs in (
        <bold>
         e
        </bold>
        ) farbkodiert für die Entfernung vom Substrat. Sowohl WF- (
        <bold>
         f
        </bold>
        ) als auch 3D ZS-DeconvNet-verarbeitete Bilder (
        <bold>
         g
        </bold>
        ) werden zum Vergleich gezeigt.
        <bold>
         h
        </bold>
        Zeitverlauf-3D ZS-DeconvNet-verbesserte Bilder, die den Prozess der hypodermalen Zellfusion (rote Pfeile) während der Entwicklung eines
        <italic>
         C. elegans
        </italic>
        -Embryos zeigen. Skalenzähler, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        ,
        <bold>
         e
        </bold>
        ), 2 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 3 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         h
        </bold>
        ), 1 μm (Zoom-Bereich von
        <bold>
         g
        </bold>
        ). Gamma-Wert, 0,7 für Zytomembran und Lysosomen im
        <italic>
         C. elegans
        </italic>
        -Embryo.
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17">
     Wir bildeten als nächstes Caenorhabditis elegans-Embryonen mit apikalen Junctions, Zellmembranen und Lysosomen ab, die mit der 3D-WF-Modus unseres Multi-SIM-Systems markiert wurden (Methods). Um sicherzustellen, dass die Entwicklung von C. elegans-Embryonen nicht gestört wurde, erwarben wir Roh-Bildstapel bei relativ geringer Lichtanregung in Abständen von 30 Sekunden für mehr als 200 Zeitpunkte. Allerdings sind die WF-Bilder unter diesen Bedingungen stark von Hintergrund-Rauschen und -Störungen kontaminiert (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, f
     </xref>
     ). Selbst in dieser herausfordernden Situation zeigen die 3D-ZS-DeconvNet-Bilder eine erhebliche Unterdrückung von Rauschen und Hintergrund, während die räumliche Auflösung der subzellulären Details verbessert wird (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, g
     </xref>
     und Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM11">
      8
     </xref>
     ), wodurch es möglich ist, den elaborierten Prozess der embryonalen Entwicklung, z.B. die hypodermale Zellfusion (Fig.
     <xref ref-type="fig" rid="Fig4">
      4h
     </xref>
     ), sogar mit einem einfachen WF-Mikroskop zu untersuchen
     <sup>
      <xref ref-type="bibr" rid="CR48">
       48
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     ZS-Rauschunterdrückung und Auflösungsverbesserung in multimodalen SIM-Bildern
    </title>
    <p id="Par18">
     Unter den verschiedenen Formen der SR-Mikroskopie wird die strukturierte Beleuchtungsmikroskopie (SIM) oft als ausgewogene Option für die SR-Live-Zell-Bildgebung angesehen, da sie weniger als zehn rohe modulierte Bilder benötigt, um eine zweifache Verbesserung der räumlichen Auflösung zu erzielen
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     . Dennoch hat die konventionelle SIM zwei kritische Einschränkungen: Erstens erfordert eine weitere Auflösungsverbesserung erheblich mehr Rohdaten, d. h. mindestens 25 Rohbilder sind für die nichtlineare SIM erforderlich, um eine Auflösung von unter 80 nm zu erzielen; zweitens erfordert die Nachrekonstruktion von SIM-Bildern im Allgemeinen Rohbilder mit hoher SNR, um von Rauschen induzierte Rekonstruktionsartefakte zu eliminieren, was die schnelle, niedrige Licht- und langfristige Live-Zell-Bildgebung beeinträchtigt
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     . Aktuelle Studien haben überwachte Lernansätze erforscht, indem sie SIM-Bilder entweder entrauschten oder SR-SIM-Bilder direkt aus verrauschten Rohbildern rekonstruierten, um eine niedrige Licht-SIM-Rekonstruktion zu erzielen; jedoch erfordern diese Methoden umfangreiche Trainingsdaten und verbessern die Auflösung nicht weiter. Im Hinblick auf die hervorragenden Entrauschungs- und SR-Fähigkeiten von ZS-DeconvNet integrierten wir das Zero-Shot-Lernschema mit dem konventionellen SIM-Rekonstruktionsalgorithmus und bewiesen theoretisch, dass ZS-DeconvNet für die Verarbeitung von SR-SIM-Bildern geeignet ist (Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Wir entwarfen das ZS-DeconvNet-verbesserte SIM-Modell (ZS-DeconvNet-SIM), um SR-SIM-Bilder gleichzeitig zu entrauschen und zu schärfen (Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     , und Methoden). Durch die bemerkenswerte Verbesserung der SNR und Auflösung, die durch ZS-DeconvNet-SIM bereitgestellt wird (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ), konnten die hohlen Strukturen von Clathrin-bedeckten Gruben (CCPs) in einer SUM-159-Zelle und die dicht miteinander verflochtenen Zytoskelette in einer COS-7-Zelle, die in WF- und konventionellen SIM-Bildern nicht zu erkennen sind, klar aufgelöst werden (Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ). Darüber hinaus zeigten wir, dass ZS-DeconvNet-SIM auf die 3D-SIM-Modality angewendet werden kann, um 3D-SIM-Bilder in beiden lateralen und axialen Achsen gleichzeitig zu entrauschen und zu schärfen (Methoden, Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     .
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="de">
       <title>
        und Auflösungsverbesserung in multimodalen SIM-Daten.
       </title>
      </caption>
      <p>
       <bold>
        a
       </bold>
       Schematische Darstellung der Trainingsprozedur von ZS-DeconvNet für SIM.
       <bold>
        b
       </bold>
       Fortschritt der SNR- und Auflösungsverbesserung über die CCPs in einer SUM-159-Zelle, von rohen SIM-Bildern (links), konventionellem SIM-Bild (rechts) und ZS-DeconvNet-verbessertem SIM-Bild (Mitte).
       <bold>
        c
       </bold>
       Fortschritt der SNR- und Auflösungsverbesserung über die Mikrotubuli in einer COS-7-Zelle, von rohen SIM-Bildern (links), konventionellem SIM-Bild (rechts) und ZS-DeconvNet-verbessertem SIM-Bild (Mitte).
       <bold>
        d
       </bold>
       Repräsentative Maximum-Intensitäts-Projektion (MIP) Bilder von F-Actin in einer HeLa-Zelle, die durch LLSM, LLS-SIM und LLS-SIM, das durch 3D ZS-DeconvNet verbessert wurde, über drei Dimensionen erhalten wurden.
       <bold>
        e
       </bold>
       , Repräsentative MIP-Bilder der mitochondrialen äußeren Membran, die mit TOMM20 in einer 293T-Zelle markiert wurden, die durch LLSM, LLS-SIM und LLS-SIM, das durch 3D ZS-DeconvNet verbessert wurde, über drei Dimensionen erhalten wurden. Skalenzähler, 1 μm (
       <bold>
        a
       </bold>
       ), 2 μm (
       <bold>
        b
       </bold>
       ,
       <bold>
        c
       </bold>
       ), 0,5 μm (Zoom-Bereiche in
       <bold>
        b
       </bold>
       ,
       <bold>
        c
       </bold>
       ), 3 μm (
       <bold>
        d
       </bold>
       ,
       <bold>
        e
       </bold>
       ).
      </p>
     </fig>
    </p>
    <p id="Par19">
     Darüber hinaus integrierten wir 3D ZS-DeconvNet mit LLS-SIM, um die 3D ZS-DeconvNet-SIM-Modality zu entwickeln (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ). Durch die Einbeziehung der anisotropen PSF der konventionellen LLS-SIM in den Trainingsprozess verbesserte 3D ZS-DeconvNet LLS-SIM nicht nur die Kontraste und Auflösung in allen drei Dimensionen, sondern bot auch eine annähernd isotrope laterale Auflösung von ~150 nm (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     , und Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ). Diese erfolgreichen Anwendungen von ZS-DeconvNet auf multimodale SIM-Systeme demonstrieren seine Fähigkeit, die räumlich-zeitliche Auflösungsbandbreite bestehender SR-Techniken weiter zu erweitern
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     .
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    Diskussion
   </title>
   <p id="Par20">
    Das ultimative Ziel der Live-Bildgebung ist es, die meisten räumlich-zeitlichen Informationen über Bioprozesse mit der geringsten Invasivität in biologische Proben zu sammeln. Allerdings resultieren die gegenseitigen Einschränkungen zwischen Bildgebungsrate, Dauer, Auflösung und SNR in der Fluoreszenzmikroskopie zusammen in der räumlich-zeitlichen Bandbreiteneinschränkung, die die synergistische Verbesserung aller dieser Aspekte limitiert. Zum Beispiel müssen konventionelle SR-Techniken auf repetitive Akquisitionen oder zusätzliche Anregung zurückgreifen, um eine höhere räumliche Auflösung zu erzielen, was die Phototoxizität und Photobleichung verschlimmert und die schnelle, langfristige Beobachtung von Bioprozessen behindert. Um die räumlich-zeitlichen Bandbreiteneinschränkungen in der Mikroskopie zu überwinden, führten wir eine eingehende Analyse der Rauschverbreitung im optischen Bildgebungsmodell und der SIM-Rekonstruktion durch (Supplementary Note
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ), bewiesen die Konvergenz der recorruption-integrierten selbstüberwachten Verlustfunktion in beiden gewöhnlichen und SIM-Szenarien auf der Basis der Linearität der PSF-Faltung und schlugen das vielseitige ZS-DeconvNet-Rahmenwerk vor, das in verschiedene optische Fluoreszenzmikroskope integriert werden kann, um die Bild-SNR und Auflösung sofort zu verbessern, ohne andere Bildgebungseigenschaften zu beeinträchtigen. Wir betonen, dass die Anwendung von ZS-DeconvNet robust gegenüber den Hyperparametern im Bildrecorruptionsprozess ist (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ) und dass ZS-DeconvNet gut mit nur einem Slice oder Stapel von Rohbildern trainiert werden kann (Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ) ohne die Annahme der strukturellen Spärlichkeit und zeitlichen Kontinuität zu verwenden
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    . Die qualitativen und quantitativen Bewertungen von simulierten und experimentellen Daten zeigen, dass unsere Methoden die Bildqualität und Auflösung um mehr als 1,5-fach mit hoher Treue und Quantifizierbarkeit verbessern, auch unter niedrigen Lichtbedingungen, und damit die schnelle, langfristige, superauflösende Beobachtung mehrerer subzellulärer Dynamiken ermöglichen.
   </p>
   <p id="Par21">
    Die vorgeschlagene ZS-DeconvNet-Methode hat eine breite Funktionalität für verschiedene Arten von Bildgebungsmodalitäten, von der scannbasierten Mikroskopie, z. B. der konfokalen Mikroskopie und der Zwei-Photonen-Mikroskopie (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     25
    </xref>
    ), bis zur weitfeldbasierten Mikroskopie, z. B. TIRF, 3D-WF-Mikroskopie, LLSM und multimodaler SIM. Wir demonstrieren ihre Fähigkeiten mit mehr als 10 verschiedenen festen oder lebenden Proben, die mit sechs verschiedenen Mikroskopiesystemen aufgenommen wurden, einschließlich planarer und volumetrischer Bildgebung mehrerer Organellen in einzelnen Zellen, Beobachtung subzellulärer Dynamiken und Interaktionen während der Zellmitose und multicolorer 3D-Bildgebung von frühen Maus-Embryonen und
    <italic>
     C. elegans
    </italic>
    -Embryonen. Um unsere Methoden noch zugänglicher und benutzerfreundlicher zu machen, integrierten wir ZS-DeconvNet und 3D ZS-DeconvNet in ein benutzerfreundliches Fiji-Plugin (Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     26
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     27
    </xref>
    , Supplementary Notes
    <xref ref-type="supplementary-material" rid="MOESM1">
     3
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     4
    </xref>
    , und Supplementary Video
    <xref ref-type="supplementary-material" rid="MOESM12">
     9
    </xref>
    ), sodass Benutzer auch ohne Erfahrung in der Deep-Learning-Technologie leicht ihre eigenen ZS-DeconvNet-Modelle trainieren und Mikroskopiebilder in Fiji in wenigen Mausklicks verbessern können. Die Funktionalität und Benutzerfreundlichkeit von ZS-DeconvNet demonstrieren sein großes Potenzial, die Leistung bestehender optischer Mikroskope zu verbessern.
   </p>
   <p id="Par22">
    Trotz seiner allgemeinen Robustheit und Anwendbarkeit sollten Benutzer von ZS-DeconvNet die potenzielle Erscheinung von Halluzinationen und seine Einschränkungen sorgfältig berücksichtigen. Erstens kann ZS-DeconvNet extrem niedrige Fluoreszenzsignale als Photonenrauschen fehlinterpretieren und sie in den Ausgabebildern schwächen (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     28a
    </xref>
    ). Diese Art von Fehlern kann bis zu einem gewissen Grad durch Bildqualitäts-Prüfwerkzeuge wie SQUIRREL
    <sup>
     <xref ref-type="bibr" rid="CR54">
      54
     </xref>
    </sup>
    erkannt werden. Zweitens kann es bei der Anwendung eines gut trainierten ZS-DeconvNet-Modells auf die Verarbeitung von Bildern, die sich erheblich von den Trainingsdaten unterscheiden, z. B. mit einer anderen Bildgebungsmodality aufgenommen, zu einer bemerkbaren Leistungsverschlechterung und einem höheren Risiko der Halluzinationsgenerierung kommen (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     28b
    </xref>
    ). Drittens sollten ZS-DeconvNet-Modelle mit abgestimmten PSFs auf die Datenmenge trainiert werden, da eine unangemessene Trainierung mit nicht abgestimmten PSFs zu einer unauffälligen Auflösungsverbesserung oder Ringing-Artefakten führen kann (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     28c
    </xref>
    ). Schließlich erwarten wir nicht, dass das unsupervisierte ZS-DeconvNet SR-Bilder von gleicher Qualität wie supervisierte DLSR-Modelle erzeugt, die mit hochwertigen Datensätzen trainiert wurden (Supplementary Fig.
    <xref ref-type="supplementary-material" rid="MOESM1">
     11
    </xref>
    ). Allerdings kann ZS-DeconvNet in Bildgebungsversuchen, bei denen ein solcher Datensatz nicht verfügbar ist, ein leistungsfähiges und benutzerfreundliches Werkzeug sein, um biologische Details so fein wie möglich aufzulösen.
   </p>
   <p id="Par23"/>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    Methoden
   </title>
   <sec id="Sec12">
    <title>
     Multi-SIM-System
    </title>
    <p id="Par24"/>
   </sec>
   <sec id="Sec13">
    <title>
     LLS-SIM-System
    </title>
    <p id="Par25"/>
   </sec>
   <sec id="Sec14">
    <title>
     Konfokal-System
    </title>
    <p id="Par26"/>
   </sec>
   <sec id="Sec15">
    <title>
     Architekturen und Ziel Funktionen von ZS-DeconvNet
    </title>
    <p id="Par27"/>
    <p id="Par28"/>
    <p id="Par29">
     Es ist bemerkenswert, dass die theoretische Grundlage von ZS-DeconvNet modellagnostisch ist, sodass sowohl U-Net als auch RCAN nicht die einzigen anwendbaren Backbone-Modelle sind, sondern weit verbreitete und effiziente ones. Die Ausrüstung von ZS-DeconvNet mit anderen State-of-the-Art-Netzwerken, z. B. DFCAN und RLN, kann seine Denoising- und SR-Fähigkeit weiter verbessern
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     Implementierung von 2D ZS-DeconvNet
    </title>
    <p id="Par30">
     Die Bildpaare
     <inline-formula id="IEq21">
      <alternatives>
       <math id="IEq21_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq21_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq21.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     verwendet für die Trainierung von 2D-ZS-DeconvNet-Modellen wurden nach einem modifizierten Schema aus der ursprünglichen recorrupted to recorrupted-Strategie unter der Annahme von gemischten Poisson-Gaussian-Noise-Verteilungen generiert, wobei drei Hyperparameter
     <inline-formula id="IEq22">
      <alternatives>
       <math id="IEq22_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq22_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq22.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq23">
      <alternatives>
       <math id="IEq23_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq23_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq23.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq24">
      <alternatives>
       <math id="IEq24_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq24_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq24.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     benötigt wurden. Das Recorruption-Verfahren aus einem einzelnen verrauschten Bild
     <italic>
      y
     </italic>
     kann in Matrixform wie folgt dargestellt werden:
     <disp-formula id="Equ9">
      <label>
       9
      </label>
      <alternatives>
       <math id="Equ9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̂
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         +
        </mo>
        <mi>
         D
        </mi>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ9_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}+D{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ10">
      <label>
       10
      </label>
      <alternatives>
       <math id="Equ10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mo>
          ̃
         </mo>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         −
        </mo>
        <msup>
         <mrow>
          <mi>
           D
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           1
          </mi>
         </mrow>
        </msup>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ10_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}-{D}^{-{{{{{\bf{1}}}}}}}{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     wo
     <inline-formula id="IEq25">
      <alternatives>
       <math id="IEq25_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
        <mo>
         =
        </mo>
        <mi>
         α
        </mi>
        <mi>
         I
        </mi>
       </math>
       <tex-math id="IEq25_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\alpha I$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq25.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     eine invertierbare Matrix ist, die als eine vergrößerte Einheitsmatrix mit einem Faktor von
     <inline-formula id="IEq26">
      <alternatives>
       <math id="IEq26_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         α
        </mi>
       </math>
       <tex-math id="IEq26_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq26.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     definiert ist, der die Gesamtbetrag der hinzugefügten Rauschen kontrolliert, und
     <inline-formula id="IEq27">
      <alternatives>
       <math id="IEq27_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="IEq27_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq27.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     eine zufällige Rauschabbildung ist, die aus einer Gaußschen Verteilung mit Nullmittelpunkt stammt:
     <disp-formula id="Equ11">
      <label>
       11
      </label>
      <alternatives>
       <math id="Equ11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
        <mo>
         ~
        </mo>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         N
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           0
          </mn>
          <mo>
           ,
          </mo>
          <msup>
           <mrow>
            <mi>
             σ
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mi>
           I
          </mi>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ11_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}} \sim {{{{{\mathcal{N}}}}}}\left(0,{\sigma }^{2}I\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ12">
      <label>
       12
      </label>
      <alternatives>
       <math id="Equ12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msup>
         <mrow>
          <mi>
           σ
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msup>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
        <mi>
         H
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="Equ12_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }^{2}={\beta }_{1}H\left({{{{{\bf{y}}}}}}-{{{{{\bf{b}}}}}}\right)+{\beta }_{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     wo
     <inline-formula id="IEq28">
      <alternatives>
       <math id="IEq28_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq28_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq28.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     der Poisson-Faktor ist, der die Varianz des signalabhängigen Rauschens beeinflusst, und
     <inline-formula id="IEq29">
      <alternatives>
       <math id="IEq29_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq29_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq29.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     der Gauß-Faktor ist, der die Varianz des additiven Gauß-Rauschens darstellt.
     <inline-formula id="IEq30">
      <alternatives>
       <math id="IEq30_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         b
        </mi>
       </math>
       <tex-math id="IEq30_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{b}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq30.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ist der Hintergrund, der ungefähr als ein fester Wert im Verhältnis zur Kamera angesehen wird, indem wir die Fluoreszenzsignale aus der Probe extrahieren.
     <inline-formula id="IEq31">
      <alternatives>
       <math id="IEq31_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         H
        </mi>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq31_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq31.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ist ein linearer Tiefpassfilter, der verwendet wird, um das Bild vorläufig zu glätten und das Rauschen zu reduzieren, und wir haben in unseren Experimenten einen Durchschnittsfilter mit einer Größe von 5 Pixeln verwendet
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     .
    </p>
    <p id="Par31">
     Wie in Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     bewiesen wurde, ist der theoretisch optimale Wert von sowohl
     <inline-formula id="IEq32">
      <alternatives>
       <math id="IEq32_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq32_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq32.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     und
     <inline-formula id="IEq33">
      <alternatives>
       <math id="IEq33_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq33_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq33.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     1 ist, während
     <inline-formula id="IEq34">
      <alternatives>
       <math id="IEq34_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq34_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq34.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     von der Kamera abhängt und aus der probefreien Region des Bildes selbst oder nach standardmäßigen Protokollen vorher bestimmt werden kann
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
     </sup>
     . Die Bewertung von simulierten Daten hat gezeigt, dass die beste Denoising- und SR-Leistung bei den theoretisch optimalen Werten dieser Hyperparameter unabhängig von der Struktur und dem SNR der Testbilder erreicht wird (Supplementary Figs.
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ).
    </p>
   </sec>
   <sec id="Sec17">
    <title>
     Implementierung von 3D ZS-DeconvNet
    </title>
    <p id="Par32">
     Das Trainingsverfahren von 3D ZS-DeconvNet integriert das räumlich interpolierte Selbstlernverfahren mit dem selbstüberwachten Inversproblemsolver. Im Trainingsprozess wurde jeder verrauschte Bildstapel in ungerade und gerade Schichten unterteilt, die dann als Eingabe und Ziele verwendet wurden, nachdem sie durch zufälliges Drehen, Beschneiden und Spiegeln augmentiert wurden. Um die Erwartungslücke zwischen ungeraden und geraden Schichten zu beheben, führten wir den Gap-Amending-Regularization-(GAR)-Term in beide Denoising- und Deconvolutionsverluste ein, der mit dem gedenoisierten Stapel (markiert mit dem roten Kasten in Fig.
     <xref ref-type="fig" rid="Fig3">
      3a
     </xref>
     ), verrauschten geraden Schichten und Netzwerkausgaben berechnet wurde (im Detail in Supplementary Note
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec18">
    <title>
     Implementierung von 2D/3D ZS-DeconvNet-SIM
    </title>
    <p id="Par33">
     Für ZS-DeconvNet-SIM-Implementierungen auf 2D-SIM und 3D-SIM wurden alle Roh-SIM-Bilder zuerst in zwei Sätze von recorrupten Rohbildern durch Gleichung 9 und 10 augmentiert und in ein Paar von SR-SIM-Bildern über das konventionelle SIM-Rekonstruktionsverfahren rekonstruiert. Die generierten SIM-Bildpaare wurden dann für selbstüberwachtes Training in ähnlicher Weise wie für die Trainierung von ZS-DeconvNet-Modellen verwendet. Für 3D ZS-DeconvNet-SIM, das auf LLS-SIM (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     ) angewendet wird, wurden anstelle der Rohbilder die postrekonstruierten volumetrischen SIM-Daten axial in zwei SIM-Stapel unterteilt, die jeweils ungerade und gerade Schichten enthielten, die in den nachfolgenden Trainingsverfahren von 3D ZS-DeconvNet-Modellen mit Verlustfunktionen wie in Gleichung 6-8 verwendet wurden. Der schematische Workflow von ZS-DeconvNet-SIM ist in Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     und Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20
     </xref>
     dargestellt
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec19">
    <title>
     PSF-Verwendung und -Generierung
    </title>
    <p id="Par34">
     Im Trainingsverfahren von ZS-DeconvNet verwendeten wir experimentell ermittelte oder simulierte PSFs (mit PSF-Generator-Fiji-Plugin, lizenziert von EPFL), die den Bildgebungs-Konfigurationen entsprechen. Unabhängige ZS-DeconvNet-Modelle wurden für jede biologische Struktur und Emissionswellenlänge für die beste Leistung trainiert.
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     Modelltraining und Testzeit-Anpassung
    </title>
    <p id="Par35">
     In dieser Arbeit wurden ZS-DeconvNet-Modelle auf einem PC mit einem Intel Core i7-11700-Prozessor und einer RTX 3090-Grafikkarte (NVIDIA) unter der Softwareumgebung von TensorFlow 2.5.0 und Python 3.9.7 trainiert. Bevor das Training begann, wurden die paarweisen Eingabe-/GT-Bilder durch zufälliges Beschneiden, horizontales/vertikales Spiegeln und Drehtransformation in mehrere Patch-Paare aufgeteilt, um den Trainingsdatensatz weiter zu bereichern, der letztendlich ~20.000 Paare von 2D-Patches (128×128 Pixel) oder ~10.000 Paare von 3D-Patches (64×64×13 Voxel) erzeugte. Das Training wurde typischerweise mit dem Adam-Optimizer und einem initialen Lernrate von 0,5 × 10^(-4) durchgeführt, die alle 10.000 Iterationen um einen Faktor von 0,5 abnahm. Die Batch-Größe betrug 4 für 2D-Bilder und 3 für 3D-Stacks. Der gesamte Trainingsprozess erforderte in der Regel 50.000 Iterationen für 2D-Bilder und 10.000 Iterationen für 3D-Stacks. Die verstrichene Zeit für das Training von 50.000 Iterationen für 2D-Modelle und 10.000 Iterationen für 3D-Modelle betrug ~1 Stunde und ~2 Stunden, respectively. Wie oft bei den meisten Methoden basierend auf tiefem Lernen ist das Training von ZS-DeconvNet ein einmaliger Vorgang in den meisten Fällen der Live-Zell-Bildgebung, bei dem die Benutzer das ZS-DeconvNet-Modell mit allen Frames trainieren und dann das gut trainierte Modell auf alle Daten desselben biologischen Präparats mit hoher Verarbeitungsgeschwindigkeit anwenden. Um die durch Dekonvolution verursachten Randartefakte zu eliminieren, fügten wir in der Regel 2 leere Slices an die Ober- und Unterseite der 3D-Stacks und einen Rand von 8 Pixeln für jede xy-Slice in beiden Trainings- und Inferenzprozessen hinzu (Supplementary Fig. 30a). Insbesondere beim Verarbeiten der Zeitverlaufsdaten der Zellmitose (Fig. 3e, f) ermöglichte die unüberwachte Eigenschaft von ZS-DeconvNet eine Testzeit-Adaptationslernstrategie, bei der wir zunächst ein allgemeines Modell für jede biologische Struktur mit Daten des gesamten Prozesses trainierten und dann das vortrainierte Modell für jeden Zeitpunkt mit einer kleinen Anzahl von TrainingsSchritten (in der Regel 50 Iterationen, die ~1 Minute dauerten) feinjustierten, um die strukturelle Information der Rohdaten voll auszunutzen und die optimale SR-Leistung zu erzielen. Zu beachten ist, dass die Testzeit-Adaptation nicht notwendig, sondern eine optionale Technik ist, um die Leistung von ZS-DeconvNet insbesondere unter Umständen zu verbessern, bei denen sich die biologischen Präparate während des Beobachtungszeitraums stark verändern, z. B. die Chromosomen während der Mitose (Supplementary Fig. 31).
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     Datennachverarbeitung und SR-Bildbewertung
    </title>
    <p id="Par36">
     Für Bildgebungsmodi, die eine weite Feld-detektion wie LLSM verwenden, kann das fixe Muster-Rauschen (FPN), das durch die Nicht-Uniformität in der Pixel-Empfindlichkeit der Kamera verursacht wird, nicht durch noise2noise-basierte Schemata entfernt werden. In unserer Implementierung von ZS-DeconvNet würde das FPN in der Dekonvolutionsphase verstärkt und wurde insbesondere bei Bildgebungsbedingungen mit extrem niedrigem SNR nicht mehr vernachlässigbar. Für sCMOS-Sensoren, die in der Fluoreszenzmikroskopie am häufigsten verwendet werden, präsentiert sich das fixe Muster in der Regel als regelmäßiges Erscheinungsbild von horizontalen oder vertikalen Streifen, die dem Spaltenverstärker zuzuschreiben sind. Um dies zu beheben, wendeten wir einfach eine Apodisationsmaske im Fourier-Bereich an, um die streifenförmigen Artefakte zu unterdrücken, während wir andere Frequenzkomponenten der Proben erhalten haben (Supplementary Fig. 30b). Es ist zu beachten, dass das fixe Muster-Rauschen auch grundlegend durch Vor-Kalibrierung der erfassten Rohbilder vor dem Einbringen in das Netzwerkmodell entfernt werden kann, indem man den etablierten Verfahren folgt.
    </p>
    <p id="Par37">
     Andere computergestützte SR-Ansätze, die in dieser Arbeit verglichen werden, wie z. B. die sparse Dekonvolution, DeepCAD-basierte Dekonvolution und SRRF, wurden gemäß den Anweisungen in den Originalarbeiten implementiert. Insbesondere versuchten wir, die optimalen Hyperparameter für die sparse Dekonvolution auszuwählen, um ein rekonstruiertes Bild mit den wenigsten Artefakten und der höchsten Auflösung zu erhalten. Die DeepCAD-basierte Dekonvolution (Fig. 2a und 3f) wurde durchgeführt, indem die zeitliche Stichprobenschema in unser ZS-DeconvNet-Framework integriert wurde, d. h. Bilder, die aus den Zeitverlaufsdaten stichprobenartig entnommen wurden, um unsere dual-stufigen Netzwerkmodelle zu trainieren, wodurch wir sicherstellten, dass das gleiche Modell und die gleichen Rechenkosten für einen fairen Vergleich verwendet wurden.
    </p>
    <p id="Par38"/>
    <p id="Par39">
     Die lineare Transformation wird auf alle Methoden angewendet, um einen fairen Vergleich zu ermöglichen; (3) Berechnung des PSNR zwischen dem normalisierten GT-Bild
     <bold>
      x
     </bold>
     und dem linear transformierten Bild
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     .
    </p>
    <p id="Par40">
     Für die PSNR-Bewertung von 3D ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ) verwendeten wir direkt die LLS-SIM-Bilder als Referenz, da sowohl LLS-SIM als auch unser 3D ZS-DeconvNet eine Auflösungsverbesserung von etwa 1,5-fach theoretisch bereitstellten. Der Gesamtberechnungsprozess ist ähnlich wie bei den 2D-Fällen, mit Ausnahme, dass die SR-Stacks nicht konvolutiert wurden und der PSNR nur innerhalb der feature-only-Regionen mit einem Schwellenwert von 0,02 berechnet wurde, um ein abnormal hohes PSNR-Wert zu vermeiden.
    </p>
    <p id="Par41">
     Um einen besseren Kontrast und eine bessere Visualisierung zu ermöglichen, führten wir eine percentile-Normalisierung für die Deconvolutionsbilder durch, die durch RL-Deconvolution, sparse Deconvolution und ZS-DeconvNet generiert wurden, die wie folgt formuliert ist:
     <disp-formula id="Equ15">
      <label>
       15
      </label>
      <alternatives>
       <math id="Equ15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="normal">
           Norm
          </mi>
         </mrow>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             l
            </mi>
            <mi>
             o
            </mi>
            <mi>
             w
            </mi>
           </mrow>
          </msub>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             h
            </mi>
            <mi>
             i
            </mi>
            <mi>
             g
            </mi>
            <mi>
             h
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               h
              </mi>
              <mi>
               i
              </mi>
              <mi>
               g
              </mi>
              <mi>
               h
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
        <mo>
         ,
        </mo>
       </math>
       <tex-math id="Equ15_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{Norm}}}}}}}_{p}\left({{{{{\bf{Y}}}}}},{p}_{{low}},{p}_{{high}}\right)=\frac{{{{{{\bf{Y}}}}}}-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)}{{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{high}}\right)-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)},$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ15.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     , wobei percentile(
     <bold>
      Y,
     </bold>
     <italic>
      p
     </italic>
     ) den Intensitätswert ausgibt, der
     <italic>
      p
     </italic>
     % in Bild
     <bold>
      Y
     </bold>
     rangiert
     <sup/>
     .
     <inline-formula id="IEq40">
      <alternatives>
       <math id="IEq40_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           l
          </mi>
          <mi>
           o
          </mi>
          <mi>
           w
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq40_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{low}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq40.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     und
     <inline-formula id="IEq41">
      <alternatives>
       <math id="IEq41_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           h
          </mi>
          <mi>
           i
          </mi>
          <mi>
           g
          </mi>
          <mi>
           h
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq41_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{high}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq41.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     werden typischerweise auf 3 und 100 in unseren Abbildungen und Videos eingestellt.
    </p>
   </sec>
   <sec id="Sec22">
    <title>
     Zellkultur, Transfektion und Färbung
    </title>
    <p id="Par42">
     Cos7-, HeLa- und 293-T-Zellen sowie ihre stabilen Zelllinien wurden in DMEM (Gibco, Kat.-Nr. 11965092) kultiviert, das mit 10% fetalem Kälberserum (Gibco, Kat.-Nr. 10099141 C) und 1 × Penicillin-Streptomycin (Thermo Fisher, 15140122) unter 37 °C in einem Thermo Scientific Heracell 150i CO
     <sub>
      2
     </sub>
     -Inkubator supplementiert wurde. SUM159-Zellen wurden in DMEM/F12K-Medium kultiviert, das mit 5% fetalem Kälberserum (FBS) und 1% Penicillin-Streptomycin-Lösung supplementiert wurde.
    </p>
    <p id="Par43">
     Für die Live-Zell-Imaging wurden 35 mm große Deckgläser mit 50 μg/ml Kollagen und 1 × 10 Zellen beschichtet. Für die transiente Transfektion wurden Zellen mit Plasmiden unter Verwendung von Lipofectamine 3000 (Invitrogen, Kat.-Nr. L3000150) nach dem Protokoll des Herstellers 12 Stunden nach dem Plating transfiziert. Die Zellen wurden 12 Stunden nach der Transfektion imagiert. Wenn angegeben, wurden die Zellen, die mit Halo-Tag-Plasmiden transfiziert wurden, mit 10 nM JF549-Ligand für 15 Minuten nach dem veröffentlichten Protokoll
     <sup>
      <xref ref-type="bibr" rid="CR65">
       65
      </xref>
     </sup>
     markiert. Die Zellen wurden mit frischem Medium gewaschen, um ungebundenes Ligand zu entfernen, und sofort danach imagiert. Die in der transienten Transfektion verwendeten Plasmide umfassen Lifeact-mEmerald, Clathrin-mEmerald, 3 × mEmerald-Ensconsin, Lamp1-Halo, 2 × mEmerald-Tomm20, Myosin2-Halo, KDEL-mCherry und Halo-Calnexin.
    </p>
    <p id="Par44">
     Für die Lentiviruspaketering wurden 1 μg Lentivirustransfer-Vektor-DNA zusammen mit 0,5 μg psPAX2-Paketering und 0,5 μg pMD2.G-Envelop-Pasmid-DNA in 90% konfluenten HEK293T-Zellen in einer 6-cm-Petri-Schale unter Verwendung von Lipofectamin 3000 nach dem Herstellerprotokoll ko-transfiziert. Nach 2 Tagen wurde das Supernatant geerntet und mit einem 0,22-μm-Filter (Millipore) gefiltert. Für die Konstruktion von stabilen Zellen wurden HeLa- und Cos7-Zellen mit Lentiviren infiziert, die den endoplasmatischen Retikulum-Marker Calnexin-mEmerald und den F-Aktin-Marker Lifeact-mEmerald kodierten
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     . 48 Stunden später wurden die Zellen durch einen Flusszytometer (FACSAria III, BD Biosciences) angereichert und dann jeweils eine Zelle pro Brunnen in 96-Well-Platten gepflanzt. Monoklonale Zellen wurden für unsere Experimente verwendet. Insbesondere wurden Lifeact-mEmerald für COS7 in Figs.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     und
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     verwendet; Calnexin-mEmerald, Mito-dsRed und Halo-H2B für HeLa-Zellen in Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ; H2B-mCherry für HeLa-mEmerald-SC35 in Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     Genomeditierte Zelllinien
    </title>
    <p id="Par45">
     SUM159-Zellen wurden sequenziell geneditiert, um EGFP an das N-Terminus von Rab11A und dann Halo an das C-Terminus von Lamp1 unter Verwendung des CRISPR/Cas9-Ansatzes
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     zu inkorporieren. Die einzelnen Leit-RNA-Zielsequenzen sind 5'-TCGCTCCTCGGCCGCGCAAT-3' für RAB11A und 5'-CTATCTAGCCTGGTGCACGC-3' für LAMP1. SUM159 wurden mit dem EGFP-Rab11A-Donorplasmid, dem Plasmid, das für die spCas9 kodiert, und dem freien PCR-Produkt, das die Ziel-Leit-RNA-Sequenz enthält, unter Verwendung von Lipofectamin 3000 (Invitrogen) nach dem Herstellerprotokoll transfiziert. Die Zellen, die EGFP exprimierten, wurden durch fluoreszenzaktivierte Zellsortierung (FACS) (FACSAria II, BD Biosciences) angereichert und dann einer Einzelzellsortierung in 96-Well-Platten unterzogen. Die monoklonalen Zellen mit erfolgreicher EGFP-Inkorporation wurden durch PCR-Screening unter Verwendung von GoTaq-Polymerase (Promega) identifiziert. Die klonalen SUM159-Zellen, die EGFP-Rab11A +/+ exprimierten, wurden einer zweiten Runde der Geneditierung unterzogen, um Lamp1-Halo in das Genom zu inkorporieren, wie oben beschrieben. Die transfizierten Zellen wurden mit 10 nM Janelia Fluor 646 HaloTag-Liganden (Promega) für 15 Minuten gefärbt. Um den ungebundenen Farbstoff zu entfernen, wurden die Proben mit frischem Medium gewaschen und dann durch FACS angereichert. Die monoklonalen SUM159-Zellen, die sowohl EGFP-Rab11A +/+ als auch Lamp1-Halo +/+ exprimierten, wurden durch PCR- und Western-Blot-Analyse bestätigt.
    </p>
    <p id="Par46">
     SUM159-Zellen wurden geneditiert, um EGFP an das C-Terminus von Clathrin-Leichtketten-A (Clathrin-EGFP) unter Verwendung des TALEN-basierten Ansatzes
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     zu inkorporieren. Die Clathrin-EGFP-exprimierenden Zellen wurden durch zwei aufeinanderfolgende Bulk-Sortierungen angereichert.
    </p>
    <p id="Par47">
     HeLa-Zelllinien wurden geneditiert, um mEmerald an das C-Terminus des humanen genetischen SC35 unter Verwendung des CRISPR-Cas9-Geneditierungssystems zu inkorporieren. Die Ziel-Leit-RNA-Sequenz ist 5'-CGAGCAGCACTCCTAATGAT-3', und die Leit-RNA wurde in pX330A-1×2 (Addgene, 58766) ligiert. Das resultierende Plasmid wurde hier als pX330-SC35-gRNA bezeichnet. Um den Donorvektor p-SC35-doner zu konstruieren, wurde mEmerald mit etwa 1800 bp Homologiearmen, die komplementär zum Stopcodon des humanen genetischen SC35-Lokus sind, ligiert und in pEASY-blunt (Transgene, CB101) kloniert. 2 × 10 HeLa-Zellen, die in einer 6-cm-Petri-Schale wuchsen, wurden mit 1,2 μg pX330-SC35-gRNA und 0,4 μg p-SC35-doner transfiziert. 48 Stunden nach der Transfektion wurden die mEmerald-positiven Zellen durch FACS (FACSAria III, BD Biosciences) sortiert. Nach einer Woche wurden H2B-mCherry-Lentiviren in die sortierten Zellen infiziert und dann einzelne Zellen in 96-Well-Platten gepflanzt. Nach zwei Wochen wurden die genetischen DNA von verschiedenen Einzelzellklonen extrahiert und durch PCR- und Western-Blot-Analyse validiert. Homozygote SC35-Knock-in-Zellen wurden für die Studie ausgewählt. Die erfolgreiche SC35-Knock-in wurde durch PCR- und Western-Blot-Analyse bestätigt
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     <italic>
      C. elegans
     </italic>
     -Embryon-Präparation
    </title>
    <p id="Par48">
     <italic>
      C. elegans
     </italic>
     -Stämme wurden bei 20 °C auf Nematoden-Wachstumsmedium (NGM)-Platten, die mit OP50 beimpft waren, nach Standardprotokollen
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     kultiviert. TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ;
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ;
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     wurde in dieser Studie verwendet. Das Plasmid
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     wurde nach dem Clontech In-Fusion PCR-Klonierungssystem konstruiert und in
     <italic>
      jcIs1;qxIs257
     </italic>
     mikroinjiziert
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     . Der extrachromosomale Array
     <italic>
      wyEx51119
     </italic>
     markierte die epidermale Zellmembran.
     <italic>
      jcIs1
     </italic>
     markierte die apikale Junction-Domäne von
     <italic>
      C. elegans
     </italic>
     .
     <italic>
      qxIs257
     </italic>
     markierte Lysosomen in epidermalen Zellen
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     .
    </p>
    <p id="Par49">
     Etwa 50 transgene Würmer im L4-Stadium wurden 48 bis 60 Stunden vor den Experimenten auf NGM-Platten mit frischem OP50 gelegt. Transgene Eier wurden unter dem dissezierenden Fluoreszenzmikroskop (Olympus MVX10) gesammelt und auf 3% Agarose-Pads montiert. Embryonen im Stadium von Lima-Bohne bis 2-fach wurden dann mit dem 3D-WF-Modus unseres Multi-SIM-Systems aufgenommen.
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     Maus-Embryon-Präparation
    </title>
    <p id="Par50">
     Die in dieser Studie verwendeten Mäuse waren vom Hintergrund C57BL/6 J. Alle Tierversuche wurden von den Animal Care and Use Committees (IACUC) des Instituts für Biophysik, Chinesische Akademie der Wissenschaften, Peking, China, genehmigt. Präimplantations-Embryonen wurden von 5-6 Wochen alten Weibchen isoliert, die durch intraperitoneale Injektion von 5 internationalen Einheiten (IU) Schwangerem-Stuten-Serum-Gonadotropin (PMSG; LEE BIOSOLUTIONS) und 5 IU humanem Choriongonadotropin (hCG; Millipore) 48 Stunden später superovuliert und mit Männchen verpaart wurden. Zygoten wurden bei E0,5 in M2-Medium (Millipore) gewonnen und in KSOM-Medium (Millipore) in einem CO2-Inkubator (Thermo Scientific) bei 37°C mit 5% CO2 bis zum späten 8-Zell-Stadium kultiviert.
    </p>
    <p id="Par51">
     Für die Immunfluoreszenz wurden Embryonen mit 4% Paraformaldehyd in PBS für 30 Minuten bei Raumtemperatur (RT) fixiert und drei Mal mit PBS gewaschen. Embryonen wurden dann in 0,5% TritonX-100 (Sigma) in PBS für 20 Minuten bei RT permeabilisiert, drei Mal mit PBS gewaschen, in 1% Rinder-Serum-Albumin in PBS für 1 Stunde bei RT blockiert und über Nacht bei 4°C mit anti-pERM-Antikörper (Abcam, ab76247), anti-alpha-Tubulin-FITC (Sigma, F2168-.2 ML) und Phalloidin-Rhodamin (Molecular Probes, R415) inkubiert. Dann wurden Embryonen drei Mal mit PBS gewaschen, für 1 Stunde bei RT mit sekundären Antikörpern (Life technologies) inkubiert, für 15 Minuten bei RT mit Hoescht 33342 (Thermo) gefärbt, drei Mal mit PBS gewaschen und mit dem selbstgebauten Konfokalmikroskop aufgenommen.
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     3D-Bildvisualisierung
    </title>
    <p id="Par52">
     Die axial farbkodierten Bilder von Lysosomen in Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     wurden mit Fiji erstellt. Die 3D-Renderings-Bilder von Mitose-Zellen und Maus-Embryonen in Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     wurden mit der kommerziellen Software Amira visualisiert und erstellt.
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     Statistik und Reproduzierbarkeit
    </title>
    <p id="Par53">
     Experimente in Fig.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i,
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f,
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     und
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     wurden unabhängig mit mindestens 3 Proben, d. h. Zellen oder Embryonen, wiederholt, die alle ähnliche Ergebnisse erzielten.
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     Zusammenfassung der Berichterstattung
    </title>
    <p id="Par54">
     Weitere Informationen zum Forschungsdesign sind im
     <xref ref-type="supplementary-material" rid="MOESM13">
      Nature Portfolio Reporting Summary
     </xref>
     verfügbar, der diesem Artikel beigefügt ist.
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Danksagungen
   </title>
   <p>
    Die Autoren danken T. Kirchhausen für die Spenderplasmide, die für die Geneditierung verwendet wurden, und für die Hilfe bei der Erstellung der geneditierten Zelllinien, sowie Prof. Xiaochen Wang und Dr. Kangmin He für
    <italic>
     C. elegans
    </italic>
    -Stämme und geneditierte SUM159-Zelllinien. Diese Arbeit wurde unterstützt durch Zuschüsse der Nationalen Naturwissenschaftlichen Stiftung Chinas (32125024, 32271513, 62071271 und 62088102); des Ministeriums für Wissenschaft und Technologie (2021YFA1300303 und 2020AA0105500); der Chinesischen Akademie der Wissenschaften (ZDBS-LY-SM004 und XDA16021401); des Collaborative Research Fund des Chinesischen Instituts für Hirnforschung, Peking (2021-NKX-XM-03); der China Postdoctoral Science Foundation (2022M721842, 2023T160365); der New Cornerstone Science Foundation; des Shuimu Tsinghua Scholar Program (2022SM035); der Peking Naturwissenschaftlichen Stiftung (JQ21012).
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Beiträge der Autoren
   </title>
   <p>
    Q.D. und Dong Li überwachten die Forschung. Q.D., Dong Li und C.Q. konzipierten und initiierten dieses Projekt. C.Q. entwarf die detaillierten Implementierungen unter der Anleitung von Q.D. und Dong Li. Y.Z, C.Q. und X.C entwickelten den Python-Code, führten Simulationen durch und verarbeiteten relevante Bildgebungsdaten. H.C., C.Q. und Y.Z. entwickelten das Fiji-Plugin. T.J., R.W, C.Q, H.L., W.F., Di Li und J.G. bereiteten Proben vor und führten Bildgebungs-Experimente durch. C.Q., Y.Z., X.C. und Q.M. analysierten die Daten mit konzeptionellen Ratschlägen von Q.D., Dong Li, J.W, Y.W. und H.Q. C.Q., Y.Z und Q.M. komponierten die Abbildungen und Videos, erstellten die Tutorial-Homepage unter der Aufsicht von Q.D. und Dong Li. Q.D., Dong Li und C.Q. schrieben das Manuskript, mit Input von allen Autoren. Alle Autoren diskutierten die Ergebnisse und kommentierten das Manuskript.
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Peer-Review
   </title>
   <sec id="FPar1">
    <title>
     Peer-Review-Informationen
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Datenverfügbarkeit
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Code-Verfügbarkeit
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Interessenkonflikte
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    Referenzen
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      Zusätzliche Informationen
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      Quelldaten
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Zusätzliche Informationen
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
