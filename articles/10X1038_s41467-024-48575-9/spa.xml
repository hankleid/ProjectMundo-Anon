<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type='text/xsl' href='/w/ProjectMundo-Anon-106A/style/jats-html.xsl'?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     El aprendizaje sin ejemplos previos permite la eliminación instantánea de ruido y super-resolución en la microscopía de fluorescencia óptica
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Resumen
    </title>
    <p id="Par1">
     Los métodos computacionales de super-resolución, incluidos los algoritmos analíticos convencionales y los modelos de aprendizaje profundo, han mejorado sustancialmente la microscopía óptica. Entre ellos, las redes neuronales profundas supervisadas han demostrado un rendimiento sobresaliente, sin embargo, requieren abundantes datos de entrenamiento de alta calidad, los cuales son laboriosos e incluso imprácticos de adquirir debido a la alta dinámica de las células vivas. Aquí, desarrollamos redes de deconvolución sin ejemplos previos (ZS-DeconvNet) que mejoran instantáneamente la resolución de las imágenes de microscopio en más de 1.5 veces sobre el límite de difracción con una fluorescencia 10 veces menor que las condiciones ordinarias de imagen de super-resolución, de manera no supervisada sin la necesidad de verdades fundamentales o adquisición adicional de datos. Demostramos la versátil aplicabilidad de ZS-DeconvNet en múltiples modalidades de imagen, incluyendo microscopía de fluorescencia de reflexión interna total, microscopía de campo amplio tridimensional, microscopía confocal, microscopía de dos fotones, microscopía de hoja de luz de rejilla, y microscopía de iluminación estructurada multimodal, lo que permite la imagen de super-resolución 2D/3D a largo plazo y en múltiples colores de bioprocesos subcelulares desde células mitóticas individuales hasta embriones multicelulares de ratón y
     <italic>
      C. elegans
     </italic>
     .
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    Introducción
   </title>
   <p id="Par3">
    La microscopía de fluorescencia óptica es una herramienta esencial para la investigación biológica. Los desarrollos recientes de técnicas de superresolución (SR) proporcionan una capacidad de resolución sin precedentes para visualizar las finas estructuras dinámicas de diversos bioprocesos
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
    </sup>
    . Sin embargo, el aumento en la resolución espacial mediante cualquier método SR conlleva compromisos en otras métricas de imagen, por ejemplo, duración o velocidad, que son igualmente importantes para diseccionar bioprocesos
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
    </sup>
    . Recientemente, los métodos computacionales de SR han ganado considerable atención por su capacidad para mejorar instantáneamente la resolución de la imagen in silico, permitiendo una mejora significativa de los sistemas de microscopía de fluorescencia existentes y la extensión de su rango de aplicación
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    .
   </p>
   <p id="Par4">
    En general, los métodos computacionales de SR existentes se pueden clasificar en dos categorías: métodos basados en modelos analíticos, como los algoritmos de deconvolución, y métodos basados en aprendizaje profundo, por ejemplo, redes neuronales SR
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . La primera categoría a menudo emplea modelos analíticos que prescriben ciertas suposiciones sobre las propiedades del espécimen y la imagen, por ejemplo, esparcidad y simetría local, para mejorar la resolución de la imagen con múltiples parámetros ajustables. El ajuste de parámetros depende de la experiencia y consume tiempo, y los resultados de los modelos analíticos dependen en gran medida de los conjuntos de parámetros
    <sup>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     ,
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    . Además, en experimentos prácticos, los modelos hechos a mano con ciertas suposiciones no pueden abordar la complejidad estadística completa de la imagen de microscopio, por lo que carecen de robustez y son propensos a generar artefactos, especialmente bajo condiciones de baja relación señal-ruido (SNR)
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    . Por otro lado, los métodos de SR basados en aprendizaje profundo (DLSR) han logrado un éxito sorprendente al aprender la relación de transformación de imagen de extremo a extremo según grandes cantidades de datos ejemplares sin la necesidad de un modelo analítico explícito
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Cabe destacar que el esquema de inversión basado en datos a través del aprendizaje profundo puede aproximar no solo la función pseudoinversa del proceso de degradación de la imagen, sino también las características estocásticas de las soluciones SR. No obstante, el entrenamiento de modelos DLSR requiere adquirir grandes cantidades de imágenes de entrada de baja resolución emparejadas y de imágenes SR de alta calidad como verdad de base (GT), lo cual es extremadamente laborioso y a veces incluso impracticable debido a las rápidas dinámicas o al bajo SNR de fluorescencia en especímenes biológicos
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Además, el rendimiento de los métodos DLSR depende en gran medida de la calidad y cantidad de los datos de entrenamiento
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Estos factores obstaculizan significativamente la amplia aplicación de los métodos DLSR en experimentos de imagen diarios a pesar de su atractivo rendimiento SR en comparación con los métodos basados en modelos analíticos
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    .
   </p>
   <p id="Par5">
    Aquí, presentamos un marco de red neuronal profunda de deconvolución de cero disparos (ZS-DeconvNet) que es capaz de entrenar una red DLSR de manera no supervisada utilizando tan solo una sola imagen plana o un conjunto de imágenes volumétricas de baja resolución y bajo SNR, lo que resulta en una implementación de cero disparos
    <sup>
     <xref ref-type="bibr" rid="CR18">
      18
     </xref>
    </sup>
    . De esta manera, en comparación con los métodos DLSR de última generación, el ZS-DeconvNet puede adaptarse a diversas circunstancias de bioimagen, donde los bioprocesos son demasiado dinámicos, demasiado sensibles a la luz para adquirir las imágenes SR de verdad de base, o el proceso de adquisición de imágenes se ve afectado por factores desconocidos y no ideales. Caracterizamos que ZS-DeconvNet puede mejorar la resolución en más de 1.5 veces sobre los límites de difracción con alta fidelidad y cuantificabilidad, incluso cuando se entrena con una sola imagen de entrada de bajo SNR y sin la necesidad de ajuste de parámetros específicos de la imagen
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     ,
     <xref ref-type="bibr" rid="CR19">
      19
     </xref>
     ,
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
     ,
     <xref ref-type="bibr" rid="CR21">
      21
     </xref>
     ,
     <xref ref-type="bibr" rid="CR22">
      22
     </xref>
     ,
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
    </sup>
    . Demostramos que el ZS-DeconvNet debidamente entrenado podría inferir la imagen de alta resolución en una escala de tiempo de milisegundos, logrando una imagen SR 2D/3D de alto rendimiento a largo plazo de múltiples interacciones de orgánulos, dinámicas citoesqueléticas y de orgánulos durante los procesos sensibles a la luz de migración y mitosis, y estructuras y dinámicas subcelulares en el desarrollo de
    <italic>
     C. elegans
    </italic>
    y embriones de ratón. Además, para permitir que el ZS-DeconvNet sea ampliamente accesible para la comunidad de investigación biológica, construimos una caja de herramientas de plugin de Fiji y una página de inicio de tutorial para los métodos ZS-DeconvNet
    <sup>
     <xref ref-type="bibr" rid="CR24">
      24
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    Resultados
   </title>
   <sec id="Sec3">
    <title>
     Desarrollo y caracterización de ZS-DeconvNet
    </title>
    <p id="Par6">
     El concepto de ZS-DeconvNet se basa en el modelo de imagen óptica hacia adelante informado por un solucionador de problemas inversos no supervisado:
     <disp-formula id="Equ1">
      <label>
       1
      </label>
      <alternatives>
       <math id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <msubsup>
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\arg }}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\Big|\Big|{{{{{{\bf{y}}}}}}-{\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{\bf{y}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }{\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <bold>
      y
     </bold>
     denota la imagen ruidosa de baja resolución, PSF es la función de dispersión de puntos (PSF),
     <inline-formula id="IEq1">
      <alternatives>
       <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     representa una red neuronal profunda (DNN) con parámetros entrenables
     <bold>
      θ
     </bold>
     , y
     <inline-formula id="IEq2">
      <alternatives>
       <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     indica la operación de submuestreo. Si la DNN se entrena directamente a través de la función objetivo anterior, amplificará indeseablemente el ruido de fotones contenido en las imágenes biológicas, lo que contaminará sustancialmente la información real del espécimen en condiciones de bajo SNR (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1a
     </xref>
     ). Para mejorar la robustez al ruido de ZS-DeconvNet mientras se mantiene su característica no supervisada, adoptamos un esquema de recorruptación de imágenes que genera dos imágenes recorruptadas independientes del ruido a partir de la imagen original, que luego se utilizan como entradas y GTs en el entrenamiento de la red (Métodos). Demostramos teóricamente la validez de la aproximación gaussiana al modelo de ruido mixto Poisson-Gaussiano para imágenes sCMOS ordinarias y probamos la convergencia de incorporar el esquema de recorruptación en el solucionador de problemas inversos no supervisado (Nota Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Además, introdujimos el término de regularización Hessiana, que ha demostrado ser útil para mitigar artefactos de reconstrucción en imágenes de microscopía, para regular la convergencia de la red (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b–e
     </xref>
     ). En conjunto, la función objetivo general de ZS-DeconvNet se puede formular como:
     <disp-formula id="Equ2">
      <label>
       2
      </label>
      <alternatives>
       <math id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfrac>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </mfrac>
        <msubsup>
         <mrow>
          <mo mathsize="big">
           ∑
          </mo>
         </mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </msubsup>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msup>
           <mrow>
            <mi>
             D
            </mi>
           </mrow>
           <mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </msup>
          <mi mathvariant="bold">
           g
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi>
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   i
                  </mi>
                 </mrow>
                </msub>
                <mi mathvariant="bold-italic">
                 +
                </mi>
                <mi>
                 D
                </mi>
                <mi mathvariant="bold">
                 g
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mi>
               i
              </mi>
             </mrow>
            </msub>
            <mi mathvariant="bold-italic">
             +
            </mi>
            <mi>
             D
            </mi>
            <mi mathvariant="bold">
             g
            </mi>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{arg}}}}}}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\frac{1}{N}{\sum }_{i=1}^{N}{{{{{\mathcal{L}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}-{D}^{-1}{{{{{\bf{g}}}}}},{\left({f}_{\theta }\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }\right)+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <italic>
      N
     </italic>
     es el número total de imágenes a procesar,
     <inline-formula id="IEq3">
      <alternatives>
       <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
       </math>
       <tex-math id="IEq3_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq3.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es una matriz de control de ruido invertible que se puede calcular según los niveles de señal y ruido (Métodos), y
     <bold>
      g
     </bold>
     es un mapa de ruido aleatorio que se muestrea de una distribución normal estándar. Nos referimos a la primera parte de la función objetivo como el término de degradación, que representa la fidelidad de la inferencia, y la segunda parte como el término de regularización, que racionaliza las salidas SR
     <sup>
      <xref ref-type="bibr" rid="CR25">
       25
      </xref>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
      <xref ref-type="bibr" rid="CR27">
       27
      </xref>
      ,
      <xref ref-type="bibr" rid="CR28">
       28
      </xref>
     </sup>
     .
    </p>
    <p id="Par7">
     Después de definir la función objetivo, adoptamos una arquitectura DNN de dos etapas compuesta por dos U-Nets conectados secuencialmente como una base simple pero efectiva para ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig1">
      1a, b
     </xref>
     y Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2a
     </xref>
     ). La primera etapa sirve como un eliminador de ruido para generar imágenes sin ruido de acuerdo con la pérdida de eliminación de ruido (Métodos), y la segunda etapa mejora la resolución de la imagen de acuerdo con la pérdida de deconvolución no supervisada descrita anteriormente. Empíricamente encontramos que la arquitectura de dos etapas y la función de pérdida regulada por el modelo físico estabilizan los procedimientos de entrenamiento y otorgan interpretabilidad al modelo de red en general
     <sup>
      <xref ref-type="bibr" rid="CR29">
       29
      </xref>
     </sup>
     .
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="en">
       <title>
        Redes de deconvolución de cero disparos.
       </title>
       <p>
        <bold>
         a
        </bold>
        La arquitectura de doble etapa de ZS-DeconvNet y el esquema de su fase de entrenamiento.
        <bold>
         b
        </bold>
        El esquema de la fase de inferencia de ZS-DeconvNet.
        <bold>
         c
        </bold>
        Imágenes SR representativas de Lyso y MTs reconstruidas por deconvolución RL (segunda columna), deconvolución dispersa (tercera columna) y ZS-DeconvNet (cuarta columna). Las imágenes WF claras se muestran como referencia.
        <bold>
         d
        </bold>
        Comparaciones estadísticas de deconvolución RL, deconvolución dispersa y ZS-DeconvNet en términos de PSNR y resolución (
        <italic>
         n
        </italic>
        = 100 regiones de interés).
        <bold>
         e
        </bold>
        Comparaciones de ancho completo a la mitad del máximo (FWHM) de imágenes WF claras e imágenes procesadas mediante deconvolución RL, deconvolución dispersa y ZS-DeconvNet (
        <italic>
         n
        </italic>
        = 30 microtúbulos). El límite de difracción teórico está etiquetado con la línea discontinua gris como referencia.
        <bold>
         f
        </bold>
        Comparación del tiempo de prueba entre la deconvolución dispersa basada en GPU y ZS-DeconvNet (promedio de 25 imágenes de prueba de 1024 × 1024 píxeles). Línea central, medianas; límites, 75% y 25%; bigotes, el valor más grande entre el punto de datos más grande y el percentil 75 más 1.5× el rango intercuartil (IQR), y el valor más pequeño entre el punto de datos más pequeño y el percentil 25 menos 1.5× el IQR; valores atípicos, puntos de datos más grandes que el bigote superior o más pequeños que el bigote inferior. Los datos fuente se proporcionan como un archivo de datos fuente. Barra de escala, 1.5 μm (
        <bold>
         a
        </bold>
        ), 5 μm (
        <bold>
         c
        </bold>
        ), 2 μm (regiones ampliadas en (
        <bold>
         c
        </bold>
        )).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig1_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par8">
     Para caracterizar y evaluar ZS-DeconvNet, primero simulamos las imágenes de microscopía de estructuras puntuales y tubulares contaminadas por ruido Gaussiano-Poisson en niveles de señal crecientes de 5 a 25 cuentas de fotones promedio, lo que nos permitió probar sistemáticamente cómo las configuraciones de hiperparámetros de recorruptión en diferentes condiciones de imagen influyen en los resultados finales (Nota Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2
     </xref>
     ). Encontramos que los hiperparámetros óptimos son teóricamente independientes del contenido de la imagen y de los niveles de señal (Figs. Suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      5
     </xref>
     ), permitiendo así una aplicación robusta de ZS-DeconvNet en varios especímenes biológicos y configuraciones de imagen (Nota Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ). A continuación, comparamos el rendimiento de los modelos ZS-DeconvNet entrenados con los datos aumentados mediante recorruptión de una sola imagen ruidosa con algoritmos de deconvolución analítica o los modelos entrenados con números de imágenes simuladas o adquiridas independientemente. Para ello, empleamos el modo de iluminación de fluorescencia reflectante interna total (TIRF) de nuestra microscopía de iluminación estructurada multimodal construida en casa (Multi-SIM) para adquirir ~20 conjuntos de imágenes TIRF limitadas por difracción a bajo y alto SNR para cada estructura subcelular de lisosomas (Lyso) y microtúbulos (MTs), de las cuales las imágenes de bajo SNR se usaron para entrenamiento y prueba, mientras que sus contrapartes de alto SNR sirvieron como referencia (Métodos). Encontramos que la relación señal-ruido de pico (PSNR) y la resolución de las imágenes ZS-DeconvNet fueron sustancialmente mejores que las generadas por algoritmos analíticos, como el clásico Richardson-Lucy (RL) y la deconvolución dispersa más reciente (Fig.
     <xref ref-type="fig" rid="Fig1">
      1c–e
     </xref>
     ) y la tasa de rendimiento de un ZS-DeconvNet bien entrenado es &gt;100 veces mayor que la del algoritmo de deconvolución dispersa (Fig.
     <xref ref-type="fig" rid="Fig1">
      1f
     </xref>
     ). En particular, incluso si el ZS-DeconvNet fue entrenado con los datos aumentados de una sola imagen de entrada, la calidad perceptual y las métricas cuantificadas de sus imágenes de salida fueron comparables con las imágenes del modelo entrenado con mayores cantidades de datos (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      6
     </xref>
     ). Además, validamos la mejora de resolución, cuantificabilidad y la capacidad de generalización de ZS-DeconvNet (Figs. Suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      7
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      10
     </xref>
     ), y lo comparamos con el modelo supervisado DFCAN (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      11
     </xref>
     ) en datos sintéticos y experimentales. Estas caracterizaciones demuestran que ZS-DeconvNet es capaz de generar imágenes DLSR de alta calidad con una mejora de resolución de 1.5 veces en relación con el límite de difracción mientras utiliza la menor cantidad de datos de entrenamiento, lo que tiene un gran potencial para mejorar el rendimiento de imagen de diversos sistemas de microscopía y extender su aplicabilidad a una amplia variedad de bioprocesos que son desafiantes para los métodos convencionales
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     Observación a largo plazo de bioprocesos sensibles a la fototoxicidad
    </title>
    <p id="Par9">
     La adhesión y migración celular son esenciales en los procesos morfogenéticos y contribuyen a muchas enfermedades
     <sup>
      <xref ref-type="bibr" rid="CR31">
       31
      </xref>
     </sup>
     . Visualizar la dinámica del citoesqueleto a alta resolución durante el proceso de adhesión/migración es crítico para dilucidar el mecanismo subyacente. Sin embargo, debido a la severa fotosensibilidad, los procesos completos de adhesión y migración celular se registran típicamente a bajas tasas de fotogramas, es decir, varios segundos por fotograma, y bajas intensidades de luz
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR32">
       32
      </xref>
     </sup>
     . Bajo estas condiciones de imagen, ni la deconvolución RL ni el aprendizaje auto-supervisado basado en continuidad temporal (Métodos) logran recuperar y afinar la estructura intrincada de F-actina y miosina-II (Fig.
     <xref ref-type="fig" rid="Fig2">
      2a
     </xref>
     , Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      12
     </xref>
     , y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM4">
      1
     </xref>
     ). En contraste, el modelo ZS-DeconvNet mejora efectivamente tanto el SNR como la resolución de las grabaciones de lapso de tiempo a dos colores de cel
     <sup>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
     </sup>
     .
     <fig id="Fig2" position="float">
      <label>
       Fig. 2
      </label>
      <caption xml:lang="en">
       <title>
        Imágenes SR a largo plazo de bioprocesos rápidos y fotosensibles a través de ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Imágenes SR representativas reconstruidas por ZS-DeconvNet del citoesqueleto de F-actina y miosina-II en una célula COS-7 coexpresando mEmerald-lifeact y mCherry-myosin-IIA. Se muestran comparaciones de la imagen TIRF ruidosa en bruto y las imágenes procesadas por deconvolución RL, deconvolución basada en DeepCAD y ZS-DeconvNet.
        <bold>
         b
        </bold>
        Imágenes SR de lapso de tiempo a dos colores mejoradas a través de ZS-DeconvNet que muestran la dinámica coordinada de F-actina (cian) y miosina-II (amarillo) durante todo el proceso de extensión después de colocar una célula COS-7 sobre un cubreobjetos (Video Suplementario
        <xref ref-type="supplementary-material" rid="MOESM5">
         2
        </xref>
        ).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Imágenes SR de lapso de tiempo a dos colores mejoradas a través de ZS-DeconvNet de F-actina y miosina-II en una célula COS-7 en movimiento que muestran que la miosina-II se concentra preferentemente en la parte trasera de la célula (delimitada por líneas discontinuas amarillas en
        <bold>
         d
        </bold>
        ), opuesta a la dirección de movimiento (indicada por las flechas blancas en
        <bold>
         d
        </bold>
        ) (Video Suplementario
        <xref ref-type="supplementary-material" rid="MOESM6">
         3
        </xref>
        ).
        <bold>
         e
        </bold>
        Imagen SR representativa generada a través de ZS-DeconvNet de endosomas de reciclaje (REs, verde) y endosomas tardíos (LEs, magenta) en una célula SUM-159 editada genéticamente que expresa endógenamente EGFP-Rab11 y mCherry-Lamp1 (Video Suplementario
        <xref ref-type="supplementary-material" rid="MOESM7">
         4
        </xref>
        ).
        <bold>
         f
        </bold>
        Trayectorias típicas de movimientos de RE (arriba) y LE (abajo) que muestran la motilidad direccional rápida de RE y la naturaleza bidireccional de LE.
        <bold>
         g
        </bold>
        Comparaciones de la velocidad, desplazamiento y tiempo de viaje entre Lyso/LEs y REs, y cuantificación del tiempo de residencia de los REs cerca de sus sitios de exocitosis antes de fusionarse con la membrana plasmática (
        <italic>
         n
        </italic>
        = 505 trayectorias para REs y
        <italic>
         n
        </italic>
        = 230 trayectorias para LEs). Un pequeño número de puntos de datos que exceden el tiempo de transporte de 150 s o el desplazamiento de 60 μm no se mostraron para una mejor presentación de las distribuciones. Línea central, medianas; límites, 75% y 25%. La significancia estadística se determinó utilizando la prueba de Mann-Whitney no apareada (p =
        <inline-formula id="IEq4">
         <alternatives>
          <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            1.38
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              7
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq4_TeX">
           \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$1.38\times {10}^{-7}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq4.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ,
        <inline-formula id="IEq5">
         <alternatives>
          <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            5.65
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              35
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq5_TeX">
           \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$5.65\times {10}^{-35}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq5.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        , y
        <inline-formula id="IEq6">
         <alternatives>
          <math id="IEq6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            6.26
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              40
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq6_TeX">
           \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$6.26\times {10}^{-40}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq6.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        para pruebas de la velocidad de movimiento, tiempo de transporte y desplazamiento, respectivamente). ****
        <italic>
         p
        </italic>
        &lt; 0.0001. Los datos fuente se proporcionan como un archivo de datos fuente.
        <bold>
         h
        </bold>
        Las imágenes de lapso de tiempo ilustran el movimiento direccional de un RE en forma de varilla y la fusión subsiguiente con la membrana plasmática.
        <bold>
         i
        </bold>
        Las imágenes de lapso de tiempo ilustran tres LEs que se enlazan entre sí y co-migran a cierta distancia antes de dividirse en LEs individuales. Barra de escala, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 2 μm (regiones ampliadas en
        <bold>
         a
        </bold>
        ), 8 μm (
        <bold>
         b
        </bold>
        ), 3 μm (
        <bold>
         e
        </bold>
        ), 0.5 μm (región ampliada en
        <bold>
         e
        </bold>
        ), 1 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         f
        </bold>
        ,
        <bold>
         i
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig2_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par10">
     procesos de extensión después de dejar caer una célula coexpresando mEmerald-Lifeact y mCherry-miosina-IIA sobre un cubreobjetos (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Curiosamente, observamos que en ciertas sustancias las células se arrastraban alrededor del sitio de contacto para explorar el vecindario antes de extenderse y adherirse (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). El arrastre celular fue precedido por la acumulación polarizada de miosina-II en la parte trasera de la célula, lo que lleva a la migración celular en la dirección opuesta impulsada por la contractilidad posterior de miosina-II. Además, la dirección de la migración podría cambiar rápidamente en respuesta a la redistribución dinámica de miosina-II dentro de la célula (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Estos resultados demuestran que la cinética de la adhesión y migración celular puede ser registrada fielmente por la imagen asistida por ZS-DeconvNet sin perturbar este proceso largo y vulnerable.
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     Visualización de la rápida dinámica del sistema endolisosomal
    </title>
    <p id="Par11">
     El sistema endolisosomal incluye diversos tipos de vesículas que funcionan de manera altamente dinámica, pero bien organizada. Aunque la imagen de fluorescencia de células vivas ha mejorado notablemente nuestra comprensión del sistema endolisosomal, la mayoría de los estudios tuvieron que sobreexpresar las proteínas de interés para registrar su rápida dinámica, lo que a menudo resultó en morfologías o comportamientos artefactuales. Con ZS-DeconvNet, pudimos capturar la línea celular SUM-159 knock-in expresando endógenamente EGFP-Rab11 y mCherry-Lamp1 para 1,500 fotogramas a una resolución de ~150 nm y 3 fotogramas por segundo en dos colores (Fig.
     <xref ref-type="fig" rid="Fig2">
      2e
     </xref>
     y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM7">
      4
     </xref>
     ), permitiéndonos visualizar y rastrear el movimiento rápido de los endosomas recicladores (REs) y lisosomas o endosomas tardíos (LEs) en una escala espaciotemporal sustancialmente más fina y una ventana de observación más larga que la lograda previamente
     <sup>
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR34">
       34
      </xref>
     </sup>
     . Como se ejemplifica en Fig.
     <xref ref-type="fig" rid="Fig2">
      2f–h
     </xref>
     , encontramos que la mayoría de los REs (n = 505 trayectorias) experimentaron un movimiento direccional, con un desplazamiento total de 6.7 ± 5.4 µm a una alta velocidad de 2.2 ± 1.2 µm/s (velocidad instantánea superior a 5.3 µm/s), con una rara pausa intermedia, luego se detuvieron en sitios específicos por un período de 13.5 ± 10.3 seg antes de fusionarse con la membrana plasmática. Esta observación sugiere que los REs podrían ser transportados eficientemente a largas distancias a regiones cercanas a la membrana plasmática para facilitar la exocitosis subsiguiente. Inesperadamente, ZS-DeconvNet capturó múltiples eventos de fisión de los REs positivos para Rab11, en los cuales ambos REs separados experimentaron exocitosis secuencialmente (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      13a
     </xref>
     ) o un RE se alejó (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      13b
     </xref>
     ). Esta observación indica que los REs altamente especializados positivos para Rab11 pueden estar sujetos a una clasificación de carga adicional justo antes de la exocitosis.
    </p>
    <p id="Par12">
     En contraste, los movimientos de los LEs fueron típicamente discontinuos y procedieron de manera bidireccional de parada y arranque a una velocidad relativamente lenta de 1.6 ± 0.6 µm/s (n = 230 trayectorias) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2f, g, i
     </xref>
     ). Aunque el transporte de los LEs parecía ineficiente, los LEs a menudo persistieron por un largo período de 91.8 s con un desplazamiento total de hasta 23.6 µm (promediado de n = 230 trayectorias) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2h
     </xref>
     ). Curiosamente, notamos que dos o más LEs a veces tendían a unirse entre sí en una forma de beso y permanencia y migrar por cierta distancia antes de dividirse nuevamente en LEs individuales (Fig.
     <xref ref-type="fig" rid="Fig2">
      2i
     </xref>
     y Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      13c
     </xref>
     ), lo que podría facilitar el movimiento direccional de los LEs sin suficientes adaptadores de proteínas motoras para el transporte de largo alcance. Estas complejas dinámicas de los LEs sugieren que su posicionamiento y movilidad están delicadamente regulados por múltiples factores, como motores basados en MT y contactos de membrana.
    </p>
   </sec>
   <sec id="Sec6">
    <title>
     3D ZS-DeconvNet para microscopía de hoja de luz enrejada
    </title>
    <p id="Par13">
     La imagen volumétrica de células vivas proporciona más información biológica que las observaciones en 2D; sin embargo, está sujeta a una fototoxicidad, fotoblanqueo y contaminación por fluorescencia fuera de foco mucho más severas. Para extender la capacidad superior de ZS-DeconvNet a la imagen SR volumétrica, actualizamos la base de la arquitectura de red de dos etapas a un RCAN 3D, que ha demostrado ser adecuado para la restauración de imágenes volumétricas (Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     y Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ). A continuación, integramos nuestro esquema de aprendizaje auto-supervisado espacialmente intercalado previamente propuesto con el solucionador de problemas inversos auto-supervisado informado por el modelo físico para construir el 3D ZS-DeconvNet. El 3D ZS-DeconvNet con el esquema auto-supervisado espacialmente intercalado sigue un procedimiento de aumento de datos más simple (Métodos), mientras logra un rendimiento comparativo o incluso mejor que la estrategia basada en recorruption (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="en">
       <title>
        Caracterizaciones y demostraciones de 3D ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        La arquitectura de la red de 3D ZS-DeconvNet y el esquema de su fase de entrenamiento.
        <bold>
         b
        </bold>
        El esquema de la fase de inferencia de 3D ZS-DeconvNet.
        <bold>
         c
        </bold>
        Imágenes representativas de proyección de máxima intensidad (MIP) SR de F-actina, membrana externa de mitocondrias y RE reconstruidas por deconvolución dispersa (segunda columna), 3D ZS-DeconvNet (tercera columna) y LLS-SIM (cuarta columna). Los recuentos promedio de sCMOS de los píxeles más altos del 1% para imágenes sin procesar antes del procesamiento están etiquetados en la esquina superior derecha.
        <bold>
         d
        </bold>
        Comparaciones estadísticas de deconvolución RL, deconvolución dispersa y ZS-DeconvNet en términos de PSNR y resolución en diferentes especímenes (
        <italic>
         n
        </italic>
        = 40 regiones de interés). La resolución se midió mediante análisis de correlación de anillo de Fourier
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        con pilas de imágenes de F-actina. Línea central, medianas; límites, 75% y 25%; bigotes, máximo y mínimo. Los datos fuente se proporcionan como un archivo de datos fuente.
        <bold>
         e
        </bold>
        Imágenes de renderizado 3D en tres colores de lapso de tiempo reconstruidas a través de 3D ZS-DeconvNet de RE, H2B y Mito, mostrando sus transformaciones en morfología y distribución, así como dinámicas de interacción durante la mitosis (Video Suplementario
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ).
        <bold>
         f
        </bold>
        Imágenes representativas en tres colores obtenidas con LLSM convencional (primera columna), deconvolución dispersa (segunda columna), deconvolución basada en DeepCAD (tercera columna) (Métodos) y 3D ZS-DeconvNet (cuarta columna). Las comparaciones se realizan en dos puntos de tiempo típicos de los datos de lapso de tiempo mostrados en (
        <bold>
         e
        </bold>
        ). Barra de escala, 5 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         e
        </bold>
        ,
        <bold>
         f
        </bold>
        ), 1.5 μm (regiones ampliadas de
        <bold>
         c
        </bold>
        ), 2 μm (regiones ampliadas de
        <bold>
         f
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     Evaluamos sistemáticamente el modelo 3D ZS-DeconvNet con conjuntos de datos de tres especímenes biológicos diferentes adquiridos a través de nuestra microscopía de iluminación estructurada de hoja de luz de rejilla (LLS-SIM) construida en casa, en la cual los datos limitados por difracción adquiridos por el modo de microscopía de hoja de luz de rejilla (LLSM) se usaron para el entrenamiento, mientras que las contrapartes SR adquiridas por el modo LLS-SIM sirvieron como referencias (Métodos). Encontramos que el 3D ZS-DeconvNet reconstruyó con éxito los filamentos elaborados de F-actina, la estructura hueca de la membrana externa mitocondrial (Mito) y las intrincadas redes del retículo endoplásmico (ER) con alta fidelidad y resolución comparable a las imágenes LLS-SIM adquiridas bajo condiciones de alto SNR (Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ). Las cuantificaciones de PSNR y resolución ilustran que el modelo 3D ZS-DeconvNet supera sustancialmente a los enfoques convencionales basados en modelos analíticos en diversos especímenes biológicos (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ). Demostramos que al entrenar con las pilas de imágenes ruidosas en sí mismas, el 3D ZS-DeconvNet de dos etapas no solo generó resultados sin ruido comparables a las técnicas de eliminación de ruido auto-supervisadas de última generación (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ), sino que también proporcionó pilas de imágenes superresueltas con una mejora significativa en la resolución de más de 1.5 veces tanto lateralmente (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ) como axialmente (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ). Además, al incorporar secuencialmente métodos de mejora de resolución axial basados en autoaprendizaje, la resolución axial puede mejorarse aún más (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     Imágenes volumétricas de superresolución a largo plazo habilitadas por 3D ZS-DeconvNet
    </title>
    <p id="Par15">
     La observación volumétrica de la división celular a alta resolución espaciotemporal es de vital importancia para explorar los mecanismos biológicos relacionados con la mitosis, como el mecanismo que asigna los numerosos orgánulos distintos en el citoplasma a cada célula hija
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
      ,
      <xref ref-type="bibr" rid="CR42">
       42
      </xref>
     </sup>
     . Debido a la extrema sensibilidad a la luz y vulnerabilidad de las células mitóticas, la imagen SR volumétrica previa de este proceso ha dependido del sistema LLS-SIM de baja luz y la reconstrucción SR basada en aprendizaje supervisado
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     . Sin embargo, recopilar datos de entrenamiento de alta calidad es extremadamente laborioso y a veces impracticable porque la morfología y distribución de los orgánulos suelen sufrir cambios dramáticos durante la mitosis
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
     </sup>
     . Aquí, demostramos que el modelo auto-supervisado 3D ZS-DeconvNet puede aplicarse generalmente para superresolver las finas estructuras subcelulares del ER, Mito y cromosomas a partir de volúmenes LLSM ruidosos sin la necesidad de datos de entrenamiento adicionales, permitiendo así la observación SR volumétrica rápida y a largo plazo de múltiples orgánulos para 1,000 puntos de tiempo a intervalos de 10 segundos en una célula HeLa mitótica (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e
     </xref>
     y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM8">
      5
     </xref>
     ). Además, la propiedad no supervisada de ZS-DeconvNet nos permite integrar una estrategia de aprendizaje de adaptación en tiempo de prueba para explotar completamente el contenido estructural en cada volumen ruidoso, lo que produjo el mejor rendimiento 3D SR (Métodos). En contraste, el algoritmo de deconvolución convencional dependiente de priori y el método de aprendizaje auto-supervisado temporalmente intercalado no lograron restaurar los detalles de alta frecuencia de los especímenes debido a la baja condición de SNR y la débil consistencia temporal entre puntos de tiempo adyacentes (Fig.
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     y Métodos). Además, según la baja invasividad proporcionada por 3D ZS-DeconvNet, un grupo de células HeLa mitóticas etiquetadas con H2B-mCherry y HeLa-mEmerald-SC35 fueron imagenadas en un campo de visión (FOV) grande de 100×50×25 μm para más de 300 puntos de tiempo, registrando así los procesos completos de desensamblaje y reensamblaje de los gránulos nucleares a una alta resolución espaciotemporal (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM9">
      6
     </xref>
     ). En resumen, 3D ZS-DeconvNet permite a los biólogos explorar fácilmente varios bioprocesos sensibles a la luz con baja invasividad a una resolución espaciotemporal sustancialmente más alta sin la necesidad de conjuntos de datos adicionales o modificaciones en la configuración óptica
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      ,
      <xref ref-type="bibr" rid="CR44">
       44
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet para microscopía confocal y de campo amplio
    </title>
    <p id="Par16">
     El ZS-DeconvNet se basa en la aleatoriedad de los ruidos y la característica de filtro de paso bajo de los microscopios ópticos, que son comunes para varios tipos de modalidades de microscopía. Sobre esta base, esperamos que ZS-DeconvNet pueda aplicarse generalmente a toda la microscopía, por ejemplo, la microscopía confocal y la microscopía de campo amplio (WF) más comúnmente utilizadas. Para investigar el rendimiento de 3D ZS-DeconvNet en datos confocales, empleamos nuestro microscopio confocal construido en casa para adquirir un volumen de cuatro colores del embrión temprano de ratón inmunoteñido para el microtúbulo, cromosomas, actina y dominio apical (Métodos), que juegan roles clave en la primera decisión de destino celular y son críticos para el desarrollo del embrión
     <sup>
      <xref ref-type="bibr" rid="CR45">
       45
      </xref>
      ,
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
      ,
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
     </sup>
     . Luego entrenamos modelos 3D ZS-DeconvNet en este único volumen ruidoso y procesamos los datos originales con los modelos entrenados. Como se muestra en las Figs.
     <xref ref-type="fig" rid="Fig4">
      4a, b
     </xref>
     , 3D ZS-DeconvNet mejora significativamente el SNR, el contraste y la resolución del volumen de datos confocales y resuelve las finas estructuras de los puentes de microtúbulos y los anillos de actina (Fig.
     <xref ref-type="fig" rid="Fig4">
      4c, d
     </xref>
     , Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      19
     </xref>
     , y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM10">
      7
     </xref>
     ). Estos resultados indican que ZS-DeconvNet permite una mayor resolución espacial con un presupuesto de fotones más bajo para la microscopía confocal en la imagen de especímenes a gran escala, por ejemplo, embriones tempranos de ratón, lo cual es crítico para la investigación sobre la polaridad celular, el transporte intracelular y la formación del blastocisto
     <sup>
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
     </sup>
     .
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="en">
       <title>
        Generalización de ZS-DeconvNet a múltiples modalidades de imagen.
       </title>
       <p>
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        Imágenes representativas de confocal (arriba a la izquierda), deconvolución dispersa (abajo a la izquierda) y mejoradas por 3D ZS-DeconvNet (derecha) de un embrión de ratón temprano inmunoteñido para microtúbulos (cian), cromosomas (naranja), anillos de actina (magenta) y dominio apical (verde).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Regiones ampliadas de puentes de microtúbulos (c) y anillos de actina (d) etiquetadas con cajas de líneas discontinuas blancas en (
        <bold>
         a
        </bold>
        ) y (
        <bold>
         b
        </bold>
        ) adquiridas mediante microscopía confocal, deconvolución dispersa y 3D ZS-DeconvNet.
        <bold>
         e
        </bold>
        Imágenes representativas de WF (región central) y mejoradas por 3D ZS-DeconvNet (región circundante) de un embrión de
        <italic>
         C. elegans
        </italic>
        con unión apical, membrana celular (cian) y lisosomas (rojo) etiquetados.
        <bold>
         f
        </bold>
        ,
        <bold>
         g
        </bold>
        Canal de lisosomas de la región central en (
        <bold>
         e
        </bold>
        ) codificado por colores para la distancia desde el sustrato. Se muestran para comparación tanto las imágenes WF (
        <bold>
         f
        </bold>
        ) como las procesadas por 3D ZS-DeconvNet (
        <bold>
         g
        </bold>
        ).
        <bold>
         h
        </bold>
        Imágenes mejoradas por 3D ZS-DeconvNet de lapso de tiempo que muestran el proceso de fusión de células hipodérmicas (flechas rojas) durante el desarrollo de un embrión de
        <italic>
         C. elegans
        </italic>
        . Barra de escala, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        ,
        <bold>
         e
        </bold>
        ), 2 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 3 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         h
        </bold>
        ), 1 μm (región ampliada de
        <bold>
         g
        </bold>
        ). Valor gamma, 0.7 para la membrana citoplasmática y lisosomas en el embrión de
        <italic>
         C. elegans
        </italic>
        .
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17">
     A continuación, imagenamos embriones de Caenorhabditis elegans con uniones apicales, membranas celulares y lisosomas marcados utilizando el modo 3D WF de nuestro sistema Multi-SIM (Métodos). Para asegurar que el desarrollo del embrión de
     <italic>
      C. elegans
     </italic>
     no fuera perturbado, adquirimos pilas de imágenes en bruto con una excitación de luz relativamente baja en intervalos de 30 segundos para más de 200 puntos de tiempo. Sin embargo, bajo tales condiciones, las imágenes WF están fuertemente contaminadas por el fondo fuera de foco y el ruido (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, f
     </xref>
     ). Incluso en esta situación desafiante, las imágenes 3D ZS-DeconvNet presentaron una considerable supresión del ruido y el fondo mientras mejoraban la resolución espacial de los detalles subcelulares (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, g
     </xref>
     y Video Suplementario
     <xref ref-type="supplementary-material" rid="MOESM11">
      8
     </xref>
     ), permitiéndonos así investigar el elaborado proceso de desarrollo embrionario, por ejemplo, la fusión de células hipodérmicas (Fig.
     <xref ref-type="fig" rid="Fig4">
      4h
     </xref>
     ), incluso a través de un simple microscopio WF
     <sup>
      <xref ref-type="bibr" rid="CR48">
       48
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     Mejora de la resolución y reducción de ruido ZS en imágenes SIM multimodales
    </title>
    <p id="Par18">
     Entre las diversas formas de microscopía de SR, la microscopía de iluminación estructurada (SIM) se reconoce a menudo como una opción equilibrada para la obtención de imágenes de células vivas en SR porque necesita menos de diez imágenes moduladas en bruto para proporcionar una mejora de dos veces en la resolución espacial
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     . No obstante, la SIM convencional tiene dos limitaciones críticas: primero, la mejora adicional de la resolución requiere considerablemente más datos en bruto, es decir, se necesitan al menos 25 imágenes en bruto para la SIM no lineal para obtener una resolución inferior a 80 nm; segundo, la post-reconstrucción de imágenes SIM generalmente requiere imágenes en bruto con un alto SNR para eliminar artefactos de reconstrucción inducidos por el ruido, lo que perjudica la obtención de imágenes rápidas, con poca luz y a largo plazo de células vivas
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     . Estudios recientes han explorado enfoques de aprendizaje supervisado ya sea para eliminar el ruido de las imágenes SIM o para reconstruir imágenes SR SIM directamente a partir de imágenes en bruto ruidosas para lograr la reconstrucción SIM con poca luz; sin embargo, estos métodos requieren abundantes datos de entrenamiento y no mejoran aún más la resolución. A la luz de la capacidad de eliminación de ruido y SR de ZS-DeconvNet, integramos el esquema de aprendizaje de cero disparos con el algoritmo de reconstrucción SIM convencional, y demostramos teóricamente que ZS-DeconvNet es adecuado para procesar las imágenes SR-SIM (Nota Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Diseñamos el modelo SIM mejorado por ZS-DeconvNet (ZS-DeconvNet-SIM) para eliminar el ruido y afinar simultáneamente las imágenes SR SIM de manera no supervisada (Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     , Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     , y Métodos). Recurriendo a la notable mejora tanto en SNR como en resolución proporcionada por ZS-DeconvNet-SIM (Figs. Suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ), la estructura hueca de las fosas recubiertas de clatrina (CCPs) en una célula SUM-159 y los citoesqueletos densamente entrelazados en una célula COS-7, que son indistinguibles en imágenes WF y SIM convencionales, se resolvieron claramente (Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ). Además, demostramos que el ZS-DeconvNet-SIM se puede aplicar en la modalidad 3D-SIM para eliminar el ruido y afinar simultáneamente las imágenes 3D-SIM en ambos ejes lateral y axial (Métodos, Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     .
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="en">
       <title>
        Desenfoque y mejora de resolución sin entrenamiento previo en datos multimodales de SIM.
       </title>
       <p>
        <bold>
         a
        </bold>
        Esquema del procedimiento de entrenamiento de ZS-DeconvNet para SIM.
        <bold>
         b
        </bold>
        Progresión de la mejora de SNR y resolución a través de los CCPs en una célula SUM-159, desde imágenes SIM sin procesar (izquierda), imagen SIM convencional (derecha) e imagen SIM mejorada por ZS-DeconvNet (centro).
        <bold>
         c
        </bold>
        Progresión de la mejora de SNR y resolución a través de los microtúbulos en una célula COS-7, desde imágenes SIM sin procesar (izquierda), imagen SIM convencional (derecha) e imagen SIM mejorada por ZS-DeconvNet (centro).
        <bold>
         d
        </bold>
        Imágenes representativas de proyección de máxima intensidad (MIP) de F-actina en una célula HeLa obtenidas a través de LLSM, LLS-SIM y LLS-SIM mejoradas por 3D ZS-DeconvNet en tres dimensiones.
        <bold>
         e
        </bold>
        , Imágenes MIP representativas de la membrana externa mitocondrial etiquetada con TOMM20 en una célula 293 T obtenidas a través de LLSM, LLS-SIM y LLS-SIM mejoradas por 3D ZS-DeconvNet en tres dimensiones. Barra de escala, 1 μm (
        <bold>
         a
        </bold>
        ), 2 μm (
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 0.5 μm (regiones ampliadas en
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 3 μm (
        <bold>
         d
        </bold>
        ,
        <bold>
         e
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig5_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par19">
     Además, integramos 3D ZS-DeconvNet con LLS-SIM para desarrollar la modalidad 3D ZS-DeconvNet-SIM (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ). Al incorporar el PSF anisotrópico de LLS-SIM convencional en el proceso de entrenamiento, 3D ZS-DeconvNet LLS-SIM no solo mejoró notablemente el contraste y la resolución en las tres dimensiones, sino que también proporcionó una resolución lateral aproximadamente isotrópica de ~150 nm (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     , y Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ). Estas aplicaciones exitosas de ZS-DeconvNet a sistemas SIM multimodales demuestran su capacidad para extender aún más el ancho de banda de resolución espaciotemporal de las técnicas SR existentes
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     .
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    Discusión
   </title>
   <p id="Par20">
    El objetivo final de la obtención de imágenes en vivo es recopilar la mayor cantidad de información espaciotemporal sobre los bioprocesos con la menor invasividad para los especímenes biológicos. Sin embargo, las restricciones mutuas entre la velocidad de obtención de imágenes, la duración, la resolución y el SNR en la microscopía de fluorescencia resultan en la limitación del ancho de banda espaciotemporal, lo que limita la mejora sinérgica en todos estos aspectos. Por ejemplo, para obtener una mayor resolución espacial, las técnicas SR convencionales deben depender de adquisiciones repetitivas o excitación adicional, lo que agrava la fototoxicidad y el fotoblanqueo, impidiendo observaciones rápidas y a largo plazo de los bioprocesos. Para abordar las limitaciones del ancho de banda espaciotemporal en la microscopía, realizamos un análisis en profundidad de la propagación del ruido en el modelo de obtención de imágenes ópticas y la reconstrucción SIM (Nota Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ), demostramos la convergencia de la función de pérdida auto-supervisada integrada con recorruptión en escenarios tanto ordinarios como SIM basados en la linealidad de la convolución PSF, y propusimos el versátil marco ZS-DeconvNet, que se puede incorporar con varios microscopios de fluorescencia óptica para mejorar instantáneamente el SNR y la resolución de la imagen sin comprometer otras propiedades de obtención de imágenes. Enfatizamos que la aplicación de ZS-DeconvNet es robusta a los hiperparámetros en el proceso de recorruptión de imágenes (Fig. Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ) y que ZS-DeconvNet se puede entrenar bien con solo una rebanada o pila de imágenes en bruto (Figs. Suplementarias
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ) sin usar suposiciones de esparcidad estructural y continuidad temporal
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    . Las evaluaciones cualitativas y cuantitativas en datos tanto simulados como experimentales muestran que nuestros métodos mejoran sustancialmente la calidad y resolución de la imagen en más de 1.5 veces con alta fidelidad y cuantificabilidad incluso en condiciones de poca luz, permitiendo así observaciones rápidas y a largo plazo de múltiples dinámicas subcelulares.
   </p>
   <p id="Par21">
    El método ZS-DeconvNet propuesto tiene una amplia funcionalidad para varios tipos de modalidades de obtención de imágenes, desde microscopía basada en escaneo, por ejemplo, microscopía confocal y microscopía de dos fotones (Fig. Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     25
    </xref>
    ), hasta microscopía basada en detección de campo amplio, por ejemplo, TIRF, microscopía 3D WF, LLSM y SIM multimodal. Demostramos sus capacidades con más de 10 especímenes distintos, fijos o vivos, obtenidos a través de seis configuraciones de microscopía diferentes, incluyendo obtención de imágenes planas y volumétricas de múltiples orgánulos en células individuales, observaciones de dinámicas subcelulares e interacciones durante la mitosis celular, y obtención de imágenes 3D multicolor de embriones de ratón en etapas tempranas y embriones de
    <italic>
     C. elegans
    </italic>
    . Para hacer que nuestros métodos sean más accesibles y convenientes de usar, integramos ZS-DeconvNet y 3D ZS-DeconvNet en un plugin de Fiji fácil de usar (Figs. Suplementarias
    <xref ref-type="supplementary-material" rid="MOESM1">
     26
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     27
    </xref>
    , Notas Suplementarias
    <xref ref-type="supplementary-material" rid="MOESM1">
     3
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     4
    </xref>
    , y Video Suplementario
    <xref ref-type="supplementary-material" rid="MOESM12">
     9
    </xref>
    ), permitiendo a los usuarios, incluso sin experiencia en aprendizaje profundo, entrenar fácilmente sus propios modelos ZS-DeconvNet y mejorar imágenes de microscopía abiertas en Fiji con algunos clics del ratón. La funcionalidad y conveniencia de ZS-DeconvNet demuestran su gran potencial para mejorar el rendimiento de la microscopía óptica existente.
   </p>
   <p id="Par22">
    A pesar de su robustez y aplicabilidad general, los usuarios de ZS-DeconvNet deben considerar cuidadosamente la posible aparición de alucinaciones y sus limitaciones. Primero, ZS-DeconvNet puede confundir señales de fluorescencia extremadamente bajas como ruido de fotones, debilitándolas así en las imágenes de salida (Fig. Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     28a
    </xref>
    ). Este tipo de errores podría detectarse hasta cierto punto mediante herramientas de verificación de calidad de imagen como SQUIRREL
    <sup>
     <xref ref-type="bibr" rid="CR54">
      54
     </xref>
    </sup>
    . Segundo, si un modelo ZS-DeconvNet bien entrenado se aplica para procesar imágenes significativamente diferentes de los datos de entrenamiento, por ejemplo, adquiridas con una modalidad de obtención de imágenes diferente, podría haber una degradación notable del rendimiento y un mayor riesgo de generación de alucinaciones (Fig. Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     28b
    </xref>
    ). Tercero, los modelos ZS-DeconvNet deben entrenarse utilizando PSFs que coincidan con el conjunto de datos, de lo contrario, un entrenamiento inadecuado con PSFs no coincidentes podría resultar en una mejora de resolución poco visible o artefactos de anillo (Fig. Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     28c
    </xref>
    ). Finalmente, no esperamos que el ZS-DeconvNet no supervisado genere imágenes SR tan buenas como los modelos DLSR supervisados entrenados con conjuntos de datos de alta calidad (Fig. Suplementaria
    <xref ref-type="supplementary-material" rid="MOESM1">
     11
    </xref>
    ). Sin embargo, en experimentos de obtención de imágenes cuando dicho conjunto de datos no está disponible, ZS-DeconvNet será una herramienta poderosa y conveniente para resolver detalles biológicos tan finos como sea posible.
   </p>
   <p id="Par23">
    Se pueden prever varias mejoras y extensiones de ZS-DeconvNet. Primero, adoptamos los modelos de base U-Net y RCAN comúnmente utilizados en nuestros experimentos para la demostración conceptual. Combinar el marco de ZS-DeconvNet con arquitecturas de red más avanzadas, como la red Richardson-Lucy, que incorpora el proceso de formación de imágenes para acelerar la extracción de información de SR, puede mejorar aún más la capacidad de SR con mayor eficiencia computacional. Segundo, aunque solo presentamos las aplicaciones de ZS-DeconvNet en SIM, se puede especular razonablemente que otras técnicas de SR basadas en óptica, como la microscopía de localización fotoactivada, la microscopía de agotamiento por emisión estimulada y la microscopía de escaneo de imágenes, pueden mejorarse integrando ZS-DeconvNet en sus flujos de procesamiento de imágenes. Tercero, debido a la falta de generalización, los usuarios necesitan entrenar un modelo especializado para cada tipo de espécimen para lograr el mejor rendimiento. La incorporación de técnicas de adaptación de dominio o generalización de dominio con nuestros métodos puede aliviar efectivamente la carga de aplicar modelos entrenados en dominios no vistos. Finalmente, utilizamos un PSF espacialmente invariante para los sistemas de imagen bien calibrados en este trabajo. Con un PSF que varía espacialmente, la funcionalidad de ZS-DeconvNet puede extenderse aún más a varias tareas de procesamiento de imágenes, como la reconstrucción de campo de luz en el espacio de fase y la óptica adaptativa digital
    <sup>
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     <xref ref-type="bibr" rid="CR55">
      55
     </xref>
     <xref ref-type="bibr" rid="CR56">
      56
     </xref>
     <xref ref-type="bibr" rid="CR57">
      57
     </xref>
     <xref ref-type="bibr" rid="CR43">
      43
     </xref>
     <xref ref-type="bibr" rid="CR58">
      58
     </xref>
     <xref ref-type="bibr" rid="CR59">
      59
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    Métodos
   </title>
   <sec id="Sec12">
    <title>
     Sistema Multi-SIM
    </title>
    <p id="Par24">
     El sistema Multi-SIM se construyó sobre un microscopio de fluorescencia inventado (Ti2E, Nikon). Tres haces de láser de 488 nm (Genesis-MX-SLM, Coherent), 560 nm (2RU-VFL-P-500-560, MPB Communications) y 640 nm (LBX-640-500, Oxxius) se combinaron colinealmente y luego pasaron a través de un filtro acusto-óptico sintonizable (AOTF, AOTFnC-400.650, AA Quanta Tech), que sirve para seleccionar la longitud de onda del láser deseada y controlar su potencia y tiempo de exposición. Posteriormente, la luz láser seleccionada se expandió y se envió a un modulador de iluminación, que está compuesto por un modulador espacial de luz ferroeléctrico (SLM, QXGA-3DM, Forth Dimension Display), un divisor de haz de polarización y una placa de media onda acromática. Se generaron diferentes modos de iluminación ajustando los patrones mostrados en el SLM, por ejemplo, patrones de rejilla de 3 fases × 3 orientaciones a 1.41 NA para TIRF-SIM o 1.35 NA para GI-SIM. A continuación, la luz modulada pasó a través de un rotador de polarización que consiste en una celda de cristal líquido (Meadowlark, LRC-200) y una placa de cuarto de onda, que rotó la polarización lineal para mantener la s-polarización necesaria, maximizando así el contraste del patrón para todas las orientaciones del patrón. Los órdenes de difracción, excepto los órdenes ±1 para TIRF/GI-SIM, fueron filtrados por una máscara espacial y luego retransmitidos al plano focal posterior de los objetivos (1.49 NA, Nikon). Las imágenes SIM en bruto excitadas por diferentes patrones de iluminación fueron recogidas secuencialmente por el mismo objetivo, luego separadas por un divisor de haz dicróico (Chroma, ZT405/488/560/647tpc), finalmente capturadas con una cámara sCMOS (Hamamatsu, Orca Flash 4.0 v3). Para la imagen en vivo, las células se mantuvieron en un incubador de etapa superior equipado en la microscopía (OkO Lab, H301) para mantener la condición a 37°C con 5% de CO2. El sistema Multi-SIM trabajó en el modo TIRF y modo 3D WF en los experimentos mostrados en las Figs.
     <xref ref-type="fig" rid="Fig1">
      1
     </xref>
     ,
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     y
     <xref ref-type="fig" rid="Fig4">
      4e–h
     </xref>
     ajustando los patrones mostrados en el SLM para generar iluminación TIRF o WF uniforme, y trabajó en el modo TIRF/GI-SIM y modo 3D-SIM en la Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     y Figuras Suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     -
     <xref ref-type="supplementary-material" rid="MOESM1">
      24
     </xref>
     <sup/>
     . Además de los modos TIRF, 3D WF, TIRF/GI-SIM y 3D-SIM utilizados en este trabajo, el sistema Multi-SIM integró diversas modalidades SIM, incluyendo SIM no lineal y SIM de corte apilado en una sola configuración, que ha estado disponible comercialmente de NanoInsights Inc. (nanoinsights-tech.com).
    </p>
   </sec>
   <sec id="Sec13">
    <title>
     Sistema LLS-SIM
    </title>
    <p id="Par25">
     El sistema LLS-SIM construido en casa se desarrolló a partir del diseño original
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     . Similar al combinador de láser y modulador de patrones utilizado en nuestro sistema Multi-SIM, se seleccionaron y controlaron tres láseres de 488 nm, 560 nm y 640 nm (MPB Communications) mediante un AOTF, y luego se modularon mediante los patrones de rejilla mostrados en el SLM. La luz de excitación fue luego filtrada por una máscara anular equivalente a 0.5 NA externa y 0.375 NA interna para el objetivo de excitación (Special Optics). Posteriormente, la luz de excitación filtrada pasó a través de un par de espejos galvo (
     <italic>
      x
     </italic>
     - y
     <italic>
      z
     </italic>
     -galvo) (Cambridge Technology, 6210H). En el modo LLS-SIM, los patrones de rejilla de 3 fases se mostraron secuencialmente en el SLM y se sincronizaron con el tiempo "ON" programado del AOTF, y luego se escanearon mediante el piezo de la muestra en un tamaño de paso de 0.39 μm, que equivale a un intervalo z de 0.2 μm, para adquirir las imágenes volumétricas LLSM. En el modo LLSM, un patrón de rejilla fijo fue rápidamente oscilado por el
     <italic>
      x
     </italic>
     -galvo, y luego escaneado por el piezo de la muestra. En particular, utilizamos la onda triangular al invertir la dirección de escaneo del escenario piezoeléctrico para minimizar el tiempo de retorno al extremo. Los especímenes de células vivas se mantuvieron en un incubador de microscopio personalizado (OKO Lab, H301-LLSM-SS316) para mantener la condición fisiológica de 37°C y 5% de CO2 durante la imagen. La luz de emisión fue recogida por el objetivo de detección (Nikon, CFI Apo LWD 25XW, 1.1NA) y capturada por una cámara sCMOS (Hamamatsu, Orca Fusion).
    </p>
   </sec>
   <sec id="Sec14">
    <title>
     Sistema confocal
    </title>
    <p id="Par26">
     La microscopía confocal construida en casa se desarrolló como una modificación del sistema de microscopía de escaneo de imágenes basado en un microscopio de fluorescencia inventado comercialmente (Ti2E, Nikon). Cuatro haces de láser de 405 nm, 488 nm, 561 nm y 640 nm (BDL-405-SMN, BDL-488-SMN, BDS-561-SMY-FBE y BDL-640-SMN, Becker &amp; Hickel) se combinaron colinealmente y luego se expandieron 6.25 veces. Después de ser reflejados por un espejo dicróico de banda múltiple (Di03-R405/488/561/635, Semrock), los láseres pasaron a través de dos escáneres de galvanómetro (8315k, CT Cambridge Technology) y luego se dirigieron hacia el objetivo (CFI SR HP Plan Apo Lambda S 100XC/1.35NA, Sil, Nikon) a través de una lente de escaneo y una lente de tubo. La fluorescencia de emisión fue recogida por el mismo objetivo, desescaneada y pasada a través del espejo dicróico de banda múltiple y luego separada en el canal verde y luego en el canal rojo por un divisor de haz dicróico (FF573-DI01, Semrock). Las señales del canal verde (filtradas por FF02-447/60, FF03-525/50, Semrock) fueron recogidas por un módulo de conteo de fotones individuales (SPCM-AQRH-44, Excelitas) y finalmente contadas por un contador digital (BNC-2121, National Instruments). Las señales del canal rojo (filtradas por FF01-609/57, FF01-679/41, Semrock) fueron recogidas por un haz de fibra y luego capturadas por un tubo fotomultiplicador multicanal (PML-16-GASP) y cuantificadas por un contador de fotones individuales (SPC-164-PCI, Becker &amp; Hickel). El orificio se mantuvo abierto durante la adquisición de imágenes y el factor de aumento general fue de 333× para el canal verde y 666× para el canal rojo. La adquisición/visualización/procesamiento de datos fue operada por un software desarrollado en casa basado en LabView (National Instruments) y el software también controló todos los dispositivos del microscopio durante la adquisición de imágenes, como los escáneres de galvanómetro, el escenario piezoeléctrico axial y la potencia del láser enviando señales analógicas a través de una tarjeta de matriz de puertas programables en campo (NI PXIe-7868R, National Instruments)
     <sup>
      <xref ref-type="bibr" rid="CR60">
       60
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec15">
    <title>
     Arquitecturas y funciones objetivo de ZS-DeconvNet
    </title>
    <p id="Par27">
     ZS-DeconvNet adopta una arquitectura de dos etapas, que factoriza la tarea de superresolución de bajo SNR en dos subdivisiones secuenciales de eliminación de ruido y deconvolución, y cada etapa es responsable de una subtarea, respectivamente. El diseño de dos etapas es útil para regular los procedimientos de entrenamiento y eliminar los artefactos inducidos por el ruido en los resultados finales
     <sup>
      <xref ref-type="bibr" rid="CR11">
       11
      </xref>
     </sup>
     . Para imágenes 2D, se utiliza un modelo U-Net simplificado con cuatro módulos de muestreo descendente y ascendente como la base de cada etapa. La arquitectura de red general de ZS-DeconvNet que utilizamos para SR de imágenes 2D en este trabajo se muestra en la Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      2a
     </xref>
     <sup>
      <xref ref-type="bibr" rid="CR29">
       29
      </xref>
     </sup>
     . En la fase de entrenamiento, diseñamos una función de pérdida combinada que consiste en un término de eliminación de ruido y un término de deconvolución, que corresponden respectivamente a la etapa de eliminación de ruido y la etapa de deconvolución:
     <disp-formula id="Equ3">
      <label>
       3
      </label>
      <alternatives>
       <math id="Equ3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mi>
         μ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           1
          </mn>
          <mo>
           −
          </mo>
          <mi>
           μ
          </mi>
         </mrow>
        </mfenced>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           c
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ3_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{\mathcal{L}}}}}}\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)=\mu {{{{{{\mathcal{L}}}}}}}_{{den}}\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)+\left(1-\mu \right){{{{{{\mathcal{L}}}}}}}_{{dec}}\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ3.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <inline-formula id="IEq04">
      <alternatives>
       <math id="IEq04_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="IEq04_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq04.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     indica el par de imágenes recorruptas (ver la siguiente sección para los detalles de la recorruptación de imágenes), y
     <inline-formula id="IEq05">
      <alternatives>
       <math id="IEq05_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         μ
        </mi>
       </math>
       <tex-math id="IEq05_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\mu$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq05.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es un factor de ponderación escalar para equilibrar los dos términos, que empíricamente establecimos como 0.5 en nuestros experimentos. También hemos validado que el rendimiento de ZS-DeconvNet es estable en todas las muestras para un amplio rango de
     <inline-formula id="IEq06">
      <alternatives>
       <math id="IEq06_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         μ
        </mi>
       </math>
       <tex-math id="IEq06_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\mu$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq06.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      29
     </xref>
     ). La pérdida de eliminación de ruido
     <inline-formula id="IEq7">
      <alternatives>
       <math id="IEq7_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq7_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\mathcal{L}}}}}}}_{{den}}(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq7.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     y la pérdida de deconvolución
     <inline-formula id="IEq8">
      <alternatives>
       <math id="IEq8_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           c
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="IEq8_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\mathcal{L}}}}}}}_{{dec}}\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq8.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     se definen como sigue:
     <disp-formula id="Equ4">
      <label>
       4
      </label>
      <alternatives>
       <math id="Equ4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <msubsup>
         <mrow>
          <msub>
           <mrow>
            <mstyle mathsize="1.61em">
             <mfenced open="∣">
              <mrow/>
             </mfenced>
            </mstyle>
            <mstyle mathsize="1.61em">
             <mfenced open="∣">
              <mrow/>
             </mfenced>
            </mstyle>
            <mspace width="0.25em"/>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <msup>
             <mrow>
              <mi mathvariant="bold-italic">
               θ
              </mi>
             </mrow>
             <mrow>
              <mo>
               ′
              </mo>
             </mrow>
            </msup>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mover accent="true">
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mo>
               ̂
              </mo>
             </mrow>
            </mover>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ4_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\mathcal{L}}}}}}}_{{den}}\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)={{{\Big|\Big| \, f}}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left(\hat{{{{{{\bf{y}}}}}}}\right)-\widetilde{{{{{{\bf{y}}}}}}}{{\Big|\Big|}}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ4.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ5">
      <label>
       5
      </label>
      <alternatives>
       <math id="Equ5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           c
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <msubsup>
         <mrow>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <msub>
           <mrow>
            <mrow>
             <mo>
              (
             </mo>
             <mrow>
              <mspace width="0.16em"/>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mover accent="true">
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mo>
                   ̂
                  </mo>
                 </mrow>
                </mover>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
             <mo>
              )
             </mo>
            </mrow>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mover accent="true">
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mo>
               ̂
              </mo>
             </mrow>
            </mover>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ5_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\mathcal{L}}}}}}}_{{dec}}\left(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}}\right)={{\Big|\Big|}{(\;{f}_{{{{{{\boldsymbol{\theta }}}}}}}\left(\hat{{{{{{\bf{y}}}}}}}\right)*{{{{{\rm{PSF}}}}}})}_{\downarrow }-\widetilde{{{{{{\bf{y}}}}}}}{{\Big|\Big|}}}_{2}^{2}+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left(\hat{{{{{{\bf{y}}}}}}}\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ5.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde PSF denota la función de dispersión de punto del sistema óptico,
     <inline-formula id="IEq9">
      <alternatives>
       <math id="IEq9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq9_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el operador de muestreo descendente,
     <inline-formula id="IEq10">
      <alternatives>
       <math id="IEq10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <msup>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
           <mrow>
            <mo>
             ′
            </mo>
           </mrow>
          </msup>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="IEq10_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left(\hat{{{{{{\bf{y}}}}}}}\right)$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     y
     <inline-formula id="IEq11">
      <alternatives>
       <math id="IEq11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="IEq11_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}\left(\hat{{{{{{\bf{y}}}}}}}\right)$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     son las imágenes de salida de la etapa de eliminación de ruido y la etapa de deconvolución,
     <inline-formula id="IEq12">
      <alternatives>
       <math id="IEq12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq12_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\mathcal{R}}}}}}}_{{Hessian}}(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el término de regularización de Hessian utilizado para regular el espacio de soluciones, y
     <inline-formula id="IEq13">
      <alternatives>
       <math id="IEq13_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         λ
        </mi>
       </math>
       <tex-math id="IEq13_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\lambda$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq13.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el escalar de ponderación para equilibrar el impacto de la regularización, que empíricamente establecimos como 0.02 para el mejor rendimiento en las implementaciones de ZS-DeconvNet 2D.
    </p>
    <p id="Par28">
     For 3D ZS-DeconvNet, we deploy 3D RCAN as the backbone model for the two stages, each of which includes two residual groups consisting of two channel attention blocks. The overall architecture is illustrated in Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     <sup/>
     . During training procedures, the 3D ZS-DeconvNet is optimized iteratively following a similar loss function to its 2D versions, nevertheless, with two major modifications in detail: first, the image pairs used for training were generated by axial sampling rather than via recorruption, resulting in a totally parameter-free data augmentation strategy; second, the gap amending regularization (GAR) was implemented in both denoising term and deconvolution term to correct the inconsistency between the inputs and targets which are originally interleaved in the same noisy image stack. The loss function can be formulated as:
     <disp-formula id="Equ6">
      <label>
       6
      </label>
      <alternatives>
       <math id="Equ6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           z
          </mi>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mi>
         μ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           z
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           1
          </mn>
          <mo>
           −
          </mo>
          <mi>
           μ
          </mi>
         </mrow>
        </mfenced>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           c
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           z
          </mi>
         </mrow>
        </mfenced>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           z
          </mi>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <msubsup>
         <mrow>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mspace width="0.25em"/>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <msup>
             <mrow>
              <mi mathvariant="bold-italic">
               θ
              </mi>
             </mrow>
             <mrow>
              <mo>
               ′
              </mo>
             </mrow>
            </msup>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               S
              </mi>
             </mrow>
             <mrow>
              <mi>
               o
              </mi>
              <mi>
               d
              </mi>
              <mi>
               d
              </mi>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <mi mathvariant="bold">
               z
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mi>
             S
            </mi>
           </mrow>
           <mrow>
            <mi>
             e
            </mi>
            <mi>
             v
            </mi>
            <mi>
             e
            </mi>
            <mi>
             n
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             z
            </mi>
           </mrow>
          </mfenced>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ6_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\mathcal{L}}}}}}\left({{{{{\bf{z}}}}}}\right)=\mu {{{{{{\mathcal{L}}}}}}}_{{den}}\left({{{{{\bf{z}}}}}}\right)+\left(1 - \mu \right){{{{{{\mathcal{L}}}}}}}_{{dec}}\left({{{{{\bf{z}}}}}}\right) \\ {{{{{{\mathcal{L}}}}}}}_{{den}}\left({{{{{\bf{z}}}}}}\right)={{\Big|\Big|} \, {f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left({S}_{{odd}}\left({{{{{\bf{z}}}}}}\right)\right)-{S}_{{even}}\left({{{{{\bf{z}}}}}}\right){\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_Equ6.gif"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ7">
      <label>
       7
      </label>
      <alternatives>
       <math id="Equ7_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         +
        </mo>
        <mi>
         γ
        </mi>
        <msubsup>
         <mrow>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mspace width="0.25em"/>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <msup>
             <mrow>
              <mi mathvariant="bold-italic">
               θ
              </mi>
             </mrow>
             <mrow>
              <mo>
               ′
              </mo>
             </mrow>
            </msup>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               S
              </mi>
             </mrow>
             <mrow>
              <mi>
               o
              </mi>
              <mi>
               d
              </mi>
              <mi>
               d
              </mi>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <mi mathvariant="bold">
               z
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mi>
             S
            </mi>
           </mrow>
           <mrow>
            <mi>
             e
            </mi>
            <mi>
             v
            </mi>
            <mi>
             e
            </mi>
            <mi>
             n
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             z
            </mi>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               S
              </mi>
             </mrow>
             <mrow>
              <mi>
               o
              </mi>
              <mi>
               d
              </mi>
              <mi>
               d
              </mi>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <msup>
                 <mrow>
                  <mi mathvariant="bold-italic">
                   θ
                  </mi>
                 </mrow>
                 <mrow>
                  <mo>
                   ′
                  </mo>
                 </mrow>
                </msup>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 z
                </mi>
               </mrow>
              </mfenced>
             </mrow>
            </mfenced>
            <mo>
             −
            </mo>
            <msub>
             <mrow>
              <mi>
               S
              </mi>
             </mrow>
             <mrow>
              <mi>
               e
              </mi>
              <mi>
               v
              </mi>
              <mi>
               e
              </mi>
              <mi>
               n
              </mi>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <msup>
                 <mrow>
                  <mi mathvariant="bold-italic">
                   θ
                  </mi>
                 </mrow>
                 <mrow>
                  <mo>
                   ′
                  </mo>
                 </mrow>
                </msup>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 z
                </mi>
               </mrow>
              </mfenced>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           L
          </mi>
         </mrow>
         <mrow>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           c
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           z
          </mi>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <msubsup>
         <mrow>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <mspace width="0.25em"/>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi>
                   S
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   o
                  </mi>
                  <mi>
                   d
                  </mi>
                  <mi>
                   d
                  </mi>
                 </mrow>
                </msub>
                <mfenced close=")" open="(">
                 <mrow>
                  <mi mathvariant="bold">
                   z
                  </mi>
                 </mrow>
                </mfenced>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mi>
             S
            </mi>
           </mrow>
           <mrow>
            <mi>
             e
            </mi>
            <mi>
             v
            </mi>
            <mi>
             e
            </mi>
            <mi>
             n
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             z
            </mi>
           </mrow>
          </mfenced>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ7_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$	+\gamma {{\Big|\Big|}\,{f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left({S}_{{odd}}\left({{{{{\bf{z}}}}}}\right)\right)-{S}_{{even}}\left({{{{{\bf{z}}}}}}\right)-\left({S}_{{odd}}\left({f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left({{{{{\bf{z}}}}}}\right)\right)-{S}_{{even}}\left({f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{\prime} }}}\left({{{{{\bf{z}}}}}}\right)\right)\right){\Big|\Big|}}_{2}^{2}\\ 	 {{{{{{\mathcal{L}}}}}}}_{{dec}}\left({{{{{\bf{z}}}}}}\right)={{\Big|\Big|}{\left(\,{f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({S}_{{odd}}\left({{{{{\bf{z}}}}}}\right)\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }-{S}_{{even}}\left({{{{{\bf{z}}}}}}\right){\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_Equ7.gif"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ8">
      <label>
       8
      </label>
      <alternatives>
       <math id="Equ8_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         +
        </mo>
        <mi>
         γ
        </mi>
        <msubsup>
         <mrow>
          <msub>
           <mrow>
            <mstyle mathsize="1.61em">
             <mfenced open="∣">
              <mrow/>
             </mfenced>
            </mstyle>
            <mstyle mathsize="1.61em">
             <mfenced open="∣">
              <mrow/>
             </mfenced>
            </mstyle>
            <mfenced close=")" open="(">
             <mrow>
              <mspace width="0.25em"/>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi>
                   S
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   o
                  </mi>
                  <mi>
                   d
                  </mi>
                  <mi>
                   d
                  </mi>
                 </mrow>
                </msub>
                <mfenced close=")" open="(">
                 <mrow>
                  <mi mathvariant="bold">
                   z
                  </mi>
                 </mrow>
                </mfenced>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mi>
             S
            </mi>
           </mrow>
           <mrow>
            <mi>
             e
            </mi>
            <mi>
             v
            </mi>
            <mi>
             e
            </mi>
            <mi>
             n
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             z
            </mi>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mi>
             S
            </mi>
           </mrow>
           <mrow>
            <mi>
             o
            </mi>
            <mi>
             d
            </mi>
            <mi>
             d
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               f
              </mi>
             </mrow>
             <mrow>
              <msup>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
               <mrow>
                <mo>
                 ′
                </mo>
               </mrow>
              </msup>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <mi mathvariant="bold">
               z
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
          <mo>
           +
          </mo>
          <msub>
           <mrow>
            <mi>
             S
            </mi>
           </mrow>
           <mrow>
            <mi>
             e
            </mi>
            <mi>
             v
            </mi>
            <mi>
             e
            </mi>
            <mi>
             n
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <mspace width="0.25em"/>
            <msub>
             <mrow>
              <mi>
               f
              </mi>
             </mrow>
             <mrow>
              <msup>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
               <mrow>
                <mo>
                 ′
                </mo>
               </mrow>
              </msup>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <mi mathvariant="bold">
               z
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mspace width="0.25em"/>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               S
              </mi>
             </mrow>
             <mrow>
              <mi>
               o
              </mi>
              <mi>
               d
              </mi>
              <mi>
               d
              </mi>
             </mrow>
            </msub>
            <mfenced close=")" open="(">
             <mrow>
              <mi mathvariant="bold">
               z
              </mi>
             </mrow>
            </mfenced>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ8_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$	+\gamma {{{\Big|\Big|}\left(\,{f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({S}_{{odd}}\left({{{{{\bf{z}}}}}}\right)\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }-{S}_{{even}}\left({{{{{\bf{z}}}}}}\right)-{S}_{{odd}}\left({f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left({{{{{\bf{z}}}}}}\right)\right)+{S}_{{even}}\left(\,{f}_{{{{{{{\boldsymbol{\theta }}}}}}}^{{{{\prime} }}}}\left({{{{{\bf{z}}}}}}\right)\right){\Big|\Big|}}_{2}^{2} \\ 	+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left(\,{f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({S}_{{odd}}\left({{{{{\bf{z}}}}}}\right)\right)\right)$$\end{document}
       </tex-math>
       <graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_Equ8.gif"/>
      </alternatives>
     </disp-formula>
     where
     <inline-formula id="IEq14">
      <alternatives>
       <math id="IEq14_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         z
        </mi>
       </math>
       <tex-math id="IEq14_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{z}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq14.gif"/>
      </alternatives>
     </inline-formula>
     is the 3D noisy image stack,
     <inline-formula id="IEq15">
      <alternatives>
       <math id="IEq15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           S
          </mi>
         </mrow>
         <mrow>
          <mi>
           o
          </mi>
          <mi>
           d
          </mi>
          <mi>
           d
          </mi>
         </mrow>
        </msub>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq15_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${S}_{{odd}}(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq15.gif"/>
      </alternatives>
     </inline-formula>
     and
     <inline-formula id="IEq16">
      <alternatives>
       <math id="IEq16_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           S
          </mi>
         </mrow>
         <mrow>
          <mi>
           e
          </mi>
          <mi>
           v
          </mi>
          <mi>
           e
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq16_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${S}_{{even}}(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq16.gif"/>
      </alternatives>
     </inline-formula>
     represent the axial sampling operator which takes an image stack and returns its odd slices or even slices, respectively, stacked in the same order as the original stack,
     <inline-formula id="IEq17">
      <alternatives>
       <math id="IEq17_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         γ
        </mi>
       </math>
       <tex-math id="IEq17_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq17.gif"/>
      </alternatives>
     </inline-formula>
     and
     <inline-formula id="IEq18">
      <alternatives>
       <math id="IEq18_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         λ
        </mi>
       </math>
       <tex-math id="IEq18_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq18.gif"/>
      </alternatives>
     </inline-formula>
     are weighting scalars of the GAR term and the Hessian regularization term, which are set to
     <inline-formula id="IEq19">
      <alternatives>
       <math id="IEq19_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         γ
        </mi>
        <mo>
         =
        </mo>
        <mn>
         1
        </mn>
       </math>
       <tex-math id="IEq19_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma=1$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq19.gif"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq20">
      <alternatives>
       <math id="IEq20_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         λ
        </mi>
        <mo>
         =
        </mo>
        <mn>
         0.1
        </mn>
       </math>
       <tex-math id="IEq20_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda=0.1$$\end{document}
       </tex-math>
       <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41467_2024_48575_Article_IEq20.gif"/>
      </alternatives>
     </inline-formula>
     for the implementation of 3D ZS-DeconvNet
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
    </p>
    <p id="Par29">
     Es notable que, dado que la base teórica de ZS-DeconvNet es independiente del modelo, tanto U-Net como RCAN no son los únicos modelos de base aplicables, sino los más adoptados y eficientes. Equipar ZS-DeconvNet con otras arquitecturas de red de última generación, por ejemplo, DFCAN y RLN, puede mejorar aún más su capacidad de eliminación de ruido y superresolución
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     Implementación de 2D ZS-DeconvNet
    </title>
    <p id="Par30">
     Los pares de imágenes
     <inline-formula id="IEq21">
      <alternatives>
       <math id="IEq21_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq21_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq21.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     utilizados para entrenar modelos 2D ZS-DeconvNet fueron generados siguiendo un esquema modificado de la estrategia original de recorrupto a recorrupto bajo la suposición de distribuciones de ruido mixto Poisson-Gaussiano, donde tres hiperparámetros
     <inline-formula id="IEq22">
      <alternatives>
       <math id="IEq22_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq22_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq22.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq23">
      <alternatives>
       <math id="IEq23_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq23_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq23.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq24">
      <alternatives>
       <math id="IEq24_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq24_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq24.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     necesitaban ser pre-caracterizados. El procedimiento de recorrupto de una sola imagen ruidosa
     <italic>
      y
     </italic>
     puede representarse en forma matricial como:
     <disp-formula id="Equ9">
      <label>
       9
      </label>
      <alternatives>
       <math id="Equ9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̂
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         +
        </mo>
        <mi>
         D
        </mi>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ9_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\hat{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}+D{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ10">
      <label>
       10
      </label>
      <alternatives>
       <math id="Equ10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mo>
          ̃
         </mo>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         −
        </mo>
        <msup>
         <mrow>
          <mi>
           D
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           1
          </mi>
         </mrow>
        </msup>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ10_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\widetilde{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}-{D}^{-{{{{{\bf{1}}}}}}}{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <inline-formula id="IEq25">
      <alternatives>
       <math id="IEq25_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
        <mo>
         =
        </mo>
        <mi>
         α
        </mi>
        <mi>
         I
        </mi>
       </math>
       <tex-math id="IEq25_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$D=\alpha I$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq25.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es una matriz invertible definida como una matriz unitaria ampliada por un factor de
     <inline-formula id="IEq26">
      <alternatives>
       <math id="IEq26_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         α
        </mi>
       </math>
       <tex-math id="IEq26_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$\alpha$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq26.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , que controla la magnitud total de los ruidos añadidos, y
     <inline-formula id="IEq27">
      <alternatives>
       <math id="IEq27_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="IEq27_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq27.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es un mapa de ruido aleatorio muestreado de una distribución Gaussiana con medias cero:
     <disp-formula id="Equ11">
      <label>
       11
      </label>
      <alternatives>
       <math id="Equ11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
        <mo>
         ~
        </mo>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         N
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           0
          </mn>
          <mo>
           ,
          </mo>
          <msup>
           <mrow>
            <mi>
             σ
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mi>
           I
          </mi>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ11_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{\bf{g}}}}}} \sim {{{{{\mathcal{N}}}}}}\left(0,{\sigma }^{2}I\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ12">
      <label>
       12
      </label>
      <alternatives>
       <math id="Equ12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msup>
         <mrow>
          <mi>
           σ
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msup>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
        <mi>
         H
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="Equ12_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\sigma }^{2}={\beta }_{1}H\left({{{{{\bf{y}}}}}}-{{{{{\bf{b}}}}}}\right)+{\beta }_{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde
     <inline-formula id="IEq28">
      <alternatives>
       <math id="IEq28_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq28_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq28.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el factor Poissoniano que afecta la varianza del ruido de disparo dependiente de la señal, y
     <inline-formula id="IEq29">
      <alternatives>
       <math id="IEq29_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq29_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq29.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el factor Gaussiano que representa la varianza de los ruidos Gaussianos aditivos.
     <inline-formula id="IEq30">
      <alternatives>
       <math id="IEq30_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         b
        </mi>
       </math>
       <tex-math id="IEq30_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{\bf{b}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq30.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es el fondo, aproximadamente considerado como un valor fijo relacionado con la cámara, al restar el cual extraemos señales de fluorescencia de la muestra.
     <inline-formula id="IEq31">
      <alternatives>
       <math id="IEq31_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         H
        </mi>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq31_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$$H(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq31.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es un filtro lineal de paso bajo utilizado para suavizar preliminarmente la imagen y reducir el ruido, y adoptamos un filtro de promediado con un tamaño de 5 píxeles en nuestros experimentos
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     .
    </p>
    <p id="Par31">
     Como se demuestra en la Nota Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     , el valor teóricamente óptimo de ambos
     <inline-formula id="IEq32">
      <alternatives>
       <math id="IEq32_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq32_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq32.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     y
     <inline-formula id="IEq33">
      <alternatives>
       <math id="IEq33_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq33_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq33.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     es 1, mientras que
     <inline-formula id="IEq34">
      <alternatives>
       <math id="IEq34_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq34_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq34.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     depende de la cámara y puede estimarse a partir de la región libre de muestras de la imagen en sí o pre-calibrarse siguiendo protocolos estándar
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
     </sup>
     . Las evaluaciones en datos simulados han demostrado que el mejor rendimiento de eliminación de ruido y superresolución se logra en los valores teóricamente óptimos de estos hiperparámetros independientemente de la estructura y SNR de las imágenes de prueba (Figuras Suplementarias
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ).
    </p>
   </sec>
   <sec id="Sec17">
    <title>
     Implementación de 3D ZS-DeconvNet
    </title>
    <p id="Par32">
     El esquema de entrenamiento de 3D ZS-DeconvNet integra el esquema de aprendizaje auto-supervisado intercalado espacialmente con el solucionador de problemas inversos auto-supervisado. En el proceso de entrenamiento, cada pila de imágenes ruidosas se dividió en cortes impares y pares, que luego se utilizaron como entrada y objetivos, respectivamente, después de la ampliación mediante rotación aleatoria, recorte y volteo. Para enmendar la brecha de expectativas entre los cortes impares y pares, introdujimos el término de regularización de enmienda de brecha (GAR) tanto en la pérdida de eliminación de ruido como en la pérdida de deconvolución, que se calculó con la pila denoised (etiquetada con el cuadro rojo en la Fig.
     <xref ref-type="fig" rid="Fig3">
      3a
     </xref>
     ), cortes pares ruidosos y salidas de la red (detallado en la Nota Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec18">
    <title>
     Implementación de 2D/3D ZS-DeconvNet-SIM
    </title>
    <p id="Par33">
     Para las implementaciones de ZS-DeconvNet-SIM en 2D-SIM y 3D-SIM, cada conjunto de imágenes SIM crudas se aumentó primero en dos conjuntos de imágenes crudas recorruptas a través de las Ecuaciones 9 y 10, y se reconstruyeron en un par de imágenes SR SIM a través del algoritmo de reconstrucción SIM convencional. Los pares de imágenes SIM generados se utilizaron luego para el entrenamiento auto-supervisado de manera similar al entrenamiento de los modelos ZS-DeconvNet. Para 3D ZS-DeconvNet-SIM aplicado en LLS-SIM (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     ), los datos SIM volumétricos post-reconstruidos en lugar de las imágenes crudas se muestrearon axialmente en dos pilas SIM que contenían respectivamente cortes impares y pares, que se utilizaron en los procedimientos de entrenamiento subsiguientes de los modelos 3D ZS-DeconvNet con funciones de pérdida descritas en las Ecuaciones 6-8. El flujo de trabajo esquemático de ZS-DeconvNet-SIM se muestra en la Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     y la Figura Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      20
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec19">
    <title>
     Uso y generación de PSF
    </title>
    <p id="Par34">
     En el procedimiento de entrenamiento de ZS-DeconvNet, utilizamos PSFs adquiridos experimentalmente o simulados (con el complemento PSF Generator Fiji licenciado por EPFL) que corresponden a las configuraciones de imagen. Se entrenaron modelos ZS-DeconvNet independientes para cada estructura biológica y longitud de onda de emisión para obtener el mejor rendimiento.
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     Entrenamiento del modelo y adaptación en tiempo de prueba
    </title>
    <p id="Par35">
     En este trabajo, los modelos ZS-DeconvNet se entrenaron en una PC con un procesador Intel Core i7-11700 y una tarjeta gráfica RTX 3090 (NVIDIA) bajo el entorno de software de TensorFlow 2.5.0 y python 3.9.7. Antes del entrenamiento, las imágenes de entrada/GT emparejadas se aumentaron primero en varios pares de parches mediante recorte aleatorio, volteo horizontal/vertical y transformación de rotación para enriquecer aún más el conjunto de datos de entrenamiento, lo que finalmente generó ~20,000 pares de parches 2D (128
     <inline-formula id="IEq35">
      <alternatives>
       <math id="IEq35_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq35_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq35.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     128 píxeles) o ~10,000 pares de parches 3D (64
     <inline-formula id="IEq36">
      <alternatives>
       <math id="IEq36_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq36_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq36.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     64
     <inline-formula id="IEq37">
      <alternatives>
       <math id="IEq37_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mo>
         ×
        </mo>
       </math>
       <tex-math id="IEq37_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq37.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     13 vóxeles). El entrenamiento se realizó típicamente con el optimizador Adam y una tasa de aprendizaje inicial de
     <inline-formula id="IEq38">
      <alternatives>
       <math id="IEq38_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mn>
         0.5
        </mn>
        <mo>
         ×
        </mo>
        <msup>
         <mrow>
          <mn>
           10
          </mn>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           4
          </mn>
         </mrow>
        </msup>
       </math>
       <tex-math id="IEq38_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times {10}^{-4}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq38.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , que decaería con un factor de 0.5 cada 10,000 iteraciones. El tamaño del lote de entrenamiento fue de 4 para imágenes 2D y 3 para pilas 3D. El proceso de entrenamiento completo generalmente requería 50,000 iteraciones para imágenes 2D y 10,000 iteraciones para pilas 3D. El tiempo transcurrido para entrenar 50,000 iteraciones para modelos 2D y 10,000 iteraciones para modelos 3D fue de ~1 h y ~2 h, respectivamente. Como suele ser el caso con la mayoría de los métodos basados en aprendizaje profundo, el entrenamiento de ZS-DeconvNet es un procedimiento único en la mayoría de los casos de imágenes de células vivas, donde los usuarios entrenan el modelo ZS-DeconvNet con todos los fotogramas, luego los modelos bien entrenados son aplicables para todos los datos del mismo espécimen biológico a alta velocidad de procesamiento. Para eliminar los artefactos de borde inducidos por la deconvolución, típicamente rellenamos con 2 cortes en blanco en la parte superior e inferior de las pilas 3D y un margen de 8 píxeles para cada corte xy en ambos procesos de entrenamiento e inferencia (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      30a
     </xref>
     ). En particular, al procesar los datos de lapso de tiempo de la mitosis celular (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     ), la propiedad no supervisada de ZS-DeconvNet permitió una estrategia de aprendizaje de adaptación en tiempo de prueba en la que primero entrenamos un modelo general para cada estructura biológica con datos de todo el proceso y luego afinamos el modelo preentrenado para cada punto de tiempo con un pequeño número de pasos de entrenamiento (típicamente 50 iteraciones que toman ~1 min) para explotar completamente la información estructural de los datos en bruto y obtener el rendimiento óptimo de SR. Cabe destacar que la adaptación en tiempo de prueba no es necesaria, sino una técnica opcional para mejorar el rendimiento de ZS-DeconvNet especialmente en circunstancias donde hay grandes cambios morfológicos en los especímenes biológicos durante la ventana de observación, por ejemplo, los cromosomas durante la mitosis (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      31
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     Post-procesamiento de datos y evaluación de imágenes SR
    </title>
    <p id="Par36">
     Para modalidades de imagen que emplean detección de campo amplio como LLSM, el ruido de patrón fijo (FPN) que es inducido por la no uniformidad en la sensibilidad de los píxeles de la cámara no puede ser eliminado por esquemas basados en noise2noise
     <sup>
      <xref ref-type="bibr" rid="CR62">
       62
      </xref>
     </sup>
     . En nuestra implementación de ZS-DeconvNet, el FPN se vería aumentado en la etapa de deconvolución y se volvería no despreciable especialmente en condiciones de imagen de SNR extremadamente bajo. Para sensores sCMOS, que son los más comunes en microscopía de fluorescencia, el patrón fijo generalmente presenta una apariencia regular de rayas horizontales o verticales atribuidas al amplificador de columna. Para este fin, simplemente aplicamos una máscara de apodización en el dominio de Fourier para suprimir los artefactos de rayas mientras preservamos otros componentes de frecuencia de las muestras (Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      30b
     </xref>
     ). Se observa que el ruido de patrón fijo también puede ser eliminado fundamentalmente mediante pre-calibración de las imágenes en bruto adquiridas antes de ser enviadas al modelo de red siguiendo los procedimientos bien establecidos
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
      ,
      <xref ref-type="bibr" rid="CR63">
       63
      </xref>
      ,
      <xref ref-type="bibr" rid="CR64">
       64
      </xref>
     </sup>
     .
    </p>
    <p id="Par37">
     Otros enfoques computacionales de SR comparados en este trabajo, es decir, la deconvolución escasa, la deconvolución basada en DeepCAD y SRRF se implementan siguiendo las instrucciones en los artículos originales. Específicamente, hicimos nuestro mejor esfuerzo para seleccionar los hiperparámetros óptimos para la deconvolución escasa para obtener una imagen reconstruida con la menor cantidad de artefactos y la mayor resolución. Y la deconvolución basada en DeepCAD (Figs.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a y
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     ) se llevó a cabo integrando el esquema de muestreo temporal en nuestro marco ZS-DeconvNet, es decir, utilizando imágenes muestreadas temporalmente de los datos de lapso de tiempo para entrenar nuestros modelos de red de dos etapas, asegurando el mismo tamaño de modelo y costo computacional para una comparación justa
     <sup>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      <xref ref-type="bibr" rid="CR13">
       13
      </xref>
     </sup>
     .
    </p>
    <p id="Par38">
     Para evaluar cuantitativamente el rendimiento de SR de ZS-DeconvNet 2D y otros enfoques computacionales de SR con solo referencias limitadas por difracción, calculamos PSNR entre objetivos WF claros e imágenes SR degradadas con el PSF siguiendo tres pasos: (1) Convolucionar la imagen SR con el PSF correspondiente y reducir el tamaño de la imagen convolucionada
     <bold>
      I
     </bold>
     al tamaño de GT; (2) Normalizar la imagen GT
     <bold>
      x
     </bold>
     al rango de [0, 1] y luego aplicar una transformación lineal a la imagen convolucionada
     <bold>
      I
     </bold>
     para igualar su rango dinámico con
     <bold>
      x
     </bold>
     :
     <disp-formula id="Equ13">
      <label>
       13
      </label>
      <alternatives>
       <math id="Equ13_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
        <mo>
         =
        </mo>
        <mi>
         a
        </mi>
        <mi mathvariant="bold">
         I
        </mi>
        <mo>
         +
        </mo>
        <mi>
         b
        </mi>
       </math>
       <tex-math id="Equ13_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}=a{{{{{\bf{I}}}}}}+b$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ13.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ14">
      <label>
       14
      </label>
      <alternatives>
       <math id="Equ14_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mfenced close=")" open="(">
         <mrow>
          <mi>
           a
          </mi>
          <mo>
           ,
          </mo>
          <mi>
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           a
          </mi>
          <mi>
           r
          </mi>
          <mi>
           g
          </mi>
          <mi>
           m
          </mi>
          <mi>
           i
          </mi>
          <mi>
           n
          </mi>
         </mrow>
         <mrow>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi>
               θ
              </mi>
             </mrow>
             <mrow>
              <mn>
               1
              </mn>
             </mrow>
            </msub>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               θ
              </mi>
             </mrow>
             <mrow>
              <mn>
               2
              </mn>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           ∈
          </mo>
          <msup>
           <mrow>
            <mi mathvariant="double-struck">
             R
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msubsup>
           <mrow>
            <msub>
             <mrow>
              <mo>
               ∣
              </mo>
              <mo>
               ∣
              </mo>
              <mi>
               θ
              </mi>
             </mrow>
             <mrow>
              <mn>
               1
              </mn>
             </mrow>
            </msub>
            <mi mathvariant="bold">
             I
            </mi>
            <mo>
             +
            </mo>
            <msub>
             <mrow>
              <mi>
               θ
              </mi>
             </mrow>
             <mrow>
              <mn>
               2
              </mn>
             </mrow>
            </msub>
            <mo>
             −
            </mo>
            <mi mathvariant="bold">
             x∣∣
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msubsup>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ14_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left(a,b\right)={{argmin}}_{\left({\theta }_{1},{\theta }_{2}\right)\in {{\mathbb{R}}}^{2}}\left({{{||}\theta }_{1}{{{{{\bf{I}}}}}}+{\theta }_{2}-{{{{{\bf{x||}}}}}}}_{2}^{2}\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ14.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR53">
       53
      </xref>
     </sup>
     .
    </p>
    <p id="Par39">
     La transformación lineal se aplica a todos los métodos para una comparación justa; (3) Calcular el PSNR entre la imagen GT normalizada
     <bold>
      x
     </bold>
     y la imagen transformada linealmente
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     .
    </p>
    <p id="Par40">
     Para la evaluación del PSNR de 3D ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ), utilizamos directamente las imágenes LLS-SIM como referencia, ya que tanto LLS-SIM como nuestro 3D ZS-DeconvNet proporcionaron una mejora de resolución de ~1.5 veces teóricamente. El proceso de cálculo general es similar a los casos 2D, excepto que las pilas SR no fueron convolucionadas y el PSNR se calculó solo dentro de las regiones de características con un umbral de 0.02 para evitar obtener un valor anormalmente alto de PSNR.
    </p>
    <p id="Par41">
     Para proporcionar mejor contraste y visualización, realizamos igualmente una normalización percentil para las imágenes de deconvolución generadas por deconvolución RL, deconvolución dispersa y ZS-DeconvNet, que se formula como:
     <disp-formula id="Equ15">
      <label>
       15
      </label>
      <alternatives>
       <math id="Equ15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="normal">
           Norm
          </mi>
         </mrow>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             l
            </mi>
            <mi>
             o
            </mi>
            <mi>
             w
            </mi>
           </mrow>
          </msub>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             h
            </mi>
            <mi>
             i
            </mi>
            <mi>
             g
            </mi>
            <mi>
             h
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               h
              </mi>
              <mi>
               i
              </mi>
              <mi>
               g
              </mi>
              <mi>
               h
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
        <mo>
         ,
        </mo>
       </math>
       <tex-math id="Equ15_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${{{{{{\rm{Norm}}}}}}}_{p}\left({{{{{\bf{Y}}}}}},{p}_{{low}},{p}_{{high}}\right)=\frac{{{{{{\bf{Y}}}}}}-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)}{{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{high}}\right)-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)},$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ15.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     donde percentile(
     <bold>
      Y,
     </bold>
     <italic>
      p
     </italic>
     ) produce el valor de intensidad que ocupa el rango
     <italic>
      p
     </italic>
     % en la imagen
     <bold>
      Y
     </bold>
     <sup/>
     .
     <inline-formula id="IEq40">
      <alternatives>
       <math id="IEq40_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           l
          </mi>
          <mi>
           o
          </mi>
          <mi>
           w
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq40_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${p}_{{low}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq40.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     y
     <inline-formula id="IEq41">
      <alternatives>
       <math id="IEq41_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           h
          </mi>
          <mi>
           i
          </mi>
          <mi>
           g
          </mi>
          <mi>
           h
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq41_TeX">
        \documentclass[12pt]{minimal}
                \usepackage{amsmath}
                \usepackage{wasysym}
                \usepackage{amsfonts}
                \usepackage{amssymb}
                \usepackage{amsbsy}
                \usepackage{mathrsfs}
                \usepackage{upgreek}
                \setlength{\oddsidemargin}{-69pt}
                \begin{document}$${p}_{{high}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq41.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     se establecen típicamente como 3 y 100 en nuestra figura y videos.
    </p>
   </sec>
   <sec id="Sec22">
    <title>
     Cultivo celular, transfección y tinción
    </title>
    <p id="Par42">
     Las células Cos7, HeLa, 293 T, así como sus líneas celulares estables, se cultivaron en DMEM (Gibco, cat. no. 11965092), suplementado con 10% de suero fetal bovino (Gibco, cat. no. 10099141 C) y 1× penicilina-estreptomicina (Thermo Fisher, 15140122) a 37°C en una incubadora de CO
     <sub>
      2
     </sub>
     Thermo Scientific™ Heracell™ 150i. Las células SUM159 se cultivaron en medio DMEM/F12K suplementado con 5% de suero fetal bovino (FBS) y 1% de solución de penicilina-estreptomicina.
    </p>
    <p id="Par43">
     Para la obtención de imágenes de células vivas, los cubreobjetos de 35 mm se recubrieron previamente con 50 μg ml de colágeno y se sembraron 1×10 células en los cubreobjetos. Para la transfección transitoria, las células se transfectaron con plásmidos usando Lipofectamine 3000 (Invitrogen, cat. no. L3000150) de acuerdo con el protocolo del fabricante 12 h después de la siembra. Las células se visualizaron durante 12 h después de la transfección. Donde se indicó, las células transfectadas con plásmidos de Halo Tag se etiquetaron con 10 nM de ligando JF549 durante 15 min de acuerdo con el protocolo publicado
     <sup>
      <xref ref-type="bibr" rid="CR65">
       65
      </xref>
     </sup>
     . Las células se enjuagaron con medio fresco para eliminar el ligando no unido y se visualizaron inmediatamente después. Los plásmidos utilizados en la transfección transitoria incluyen Lifeact-mEmerald, Clathrin-mEmerald, 3×mEmerald-Ensconsin, Lamp1-Halo, 2×mEmerald-Tomm20, Myosin2-Halo, KDEL-mCherry y Halo-Calnexin.
    </p>
    <p id="Par44">
     Para el empaquetado de lentivirus, 1 μg de ADN vector de transferencia lentiviral, junto con 0.5 μg de ADN plasmídico de empaquetado psPAX2 y 0.5 μg de ADN plasmídico de envoltura pMD2.G, se cotransfectaron en células HEK293T al 90% de confluencia en una placa de Petri de 6 cm usando Lipofectamine 3000 siguiendo el protocolo del fabricante. Después de 2 días, se recolectó el sobrenadante y se filtró con un filtro de 0.22 μm (Millipore). Para la construcción de células estables, las células HeLa y Cos7 fueron infectadas con lentivirus que codifican el marcador de retículo endoplásmico Calnexin-mEmerald y el marcador de F-actina Lifeact-mEmerald
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     . Cuarenta y ocho horas después, las células se enriquecieron mediante citometría de flujo (FACSAria III, BD Biosciences) y luego se sembraron una célula por pozo en placas de 96 pocillos. Se utilizaron células monoclonales para nuestros experimentos. Específicamente, Lifeact-mEmerald para COS7 se usó en las Figs.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     y
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     ; Calnexin-mEmerald, Mito-dsRed y Halo-H2B para células HeLa se usaron en la Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ; H2B-mCherry para HeLa-mEmerald-SC35 se usó en la Fig. Suplementaria
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     Líneas celulares editadas genéticamente
    </title>
    <p id="Par45">
     Las células SUM159 fueron editadas genéticamente secuencialmente para incorporar EGFP en el extremo N de Rab11A y luego Halo en el extremo C de Lamp1 usando el enfoque CRISPR/Cas9
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     . Las secuencias de ARN guía único (sgRNA) de destino son 5’-TCGCTCCTCGGCCGCGCAAT-3’ para RAB11A y 5’-CTATCTAGCCTGGTGCACGC-3’ para LAMP1. Las SUM159 fueron transfectadas con el plásmido donante EGFP-Rab11A, el plásmido que codifica para el spCas9 y el producto de PCR libre que contiene la secuencia de destino sgRNA usando Lipofectamin 3000 (Invitrogen) de acuerdo con las instrucciones del fabricante. Las células que expresan EGFP fueron enriquecidas mediante clasificación activada por fluorescencia (FACS) (FACSAria II, BD Biosciences), y posteriormente sometidas a clasificación de células individuales en placas de 96 pocillos. Las células monoclonales con incorporación exitosa de EGFP fueron identificadas mediante cribado por PCR usando GoTaq Polymerase (Promega). Las células clonales SUM159 que expresan EGFP-Rab11A + /+ fueron sometidas a una segunda ronda de edición del genoma para incorporar Lamp1-Halo en el genoma como se describió anteriormente. Las células transfectadas fueron teñidas con 10 nM de ligandos HaloTag Janelia Fluor 646 (Promega) durante 15 minutos. Para lavar el tinte no unido, las muestras se enjuagaron con medio fresco y luego se enriquecieron mediante FACS. Las células monoclonales SUM159 que expresan tanto EGFP-Rab11A + /+ como Lamp1-Halo + /+ fueron confirmadas mediante análisis de PCR y Western blot.
    </p>
    <p id="Par46">
     Las células SUM159 fueron editadas genéticamente para incorporar EGFP en el extremo C de la cadena ligera de clatrina A (clatrina-EGFP) usando el enfoque basado en TALEN
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     . Las células que expresan clatrina-EGFP fueron enriquecidas mediante dos clasificaciones masivas secuenciales.
    </p>
    <p id="Par47">
     Las líneas celulares HeLa fueron editadas genéticamente para incorporar mEmerald en el extremo C del SC35 genómico humano usando el sistema de edición genética CRISPR-Cas9. La secuencia de destino del sgRNA es 5’-CGAGCAGCACTCCTAATGAT-3’, y el sgRNA fue ligado en pX330A-1×2 (Addgene, 58766). El plásmido resultante se nombró pX330-SC35-gRNA en adelante. Para construir el vector donante p-SC35-doner, mEmerald flanqueado con aproximadamente 1800bp de brazos de homología complementarios al codón de parada del locus SC35 genómico humano se ligaron a pEASY-blunt (Transgene, CB101). 2 × 10 células HeLa cultivadas en una placa de Petri de 6 cm fueron transfectadas con 1.2 μg de pX330-SC35-gRNA y 0.4 μg de p-SC35-doner. 48 horas después de la transfección, las células positivas para mEmerald fueron clasificadas usando FACS (FACSAria III, BD Biosciences). Después de una semana, las células clasificadas fueron infectadas con lentivirus H2B-mCherry y luego se sembraron células individuales en placas de 96 pocillos. Después de dos semanas, el ADN genómico de diferentes clones de células individuales fue extraído y validado mediante PCR y Western blot. Las células SC35 knock-in homocigotas fueron seleccionadas para el estudio. La incorporación exitosa de SC35 fue verificada mediante análisis de PCR y Western blot
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     Preparación de embriones de
     <italic>
      C. elegans
     </italic>
    </title>
    <p id="Par48">
     Las cepas de
     <italic>
      C. elegans
     </italic>
     se cultivaron a 20 °C en placas de medio de crecimiento de nematodos (NGM) sembradas con OP50 siguiendo protocolos estándar
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     . TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ;
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ;
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     se utilizó en este estudio. El plásmido
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     fue construido siguiendo el Sistema de Clonación PCR In-Fusion de Clontech y microinyectado en
     <italic>
      jcIs1;qxIs257
     </italic>
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     . La matriz extracromosómica
     <italic>
      wyEx51119
     </italic>
     marcó la membrana celular epidérmica.
     <italic>
      jcIs1
     </italic>
     marcó el dominio de la unión apical de
     <italic>
      C. elegans
     </italic>
     <italic>
      . qxIs257
     </italic>
     marcó los lisosomas en las células epidérmicas
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     .
    </p>
    <p id="Par49">
     Aproximadamente 50 gusanos transgénicos en etapa L4 fueron colocados en placas NGM con OP50 fresco de 48 a 60 horas antes de los experimentos. Los huevos transgénicos fueron recolectados bajo el microscopio fluorescente de disección (Olympus MVX10) y montados en almohadillas de agarosa al 3%. Luego, los embriones en etapa de frijol lima a 2 pliegues fueron imagenados usando el modo 3D WF de nuestro sistema Multi-SIM.
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     Preparación de embriones de ratón
    </title>
    <p id="Par50">
     Los ratones utilizados en este estudio eran de fondo C57BL/6J. Todos los experimentos con animales fueron aprobados por los Comités de Cuidado y Uso de Animales (IACUC) del Instituto de Biofísica, Academia China de Ciencias, Beijing, China. Los embriones pre-implantación fueron aislados de hembras de 5-6 semanas de edad, superovuladas por inyección intraperitoneal de 5 unidades internacionales (UI) de gonadotropina sérica de yegua preñada (PMSG; LEE BIOSOLUTIONS) y 5 UI de gonadotropina coriónica humana (hCG; Millipore) 48 horas después, y se aparearon con ratones machos. Los cigotos fueron recuperados en E0.5 en medio M2 (Millipore) y cultivados en medio KSOM (Millipore) en una incubadora de CO2 (Thermo Scientific) a 37°C con 5% de CO2 hasta la etapa tardía de 8 células.
    </p>
    <p id="Par51">
     Para la inmunofluorescencia, los embriones fueron fijados con paraformaldehído al 4% en PBS durante 30 minutos a temperatura ambiente (RT) y lavados con PBS tres veces. Luego, los embriones fueron permeabilizados en TritonX-100 al 0.5% (Sigma) en PBS durante 20 minutos a RT, lavados en PBS tres veces, bloqueados en albúmina de suero bovino al 1% en PBS durante 1 hora a RT e incubados con anticuerpo anti-pERM (Abcam, ab76247), anti-alfa-tubulina-FITC (Sigma, F2168-.2 ML) y Faloidina-Rodamina (Molecular Probes, R415) durante la noche a 4°C. Luego, los embriones fueron lavados en PBS tres veces, incubados con anticuerpos secundarios (Life technologies) durante 1 hora a RT, teñidos con Hoescht 33342 (Thermo) durante 15 minutos a RT, lavados en PBS tres veces e imagenados por el microscopio confocal construido en casa.
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     Visualización de imágenes 3D
    </title>
    <p id="Par52">
     Las imágenes de lisosomas codificadas axialmente por color mostradas en Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     fueron generadas con Fiji. Las imágenes de renderizado 3D de la célula en mitosis y embriones de ratón mostradas en Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     fueron visualizadas y generadas utilizando el software comercial Amira.
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     Estadísticas y reproducibilidad
    </title>
    <p id="Par53">
     Los experimentos en Figs.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i,
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f,
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     , y
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     fueron repetidos independientemente con al menos 3 especímenes, es decir, células o embriones, todos logrando resultados similares.
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     Resumen de informes
    </title>
    <p id="Par54">
     Más información sobre el diseño de la investigación está disponible en el
     <xref ref-type="supplementary-material" rid="MOESM13">
      Resumen de Reporte de Nature Portfolio
     </xref>
     vinculado a este artículo.
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Agradecimientos
   </title>
   <p>
    Los autores agradecen a T. Kirchhausen por los plásmidos donantes utilizados para la edición del genoma y la ayuda en la generación de las líneas celulares editadas genéticamente, y agradecen al Prof. Xiaochen Wang y al Dr. Kangmin He por las cepas de
    <italic>
     C. elegans
    </italic>
    y las líneas celulares SUM159 editadas genéticamente. Este trabajo fue apoyado por subvenciones de la Fundación Nacional de Ciencias Naturales de China (32125024, 32271513, 62071271, y 62088102); el Ministerio de Ciencia y Tecnología (2021YFA1300303 y 2020AA0105500); la Academia China de Ciencias (ZDBS-LY-SM004 y XDA16021401); el Fondo de Investigación Colaborativa del Instituto Chino para la Investigación del Cerebro, Beijing (2021-NKX-XM-03); la Fundación de Ciencias Postdoctorales de China (2022M721842, 2023T160365); la Fundación de Ciencias New Cornerstone; el Programa de Becarios Shuimu Tsinghua (2022SM035); la Fundación de Ciencias Naturales de Beijing (JQ21012).
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Contribuciones de los autores
   </title>
   <p>
    Q.D. y Dong Li supervisaron la investigación. Q.D., Dong Li, y C.Q. concibieron e iniciaron este proyecto. C.Q. diseñó las implementaciones detalladas bajo la instrucción de Q.D. y Dong Li. Y.Z, C.Q., y X.C desarrollaron el código en python, realizaron simulaciones y procesaron datos de imagen relevantes. H.C., C.Q., y Y.Z. desarrollaron el plugin de Fiji. T.J., R.W, C.Q, H.L., W.F., Di Li, y J.G. prepararon muestras y realizaron experimentos de imagen. C.Q., Y.Z., X.C., y Q.M. analizaron los datos con asesoramiento conceptual de Q.D., Dong Li, J.W, Y.W., y H.Q. C.Q., Y.Z, y Q.M. compusieron las figuras y videos, hicieron la página de tutorial bajo la supervisión de Q.D. y Dong Li. Q.D., Dong Li, y C.Q. escribieron el manuscrito, con aportes de todos los autores. Todos los autores discutieron los resultados y comentaron sobre el manuscrito.
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Revisión por pares
   </title>
   <sec id="FPar1">
    <title>
     Información de revisión por pares
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilidad de datos
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Disponibilidad de código
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Intereses en competencia
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    Referencias
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      Información suplementaria
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      Datos fuente
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Información suplementaria
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
