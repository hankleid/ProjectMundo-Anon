<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/ProjectMundo/style/jats-html.xsl"?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41467
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41467.2041-1723
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature Communications
    </journal-title>
    <abbrev-journal-title abbrev-type="publisher">
     Nat Commun
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="epub">
    2041-1723
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41467-024-48575-9
   </article-id>
   <article-id pub-id-type="manuscript">
    48575
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41467-024-48575-9
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/245/2225
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /631/1647/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1107/328/2238
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/63
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /123
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/19
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /14/69
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /139
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     Обучение с нулевым выстрелом позволяет мгновенно удалять шум и повышать разрешение в оптической флуоресцентной микроскопии
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6037-0842
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Chang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0009-0005-4082-4391
     </contrib-id>
     <name name-style="western">
      <surname>
       Zeng
      </surname>
      <given-names>
       Yunmin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au3">
     <name name-style="western">
      <surname>
       Meng
      </surname>
      <given-names>
       Quan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au4">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Xingye
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="aff" rid="Aff7">
      7
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Chen
      </surname>
      <given-names>
       Haoyu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Jiang
      </surname>
      <given-names>
       Tao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au7">
     <name name-style="western">
      <surname>
       Wei
      </surname>
      <given-names>
       Rongfei
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au8">
     <name name-style="western">
      <surname>
       Guo
      </surname>
      <given-names>
       Jiabao
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au9">
     <name name-style="western">
      <surname>
       Fu
      </surname>
      <given-names>
       Wenfeng
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au10">
     <name name-style="western">
      <surname>
       Lu
      </surname>
      <given-names>
       Huaide
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au11">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9331-265X
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Di
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au12">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-6880-959X
     </contrib-id>
     <name name-style="western">
      <surname>
       Wang
      </surname>
      <given-names>
       Yuwang
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff8">
      8
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au13">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-4896-8657
     </contrib-id>
     <name name-style="western">
      <surname>
       Qiao
      </surname>
      <given-names>
       Hui
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au14">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0003-3479-1026
     </contrib-id>
     <name name-style="western">
      <surname>
       Wu
      </surname>
      <given-names>
       Jiamin
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au15">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6787-5125
     </contrib-id>
     <name name-style="western">
      <surname>
       Li
      </surname>
      <given-names>
       Dong
      </given-names>
     </name>
     <address>
      <email>
       lidong@ibp.ac.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff5">
      5
     </xref>
     <xref ref-type="aff" rid="Aff6">
      6
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor15">
      r
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au16">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-7043-3061
     </contrib-id>
     <name name-style="western">
      <surname>
       Dai
      </surname>
      <given-names>
       Qionghai
      </given-names>
     </name>
     <address>
      <email>
       qhdai@tsinghua.edu.cn
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
     <xref ref-type="aff" rid="Aff4">
      4
     </xref>
     <xref ref-type="corresp" rid="IDs41467024485759_cor16">
      s
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Department of Automation
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Institute for Brain and Cognitive Sciences
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing Key Laboratory of Multi-dimension &amp; Multi-scale Computational Photography
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff4">
     <label>
      4
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/04bpn6s66
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.452952.d
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 5901 0211
      </institution-id>
      <institution content-type="org-division">
       Beijing Laboratory of Brain and Cognitive Intelligence
      </institution>
      <institution content-type="org-name">
       Beijing Municipal Education Commission
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100010
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff5">
     <label>
      5
     </label>
     <institution-wrap>
      <institution-id institution-id-type="GRID">
       grid.9227.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000000119573309
      </institution-id>
      <institution content-type="org-division">
       National Laboratory of Biomacromolecules, New Cornerstone Science Laboratory, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics
      </institution>
      <institution content-type="org-name">
       Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100101
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff6">
     <label>
      6
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/05qbk4x57
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.410726.6
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1797 8419
      </institution-id>
      <institution content-type="org-division">
       College of Life Sciences
      </institution>
      <institution content-type="org-name">
       University of Chinese Academy of Sciences
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100049
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff7">
     <label>
      7
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00wk2mp56
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.64939.31
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0000 9999 1211
      </institution-id>
      <institution content-type="org-division">
       Research Institute for Frontier Science
      </institution>
      <institution content-type="org-name">
       Beihang University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100191
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff8">
     <label>
      8
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03cve4549
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.12527.33
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 0662 3178
      </institution-id>
      <institution content-type="org-division">
       Beijing National Research Center for Information Science and Technology
      </institution>
      <institution content-type="org-name">
       Tsinghua University
      </institution>
     </institution-wrap>
     <addr-line content-type="postcode">
      100084
     </addr-line>
     <addr-line content-type="city">
      Beijing
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Chang Qiao, Yunmin Zeng, Quan Meng, Xingye Chen.
     </p>
    </fn>
    <corresp id="IDs41467024485759_cor15">
     <label>
      r
     </label>
     <email>
      lidong@ibp.ac.cn
     </email>
    </corresp>
    <corresp id="IDs41467024485759_cor16">
     <label>
      s
     </label>
     <email>
      qhdai@tsinghua.edu.cn
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     16
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="collection" publication-format="electronic">
    <month>
     12
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    15
   </volume>
   <issue seq="4180">
    1
   </issue>
   <elocation-id>
    4180
   </elocation-id>
   <history>
    <date date-type="registration">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      7
     </day>
     <month>
      10
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      7
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      16
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Аннотация
    </title>
    <p id="Par1">
     Вычислительные методы сверхразрешения, включая традиционные аналитические алгоритмы и модели глубокого обучения, существенно улучшили оптическую микроскопию. Среди них модели глубокого обучения с учителем продемонстрировали исключительную производительность, однако требуют обильных высококачественных данных для обучения, которые трудно и даже невозможно получить из-за высокой динамики живых клеток. Здесь мы разрабатываем сети деконволюции с нулевым выстрелом (ZS-DeconvNet), которые мгновенно повышают разрешение изображений микроскопа более чем в 1,5 раза выше предела дифракции с 10-кратным снижением флуоресценции по сравнению с обычными условиями сверхразрешения, в неуправляемом режиме без необходимости в эталонных данных или дополнительном сборе данных. Мы демонстрируем универсальное применение ZS-DeconvNet на нескольких режимах изображения, включая микроскопию флуоресценции с внутренним полным отражением, трехмерную микроскопию широкого поля, конфокальную микроскопию, двухфотонную микроскопию, микроскопию с решетчатым световым листом и многомодальную структурированную микроскопию освещения, что позволяет выполнять многокolorное, долгосрочное, сверхразрешающее 2D/3D изображение субклеточных биопроцессов от митотических одиночных клеток до многоклеточных эмбрионов мыши и
     <italic>
      C. elegans
     </italic>
     .
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     The authors introduce ZS-DeconvNet, an unsupervised computational super-resolution method for multiple types of microscopes, that enhances image resolution by more than 1.5 times over the diffraction limit with 10 times lower fluorescence than regular superresolution imaging conditions.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
    </nested-kwd>
    <kwd content-type="term" vocab-term-identifier="02">
     Physical Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0299">
      Other Physical Sciences
     </kwd>
    </nested-kwd>
   </kwd-group>
   <funding-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        National Natural Science Foundation of China (National Science Foundation of China)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100001809
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2020AA0105500
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Dai
       </surname>
       <given-names>
        Qionghai
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        China Postdoctoral Science Foundation
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002858
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2022M721842
     </award-id>
     <award-id award-type="FundRef grant">
      2023T160365
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Qiao
       </surname>
       <given-names>
        Chang
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        the Shuimu Tsinghua Scholar Program (2022SM035)
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Ministry of Science and Technology of the People’s Republic of China (Chinese Ministry of Science and Technology)
       </institution>
       <institution-id institution-id-type="doi" vocab="open-funder-registry">
        https://doi.org/10.13039/501100002855
       </institution-id>
      </institution-wrap>
     </funding-source>
     <award-id award-type="FundRef grant">
      2021YFA1300303
     </award-id>
     <principal-award-recipient>
      <name name-style="western">
       <surname>
        Li
       </surname>
       <given-names>
        Dong
       </given-names>
      </name>
     </principal-award-recipient>
    </award-group>
    <award-group>
     <funding-source>
      <institution-wrap>
       <institution>
        Chinese Academy of Sciences (ZDBS-LY-SM004 and XDA16021401); the New Cornerstone Science Foundation.
       </institution>
      </institution-wrap>
     </funding-source>
    </award-group>
   </funding-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      1
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      4180
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      7
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41467_2024_Article_48575.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1" sec-type="introduction">
   <title>
    Введение
   </title>
   <p id="Par3">
    Оптическая флуоресцентная микроскопия является важнейшим инструментом для биологических исследований. Недавние разработки методов сверхразрешения (SR) обеспечивают беспрецедентную разрешающую способность для визуализации тонких динамических структур различных биопроцессов
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
    </sup>
    . Однако, увеличение пространственного разрешения с помощью любого метода SR происходит за счет компромиссов в других метриках изображения, например, продолжительности или скорости, которые одинаково важны для изучения биопроцессов
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
    </sup>
    . Недавно, вычислительные методы SR получили значительное внимание за их способность мгновенно повышать разрешение изображения в silico, что позволяет существенно улучшить существующие системы флуоресцентной микроскопии и расширить их область применения
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    .
   </p>
   <p id="Par4">
    В целом, существующие вычислительные методы SR можно классифицировать на две категории: методы, основанные на аналитических моделях, такие как алгоритмы деконволюции, и методы, основанные на глубоком обучении, например, нейронные сети SR
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Первая категория часто использует аналитические модели, которые предполагают определенные предположения о свойствах образца и изображения, например, сжатие и локальную симметрию, для улучшения разрешения изображения с помощью нескольких настраиваемых параметров. Настройка параметров зависит от опыта и времени, и выходные данные аналитических моделей сильно зависят от набора параметров
    <sup>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     ,
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    . Кроме того, в практических экспериментах,手обранные модели с определенными предположениями не могут решить полную статистическую сложность микроскопического изображения, поэтому они лишены устойчивости и склонны генерировать артефакты, особенно при низком соотношении сигнал/шум (SNR)
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    . С другой стороны, методы SR на основе глубокого обучения (DLSR) достигли замечательного успеха в обучении отношению между изображениями без необходимости явной аналитической модели
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
    </sup>
    . Обратите внимание, что данные, управляемые обратной связью через глубокое обучение, могут аппроксимировать не только псевдообратную функцию процесса деградации изображения, но и стохастические характеристики решений SR. Однако, обучение моделей DLSR требует получения больших объемов пар низкокачественных изображений и высококачественных эталонных изображений SR, что чрезвычайно трудоемко и иногда даже нецелесообразно из-за быстрой динамики или низкого флуоресцентного SNR в биологических образцах
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Кроме того, производительность методов DLSR сильно зависит от качества и количества обучающих данных
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    . Эти факторы существенно препятствуют широкому применению методов DLSR в повседневных экспериментах по изображению, несмотря на их убедительную производительность SR по сравнению с методами, основанными на аналитических моделях
    <sup>
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
     ,
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
    </sup>
    .
   </p>
   <p id="Par5">
    Здесь мы представляем框架 глубокой нейронной сети деконволюции с нулевым выстрелом (ZS-DeconvNet), который может обучать сеть DLSR в не监督ируемом режиме, используя всего одно плоское изображение или объемный стек изображений низкого разрешения и низкого SNR, что приводит к реализации с нулевым выстрелом
    <sup>
     <xref ref-type="bibr" rid="CR18">
      18
     </xref>
    </sup>
    . Таким образом, по сравнению с современными методами DLSR, ZS-DeconvNet может адаптироваться к различным биоизображениям, где биопроцессы слишком динамичны, слишком чувствительны к свету для получения эталонных изображений SR, или процесс получения изображения подвержен неизвестным и неидеальным факторам. Мы охарактеризовали, что ZS-DeconvNet может повысить разрешение более чем на 1,5 раза над пределами дифракции с высокой достоверностью и количественностью, даже при обучении на одном низкокачественном изображении и без необходимости настраивать параметры
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
     ,
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
     ,
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
     ,
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     ,
     <xref ref-type="bibr" rid="CR19">
      19
     </xref>
     ,
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
     ,
     <xref ref-type="bibr" rid="CR21">
      21
     </xref>
     ,
     <xref ref-type="bibr" rid="CR22">
      22
     </xref>
     ,
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
    </sup>
    . Мы продемонстрировали, что правильно обученная ZS-DeconvNet может выводить высококачественное изображение с высоким разрешением на миллисекундной временной шкале, достигая высокопроизводительного долгосрочного SR-изображения 2D/3D взаимодействия множества органелл, цитоскелетной и органеллярной динамики во время светочувствительных процессов миграции и митоза, а также субклеточных структур и динамики в развитии C. elegans и мышиных эмбрионов. Кроме того, чтобы сделать ZS-DeconvNet широко доступным для биологического исследовательского сообщества, мы создали плагин Fiji и учебную страницу для методов ZS-DeconvNet
    <sup>
     <xref ref-type="bibr" rid="CR24">
      24
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec2" sec-type="results">
   <title>
    Результаты
   </title>
   <sec id="Sec3">
    <title>
     Разработка и характеристика ZS-DeconvNet
    </title>
    <p id="Par6">
     Концепция ZS-DeconvNet основана на не监督ируемом решателе обратной задачи, информированном прямой моделью оптического изображения:
     <disp-formula id="Equ1">
      <label>
       1
      </label>
      <alternatives>
       <math id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <mstyle mathsize="1.61em">
         <mfenced open="∣">
          <mrow/>
         </mfenced>
        </mstyle>
        <msubsup>
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="bold-italic">
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <mi mathvariant="bold">
                 y
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
          <mstyle mathsize="1.61em">
           <mfenced open="∣">
            <mrow/>
           </mfenced>
          </mstyle>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msubsup>
       </math>
       <tex-math id="Equ1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\arg }}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\Big|\Big|{{{{{{\bf{y}}}}}}-{\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{\bf{y}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }{\Big|\Big|}}_{2}^{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     где
     <bold>
      y
     </bold>
     обозначает шумное низкокачественное изображение, PSF — функция распространения точки (PSF),
     <inline-formula id="IEq1">
      <alternatives>
       <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq1_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{{{{{\boldsymbol{\theta }}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq1.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     представляет глубокую нейронную сеть (DNN) с обучаемыми параметрами
     <bold>
      θ
     </bold>
     , а
     <inline-formula id="IEq2">
      <alternatives>
       <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mrow>
           <mo>
            (
           </mo>
           <mrow>
            <mo>
             ⋅
            </mo>
           </mrow>
           <mo>
            )
           </mo>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           ↓
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${(\cdot )}_{\downarrow }$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     обозначает операцию понижения разрешения. Если DNN обучается直接 через вышеуказанную целевую функцию, она нежелательно усиливает фоновый шум, содержащийся в биологических изображениях, что существенно загрязняет реальную информацию об образце при низких условиях SNR (Дополнительное изображение
     <xref ref-type="supplementary-material" rid="MOESM1">
      1а
     </xref>
     ). Чтобы повысить устойчивость к шуму ZS-DeconvNet, сохраняя при этом его не监督ируемый характер, мы приняли схему рекоррупции изображения, которая генерирует два шумо-независимых рекорrupted изображения из исходного изображения, которые затем используются в качестве входных и эталонных данных в обучении сети (Методы). Мы теоретически продемонстрировали обоснованность аппроксимации Гаусса для смешанной модели Пуассона-Гаусса для обычных изображений sCMOS и доказали сходимость включения схемы рекоррупции в не监督ируемый решатель обратной задачи (Дополнительная заметка
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Кроме того, мы ввели член регуляризации Гессиана, который, как было показано, полезен для смягчения реконструкционных артефактов в микроскопических изображениях, для регулирования сходимости сети (Дополнительное изображение
     <xref ref-type="supplementary-material" rid="MOESM1">
      1b–e
     </xref>
     ). В целом, целевая функция ZS-DeconvNet может быть сформулирована как:
     <disp-formula id="Equ2">
      <label>
       2
      </label>
      <alternatives>
       <math id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         arg
        </mi>
        <msub>
         <mrow>
          <mi>
           min
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="bold-italic">
           θ
          </mi>
         </mrow>
        </msub>
        <mfrac>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </mfrac>
        <msubsup>
         <mrow>
          <mo mathsize="big">
           ∑
          </mo>
         </mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
        </msubsup>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         L
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </msub>
          <mo>
           −
          </mo>
          <msup>
           <mrow>
            <mi>
             D
            </mi>
           </mrow>
           <mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </msup>
          <mi mathvariant="bold">
           g
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msub>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mi>
                 θ
                </mi>
               </mrow>
              </msub>
              <mfenced close=")" open="(">
               <mrow>
                <msub>
                 <mrow>
                  <mi mathvariant="bold">
                   y
                  </mi>
                 </mrow>
                 <mrow>
                  <mi>
                   i
                  </mi>
                 </mrow>
                </msub>
                <mi mathvariant="bold-italic">
                 +
                </mi>
                <mi>
                 D
                </mi>
                <mi mathvariant="bold">
                 g
                </mi>
               </mrow>
              </mfenced>
              <mo>
               *
              </mo>
              <mi mathvariant="normal">
               PSF
              </mi>
             </mrow>
            </mfenced>
           </mrow>
           <mrow>
            <mi>
             ↓
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <mi>
         λ
        </mi>
        <msub>
         <mrow>
          <mi class="MJX-tex-caligraphic" mathvariant="script">
           R
          </mi>
         </mrow>
         <mrow>
          <mi>
           H
          </mi>
          <mi>
           e
          </mi>
          <mi>
           s
          </mi>
          <mi>
           s
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="bold-italic">
             θ
            </mi>
           </mrow>
          </msub>
          <mfenced close=")" open="(">
           <mrow>
            <msub>
             <mrow>
              <mi mathvariant="bold">
               y
              </mi>
             </mrow>
             <mrow>
              <mi>
               i
              </mi>
             </mrow>
            </msub>
            <mi mathvariant="bold-italic">
             +
            </mi>
            <mi>
             D
            </mi>
            <mi mathvariant="bold">
             g
            </mi>
           </mrow>
          </mfenced>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ2_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{arg}}}}}}{\min }_{{{{{{\boldsymbol{\theta }}}}}}}\frac{1}{N}{\sum }_{i=1}^{N}{{{{{\mathcal{L}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}-{D}^{-1}{{{{{\bf{g}}}}}},{\left({f}_{\theta }\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)*{{{{{\rm{PSF}}}}}}\right)}_{\downarrow }\right)+\lambda {{{{{{\mathcal{R}}}}}}}_{{Hessian}}\left({f}_{{{{{{\boldsymbol{\theta }}}}}}}\left({{{{{{\bf{y}}}}}}}_{i}{{{{{\boldsymbol{+}}}}}}D{{{{{\bf{g}}}}}}\right)\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ2.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     где
     <italic>
      N
     </italic>
     — общее количество обрабатываемых изображений,
     <inline-formula id="IEq3">
      <alternatives>
       <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
       </math>
       <tex-math id="IEq3_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq3.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — обратимая матрица управления шумом, которую можно рассчитать в соответствии с уровнями сигнала и шума (Методы), а
     <bold>
      g
     </bold>
     — случайная карта шума, отобранная из стандартного нормального распределения. Мы называем первую часть целевой функции членом деградации, который учитывает достоверность вывода, и вторую часть — членом регуляризации, который обосновывает выходные данные SR
     <sup>
      <xref ref-type="bibr" rid="CR25">
       25
      </xref>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
      <xref ref-type="bibr" rid="CR27">
       27
      </xref>
      ,
      <xref ref-type="bibr" rid="CR28">
       28
      </xref>
     </sup>
     .
    </p>
    <p id="Par7">
     После определения целевой функции мы приняли двуступенчатую архитектуру DNN, состоящую из двух последовательно соединенных U-Net в качестве простой, но эффективной основы для ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig1">
      1а, б
     </xref>
     и Дополнительное изображение
     <xref ref-type="supplementary-material" rid="MOESM1">
      2а
     </xref>
     ). Первый этап служит для шумоподавления и генерирует шумо-свободные изображения в соответствии с функцией шумоподавления (Методы), а второй этап повышает разрешение изображения в соответствии с не监督ируемой функцией деконволюции, описанной выше. Мы эмпирически обнаружили, что двуступенчатая архитектура и физически обусловленная функция потерь стабилизируют процесс обучения и наделяют интерпретируемостью общую модель сети
     <sup>
      <xref ref-type="bibr" rid="CR29">
       29
      </xref>
     </sup>
     .
     <fig id="Fig1" position="float">
      <label>
       Fig. 1
      </label>
      <caption xml:lang="ru">
       <title>
        НетSHOT-деконволюционные сети.
       </title>
       <p>
        <bold>
         a
        </bold>
        Двухэтажная архитектура ZS-DeconvNet и схема ее обучения.
        <bold>
         b
        </bold>
        Схема фазы вывода ZS-DeconvNet.
        <bold>
         c
        </bold>
        Представительные изображения SR Lyso и MT, реконструированные методом RL-деконволюции (второй столбец), разреженной деконволюции (третий столбец) и ZS-DeconvNet (четвертый столбец). Четкие изображения WF отображаются для справки.
        <bold>
         d
        </bold>
        Статистические сравнения RL-деконволюции, разреженной деконволюции и ZS-DeconvNet в терминах PSNR и разрешения (
        <italic>
         n
        </italic>
        = 100 областей интереса).
        <bold>
         e
        </bold>
        Сравнения полной ширины на половине максимума (FWHM) четких изображений WF и обработанных изображений методами RL-деконволюции, разреженной деконволюции и ZS-DeconvNet (
        <italic>
         n
        </italic>
        = 30 микротрубочек). Теоретический предел дифракции помечен серой пунктирной линией для справки.
        <bold>
         f
        </bold>
        Сравнение времени тестирования между GPU-основанной разреженной деконволюцией и ZS-DeconvNet (в среднем по 25 тестовым изображениям размером 1024 × 1024 пикселей). Центр линии, медианы; пределы, 75% и 25%; усик, большее значение между наибольшим данным точкой и 75-м процентилем плюс 1,5× межквартильный диапазон (IQR), и меньшее значение между наименьшей данным точкой и 25-м процентилем минус 1,5× IQR; выбросы, данные точки больше верхнего усика или меньше нижнего усика. Исходные данные предоставлены в виде файла Source Data. Шкала, 1,5 μm (
        <bold>
         a
        </bold>
        ), 5 μm (
        <bold>
         c
        </bold>
        ), 2 μm (зум-регионы в (
        <bold>
         c
        </bold>
        )).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig1_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par8">
     Чтобы охарактеризовать и оценить ZS-DeconvNet, мы сначала смоделировали микроскопические изображения пунктирных и трубчатых структур, загрязненных гауссовским-пуассоновским шумом при эскалирующих уровнях сигнала от 5 до 25 средних фотонных подсчетов, что позволило нам систематически проверить, как настройки гиперпараметров рекоррупции при разных условиях изображения влияют на окончательные результаты (Дополнительная заметка
     <xref ref-type="supplementary-material" rid="MOESM1">
      2
     </xref>
     ). Мы обнаружили, что оптимальные гиперпараметры теоретически независимы от содержания изображения и уровня сигнала (Дополнительные рисунки
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      5
     </xref>
     ), что позволяет обеспечить прочное применение ZS-DeconvNet к различным биологическим образцам и конфигурациям изображения (Дополнительная заметка
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ). Далее мы сравнили производительность моделей ZS-DeconvNet, обученных с данными, дополненными рекоррупцией одного шумного изображения, с аналитическими алгоритмами деconvolution или моделями, обученными на числах симулированных или независимо полученных изображений. Для этого мы использовали режим освещения внутреннего отражения (TIRF) нашей самодельной многомодальной структурированной освещения микроскопии (Multi-SIM) для получения ~20 наборов дифракционных ограничений TIRF-изображений при низком и высоком SNR для каждой субклеточной структуры лизосом (Lyso) и микротрубочек (MTs), из которых низкокачественные изображения использовались для обучения и тестирования, а их высококачественные аналоги служили ссылкой (Методы). Мы обнаружили, что пиковое соотношение сигнал-шум (PSNR) и разрешение изображений ZS-DeconvNet были существенно лучше, чем те, которые были сгенерированы аналитическими алгоритмами, такими как классический Richardson-Lucy (RL) и последний разработанный скудный деconvolution (Fig.
     <xref ref-type="fig" rid="Fig1">
      1c–e
     </xref>
     ) и скорость пропускания хорошо обученной ZS-DeconvNet более чем в 100 раз выше, чем у алгоритма скудного деconvolution (Fig.
     <xref ref-type="fig" rid="Fig1">
      1f
     </xref>
     ). В частности, даже если ZS-DeconvNet был обучен с дополненными данными из одного входного изображения, перцептивное качество и количественные метрики его выходных изображений были сопоставимы с изображениями от модели, обученной на больших объемах данных (Дополнительный рисунок
     <xref ref-type="supplementary-material" rid="MOESM1">
      6
     </xref>
     ). Кроме того, мы проверили улучшение разрешения, количественность и способность обобщения ZS-DeconvNet (Дополнительные рисунки
     <xref ref-type="supplementary-material" rid="MOESM1">
      7
     </xref>
     –
     <xref ref-type="supplementary-material" rid="MOESM1">
      10
     </xref>
     ), и сравнили его с контролируемой моделью DFCAN (Дополнительный рисунок
     <xref ref-type="supplementary-material" rid="MOESM1">
      11
     </xref>
     ) на синтетических и экспериментальных данных. Эти характеристики демонстрируют, что ZS-DeconvNet может генерировать высококачественные изображения DLSR с улучшением разрешения более чем в 1,5 раза относительно дифракционного предела при использовании наименьшего количества обучающих данных, что имеет большой потенциал для улучшения производительности различных микроскопических систем и расширения их применимости на широкий спектр биопроцессов, которые являются сложными для традиционных методов
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec4">
    <title>
     Долгосрочное наблюдение биопроцессов, чувствительных к фототоксичности
    </title>
    <p id="Par9">
     Адгезия и миграция клеток являются важными в морфогенетических процессах и способствуют многим заболеваниям
     <sup>
      <xref ref-type="bibr" rid="CR31">
       31
      </xref>
     </sup>
     . Визуализация цитоскелетной динамики на высоком разрешении во время процесса адгезии/миграции имеет решающее значение для раскрытия лежащего в основе механизма. Однако из-за сильной фоточувствительности весь процесс адгезии и миграции клеток обычно записывается при низких частотах кадров, т.е. несколько секунд на кадр, и низких интенсивностях света
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR32">
       32
      </xref>
     </sup>
     . При таких условиях изображения либо деconvolution RL, либо временная непрерывность-основанное самообучение (Методы) не могут восстановить и заострить сложную структуру F-актин и миозина-II (Fig.
     <xref ref-type="fig" rid="Fig2">
      2a
     </xref>
     , Дополнительный рисунок
     <xref ref-type="supplementary-material" rid="MOESM1">
      12
     </xref>
     , и Дополнительное видео
     <xref ref-type="supplementary-material" rid="MOESM4">
      1
     </xref>
     ). Напротив, модель ZS-DeconvNet эффективно улучшает как SNR, так и разрешение двухцветных временных записей процессов распространения клеток после помещения клетки, коэкспрессирующей mEmerald-Lifeact и mCherry-myosin-IIA, на стеклянную пластину (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     и Дополнительное видео
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Интересно, что мы наблюдали, что в определенных веществах клетки ползали вокруг контактного участка, чтобы исследовать окрестность, прежде чем распространиться и адгезироваться (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     и Дополнительное видео
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). Ползание клетки предшествовало поляризованному накоплению миозина-II в задней части клетки, что привело к миграции клетки в противоположном направлении, обусловленной контрактильностью миозина-II в задней части клетки. Кроме того, направление миграции могло быть быстро изменено в ответ на динамическую перераспределение миозина-II внутри клетки (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Эти результаты демонстрируют, что кинетика адгезии и миграции клеток может быть точно записана с помощью изображений, полученных с помощью ZS-DeconvNet, без нарушения этого длительного и уязвимого процесса.
     <fig id="Fig2" position="float">
      <label>
       Fig. 2
      </label>
      <caption xml:lang="ru">
       <title>
        Долгосрочная SR-визуализация быстрых и фоточувствительных биопроцессов с помощью ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Представительные изображения SR, реконструированные методом ZS-DeconvNet, цитоскелета F-actin и миозина-II в клетке COS-7, ко-экспрессирующей mEmerald-lifeact и mCherry-myosin-IIA. Сравнения сырого шумного изображения TIRF и изображений, обработанных методами RL-деконволюции, DeepCAD-основанной деконволюции и ZS-DeconvNet, отображаются.
        <bold>
         b
        </bold>
        Двухцветные временные изображения SR, усиленные методом ZS-DeconvNet, показывающие координированную динамику F-actin (циан) и миозина-II (желтый) на протяжении всего процесса распространения после помещения клетки COS-7 на стекло (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM5">
         2
        </xref>
        ).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Двухцветные временные изображения SR, усиленные методом ZS-DeconvNet, цитоскелета F-actin и миозина-II в ползущей клетке COS-7, показывающие, что миозин-II предпочтительно концентрируется в задней части клетки (обозначено желтыми пунктирными линиями в
        <bold>
         d
        </bold>
        ), противоположно направлению ползания (указано белыми стрелками в
        <bold>
         d
        </bold>
        ) (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM6">
         3
        </xref>
        ).
        <bold>
         e
        </bold>
        Представительное изображение SR, сгенерированное методом ZS-DeconvNet, рекайлинговых эндосом (RE, зеленый) и поздних эндосом (LE, магента) в ген-редактированной клетке SUM-159, эндогенно экспрессирующей EGFP-Rab11 и mCherry-Lamp1 (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM7">
         4
        </xref>
        ).
        <bold>
         f
        </bold>
        Типичные траектории движения RE (вверху) и LE (внизу), показывающие быструю направленную подвижность RE и двунаправленную природу LE.
        <bold>
         g
        </bold>
        Сравнения скорости, смещения и времени перемещения между Lyso/LE и RE, а также количественная оценка времени проживания RE возле их экзоцитозных сайтов перед слиянием с плазматической мембраной (
        <italic>
         n
        </italic>
        = 505 треков для RE и
        <italic>
         n
        </italic>
        = 230 треков для LE). Небольшое количество данных точек, превышающих время транспортировки 150 с или смещение 60 мкм, не отображается для лучшего представления распределений. Центр линии, медианы; пределы, 75% и 25%. Статистическая значимость определялась с помощью непарного теста Манна-Уитни (p =
        <inline-formula id="IEq4">
         <alternatives>
          <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            1.38
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              7
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq4_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.38\times {10}^{-7}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq4.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        ,
        <inline-formula id="IEq5">
         <alternatives>
          <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            5.65
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              35
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq5_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$5.65\times {10}^{-35}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq5.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        , и
        <inline-formula id="IEq6">
         <alternatives>
          <math id="IEq6_Math" xmlns="http://www.w3.org/1998/Math/MathML">
           <mn>
            6.26
           </mn>
           <mo>
            ×
           </mo>
           <msup>
            <mrow>
             <mn>
              10
             </mn>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mn>
              40
             </mn>
            </mrow>
           </msup>
          </math>
          <tex-math id="IEq6_TeX">
           \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$6.26\times {10}^{-40}$$\end{document}
          </tex-math>
          <inline-graphic href="41467_2024_48575_Article_IEq6.gif" mime-subtype="GIF" specific-use="web"/>
         </alternatives>
        </inline-formula>
        для тестов скорости перемещения, времени транспортировки и смещения, соответственно). ****
        <italic>
         p
        </italic>
        &lt; 0,0001. Исходные данные предоставлены в виде файла Source Data.
        <bold>
         h
        </bold>
        Временные изображения показывают направленное движение RE в форме палочки и последующее слияние с плазматической мембраной.
        <bold>
         i
        </bold>
        Временные изображения показывают три LE, связанные друг с другом, и совместное перемещение на определенное расстояние перед разделением на отдельные LE. Шкала, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 2 μm (зум-регионы в
        <bold>
         a
        </bold>
        ), 8 μm (
        <bold>
         b
        </bold>
        ), 3 μm (
        <bold>
         e
        </bold>
        ), 0,5 μm (зум-регион в
        <bold>
         e
        </bold>
        ), 1 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         f
        </bold>
        ,
        <bold>
         i
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig2_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par10">
     процессы распространения клеток после помещения клетки, коэкспрессирующей mEmerald-Lifeact и mCherry-myosin-IIA, на стеклянную пластину (Fig.
     <xref ref-type="fig" rid="Fig2">
      2b
     </xref>
     и Дополнительное видео
     <xref ref-type="supplementary-material" rid="MOESM5">
      2
     </xref>
     ). Интересно, что мы наблюдали, что в определенных веществах клетки ползали вокруг контактного участка, чтобы исследовать окрестность, прежде чем распространиться и адгезироваться (Fig.
     <xref ref-type="fig" rid="Fig2">
      2c
     </xref>
     и Дополнительное видео
     <xref ref-type="supplementary-material" rid="MOESM6">
      3
     </xref>
     ). Ползание клетки предшествовало поляризованному накоплению миозина-II в задней части клетки, что привело к миграции клетки в противоположном направлении, обусловленной контрактильностью миозина-II в задней части клетки. Кроме того, направление миграции могло быть быстро изменено в ответ на динамическую перераспределение миозина-II внутри клетки (Fig.
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     ). Эти результаты демонстрируют, что кинетика адгезии и миграции клеток может быть точно записана с помощью изображений, полученных с помощью ZS-DeconvNet, без нарушения этого длительного и уязвимого процесса.
    </p>
   </sec>
   <sec id="Sec5">
    <title>
     Визуализация быстрой динамики эндолизосомной системы
    </title>
    <p id="Par11">
     Эндолизосомная система включает в себя различные типы везикул, которые функционируют в высоко динамичной, но хорошо организованной манере. Хотя живая клеточная флуоресцентная микроскопия значительно улучшила наше понимание эндолизосомной системы, большинство исследований должны были переэкспрессировать белки интереса, чтобы записать их быструю динамику, что часто приводило к артефактам морфологии или поведения. С помощью ZS-DeconvNet мы смогли визуализировать линию клеток SUM-159, эндогенно экспрессирующую EGFP-Rab11 и mCherry-Lamp1, за 1500 кадров при разрешении ~150 нм и 3 кадрах в секунду в двух цветах (Fig.
     <xref ref-type="fig" rid="Fig2">
      2e
     </xref>
     и Дополнительное видео
     <xref ref-type="supplementary-material" rid="MOESM7">
      4
     </xref>
     ), что позволило нам визуализировать и отслеживать быстрое движение рециркуляционных эндосом (RE) и лизосом или поздних эндосом (LE) на существенно более тонкой пространственно-временной шкале и более длительном окне наблюдения, чем было достигнуто ранее
     <sup>
      <xref ref-type="bibr" rid="CR30">
       30
      </xref>
      <xref ref-type="bibr" rid="CR34">
       34
      </xref>
     </sup>
     . Как показано на Fig.
     <xref ref-type="fig" rid="Fig2">
      2f–h
     </xref>
     , мы обнаружили, что большинство RE (n = 505 треков) испытывали направленное движение, с общим смещением 6,7 ± 5,4 мкм при высокой скорости 2,2 ± 1,2 мкм/с (мгновенная скорость превышает 5,3 мкм/с), с редким промежуточным паузой, затем остановились в определенных местах на период 13,5 ± 10,3 с до слияния с плазматической мембраной. Это наблюдение предполагает, что RE могут быть эффективно транспортированы на длинные расстояния до областей, расположенных вблизи плазматической мембраны, чтобы облегчить последующую экзоцитоз. Неожиданно, ZS-DeconvNet захватил несколько событий деления Rab11-позитивных RE, при которых оба разделенных RE прошли экзоцитоз последовательно (Дополнительный рисунок
     <xref ref-type="supplementary-material" rid="MOESM1">
      13a
     </xref>
     ) или один RE отошел (Дополнительный рисунок
     <xref ref-type="supplementary-material" rid="MOESM1">
      13b
     </xref>
     ). Это наблюдение указывает на то, что высокоспециализированные Rab11-позитивные RE могут быть предметом дальнейшего сортировки груза прямо перед экзоцитозом.
    </p>
    <p id="Par12">
     Напротив, движения LE были обычно прерывистыми и проходили в двунаправленном стоп-энд-го манере при относительно низкой скорости 1,6 ± 0,6 мкм/с (n = 230 треков) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2f, g, i
     </xref>
     ). Хотя транспорт LE казался неэффективным, LE часто сохранялись в течение длительного периода 91,8 с с общим смещением до 23,6 мкм (в среднем от n = 230 треков) (Fig.
     <xref ref-type="fig" rid="Fig2">
      2h
     </xref>
     ). Интересно, что мы заметили, что две или более LE иногда склонны связываться друг с другом в поцелуе-и-остаться манере и мигрировать на определенное расстояние, прежде чем разделиться на отдельные LE снова (Fig.
     <xref ref-type="fig" rid="Fig2">
      2i
     </xref>
     и Дополнительный рисунок
     <xref ref-type="supplementary-material" rid="MOESM1">
      13c
     </xref>
     ), что может облегчить направленное движение LE без достаточного количества моторных белков-адаптеров для длинного транспорта. Эти сложные динамики LE предполагают, что их позиционирование и подвижность деликатно регулируются несколькими факторами, такими как MT-основанные двигатели и мембраносвязанные контакты.
    </p>
   </sec>
   <sec id="Sec6">
    <title>
     3D ZS-DeconvNet для микроскопии с решетчатым световым листом
    </title>
    <p id="Par13">
     Объемная живая микроскопия передает больше биологической информации, чем 2D-наблюдения; однако, она подвержена более сильной фототоксичности, фотобелению и контаминации флуоресценции вне фокуса. Чтобы расширить превосходную способность ZS-DeconvNet до объемной SR-изображения, мы модернизировали основу двуступенчатой архитектуры сети в 3D RCAN, которая была доказана как подходящая для восстановления объемных изображений (Fig.
     <xref ref-type="fig" rid="Fig3">
      3a, b
     </xref>
     и Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      2b
     </xref>
     ). Далее, мы интегрировали наш предыдущий предложенный пространственно-переплетенный самообучаемый алгоритм обучения с физической моделью-информированным самообучаемым решателем обратной задачи для построения 3D ZS-DeconvNet. 3D ZS-DeconvNet с пространственно-переплетенным самообучаемым алгоритмом следует более простой процедуре увеличения данных (Methods), при этом достигая сравнимой или даже лучшей производительности, чем стратегия, основанная на рециркуляции (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      14
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR35">
       35
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
     <fig id="Fig3" position="float">
      <label>
       Fig. 3
      </label>
      <caption xml:lang="ru">
       <title>
        Характеристики и демонстрации 3D ZS-DeconvNet.
       </title>
       <p>
        <bold>
         a
        </bold>
        Архитектура сети 3D ZS-DeconvNet и схема ее обучения.
        <bold>
         b
        </bold>
        Схема фазы вывода 3D ZS-DeconvNet.
        <bold>
         c
        </bold>
        Представительные изображения максимальной интенсивности проекции (MIP) SR изображений F-actin, Mito внешней мембраны и ER, реконструированные методом разреженной деконволюции (второй столбец), 3D ZS-DeconvNet (третий столбец) и LLS-SIM (четвертый столбец). Среднее количество сCMOS-пикселей для 1% пикселей с наибольшей интенсивностью для исходных изображений перед обработкой указано в правом верхнем углу.
        <bold>
         d
        </bold>
        Статистические сравнения деконволюции RL, разреженной деконволюции и ZS-DeconvNet по показателям PSNR и разрешения для разных образцов (
        <italic>
         n
        </italic>
        = 40 областей интереса). Разрешение измерялось методом анализа корреляции кольца Фурье
        <sup>
         <xref ref-type="bibr" rid="CR74">
          74
         </xref>
        </sup>
        с помощью стэков изображений F-actin. Центральная линия, медианы; пределы, 75% и 25%; усики, максимальное и минимальное значение. Исходные данные предоставлены в виде файла Source Data.
        <bold>
         e
        </bold>
        Изображения трехцветной 3D-восстановки, реконструированные методом 3D ZS-DeconvNet для ER, H2B и Mito, показывающие их трансформации морфологии и распределения, а также динамику взаимодействия во время митоза (Supplementary Video
        <xref ref-type="supplementary-material" rid="MOESM8">
         5
        </xref>
        ).
        <bold>
         f
        </bold>
        Представительные трехцветные изображения, полученные методом конвенциональной LLSM (первый столбец), разреженной деконволюции (второй столбец), деконволюции на основе DeepCAD (третий столбец) (Методы), и 3D ZS-DeconvNet (четвертый столбец). Сравнения проводятся для двух типичных временных точек данных времени, показанных в (
        <bold>
         e
        </bold>
        ). Масштабная линейка, 5 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         e
        </bold>
        ,
        <bold>
         f
        </bold>
        ), 1,5 μm (области увеличения
        <bold>
         c
        </bold>
        ), 2 μm (области увеличения
        <bold>
         f
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig3_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par14">
     Мы систематически оценили модель 3D ZS-DeconvNet с наборами данных трех разных биологических образцов, полученных с помощью нашей домашней решеточной световой микроскопии с структурированным освещением (LLS-SIM), где дифракционно-ограниченные данные, полученные в режиме LLSM, использовались для обучения, а их аналоги SR, полученные в режиме LLS-SIM, служили ссылками (Methods). Мы обнаружили, что 3D ZS-DeconvNet успешно восстановил сложные филаменты F-актина, полую структуру внешней мембраны митохондрий (Mito) и сложные сети эндоплазматического ретикулума (ER) с высокой точностью и разрешением, сравнимым с изображениями LLS-SIM, полученными при высоких условиях SNR (Fig.
     <xref ref-type="fig" rid="Fig3">
      3c
     </xref>
     ). Квантификация PSNR и разрешения показывает, что модель 3D ZS-DeconvNet существенно превосходит традиционные аналитические подходы, основанные на модели, в различных биологических образцах (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ). Мы демонстрируем, что, обучаясь на самих шумных стеках изображений, двуступенчатый 3D ZS-DeconvNet не только генерирует результаты денойзинга, сравнимые с современными самообучаемыми методами денойзинга (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      15
     </xref>
     ), но также обеспечивает сверхразрешенные стеки изображений с значительным улучшением разрешения более чем в 1,5 раза как в латеральной (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      16
     </xref>
     ), так и в аксиальной (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17
     </xref>
     ) плоскостях. Кроме того, включая самообучаемые методы повышения разрешения в аксиальной плоскости, аксиальное разрешение можно улучшить еще больше (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      17g–i
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
      <xref ref-type="bibr" rid="CR37">
       37
      </xref>
      ,
      <xref ref-type="bibr" rid="CR38">
       38
      </xref>
      <xref ref-type="bibr" rid="CR39">
       39
      </xref>
      ,
      <xref ref-type="bibr" rid="CR40">
       40
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec7">
    <title>
     Долгосрочная объемная супер-разрешающая микроскопия, обеспеченная 3D ZS-DeconvNet
    </title>
    <p id="Par15">
     Объемное наблюдение деления клеток с высокой пространственно-временной разрешающей способностью имеет решающее значение для изучения механизмов, связанных с митозом, таких как механизм, который распределяет многочисленные различные органеллы в цитоплазме каждой дочерней клетки
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
      ,
      <xref ref-type="bibr" rid="CR42">
       42
      </xref>
     </sup>
     . Из-за экстремальной светочувствительности и уязвимости митотических клеток, предыдущее объемное SR-изображение этого процесса опиралось на систему LLS-SIM с низким освещением и сверхразрешающую реконструкцию на основе обучения
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     . Однако сбор высококачественных данных обучения чрезвычайно трудоемок и иногда невозможен, поскольку морфология и распределение органелл обычно претерпевают значительные изменения во время митоза
     <sup>
      <xref ref-type="bibr" rid="CR41">
       41
      </xref>
     </sup>
     . Здесь мы демонстрируем, что самообучаемая модель 3D ZS-DeconvNet может быть общим образом применена для сверхразрешения тонких субклеточных структур ER, Mito и хромосом из шумных объемных данных LLSM без необходимости дополнительных данных обучения, что позволяет осуществлять быстрое и долгосрочное объемное SR-наблюдение за несколькими органеллами за 1000 временных точек с интервалом 10 секунд в митотической клетке HeLa (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e
     </xref>
     и Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM8">
      5
     </xref>
     ). Кроме того, самообучаемое свойство ZS-DeconvNet позволяет нам интегрировать стратегию адаптации во время тестирования для полного использования структурного содержания в каждом шумном объеме, что дало лучшую 3D SR-производительность (Methods). Напротив, традиционный алгоритм деконволюции, основанный на приоритетах, и метод самообучаемого обучения с временным интерлеявом не смогли восстановить высокочастотные детали образцов из-за низких условий SNR и слабой временной согласованности между соседними временными точками (Fig.
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     и Methods). Кроме того, согласно низкой инвазивности, обеспечиваемой 3D ZS-DeconvNet, группа митотических клеток HeLa, помеченных H2B-mCherry и HeLa-mEmerald-SC35, была изображена в большой области зрения (FOV) 100×50×25 мкм за более чем 300 временных точек, что позволило записать весь процесс разборки и повторной сборки ядерных speckles с высокой пространственно-временной разрешающей способностью (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     и Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM9">
      6
     </xref>
     ). Вкратце, 3D ZS-DeconvNet позволяет биологам легко исследовать различные светочувствительные биопроцессы с низкой инвазивностью при существенно более высокой пространственно-временной разрешающей способности без необходимости дополнительных наборов данных или модификаций оптической установки
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      ,
      <xref ref-type="bibr" rid="CR44">
       44
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     ZS-DeconvNet для конфокальной и широкопольной микроскопии
    </title>
    <p id="Par16">
     ZS-DeconvNet опирается на случайность шумов и характеристику низкочастотного фильтра оптических микроскопов, которые являются общими для различных типов микроскопии. На этой основе мы ожидаем, что ZS-DeconvNet может быть общим образом применен ко всем микроскопиям, например, наиболее часто используемой конфокальной микроскопии и микроскопии с широким полем (WF). Чтобы изучить производительность 3D ZS-DeconvNet на конфокальных данных, мы использовали наш домашний конфокальный микроскоп для получения четырехцветного объема ранней мышиной эмбриона, иммунопомеченного для микротрубочек, хромосом, актинов и апикальной области (Methods), которые играют ключевую роль в первом решении судьбы клеток и являются критическими для развития эмбриона
     <sup>
      <xref ref-type="bibr" rid="CR45">
       45
      </xref>
      ,
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
      ,
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
     </sup>
     . Затем мы обучили модели 3D ZS-DeconvNet на этом единственном шумном объеме и обработали исходные данные обученными моделями. Как показано на Figs.
     <xref ref-type="fig" rid="Fig4">
      4a, b
     </xref>
     , 3D ZS-DeconvNet существенно улучшает SNR, контраст и разрешение конфокального объема данных и разрешает тонкие структуры мостов микротрубочек и актиновых колец (Fig.
     <xref ref-type="fig" rid="Fig4">
      4c, d
     </xref>
     , Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      19
     </xref>
     и Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM10">
      7
     </xref>
     ). Эти результаты указывают на то, что ZS-DeconvNet обеспечивает более высокое пространственное разрешение при более низком бюджете фотонов для конфокальной микроскопии при изображении образцов в крупном масштабе, например, ранних мышиных эмбрионов, что имеет решающее значение для исследований по полярности клеток, внутриклеточному транспорту и формированию бластоцисты
     <sup>
      <xref ref-type="bibr" rid="CR47">
       47
      </xref>
      <xref ref-type="bibr" rid="CR46">
       46
      </xref>
     </sup>
     .
     <fig id="Fig4" position="float">
      <label>
       Fig. 4
      </label>
      <caption xml:lang="ru">
       <title>
        Обобщение ZS-DeconvNet для нескольких модальностей изображений.
       </title>
       <p>
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        Представительные конфокальные (вверху слева), разреженные деконволюционные (внизу слева) и усиленные 3D ZS-DeconvNet (справа) изображения раннего эмбриона мыши, иммунноокрашенного для микротрубочек (циан), хромосом (оранжевый), актиновых колец (магента) и апикальной области (зеленый).
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        Увеличенные области мостов микротрубочек (c) и актиновых колец (d), помеченные белыми пунктирными линиями в (
        <bold>
         a
        </bold>
        ) и (
        <bold>
         b
        </bold>
        ), полученные методами конфокальной микроскопии, разреженной деконволюции и 3D ZS-DeconvNet.
        <bold>
         e
        </bold>
        Представительные изображения WF (центральная область) и усиленные 3D ZS-DeconvNet (окружающая область) изображения эмбриона
        <italic>
         C. elegans
        </italic>
        с апикальной соединением, клеточной мембраной (циан) и лизосомами (красный), помеченными.
        <bold>
         f
        </bold>
        ,
        <bold>
         g
        </bold>
        Канал лизосом центральной области в (
        <bold>
         e
        </bold>
        ) закодирован по расстоянию от субстрата. Для сравнения показаны изображения WF (
        <bold>
         f
        </bold>
        ) и обработанные 3D ZS-DeconvNet (
        <bold>
         g
        </bold>
        ).
        <bold>
         h
        </bold>
        Изображения времени 3D ZS-DeconvNet, усиленные и показывающие процесс слияния гиподермальных клеток (красные стрелки) во время развития эмбриона
        <italic>
         C. elegans
        </italic>
        . Масштабная линейка, 5 μm (
        <bold>
         a
        </bold>
        ,
        <bold>
         b
        </bold>
        ,
        <bold>
         e
        </bold>
        ), 2 μm (
        <bold>
         c
        </bold>
        ,
        <bold>
         d
        </bold>
        ), 3 μm (
        <bold>
         g
        </bold>
        ,
        <bold>
         h
        </bold>
        ), 1 μm (область увеличения
        <bold>
         g
        </bold>
        ). Коэффициент гаммы, 0,7 для цитоплазмы и лизосом в эмбрионе
        <italic>
         C. elegans
        </italic>
        .
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig4_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par17">
     Далее мы изображали эмбрионы Caenorhabditis elegans с апикальными соединениями, клеточными мембранами и лизосомами, помеченными с помощью 3D-режима WF нашей системы Multi-SIM (Methods). Чтобы обеспечить, что развитие эмбриона C. elegans не было нарушено, мы получили сырые стеки изображений при относительно низком освещении с интервалами 30 секунд за более чем 200 временных точек. Однако в таких условиях изображения WF сильно загрязнены фоном и шумом вне фокуса (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, f
     </xref>
     ). Даже в этой сложной ситуации изображения 3D ZS-DeconvNet показали значительное подавление шума и фона, а также улучшение пространственного разрешения субклеточных деталей (Fig.
     <xref ref-type="fig" rid="Fig4">
      4e, g
     </xref>
     и Supplementary Video
     <xref ref-type="supplementary-material" rid="MOESM11">
      8
     </xref>
     ), что позволяет нам исследовать сложный процесс эмбрионального развития, например, слияние гиподермальных клеток (Fig.
     <xref ref-type="fig" rid="Fig4">
      4h
     </xref>
     ), даже с помощью простой микроскопии WF
     <sup>
      <xref ref-type="bibr" rid="CR48">
       48
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     ZS-деноизинг и повышение разрешения в многомодальных SIM-изображениях
    </title>
    <p id="Par18">
     Среди различных форм микроскопии с сверхразрешением (SR) структурированная освещение микроскопия (SIM) часто признается сбалансированным вариантом для живых клеток SR-изображений, поскольку для этого требуется менее десяти сырых модулированных изображений для обеспечения двукратного улучшения пространственного разрешения
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
     </sup>
     . Однако традиционная SIM имеет два критических ограничения: во-первых, дальнейшее улучшение разрешения требует значительно больше сырых данных, т.е. как минимум 25 сырых изображений необходимы для нелинейной SIM для получения разрешения менее 80 нм; во-вторых, постреконструкция SIM-изображений обычно требует сырых изображений с высоким соотношением сигнал/шум (SNR), чтобы исключить шумоиндуцированные реконструированные артефакты, что препятствует быстрому, низкосветному и долгосрочному живому клеточному изображению
     <sup>
      <xref ref-type="bibr" rid="CR49">
       49
      </xref>
      ,
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     . Недавние исследования изучали подходы к обучению с учителем, либо шумоподавляя SIM-изображения, либо реконструируя SR SIM-изображения непосредственно из шумных сырых изображений для достижения низкосветной SIM-реконструкции; однако, эти методы требуют обильных обучающих данных и не обеспечивают дальнейшего улучшения разрешения. Учитывая исключительную способность ZS-DeconvNet к шумоподавлению и SR, мы объединили схему обучения с нулевым выстрелом с традиционным алгоритмом SIM-реконструкции и теоретически доказали, что ZS-DeconvNet подходит для обработки SR-SIM-изображений (Дополнительная заметка
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     ). Мы разработали модель ZS-DeconvNet-SIM для одновременного шумоподавления и улучшения SR SIM-изображений в бесnadzorном режиме (Fig.
     <xref ref-type="fig" rid="Fig5">
      5a
     </xref>
     , Дополнительная фигура
     <xref ref-type="supplementary-material" rid="MOESM1">
      20a
     </xref>
     , и Методы). Благодаря замечательному улучшению SNR и разрешения, обеспечиваемому ZS-DeconvNet-SIM (Дополнительные фигуры
     <xref ref-type="supplementary-material" rid="MOESM1">
      21
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ), полая структура клатрин-оболочечных ямок (CCP) в клетке SUM-159 и плотно переплетенные цитоскелеты в клетке COS-7, которые не различимы в WF- и традиционных SIM-изображениях, были четко разрешены (Fig.
     <xref ref-type="fig" rid="Fig5">
      5b, c
     </xref>
     ). Кроме того, мы продемонстрировали, что ZS-DeconvNet-SIM может быть применен в режиме 3D-SIM для одновременного шумоподавления и улучшения 3D-SIM-изображений в обоих поперечных и осевых осях (Методы, Дополнительная фигура
     <xref ref-type="supplementary-material" rid="MOESM1">
      23
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
      ,
      <xref ref-type="bibr" rid="CR52">
       52
      </xref>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      ,
      <xref ref-type="bibr" rid="CR22">
       22
      </xref>
     </sup>
     .
     <fig id="Fig5" position="float">
      <label>
       Fig. 5
      </label>
      <caption xml:lang="ru">
       <title>
        Нулевая деноизация и повышение разрешения в многомодальных данных SIM.
       </title>
       <p>
        <bold>
         a
        </bold>
        Схема обучения ZS-DeconvNet для SIM.
        <bold>
         b
        </bold>
        Последовательность повышения SNR и разрешения через CCP в клетке SUM-159, от сырых изображений SIM (слева), конвенционального изображения SIM (справа) и усиленного изображения SIM методом ZS-DeconvNet (среднее).
        <bold>
         c
        </bold>
        Последовательность повышения SNR и разрешения через микротрубочки в клетке COS-7, от сырых изображений SIM (слева), конвенционального изображения SIM (справа) и усиленного изображения SIM методом ZS-DeconvNet (среднее).
        <bold>
         d
        </bold>
        Представительные изображения максимальной интенсивности проекции (MIP) F-actin в клетке HeLa, полученные методами LLSM, LLS-SIM и LLS-SIM, усиленные 3D ZS-DeconvNet, в трех измерениях.
        <bold>
         e
        </bold>
        , Представительные изображения MIP внешней мембраны митохондрий, помеченных TOMM20, в клетке 293 T, полученные методами LLSM, LLS-SIM и LLS-SIM, усиленные 3D ZS-DeconvNet, в трех измерениях. Масштабная линейка, 1 μm (
        <bold>
         a
        </bold>
        ), 2 μm (
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 0,5 μm (области увеличения в
        <bold>
         b
        </bold>
        ,
        <bold>
         c
        </bold>
        ), 3 μm (
        <bold>
         d
        </bold>
        ,
        <bold>
         e
        </bold>
        ).
       </p>
      </caption>
      <graphic href="/ProjectMundo/MediaObjects/10X1038_s41467-024-48575-9/41467_2024_48575_Fig5_HTML.png" mime-subtype="PNG" specific-use="web"/>
     </fig>
    </p>
    <p id="Par19">
     Кроме того, мы объединили 3D ZS-DeconvNet с LLS-SIM для разработки модальности 3D ZS-DeconvNet-SIM (Дополнительная фигура
     <xref ref-type="supplementary-material" rid="MOESM1">
      20b
     </xref>
     ). Включая анизотропную функцию распространения точки (PSF) традиционной LLS-SIM в процесс обучения, 3D ZS-DeconvNet LLS-SIM не только заметно улучшил контраст и разрешение во всех трех измерениях, но и обеспечил приблизительно изотропное поперечное разрешение ~150 нм (Fig.
     <xref ref-type="fig" rid="Fig5">
      5d, e
     </xref>
     , и Дополнительная фигура
     <xref ref-type="supplementary-material" rid="MOESM1">
      22
     </xref>
     ). Эти успешные применения ZS-DeconvNet к многомодальным SIM-системам демонстрируют его способность дальнейшего расширения спatio-темпорального разрешения существующих методов SR
     <sup>
      <xref ref-type="bibr" rid="CR36">
       36
      </xref>
     </sup>
     .
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
   <title>
    Обсуждение
   </title>
   <p id="Par20">
    Конечной целью живого изображения является сбор максимально возможной информации о биопроцессах с минимальным вмешательством в биологические образцы. Однако, взаимные ограничения между скоростью изображения, продолжительностью, разрешением и SNR в флуоресцентной микроскопии вместе приводят к ограничению спatio-темпорального разрешения, которое ограничивает синергическое улучшение всех этих аспектов. Например, для получения более высокого пространственного разрешения традиционные методы SR должны полагаться на повторные приобретения или дополнительное возбуждение, что усугубляет фототоксичность и фотобельность, препятствуя быстрому, долгосрочному наблюдению биопроцессов. Чтобы устранить ограничения спatio-темпорального разрешения в микроскопии, мы провели глубокий анализ распространения шума в оптической модели изображения и SIM-реконструкции (Дополнительная заметка
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    ), доказали сходимость функции потерь, интегрированной с рекоррупцией, в обычных и SIM-сценариях на основе линейности свертки PSF, и предложили универсальную структуру ZS-DeconvNet, которая может быть включена в различные оптические флуоресцентные микроскопы для мгновенного улучшения SNR и разрешения изображения без ухудшения других свойств изображения. Мы подчеркиваем, что применение ZS-DeconvNet является устойчивым к гиперпараметрам в процессе рекоррупции изображения (Дополнительная фигура
    <xref ref-type="supplementary-material" rid="MOESM1">
     24
    </xref>
    ) и что ZS-DeconvNet может быть хорошо обучен только одним срезом или стеком сырых изображений (Дополнительные фигуры
    <xref ref-type="supplementary-material" rid="MOESM1">
     6
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     16
    </xref>
    ) без использования предположений о структурной разреженности и временной непрерывности
    <sup>
     <xref ref-type="bibr" rid="CR53">
      53
     </xref>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     ,
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
     ,
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    . Качественные и количественные оценки на симулированных и экспериментальных данных показывают, что наш метод существенно улучшает качество и разрешение изображения более чем в 1,5 раза с высокой точностью и количественностью даже при низкосветных условиях, что позволяет проводить быстрые, долгосрочные, сверхразрешающие наблюдения множества субклеточных динамик.
   </p>
   <p id="Par21">
    Предложенный метод ZS-DeconvNet имеет широкую функциональность для различных типов модальностей изображения, от сканирующей микроскопии, например, конфокальной микроскопии и двухфотонной микроскопии (Дополнительная фигура
    <xref ref-type="supplementary-material" rid="MOESM1">
     25
    </xref>
    ), до микроскопии с широкопольным обнаружением, например, TIRF, 3D WF-микроскопии, LLSM и многомодальной SIM. Мы демонстрируем его возможности более чем на 10 различных фиксированных или живых образцах, полученных с помощью шести разных микроскопических установок, включая плановое и объемное изображение множества органелл в отдельных клетках, наблюдение субклеточных динамик и взаимодействий во время митоза, и многокolorное 3D-изображение ранних мышиных эмбрионов и эмбрионов
    <italic>
     C. elegans
    </italic>
    . Чтобы сделать наш метод более доступным и удобным в использовании, мы включили ZS-DeconvNet и 3D ZS-DeconvNet в пользовательский плагин Fiji (Дополнительные фигуры
    <xref ref-type="supplementary-material" rid="MOESM1">
     26
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     27
    </xref>
    , Дополнительные заметки
    <xref ref-type="supplementary-material" rid="MOESM1">
     3
    </xref>
    ,
    <xref ref-type="supplementary-material" rid="MOESM1">
     4
    </xref>
    , и Дополнительное видео
    <xref ref-type="supplementary-material" rid="MOESM12">
     9
    </xref>
    ), что позволяет пользователям, даже без опыта глубокого обучения, легко обучать свои собственные модели ZS-DeconvNet и улучшать микроскопические изображения, открытые в Fiji, всего за несколько кликов мыши. Функциональность и удобство ZS-DeconvNet демонстрируют его большой потенциал в улучшении производительности существующих оптических микроскопов.
   </p>
   <p id="Par22">
    Несмотря на свою общую устойчивость и применимость, пользователи ZS-DeconvNet должны тщательно учитывать потенциальное появление галлюцинаций и его ограничения. Во-первых, ZS-DeconvNet может ошибочно принять чрезвычайно низкие флуоресцентные сигналы за фоновый шум, тем самым ослабляя их на выходных изображениях (Дополнительная фигура
    <xref ref-type="supplementary-material" rid="MOESM1">
     28a
    </xref>
    ). Этот тип ошибок может быть обнаружен до некоторой степени с помощью инструментов контроля качества изображения, таких как SQUIRREL
    <sup>
     <xref ref-type="bibr" rid="CR54">
      54
     </xref>
    </sup>
    . Во-вторых, если хорошо обученная модель ZS-DeconvNet применяется к обработке изображений, существенно отличающихся от обучающих данных, например, полученных с помощью другой модальности изображения, может быть заметное ухудшение производительности и более высокий риск генерации галлюцинаций (Дополнительная фигура
    <xref ref-type="supplementary-material" rid="MOESM1">
     28b
    </xref>
    ). В-третьих, модели ZS-DeconvNet должны быть обучены с использованием совпадающих PSF с данными, в противном случае неправильное обучение с несоответствующими PSF может привести к незаметному улучшению разрешения или появлению артефактов кольцевого типа (Дополнительная фигура
    <xref ref-type="supplementary-material" rid="MOESM1">
     28c
    </xref>
    ). Наконец, мы не ожидаем, что бесnadzorный ZS-DeconvNet сгенерирует изображения SR такого же качества, как модели DLSR, обученные с высококачественными данными (Дополнительная фигура
    <xref ref-type="supplementary-material" rid="MOESM1">
     11
    </xref>
    ). Однако в экспериментах по изображению, когда такие данные недоступны, ZS-DeconvNet будет мощным и удобным инструментом для разрешения биологических деталей как можно более точно.
   </p>
   <p id="Par23"/>
  </sec>
  <sec id="Sec11" sec-type="methods">
   <title>
    Методы
   </title>
   <sec id="Sec12">
    <title>
     Система Multi-SIM
    </title>
    <p id="Par24"/>
   </sec>
   <sec id="Sec13">
    <title>
     Система LLS-SIM
    </title>
    <p id="Par25"/>
   </sec>
   <sec id="Sec14">
    <title>
     Система конфокальной микроскопии
    </title>
    <p id="Par26"/>
   </sec>
   <sec id="Sec15">
    <title>
     Архитектуры и целевые функции ZS-DeconvNet
    </title>
    <p id="Par27"/>
    <p id="Par28"/>
    <p id="Par29">
     Примечательно, что поскольку теоретическая основа ZS-DeconvNet является модельно-агностической, cả U-Net и RCAN не являются единственными применимыми базовыми моделями, но широко принятыми и эффективными. Оснащение ZS-DeconvNet другими современными архитектурами нейронных сетей, например, DFCAN и RLN, может дальнейшим образом улучшить его способность денойзинга и SR
     <sup>
      <xref ref-type="bibr" rid="CR8">
       8
      </xref>
      <xref ref-type="bibr" rid="CR12">
       12
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec16">
    <title>
     Реализация 2D ZS-DeconvNet
    </title>
    <p id="Par30">
     Пары изображений
     <inline-formula id="IEq21">
      <alternatives>
       <math id="IEq21_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mrow>
            <mo>
             ̂
            </mo>
           </mrow>
          </mover>
          <mo>
           ,
          </mo>
          <mover accent="true">
           <mrow>
            <mi mathvariant="bold">
             y
            </mi>
           </mrow>
           <mo>
            ̃
           </mo>
          </mover>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq21_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{{{{{{\bf{y}}}}}}},\widetilde{{{{{{\bf{y}}}}}}})$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq21.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     используемые для обучения 2D-моделей ZS-DeconvNet, были сгенерированы в соответствии с модифицированной схемой из оригинальной схемы рекоррупции к рекоррупции под предположением смешанных пуассоновско-гауссовских распределений шума, где три гиперпараметра
     <inline-formula id="IEq22">
      <alternatives>
       <math id="IEq22_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq22_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq22.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq23">
      <alternatives>
       <math id="IEq23_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq23_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq23.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     ,
     <inline-formula id="IEq24">
      <alternatives>
       <math id="IEq24_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq24_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq24.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     необходимо было предварительно охарактеризовать. Процедура рекоррупции из одного шумного изображения
     <italic>
      y
     </italic>
     может быть представлена в матричной форме как:
     <disp-formula id="Equ9">
      <label>
       9
      </label>
      <alternatives>
       <math id="Equ9_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̂
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         +
        </mo>
        <mi>
         D
        </mi>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ9_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}+D{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ9.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ10">
      <label>
       10
      </label>
      <alternatives>
       <math id="Equ10_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mover accent="true">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
         </mrow>
         <mo>
          ̃
         </mo>
        </mover>
        <mo>
         =
        </mo>
        <mi mathvariant="bold">
         y
        </mi>
        <mo>
         −
        </mo>
        <msup>
         <mrow>
          <mi>
           D
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           1
          </mi>
         </mrow>
        </msup>
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="Equ10_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{{{{{\bf{y}}}}}}}={{{{{\bf{y}}}}}}-{D}^{-{{{{{\bf{1}}}}}}}{{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ10.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     где
     <inline-formula id="IEq25">
      <alternatives>
       <math id="IEq25_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         D
        </mi>
        <mo>
         =
        </mo>
        <mi>
         α
        </mi>
        <mi>
         I
        </mi>
       </math>
       <tex-math id="IEq25_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\alpha I$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq25.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — обратимая матрица, определенная как масштабированная единичная матрица с коэффициентом
     <inline-formula id="IEq26">
      <alternatives>
       <math id="IEq26_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         α
        </mi>
       </math>
       <tex-math id="IEq26_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq26.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , который контролирует общую величину добавленного шума, а
     <inline-formula id="IEq27">
      <alternatives>
       <math id="IEq27_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
       </math>
       <tex-math id="IEq27_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq27.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — случайная карта шума, отобранная из гауссовского распределения с нулевым средним:
     <disp-formula id="Equ11">
      <label>
       11
      </label>
      <alternatives>
       <math id="Equ11_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         g
        </mi>
        <mo>
         ~
        </mo>
        <mi class="MJX-tex-caligraphic" mathvariant="script">
         N
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mn>
           0
          </mn>
          <mo>
           ,
          </mo>
          <msup>
           <mrow>
            <mi>
             σ
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mi>
           I
          </mi>
         </mrow>
        </mfenced>
       </math>
       <tex-math id="Equ11_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{g}}}}}} \sim {{{{{\mathcal{N}}}}}}\left(0,{\sigma }^{2}I\right)$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ11.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     <disp-formula id="Equ12">
      <label>
       12
      </label>
      <alternatives>
       <math id="Equ12_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msup>
         <mrow>
          <mi>
           σ
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msup>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
        <mi>
         H
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="bold">
           b
          </mi>
         </mrow>
        </mfenced>
        <mo>
         +
        </mo>
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="Equ12_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }^{2}={\beta }_{1}H\left({{{{{\bf{y}}}}}}-{{{{{\bf{b}}}}}}\right)+{\beta }_{2}$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ12.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     где
     <inline-formula id="IEq28">
      <alternatives>
       <math id="IEq28_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq28_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq28.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — пуассоновский фактор, влияющий на дисперсию сигнал-зависимого шума, а
     <inline-formula id="IEq29">
      <alternatives>
       <math id="IEq29_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq29_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq29.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — гауссовский фактор, представляющий дисперсию аддитивного гауссовского шума.
     <inline-formula id="IEq30">
      <alternatives>
       <math id="IEq30_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="bold">
         b
        </mi>
       </math>
       <tex-math id="IEq30_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\bf{b}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq30.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — фон, примерно regarded как фиксированное значение, связанное с камерой, вычитая которое мы извлекли флуоресцентные сигналы из образца.
     <inline-formula id="IEq31">
      <alternatives>
       <math id="IEq31_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>
         H
        </mi>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mo>
           ⋅
          </mo>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
       </math>
       <tex-math id="IEq31_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H(\cdot )$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq31.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     — линейный фильтр низкой частоты, используемый для предварительного сглаживания изображения и уменьшения шума, и мы использовали фильтр среднего значения с размером 5 пикселей в наших экспериментах
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     .
    </p>
    <p id="Par31">
     Как доказано в Дополнительной заметке
     <xref ref-type="supplementary-material" rid="MOESM1">
      1
     </xref>
     , теоретически оптимальное значение
     <inline-formula id="IEq32">
      <alternatives>
       <math id="IEq32_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           1
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq32_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq32.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     и
     <inline-formula id="IEq33">
      <alternatives>
       <math id="IEq33_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mi mathvariant="normal">
         α
        </mi>
       </math>
       <tex-math id="IEq33_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{\alpha }}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq33.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     равен 1, а
     <inline-formula id="IEq34">
      <alternatives>
       <math id="IEq34_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           β
          </mi>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq34_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq34.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     зависит от камеры и может быть оценен из области образца без образца или предварительно калиброван по стандартным протоколам
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
     </sup>
     . Оценки на симулированных данных показали, что лучшая денойзинг и SR-производительность достигаются при теоретически оптимальных значениях этих гиперпараметров, независимо от структуры и SNR тестируемых изображений (Дополнительные Фиг.
     <xref ref-type="supplementary-material" rid="MOESM1">
      3
     </xref>
     ,
     <xref ref-type="supplementary-material" rid="MOESM1">
      4
     </xref>
     ).
    </p>
   </sec>
   <sec id="Sec17">
    <title>
     Реализация 3D ZS-DeconvNet
    </title>
    <p id="Par32">
     Схема обучения 3D ZS-DeconvNet объединяет пространственно-переплетенную самоконтролируемую схему обучения с самоконтролируемым решением обратной задачи. В процессе обучения каждый шумный стек изображений был разделен на нечетные и четные срезы, которые затем использовались в качестве входных и целевых данных, соответственно, после увеличения путем случайного вращения, обрезки и переворота. Чтобы исправить разрыв в ожиданиях между нечетными и четными срезами, мы ввели член регуляризации разрыва (GAR) в оба уравнения потерь денойзинга и деконволюции, который был рассчитан с помощью денойзированного стека (помеченного красным квадратом на Фиг.
     <xref ref-type="fig" rid="Fig3">
      3а
     </xref>
     ), шумных четных срезов и выходов сети (подробно в Дополнительной заметке
     <xref ref-type="supplementary-material" rid="MOESM1">
      1б
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR9">
       9
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec18">
    <title>
     Реализация 2D/3D ZS-DeconvNet-SIM
    </title>
    <p id="Par33">
     Для реализаций ZS-DeconvNet-SIM на 2D-SIM и 3D-SIM каждый набор сырых SIM-изображений сначала был увеличен до двух наборов рекоррумпированных сырых изображений через уравнения 9 и 10, и затем реконструирован в пару SR SIM-изображений с помощью традиционного алгоритма SIM-реконструкции. Полученные пары SIM-изображений затем использовались для самоконтролируемого обучения аналогичным образом обучению моделей ZS-DeconvNet. Для 3D ZS-DeconvNet-SIM, примененного к LLS-SIM (Фиг.
     <xref ref-type="fig" rid="Fig5">
      5д, е
     </xref>
     ), пост-реконструированные объемные SIM-данные вместо сырых изображений были аксиально отобраны в два SIM-стека, содержащих нечетные и четные срезы, которые использовались в последующих процедурах обучения 3D-моделей ZS-DeconvNet с функциями потерь, описанными в уравнениях 6-8. Схематический рабочий процесс ZS-DeconvNet-SIM показан на Фиг.
     <xref ref-type="fig" rid="Fig5">
      5а
     </xref>
     и Дополнительной Фиг.
     <xref ref-type="supplementary-material" rid="MOESM1">
      20
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec19">
    <title>
     Использование и генерация PSF
    </title>
    <p id="Par34">
     В процессе обучения ZS-DeconvNet мы использовали экспериментально полученные или симулированные ПСФ (с помощью плагина PSF Generator Fiji, лицензированного EPFL), соответствующие конфигурациям изображений. Независимые модели ZS-DeconvNet были обучены для каждой биологической структуры и длины волны излучения для最佳ной производительности.
    </p>
   </sec>
   <sec id="Sec20">
    <title>
     Обучение модели и адаптация во время тестирования
    </title>
    <p id="Par35">
     В этой работе модели ZS-DeconvNet были обучены на ПК с процессором Intel Core i7-11700 и графической картой RTX 3090 (NVIDIA) в среде программного обеспечения TensorFlow 2.5.0 и python 3.9.7. Перед обучением пары входных/эталонных изображений были первоначально aumentadas в несколько пар patch через случайное обрезание, горизонтальное/вертикальное отражение и поворот для дальнейшего обогащения обучающего набора данных, в результате чего было сгенерировано ~20 000 пар 2D-патчей (128×128 пикселей) или ~10 000 пар 3D-патчей (64×64×13 вокселей). Обучение обычно проводилось с помощью оптимизатора Adam и начальной скорости обучения
     <inline-formula id="IEq38">
      <alternatives>
       <math id="IEq38_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <mn>
         0.5
        </mn>
        <mo>
         ×
        </mo>
        <msup>
         <mrow>
          <mn>
           10
          </mn>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           4
          </mn>
         </mrow>
        </msup>
       </math>
       <tex-math id="IEq38_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times {10}^{-4}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq38.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     , которая уменьшалась в 0,5 раза каждые 10 000 итераций. Размер пакета обучения был 4 для 2D-изображений и 3 для 3D-стеков. Всего процесс обучения обычно требовал 50 000 итераций для 2D-изображений и 10 000 итераций для 3D-стеков. Время, затраченное на обучение 50 000 итераций для 2D-моделей и 10 000 итераций для 3D-моделей, составляло ~1 час и ~2 часа соответственно. Как и в случае с большинством методов, основанных на глубоком обучении, обучение ZS-DeconvNet является одноразовой процедурой в большинстве случаев живой клеточной микроскопии, где пользователи обучают модель ZS-DeconvNet со всеми кадрами, а затем хорошо обученные модели применимы ко всем данным одного и того же биологического образца на высокой скорости обработки. Чтобы исключить артефакты краев, вызванные деконволюцией, мы обычно добавляли 2 пустых среза в верхнюю и нижнюю часть 3D-стеков и отступ в 8 пикселей для каждого среза xy в обоих процессах обучения и вывода (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      30a
     </xref>
     ). Особенно, когда обрабатывались временные данные деления клетки (Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     ), несупервизионное свойство ZS-DeconvNet позволяло использовать стратегию адаптации во время тестирования, при которой мы сначала обучали общую модель для каждой биологической структуры с данными всего процесса, а затем подстраивали предварительно обученную модель для каждого временного момента с небольшим количеством шагов обучения (обычно 50 итераций, занимающих ~1 минуту), чтобы полностью использовать структуру информации сырых данных и получить оптимальную производительность SR. Обратите внимание, что адаптация во время тестирования не является необходимой, но необязательной техникой для улучшения производительности ZS-DeconvNet, особенно в обстоятельствах, когда есть значительные морфологические изменения биологических образцов во время окна наблюдения, например, хромосом во время деления (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      31
     </xref>
     )
     <sup>
      <xref ref-type="bibr" rid="CR43">
       43
      </xref>
     </sup>
     .
    </p>
   </sec>
   <sec id="Sec21">
    <title>
     Постобработка данных и оценка супер-разрешающих изображений
    </title>
    <p id="Par36">
     Для методов изображения, использующих широкопольную детекцию, таких как LLSM, шум фиксированного паттерна (FPN), вызванный неоднородностью чувствительности пикселей камеры, не может быть удален методами, основанными на шуме. В нашем варианте реализации ZS-DeconvNet FPN усиливался на стадии деконволюции и становился заметным, особенно при условиях изображения с очень низким соотношением сигнала и шума. Для сCMOS-датчиков, которые являются наиболее распространенными в флуоресцентной микроскопии, фиксированный паттерн обычно представляет собой регулярный вид горизонтальных или вертикальных полос, обусловленных усилителем столбца. Для этого мы просто применили маску аподизации в области Фурье, чтобы подавить полосатые артефакты, сохраняя при этом другие частотные компоненты образцов (Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      30b
     </xref>
     ). Обратите внимание, что шум фиксированного паттерна также может быть фундаментально удален путем калибровки полученных сырых изображений перед их вводом в модель сети, следующей хорошо установленным процедурам
     <sup>
      <xref ref-type="bibr" rid="CR61">
       61
      </xref>
      ,
      <xref ref-type="bibr" rid="CR63">
       63
      </xref>
      ,
      <xref ref-type="bibr" rid="CR64">
       64
      </xref>
     </sup>
     .
    </p>
    <p id="Par37">
     Другие вычислительные подходы к SR, сравниваемые в этой работе, а именно разреженная деконволюция, деконволюция на основе DeepCAD и SRRF, реализованы в соответствии с инструкциями в оригинальных статьях. В частности, мы попытались выбрать оптимальные гиперпараметры для разреженной деконволюции, чтобы получить реконструированное изображение с наименьшим количеством артефактов и самой высокой разрешающей способностью. Деконволюция на основе DeepCAD (Fig.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a и
     <xref ref-type="fig" rid="Fig3">
      3f
     </xref>
     ) была проведена путем интеграции временной выборки в нашу структуру ZS-DeconvNet, то есть использованием изображений, временно отобранных из данных временной лапсации, для обучения наших двусторонних моделей сети, обеспечивая при этом одинаковый размер модели и вычислительные затраты для справедливого сравнения
     <sup>
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
      <xref ref-type="bibr" rid="CR33">
       33
      </xref>
      <xref ref-type="bibr" rid="CR13">
       13
      </xref>
     </sup>
     .
    </p>
    <p id="Par38"/>
    <p id="Par39">
     Линейное преобразование применяется ко всем методам для справедливого сравнения; (3) Расчет PSNR между нормализованным изображением GT
     <bold>
      x
     </bold>
     и линейно преобразованным изображением
     <inline-formula id="IEq39">
      <alternatives>
       <math id="IEq39_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="bold">
           I
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           trans
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq39_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\bf{I}}}}}}}_{{{{{{\rm{trans}}}}}}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq39.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     <sup/>
     .
    </p>
    <p id="Par40">
     Для оценки PSNR 3D ZS-DeconvNet (Fig.
     <xref ref-type="fig" rid="Fig3">
      3d
     </xref>
     ) мы напрямую использовали изображения LLS-SIM в качестве эталона, поскольку и LLS-SIM, и наш 3D ZS-DeconvNet обеспечивают теоретическое улучшение разрешения в ~1,5 раза. Общий процесс расчета аналогичен двумерным случаям, за исключением того, что стэки SR не были свёрнуты, и PSNR рассчитывался только в областях с особенностями с порогом 0,02, чтобы избежать получения аномально высокого значения PSNR.
    </p>
    <p id="Par41">
     Чтобы обеспечить лучший контраст и визуализацию, мы выполнили нормализацию процентиля для изображений, полученных методами RL-деconvolution, сPARSE-деconvolution и ZS-DeconvNet, которая формулируется как:
     <disp-formula id="Equ15">
      <label>
       15
      </label>
      <alternatives>
       <math id="Equ15_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi mathvariant="normal">
           Norm
          </mi>
         </mrow>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             l
            </mi>
            <mi>
             o
            </mi>
            <mi>
             w
            </mi>
           </mrow>
          </msub>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             p
            </mi>
           </mrow>
           <mrow>
            <mi>
             h
            </mi>
            <mi>
             i
            </mi>
            <mi>
             g
            </mi>
            <mi>
             h
            </mi>
           </mrow>
          </msub>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi mathvariant="bold">
           Y
          </mi>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               h
              </mi>
              <mi>
               i
              </mi>
              <mi>
               g
              </mi>
              <mi>
               h
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
          <mo>
           −
          </mo>
          <mi mathvariant="normal">
           percentile
          </mi>
          <mfenced close=")" open="(">
           <mrow>
            <mi mathvariant="bold">
             Y
            </mi>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               p
              </mi>
             </mrow>
             <mrow>
              <mi>
               l
              </mi>
              <mi>
               o
              </mi>
              <mi>
               w
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
        <mo>
         ,
        </mo>
       </math>
       <tex-math id="Equ15_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{Norm}}}}}}}_{p}\left({{{{{\bf{Y}}}}}},{p}_{{low}},{p}_{{high}}\right)=\frac{{{{{{\bf{Y}}}}}}-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)}{{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{high}}\right)-{{{{{\rm{percentile}}}}}}\left({{{{{\bf{Y}}}}}},{p}_{{low}}\right)},$$\end{document}
       </tex-math>
       <graphic href="41467_2024_48575_Article_Equ15.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </disp-formula>
     где percentile(
     <bold>
      Y,
     </bold>
     <italic>
      p
     </italic>
     ) выводит значение интенсивности, занимающее
     <italic>
      p
     </italic>
     % в изображении
     <bold>
      Y
     </bold>
     <sup/>
     .
     <inline-formula id="IEq40">
      <alternatives>
       <math id="IEq40_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           l
          </mi>
          <mi>
           o
          </mi>
          <mi>
           w
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq40_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{low}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq40.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     и
     <inline-formula id="IEq41">
      <alternatives>
       <math id="IEq41_Math" xmlns="http://www.w3.org/1998/Math/MathML">
        <msub>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <mrow>
          <mi>
           h
          </mi>
          <mi>
           i
          </mi>
          <mi>
           g
          </mi>
          <mi>
           h
          </mi>
         </mrow>
        </msub>
       </math>
       <tex-math id="IEq41_TeX">
        \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{{high}}$$\end{document}
       </tex-math>
       <inline-graphic href="41467_2024_48575_Article_IEq41.gif" mime-subtype="GIF" specific-use="web"/>
      </alternatives>
     </inline-formula>
     обычно устанавливаются равными 3 и 100 в наших фигурах и видео.
    </p>
   </sec>
   <sec id="Sec22">
    <title>
     Культура клеток, трансфекция и окрашивание
    </title>
    <p id="Par42">
     Клетки Cos7, HeLa, 293T, а также их стабильные линии культивировались в среде DMEM (Gibco, cat. no. 11965092), дополненной 10% фетальной бычьей сывороткой (Gibco, cat. no. 10099141 C) и 1× пенициллин-стрептомицин (Thermo Fisher, 15140122) при 37°C в инкубаторе Thermo Scientific Heracell 150i CO
     <sub>
      2
     </sub>
     . Клетки SUM159 культивировались в среде DMEM/F12K, дополненной 5% фетальной бычьей сывороткой (FBS) и 1% пенициллин-стрептомицином.
    </p>
    <p id="Par43">
     Для живой клеточной микроскопии 35-мм покровные стекла были предварительно покрыты 50 мкг/мл коллагена, и 1×10 клеток были посажены на покровные стекла. Для транзитной трансфекции клетки были трансфицированы плазмидами с помощью Lipofectamine 3000 (Invitrogen, cat. no. L3000150) в соответствии с протоколом производителя 12 часов после посадки. Клетки были проимажены в течение 12 часов после трансфекции. Если указано, клетки, трансфицированные плазмидами Halo Tag, были помечены 10 нМ лигандом JF549 в течение 15 минут в соответствии с опубликованным протоколом
     <sup>
      <xref ref-type="bibr" rid="CR65">
       65
      </xref>
     </sup>
     . Клетки были промыты свежей средой, чтобы удалить непрореагировавший лиганд, и проимажены сразу после этого. Плазмиды, использованные для транзитной трансфекции, включали Lifeact-mEmerald, Clathrin-mEmerald, 3×mEmerald-Ensconsin, Lamp1-Halo, 2×mEmerald-Tomm20, Myosin2-Halo, KDEL-mCherry и Halo-Calnexin.
    </p>
    <p id="Par44">
     Для упаковки лентивируса 1 мкг лентивирусного вектора ДНК, вместе с 0,5 мкг psPAX2 упаковочного и 0,5 мкг pMD2.G оболочечного плазмидного ДНК, были ко-трансфецированы в клетки HEK293T с конфлюенцией 90% в 6 см чашке Петри с использованием Lipofectamine 3000 в соответствии с протоколом производителя. После 2 дней супернатант был собран и отфильтрован с помощью 0,22-мкм фильтра (Millipore). Для получения стабильных клеток клетки HeLa и Cos7 были инфицированы лентивирусами, кодирующими маркер эндоплазматического ретикулума Calnexin-mEmerald и маркер F-актина Lifeact-mEmerald
     <sup>
      <xref ref-type="bibr" rid="CR66">
       66
      </xref>
     </sup>
     . Через 48 часов после этого клетки были обогащены с помощью проточной цитометрии (FACSAria III, BD Biosciences) и затем посажены по одной клетке в каждую из 96-луночных пластин. Моноклональные клетки использовались в наших экспериментах. В частности, Lifeact-mEmerald для COS7 использовался в Figs.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     и
     <xref ref-type="fig" rid="Fig5">
      5
     </xref>
     ; Calnexin-mEmerald, Mito-dsRed и Halo-H2B для клеток HeLa использовались в Fig.
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     ; H2B-mCherry для HeLa-mEmerald-SC35 использовался в Supplementary Fig.
     <xref ref-type="supplementary-material" rid="MOESM1">
      18
     </xref>
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec23">
    <title>
     Геном-редактированные клеточные линии
    </title>
    <p id="Par45">
     Клетки SUM159 были отредактированы геномно последовательно для включения EGFP в N-терминал Rab11A, а затем Halo в C-терминал Lamp1 с использованием подхода CRISPR/Cas9
     <sup>
      <xref ref-type="bibr" rid="CR67">
       67
      </xref>
      ,
      <xref ref-type="bibr" rid="CR68">
       68
      </xref>
     </sup>
     . Последовательности целевой РНК (sgRNA) являются 5'-TCGCTCCTCGGCCGCGCAAT-3' для RAB11A и 5'-CTATCTAGCCTGGTGCACGC-3' для LAMP1. Клетки SUM159 были трансфецированы плазмидой донора EGFP-Rab11A, плазмидой, кодирующей spCas9, и свободным продуктом ПЦР, содержащим последовательность целевой РНК, с использованием Lipofectamin 3000 (Invitrogen) в соответствии с инструкциями производителя. Клетки, выражающие EGFP, были обогащены с помощью проточной цитометрии (FACS) (FACSAria II, BD Biosciences) и затем подвергались одиночной сортировке клеток в 96-луночные пластины. Моноклональные клетки с успешным включением EGFP были выявлены с помощью ПЦР-скрининга с использованием полимеразы GoTaq (Promega). Клональные клетки SUM159, выражающие EGFP-Rab11A +/+ , были подвергнуты второму раунду геномной редакции для включения Lamp1-Halo в геном, как описано выше. Трансфецированные клетки были окрашены 10 нМ лигандами Janelia Fluor 646 HaloTag (Promega) в течение 15 минут. Для удаления непрореагировавшего красителя образцы были промыты свежим средством, а затем обогащены с помощью FACS. Моноклональные клетки SUM159, выражающие как EGFP-Rab11A +/+ , так и Lamp1-Halo +/+ , были подтверждены с помощью ПЦР и анализа Western blot.
    </p>
    <p id="Par46">
     Клетки SUM159 были отредактированы геномно для включения EGFP в C-терминал легкой цепи клатрина А (клатрин-EGFP) с использованием подхода TALEN
     <sup>
      <xref ref-type="bibr" rid="CR69">
       69
      </xref>
     </sup>
     . Клетки, выражающие клатрин-EGFP, были обогащены двумя последовательными bulk-сортировками.
    </p>
    <p id="Par47">
     Линии клеток HeLa были отредактированы геномно для включения mEmerald в C-терминал человеческого геномного SC35 с использованием системы редактирования генов CRISPR-Cas9. Последовательность целевой РНК (sgRNA) является 5'-CGAGCAGCACTCCTAATGAT-3', и sgRNA была вставлена в pX330A-1×2 (Addgene, 58766). Полученная плазмида была названа pX330-SC35-gRNA. Для конструкции донорного вектора p-SC35-doner mEmerald, фланкированный примерно 1800 п.о. гомологичными руками, комплементарными к стоп-кодону человеческого геномного локуса SC35, были вставлены в pEASY-blunt (Transgene, CB101). 2 × 10 клеток HeLa, выращенных в 6 см чашке Петри, были трансфецированы 1,2 мкг pX330-SC35-gRNA и 0,4 мкг p-SC35-doner. Через 48 часов после трансфекции клетки, положительные для mEmerald, были отсортированы с помощью проточной цитометрии (FACSAria III, BD Biosciences). После одной недели лентивирус H2B-mCherry был инфицирован отсортированными клетками, а затем одиночные клетки были посажены в 96-луночные пластины. После двух недель геномная ДНК разных клонов одиночных клеток была экстрагирована и подтверждена с помощью ПЦР и анализа Western blot. Гомозиготные клетки SC35 knock-in были выбраны для исследования. Успешный SC35 knock-in был подтвержден с помощью ПЦР и анализа Western blot
     <sup/>
     .
    </p>
   </sec>
   <sec id="Sec24">
    <title>
     <italic>
      C. elegans
     </italic>
     подготовка эмбриона
    </title>
    <p id="Par48">
     <italic>
      C. elegans
     </italic>
     были выращены при 20 °C на агаровых пластинах с средой NGM, засеянной OP50, в соответствии со стандартными протоколами
     <sup>
      <xref ref-type="bibr" rid="CR70">
       70
      </xref>
     </sup>
     . TV52712
     <italic>
      [wyEx51119[dlg-1p::GFP::PLCdPH]
     </italic>
     ;
     <italic>
      jcIs1[ajm-1::GFP
     </italic>
     +
     <italic>
      UNC-29(+)+rol-6(su1006)]
     </italic>
     ;
     <italic>
      qxIs257 [ced-1p::nuc-1::mCherry + unc-76(+)]]
     </italic>
     использовался в этом исследовании. Плазмида
     <italic>
      dlg-1p::GFP::PLCdPH
     </italic>
     была сконструирована с использованием системы клонирования ПЦР Clontech In-Fusion и микроинъецирована в
     <italic>
      jcIs1;qxIs257
     </italic>
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
     </sup>
     . Экстрахромосомная массив
     <italic>
      wyEx51119
     </italic>
     маркировал эпидермальную клеточную мембрану.
     <italic>
      jcIs1
     </italic>
     маркировал апикальную джанкшн-домен
     <italic>
      C. elegans
     </italic>
     .
     <italic>
      qxIs257
     </italic>
     маркировал лизосомы в эпидермальных клетках
     <sup>
      <xref ref-type="bibr" rid="CR71">
       71
      </xref>
      <xref ref-type="bibr" rid="CR72">
       72
      </xref>
     </sup>
     .
    </p>
    <p id="Par49">
     Примерно 50 личинок трансгенных червей были помещены на пластины NGM с свежим OP50 за 48-60 часов до начала экспериментов. Трансгенные яйца были собраны под флуоресцентным микроскопом (Olympus MVX10) и помещены на 3% агарозные подушки. Эмбрионы на стадии от лимы до 2-кратного деления затем были проанализированы с помощью режима 3D WF нашей системы Multi-SIM.
    </p>
   </sec>
   <sec id="Sec25">
    <title>
     Подготовка мышиного эмбриона
    </title>
    <p id="Par50">
     Мыши, использованные в этом исследовании, были породы C57BL/6J. Все эксперименты на животных были одобрены Комитетом по уходу и использованию животных (IACUC) Института биофизики, Китайской академии наук, Пекин, Китай. Эмбрионы до имплантации были выделены из 5-6-недельных самок, суперовирулированных путем внутрибрюшной инъекции 5 международных единиц (МЕ) серума беременных кобыл гонадотропина (PMSG; LEE BIOSOLUTIONS) и 5 МЕ хорионического гонадотропина человека (hCG; Millipore) через 48 часов, и спаренных с самцами. Зиготы были восстановлены на стадии E0,5 в среде M2 (Millipore) и культивировались в среде KSOM (Millipore) в инкубаторе CO2 (Thermo Scientific) при 37°C с 5% CO2 до поздней стадии 8-клетки.
    </p>
    <p id="Par51">
     Для иммунофлуоресценции эмбрионы были фиксированы 4% параформальдегидом в PBS в течение 30 минут при комнатной температуре (RT) и промыты PBS три раза. Эмбрионы затем были пермеабилизированы 0,5% TritonX-100 (Sigma) в PBS в течение 20 минут при RT, промыты PBS три раза, блокированы 1% бычьим сывороточным альбумином в PBS в течение 1 часа при RT и инкубированы с анти-pERM антителом (Abcam, ab76247), анти-альфа-тубулином-FITC (Sigma, F2168-.2 ML) и Фаллоидин-Родамином (Molecular Probes, R415) в течение ночи при 4°C. Затем эмбрионы были промыты PBS три раза, инкубированы со вторичными антителами (Life technologies) в течение 1 часа при RT, окрашены Хоэштем 33342 (Thermo) в течение 15 минут при RT, промыты PBS три раза и проанализированы с помощью домашнего конфокального микроскопа.
    </p>
   </sec>
   <sec id="Sec26">
    <title>
     Визуализация 3D-изображений
    </title>
    <p id="Par52">
     Аксиально цветокодированные изображения лизосом, показанные на Fig.
     <xref ref-type="fig" rid="Fig4">
      4f, g
     </xref>
     , были сгенерированы с помощью Fiji. 3D рендеринговые изображения митоза клетки и мышиных эмбрионов, показанные на Fig.
     <xref ref-type="fig" rid="Fig3">
      3e, f
     </xref>
     , были визуализированы и сгенерированы с помощью коммерческого программного обеспечения Amira.
    </p>
   </sec>
   <sec id="Sec27">
    <title>
     Статистика и воспроизводимость
    </title>
    <p id="Par53">
     Эксперименты на Fig.
     <xref ref-type="fig" rid="Fig2">
      2
     </xref>
     a–i,
     <xref ref-type="fig" rid="Fig3">
      3
     </xref>
     f,
     <xref ref-type="fig" rid="Fig4">
      4a–h
     </xref>
     , и
     <xref ref-type="fig" rid="Fig5">
      5b–e
     </xref>
     были независимо повторены не менее чем с 3 образцами, т.е. клетками или эмбрионами, все из которых давали аналогичные результаты.
    </p>
   </sec>
   <sec id="Sec28">
    <title>
     Сводка отчета
    </title>
    <p id="Par54">
     Дополнительная информация о дизайне исследования доступна в
     <xref ref-type="supplementary-material" rid="MOESM13">
      Nature Portfolio Reporting Summary
     </xref>
     , связанном с этой статьей.
    </p>
   </sec>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Благодарности
   </title>
   <p>
    Авторы благодарят Т. Кирххаузена за донорские плазмиды, использованные для геномного редактирования, и за помощь в создании геномно-редактированных клеточных линий, и благодарят проф. Сяочэна Вана и доктора Канмина Хэ за
    <italic>
     C. elegans
    </italic>
    штаммы и геномно-редактированные клеточные линии SUM159. Эта работа была поддержана грантами Национального природного научного фонда Китая (32125024, 32271513, 62071271 и 62088102); Министерства науки и технологий (2021YFA1300303 и 2020AA0105500); Китайской академии наук (ZDBS-LY-SM004 и XDA16021401); Фонда сотрудничества исследований Китайского института исследований мозга, Пекина (2021-NKX-XM-03); Китайского фонда научных исследований докторов (2022M721842, 2023T160365); Нового углового научного фонда; Программы ученых Шуиму Цинхуа (2022SM035); Пекинского природного научного фонда (JQ21012).
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Вклад авторов
   </title>
   <p>
    Q.D. и Дон Ли руководили исследованием. Q.D., Дон Ли и C.Q. задали и инициировали этот проект. C.Q. разработал подробные реализации под руководством Q.D. и Дон Ли. Y.Z, C.Q. и X.C разработали код на Python, выполнили симуляции и обработали соответствующие данные изображений. H.C., C.Q. и Y.Z. разработали плагин Fiji. T.J., R.W, C.Q, H.L., W.F., Ди Ли и J.G. подготовили образцы и выполнили эксперименты по изображению. C.Q., Y.Z., X.C. и Q.M. проанализировали данные с концептуальными советами от Q.D., Дон Ли, J.W, Y.W. и H.Q. C.Q., Y.Z и Q.M. составили фигуры и видео, создали домашнюю страницу учебника под руководством Q.D. и Дон Ли. Q.D., Дон Ли и C.Q. написали рукопись, с вкладом всех авторов. Все авторы обсудили результаты и прокомментировали рукопись.
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Проверка
   </title>
   <sec id="FPar1">
    <title>
     Информация о проверке
    </title>
    <p id="Par55">
     <italic>
      Nature Communications
     </italic>
     thanks Varun Mannam and Lothar Schermelleh for their contribution to the peer review of this work. A peer review file is available.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Доступность данных
   </title>
   <p>
    The SIM data of CCPs and MTs used for evaluating ZS-DeconvNet is from the publicly accessible dataset BioSR (
    <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.13264793">
     https://doi.org/10.6084/m9.figshare.13264793
    </ext-link>
    ). Other data that are generated and presented in Figs.
    <xref ref-type="fig" rid="Fig1">
     1
    </xref>
    –
    <xref ref-type="fig" rid="Fig5">
     5
    </xref>
    , Supplementary Figs.
    <xref ref-type="supplementary-material" rid="MOESM1">
     1
    </xref>
    -
    <xref ref-type="supplementary-material" rid="MOESM1">
     34
    </xref>
    , and Supplementary Videos 1–9 in this study are available upon requests.
    <xref ref-type="sec" rid="Sec30">
     Source data
    </xref>
    are provided with this paper.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Доступность кода
   </title>
   <p>
    The python codes of ZS-DeconvNet, the Fiji plugin, several representative pre-trained models, as well as some example data for training and testing are already publicly accessible on the tutorial homepage (
    <ext-link ext-link-type="uri" xlink:href="https://tristazeng.github.io/ZS-DeconvNet-page/">
     https://tristazeng.github.io/ZS-DeconvNet-page/
    </ext-link>
    ) of ZS-DeconvNet and Github repository
    <sup>
     <xref ref-type="bibr" rid="CR73">
      73
     </xref>
    </sup>
    (
    <ext-link ext-link-type="uri" xlink:href="https://github.com/TristaZeng/ZS-DeconvNet">
     https://github.com/TristaZeng/ZS-DeconvNet
    </ext-link>
    ).
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Конфликт интересов
    </title>
    <p id="Par56">
     Dong Li, C.Q. and Y.Z. filed a patent as inventors through Institute of Biophysics, Chinese Academy of Sciences, to the Chinese Patent Office (Pub. No. CN116721017A &amp; App. No. 202310735660.3), which contains the basic application of the presented ZS-DeconvNet framework. The remaining authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    Ссылки
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schermelleh
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Super-resolution microscopy demystified
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2019
      </year>
      <volume>
       21
      </volume>
      <fpage>
       72
      </fpage>
      <lpage>
       84
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXmvVOhsL4%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30602772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41556-018-0251-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Shroff
        </surname>
        <given-names>
         H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Faster, sharper, and deeper: structured illumination microscopy for biological imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1011
      </fpage>
      <lpage>
       1019
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurbL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478322
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0211-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Belthangady
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Royer
        </surname>
        <given-names>
         LA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1215
      </fpage>
      <lpage>
       1225
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXhtleis7nM
      </pub-id>
      <pub-id pub-id-type="pmid">
       31285623
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-019-0458-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sage
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       DeconvolutionLab2: An open-source software for deconvolution microscopy
      </article-title>
      <source>
       Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       115
      </volume>
      <fpage>
       28
      </fpage>
      <lpage>
       41
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXntlOitw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       28057586
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.ymeth.2016.12.015
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       40
      </volume>
      <fpage>
       606
      </fpage>
      <lpage>
       617
      </lpage>
      <pub-id pub-id-type="pmid">
       34782739
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-021-01092-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rapid image deconvolution and multiview fusion for optical microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       38
      </volume>
      <fpage>
       1337
      </fpage>
      <lpage>
       1346
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXht1yjtbnM
      </pub-id>
      <pub-id pub-id-type="pmid">
       32601431
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7642198
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-020-0560-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wang
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables cross-modality super-resolution in fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       103
      </fpage>
      <lpage>
       110
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXisFCitLvM
      </pub-id>
      <pub-id pub-id-type="pmid">
       30559434
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0239-0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Evaluation and development of deep neural networks for image super-resolution in optical microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       194
      </fpage>
      <lpage>
       202
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhvFeitL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33479522
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-020-01048-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2023
      </year>
      <volume>
       41
      </volume>
      <fpage>
       367
      </fpage>
      <lpage>
       377
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFynsrjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       36203012
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41587-022-01471-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yanny
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Monakhova
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Shuai
        </surname>
        <given-names>
         RW
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning for fast spatially varying deconvolution
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       96
      </fpage>
      <lpage>
       99
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Optic...9...96Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.442438
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhao
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Isotropic super-resolution light-sheet microscopy of dynamic intracellular structures at subsecond timescales
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2022
      </year>
      <volume>
       19
      </volume>
      <fpage>
       359
      </fpage>
      <lpage>
       369
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XntVWltLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       35277709
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-022-01395-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="other">
      Li, Y. et al. Incorporating the image formation process into deep learning improves network performance.
      <italic>
       Nat. Methods
      </italic>
      <bold>
       19
      </bold>
      , 1427–1437 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2016
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2016NatCo...712471G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XhtlaksbbM
      </pub-id>
      <pub-id pub-id-type="pmid">
       27514992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4990649
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncomms12471
      </pub-id>
      <elocation-id>
       12471
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High-fidelity 3D live-cell nanoscopy through data-driven enhanced super-resolution radial fluctuation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1949
      </fpage>
      <lpage>
       1956
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957430
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703683
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02057-w
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Richardson
        </surname>
        <given-names>
         WH
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Bayesian-based iterative method of image restoration
      </article-title>
      <source>
       JoSA
      </source>
      <year>
       1972
      </year>
      <volume>
       62
      </volume>
      <fpage>
       55
      </fpage>
      <lpage>
       59
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1972JOSA...62...55R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/JOSA.62.000055
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lucy
        </surname>
        <given-names>
         LB
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       An iterative technique for the rectification of observed distributions
      </article-title>
      <source>
       Astronomical J.
      </source>
      <year>
       1974
      </year>
      <volume>
       79
      </volume>
      <fpage>
       745
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1974AJ.....79..745L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1086/111605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Laine
        </surname>
        <given-names>
         RF
        </given-names>
       </name>
       <name>
        <surname>
         Arganda-Carreras
        </surname>
        <given-names>
         I
        </given-names>
       </name>
       <name>
        <surname>
         Henriques
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Jacquemet
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Avoiding a replication crisis in deep-learning-based bioimage analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1136
      </fpage>
      <lpage>
       1144
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFOltLfF
      </pub-id>
      <pub-id pub-id-type="pmid">
       34608322
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7611896
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01284-3
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="other">
      Shocher, A., Cohen, N. &amp; Irani, M. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 3118-3126 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3297P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLjI
      </pub-id>
      <pub-id pub-id-type="pmid">
       35676288
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9178036
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30949-6
      </pub-id>
      <elocation-id>
       3297
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Qiao
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3D structured illumination microscopy via channel attention generative adversarial network
      </article-title>
      <source>
       IEEE J. Sel. Top. Quantum Electron.
      </source>
      <year>
       2021
      </year>
      <volume>
       27
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1109/JSTQE.2021.3060762
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Fang
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning-based point-scanning super-resolution imaging
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       406
      </fpage>
      <lpage>
       416
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmtVSrtrg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33686300
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8035334
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01080-z
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jin
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep learning enables structured illumination microscopy with low light levels and enhanced speed
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatCo..11.1934J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXnvVCis7Y%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32321916
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7176720
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-020-15784-x
      </pub-id>
      <elocation-id>
       1934
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ouyang
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Aristov
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Lelek
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Hao
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         C
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep learning massively accelerates super-resolution localization microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       460
      </fpage>
      <lpage>
       468
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXns1Whs70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29658943
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4106
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Schindelin
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fiji: an open-source platform for biological-image analysis
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2012
      </year>
      <volume>
       9
      </volume>
      <fpage>
       676
      </fpage>
      <lpage>
       682
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38XhtVKnurbJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       22743772
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2019
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Self-supervised deep-learning two-photon microscopy
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2023
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.469231
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="other">
      Pang, T., Zheng, H., Quan, Y. &amp; Ji, H. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2043-2052 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lefkimmiatis
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Bourquard
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Unser
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Hessian-based norm regularization for image restoration with biomedical applications
      </article-title>
      <source>
       IEEE Trans. Image Process.
      </source>
      <year>
       2011
      </year>
      <volume>
       21
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       995
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2012ITIP...21..983L
      </pub-id>
      <pub-id assigning-authority="American Mathematical Society" pub-id-type="other">
       2951273
      </pub-id>
      <pub-id pub-id-type="pmid">
       21937351
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/TIP.2011.2168232
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Huang
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast, long-term, super-resolution imaging with Hessian structured illumination microscopy
      </article-title>
      <source>
       Nat. Biotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       36
      </volume>
      <fpage>
       451
      </fpage>
      <lpage>
       459
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXntlCkurY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29644998
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nbt.4115
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical image computing and computer-assisted intervention 234-241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Visualizing intracellular organelle and cytoskeletal interactions at nanoscale resolution on millisecond timescales
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       175
      </volume>
      <fpage>
       1430
      </fpage>
      <lpage>
       1442 e1417
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVWju7jL
      </pub-id>
      <pub-id pub-id-type="pmid">
       30454650
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.09.057
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Parsons
        </surname>
        <given-names>
         JT
        </given-names>
       </name>
       <name>
        <surname>
         Horwitz
        </surname>
        <given-names>
         AR
        </given-names>
       </name>
       <name>
        <surname>
         Schwartz
        </surname>
        <given-names>
         MA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Cell adhesion: integrating cytoskeletal dynamics and cellular tension
      </article-title>
      <source>
       Nat. Rev. Mol. cell Biol.
      </source>
      <year>
       2010
      </year>
      <volume>
       11
      </volume>
      <fpage>
       633
      </fpage>
      <lpage>
       643
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtVGgtLfL
      </pub-id>
      <pub-id pub-id-type="pmid">
       20729930
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2992881
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nrm2957
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Burnette
        </surname>
        <given-names>
         DT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A role for actin arcs in the leading-edge advance of migrating cells
      </article-title>
      <source>
       Nat. Cell Biol.
      </source>
      <year>
       2011
      </year>
      <volume>
       13
      </volume>
      <fpage>
       371
      </fpage>
      <lpage>
       382
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3MXktFWjsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       21423177
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3646481
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb2205
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 282–292 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Guo
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Single-shot super-resolution total internal reflection fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       425
      </fpage>
      <lpage>
       428
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXhtFOmtLzF
      </pub-id>
      <pub-id pub-id-type="pmid">
       29735999
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7470603
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0004-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       678
      </fpage>
      <lpage>
       687
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021shsl.book.....C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXht1Sks77O
      </pub-id>
      <pub-id pub-id-type="pmid">
       34059829
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01155-x
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lattice light-sheet microscopy: imaging molecules to embryos at high spatiotemporal resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2014
      </year>
      <volume>
       346
      </volume>
      <fpage>
       1257998
      </fpage>
      <pub-id pub-id-type="pmid">
       25342811
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4336192
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1257998
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Spatial redundancy transformer for self-supervised fluorescence image denoising
      </article-title>
      <source>
       Nat. Comput. Sci.
      </source>
      <year>
       2023
      </year>
      <volume>
       3
      </volume>
      <fpage>
       1067
      </fpage>
      <lpage>
       1080
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023usnb.book.....L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXis1emu7%2FE
      </pub-id>
      <pub-id pub-id-type="pmid">
       38177722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10766531
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s43588-023-00568-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhang
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Bio-friendly long-term subcellular dynamic recording by self-supervised image enhancement microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2023
      </year>
      <volume>
       20
      </volume>
      <fpage>
       1957
      </fpage>
      <lpage>
       1970
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXitlGhurvI
      </pub-id>
      <pub-id pub-id-type="pmid">
       37957429
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10703694
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-023-02058-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ning
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       204
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..204N
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhslygsr%2FO
      </pub-id>
      <pub-id pub-id-type="pmid">
       37640721
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10462670
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01230-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="other">
      Li, X. et al. Three-dimensional structured illumination microscopy with enhanced axial resolution.
      <italic>
       Nat. Biotechnol.
      </italic>
      <bold>
       41
      </bold>
      , 1307–1319 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Carlton
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
       <name>
        <surname>
         Jones
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Eggert
        </surname>
        <given-names>
         US
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Membrane and organelle dynamics during cell division
      </article-title>
      <source>
       Nat. Rev. Mol. Cell Biol.
      </source>
      <year>
       2020
      </year>
      <volume>
       21
      </volume>
      <fpage>
       151
      </fpage>
      <lpage>
       166
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXislCntLw%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       32034394
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41580-019-0208-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Moore
        </surname>
        <given-names>
         AS
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Actin cables and comet tails organize mitochondrial networks in mitosis
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       664
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXls1Ojsbc%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       33658713
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7990722
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-021-03309-5
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Zhang, L. &amp; Gao, X. Transfer adaptation learning: A decade survey.
      <italic>
       IEEE Trans. Neural Netw. Learn. Syst.
      </italic>
      <bold>
       35
      </bold>
      , 23–44 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lecoq
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Removing independent noise in systems neuroscience data using DeepInterpolation
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2021
      </year>
      <volume>
       18
      </volume>
      <fpage>
       1401
      </fpage>
      <lpage>
       1408
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXit1Gns7%2FN
      </pub-id>
      <pub-id pub-id-type="pmid">
       34650233
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8833814
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-021-01285-2
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A microtubule-organizing center directing intracellular transport in the early mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2017
      </year>
      <volume>
       357
      </volume>
      <fpage>
       925
      </fpage>
      <lpage>
       928
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Sci...357..925Z
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhtl2kur3F
      </pub-id>
      <pub-id pub-id-type="pmid">
       28860385
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aam9335
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zenker
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Expanding actin rings zipper the mouse embryo for blastocyst formation
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2018
      </year>
      <volume>
       173
      </volume>
      <fpage>
       776
      </fpage>
      <lpage>
       791.e717
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXlvVOhtbs%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29576449
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2018.02.035
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Zhu
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Developmental clock and mechanism of de novo polarization of the mouse embryo
      </article-title>
      <source>
       Science
      </source>
      <year>
       2020
      </year>
      <volume>
       370
      </volume>
      <fpage>
       eabd2703
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXisFyrtLzM
      </pub-id>
      <pub-id pub-id-type="pmid">
       33303584
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8210885
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abd2703
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mohler
        </surname>
        <given-names>
         WA
        </given-names>
       </name>
       <name>
        <surname>
         Simske
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
       <name>
        <surname>
         Williams-Masson
        </surname>
        <given-names>
         EM
        </given-names>
       </name>
       <name>
        <surname>
         Hardin
        </surname>
        <given-names>
         JD
        </given-names>
       </name>
       <name>
        <surname>
         White
        </surname>
        <given-names>
         JG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Dynamics and ultrastructure of developmental cell fusions in the Caenorhabditis elegans hypodermis
      </article-title>
      <source>
       Curr. Biol.
      </source>
      <year>
       1998
      </year>
      <volume>
       8
      </volume>
      <fpage>
       1087
      </fpage>
      <lpage>
       1091
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DyaK1cXmsVGktrY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       9768364
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/S0960-9822(98)70447-6
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gustafsson
        </surname>
        <given-names>
         MG
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution
      </article-title>
      <source>
       Proc. Natl Acad. Sci.
      </source>
      <year>
       2005
      </year>
      <volume>
       102
      </volume>
      <fpage>
       13081
      </fpage>
      <lpage>
       13086
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2005PNAS..10213081G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD2MXhtVaqu7bK
      </pub-id>
      <pub-id pub-id-type="pmid">
       16141335
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1201569
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.0406877102
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Extended-resolution structured illumination imaging of endocytic and cytoskeletal dynamics
      </article-title>
      <source>
       Science
      </source>
      <year>
       2015
      </year>
      <volume>
       349
      </volume>
      <fpage>
       aab3500
      </fpage>
      <pub-id pub-id-type="pmid">
       26315442
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4659358
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.aab3500
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         X
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Superresolution structured illumination microscopy reconstruction algorithms: a review
      </article-title>
      <source>
       Light Sci. Appl.
      </source>
      <year>
       2023
      </year>
      <volume>
       12
      </volume>
      <fpage>
       172
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023LSA....12..172C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXhsVKjtLrE
      </pub-id>
      <pub-id pub-id-type="pmid">
       37433801
      </pub-id>
      <pub-id pub-id-type="pmcid">
       10336069
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-023-01204-4
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR52">
     <label>
      52.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shah
        </surname>
        <given-names>
         ZH
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images
      </article-title>
      <source>
       Photonics Res.
      </source>
      <year>
       2021
      </year>
      <volume>
       9
      </volume>
      <fpage>
       B168
      </fpage>
      <lpage>
       B181
      </lpage>
      <pub-id pub-id-type="doi">
       10.1364/PRJ.416437
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR53">
     <label>
      53.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Weigert
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Content-aware image restoration: pushing the limits of fluorescence microscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       1090
      </fpage>
      <lpage>
       1097
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitlWnurfP
      </pub-id>
      <pub-id pub-id-type="pmid">
       30478326
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0216-7
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR54">
     <label>
      54.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Culley
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Quantitative mapping and minimization of super-resolution optical imaging artifacts
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2018
      </year>
      <volume>
       15
      </volume>
      <fpage>
       263
      </fpage>
      <lpage>
       266
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjtlyhsbY%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       29457791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5884429
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4605
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR55">
     <label>
      55.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Betzig
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Imaging intracellular fluorescent proteins at nanometer resolution
      </article-title>
      <source>
       Science
      </source>
      <year>
       2006
      </year>
      <volume>
       313
      </volume>
      <fpage>
       1642
      </fpage>
      <lpage>
       1645
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006Sci...313.1642B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD28XpsVOktL0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       16902090
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.1127344
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR56">
     <label>
      56.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Klar
        </surname>
        <given-names>
         TA
        </given-names>
       </name>
       <name>
        <surname>
         Jakobs
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Dyba
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Egner
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Hell
        </surname>
        <given-names>
         SW
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission
      </article-title>
      <source>
       Proc. Natl. Acad. Sci.
      </source>
      <year>
       2000
      </year>
      <volume>
       97
      </volume>
      <fpage>
       8206
      </fpage>
      <lpage>
       8210
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2000PNAS...97.8206K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD3cXlt1Ggtro%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       10899992
      </pub-id>
      <pub-id pub-id-type="pmcid">
       26924
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1073/pnas.97.15.8206
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR57">
     <label>
      57.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Muller
        </surname>
        <given-names>
         CB
        </given-names>
       </name>
       <name>
        <surname>
         Enderlein
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Image scanning microscopy
      </article-title>
      <source>
       Phys. Rev. Lett.
      </source>
      <year>
       2010
      </year>
      <volume>
       104
      </volume>
      <fpage>
       198101
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010PhRvL.104s8101M
      </pub-id>
      <pub-id pub-id-type="pmid">
       20867000
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1103/PhysRevLett.104.198101
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR58">
     <label>
      58.
     </label>
     <mixed-citation publication-type="other">
      Wang, J. et al. Generalizing to unseen domains: A survey on domain generalization.
      <italic>
       IEEE Trans. Knowl. Data Eng.
      </italic>
      <bold>
       35
      </bold>
      , 8052–8072 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR59">
     <label>
      59.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale
      </article-title>
      <source>
       Cell
      </source>
      <year>
       2021
      </year>
      <volume>
       184
      </volume>
      <fpage>
       3318
      </fpage>
      <lpage>
       3332
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXhtF2ntLfJ
      </pub-id>
      <pub-id pub-id-type="pmid">
       34038702
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cell.2021.04.029
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR60">
     <label>
      60.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Castello
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A robust and versatile platform for image scanning microscopy enabling super-resolution FLIM
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2019
      </year>
      <volume>
       16
      </volume>
      <fpage>
       175
      </fpage>
      <lpage>
       178
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXlvFSgu70%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       30643212
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41592-018-0291-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR61">
     <label>
      61.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Liu
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       sCMOS noise-correction algorithm for microscopy images
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2017
      </year>
      <volume>
       14
      </volume>
      <fpage>
       760
      </fpage>
      <lpage>
       761
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXht1eqtbjO
      </pub-id>
      <pub-id pub-id-type="pmid">
       28753600
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6016843
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.4379
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR62">
     <label>
      62.
     </label>
     <mixed-citation publication-type="other">
      Lehtinen, J. et al. in Proceedings of the International Conference on Machine Learning 2965–2974 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR63">
     <label>
      63.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Mandracchia
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Fast and accurate sCMOS noise correction for fluorescence microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2020
      </year>
      <volume>
       11
      </volume>
      <fpage>
       1
      </fpage>
      <lpage>
       12
      </lpage>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-13841-8
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR64">
     <label>
      64.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Diekmann
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Photon-free (s)CMOS camera characterization for artifact reduction in high- and super-resolution microscopy
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2022
      </year>
      <volume>
       13
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022NatCo..13.3362D
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsF2msLnL
      </pub-id>
      <pub-id pub-id-type="pmid">
       35690614
      </pub-id>
      <pub-id pub-id-type="pmcid">
       9188588
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-022-30907-2
      </pub-id>
      <elocation-id>
       3362
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR65">
     <label>
      65.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Grimm
        </surname>
        <given-names>
         JB
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A general method to improve fluorophores for live-cell and single-molecule microscopy
      </article-title>
      <source>
       Nat. methods
      </source>
      <year>
       2015
      </year>
      <volume>
       12
      </volume>
      <fpage>
       244
      </fpage>
      <lpage>
       250
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2MXhtFKjsb8%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       25599551
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4344395
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.3256
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR66">
     <label>
      66.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Riedl
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Lifeact: a versatile marker to visualize F-actin
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2008
      </year>
      <volume>
       5
      </volume>
      <fpage>
       605
      </fpage>
      <lpage>
       607
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXnslyqsr0%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       18536722
      </pub-id>
      <pub-id pub-id-type="pmcid">
       2814344
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.1220
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR67">
     <label>
      67.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         He
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Dynamics of phosphoinositide conversion in clathrin-mediated endocytic traffic
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2017
      </year>
      <volume>
       552
      </volume>
      <fpage>
       410
      </fpage>
      <lpage>
       414
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Natur.552..410H
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2sXhvFOht7rL
      </pub-id>
      <pub-id pub-id-type="pmid">
       29236694
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6263037
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature25146
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR68">
     <label>
      68.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Ran
        </surname>
        <given-names>
         FA
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Genome engineering using the CRISPR-Cas9 system
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2013
      </year>
      <volume>
       8
      </volume>
      <fpage>
       2281
      </fpage>
      <lpage>
       2308
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC2cXjvFajsA%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       24157548
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3969860
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2013.143
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR69">
     <label>
      69.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Sanjana
        </surname>
        <given-names>
         NE
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A transcription activator-like effector toolbox for genome engineering
      </article-title>
      <source>
       Nat. Protoc.
      </source>
      <year>
       2012
      </year>
      <volume>
       7
      </volume>
      <fpage>
       171
      </fpage>
      <lpage>
       192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC38Xht1KgtLg%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       22222791
      </pub-id>
      <pub-id pub-id-type="pmcid">
       3684555
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nprot.2011.431
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR70">
     <label>
      70.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Brenner
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The genetics of Caenorhabditis elegans
      </article-title>
      <source>
       Genetics
      </source>
      <year>
       1974
      </year>
      <volume>
       77
      </volume>
      <fpage>
       71
      </fpage>
      <lpage>
       94
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:STN:280:DyaE2c3ntFWlsw%3D%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       4366476
      </pub-id>
      <pub-id pub-id-type="pmcid">
       1213120
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1093/genetics/77.1.71
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR71">
     <label>
      71.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Köppen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Cooperative regulation of AJM-1 controls junctional integrity in Caenorhabditis elegans epithelia
      </article-title>
      <source>
       Nat. cell Biol.
      </source>
      <year>
       2001
      </year>
      <volume>
       3
      </volume>
      <fpage>
       983
      </fpage>
      <lpage>
       991
      </lpage>
      <pub-id pub-id-type="pmid">
       11715019
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/ncb1101-983
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR72">
     <label>
      72.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       The lysosomal membrane protein SCAV-3 maintains lysosome integrity and adult longevity
      </article-title>
      <source>
       J. Cell Biol.
      </source>
      <year>
       2016
      </year>
      <volume>
       215
      </volume>
      <fpage>
       167
      </fpage>
      <lpage>
       185
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC28XitFeltLbF
      </pub-id>
      <pub-id pub-id-type="pmid">
       27810910
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5084646
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1083/jcb.201602090
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR73">
     <label>
      73.
     </label>
     <mixed-citation publication-type="other">
      Qiao, C. et al. Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy. ZS-DeconvNet,
      <ext-link ext-link-type="doi" xlink:href="10.5281/zenodo.10991031">
       https://doi.org/10.5281/zenodo.10991031
      </ext-link>
      (2024).
     </mixed-citation>
    </ref>
    <ref id="CR74">
     <label>
      74.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Nieuwenhuizen
        </surname>
        <given-names>
         RP
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Measuring image resolution in optical nanoscopy
      </article-title>
      <source>
       Nat. Methods
      </source>
      <year>
       2013
      </year>
      <volume>
       10
      </volume>
      <fpage>
       557
      </fpage>
      <lpage>
       562
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXms1Wms7o%3D
      </pub-id>
      <pub-id pub-id-type="pmid">
       23624665
      </pub-id>
      <pub-id pub-id-type="pmcid">
       4149789
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nmeth.2448
      </pub-id>
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec29">
     <title>
      Дополнительная информация
     </title>
     <p id="Par57">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM1_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Supplementary Information
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM2_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Peer Review File
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM3_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Description of Additional Supplementary Files
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM4" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM4_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 1
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM5" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM5_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 2
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM6" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM6_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 3
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM7" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM7_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 4
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM8" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM8_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 5
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM9" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM9_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 6
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM10" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM10_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 7
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM11" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM11_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 8
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM12" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41467_2024_48575_MOESM12_ESM.mp4">
        <caption xml:lang="en">
         <p>
          Supplementary Movie 9
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM13" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM13_ESM.pdf">
        <caption xml:lang="en">
         <p>
          Reporting Summary
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
    <sec id="Sec30">
     <title>
      Источник данных
     </title>
     <p id="Par58">
      <supplementary-material content-type="local-data" id="MOESM14" xlink:title="Source data">
       <media mime-subtype="vnd.ms-excel" mimetype="application" xlink:href="MediaObjects/41467_2024_48575_MOESM14_ESM.xlsx">
        <caption xml:lang="en">
         <p>
          Source Data
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Дополнительная информация
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41467-024-48575-9">
     https://doi.org/10.1038/s41467-024-48575-9
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
