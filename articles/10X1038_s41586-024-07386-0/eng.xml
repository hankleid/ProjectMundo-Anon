<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type='text/xsl' href='/ProjectMundo/style/jats-html.xsl'?>
<!DOCTYPE response>
<article article-type="research-article" dtd-version="1.2" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
 <front>
  <journal-meta>
   <journal-id journal-id-type="publisher-id">
    41586
   </journal-id>
   <journal-id journal-id-type="doi">
    10.1038/41586.1476-4687
   </journal-id>
   <journal-title-group>
    <journal-title>
     Nature
    </journal-title>
    <journal-subtitle>
     International weekly journal of science
    </journal-subtitle>
    <abbrev-journal-title abbrev-type="publisher">
     Nature
    </abbrev-journal-title>
   </journal-title-group>
   <issn pub-type="ppub">
    0028-0836
   </issn>
   <issn pub-type="epub">
    1476-4687
   </issn>
   <publisher>
    <publisher-name>
     Nature Publishing Group UK
    </publisher-name>
    <publisher-loc>
     London
    </publisher-loc>
   </publisher>
  </journal-meta>
  <article-meta>
   <article-id pub-id-type="publisher-id">
    s41586-024-07386-0
   </article-id>
   <article-id pub-id-type="manuscript">
    7386
   </article-id>
   <article-id pub-id-type="doi">
    10.1038/s41586-024-07386-0
   </article-id>
   <article-categories>
    <subj-group subj-group-type="heading">
     <subject>
      Article
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/624/1075/146
     </subject>
    </subj-group>
    <subj-group subj-group-type="SubjectPath">
     <subject>
      /639/925/927/1021
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /132
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /119
     </subject>
    </subj-group>
    <subj-group subj-group-type="TechniquePath">
     <subject>
      /129
     </subject>
    </subj-group>
    <subj-group subj-group-type="NatureArticleTypeID">
     <subject>
      article
     </subject>
    </subj-group>
   </article-categories>
   <title-group>
    <article-title xml:lang="en">
     Full-colour 3D holographic augmented-reality displays with metasurface waveguides
    </article-title>
   </title-group>
   <contrib-group>
    <contrib contrib-type="author" equal-contrib="yes" id="Au1">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-9017-4968
     </contrib-id>
     <name name-style="western">
      <surname>
       Gopakumar
      </surname>
      <given-names>
       Manu
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" equal-contrib="yes" id="Au2">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0001-6274-8776
     </contrib-id>
     <name name-style="western">
      <surname>
       Lee
      </surname>
      <given-names>
       Gun-Yeal
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="author-notes" rid="fn1"/>
    </contrib>
    <contrib contrib-type="author" id="Au3">
     <name name-style="western">
      <surname>
       Choi
      </surname>
      <given-names>
       Suyeon
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au4">
     <name name-style="western">
      <surname>
       Chao
      </surname>
      <given-names>
       Brian
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au5">
     <name name-style="western">
      <surname>
       Peng
      </surname>
      <given-names>
       Yifan
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff2">
      2
     </xref>
    </contrib>
    <contrib contrib-type="author" id="Au6">
     <name name-style="western">
      <surname>
       Kim
      </surname>
      <given-names>
       Jonghyun
      </given-names>
     </name>
     <xref ref-type="aff" rid="Aff3">
      3
     </xref>
    </contrib>
    <contrib contrib-type="author" corresp="yes" id="Au7">
     <contrib-id contrib-id-type="orcid">
      http://orcid.org/0000-0002-9243-6885
     </contrib-id>
     <name name-style="western">
      <surname>
       Wetzstein
      </surname>
      <given-names>
       Gordon
      </given-names>
     </name>
     <address>
      <email>
       gordon.wetzstein@stanford.edu
      </email>
     </address>
     <xref ref-type="aff" rid="Aff1">
      1
     </xref>
     <xref ref-type="corresp" rid="IDs41586024073860_cor7">
      g
     </xref>
    </contrib>
    <aff id="Aff1">
     <label>
      1
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/00f54p054
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.168010.e
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 1936 8956
      </institution-id>
      <institution content-type="org-division">
       Department of Electrical Engineering
      </institution>
      <institution content-type="org-name">
       Stanford University
      </institution>
     </institution-wrap>
     <addr-line content-type="city">
      Stanford
     </addr-line>
     <addr-line content-type="state">
      CA
     </addr-line>
     <country country="US">
      USA
     </country>
    </aff>
    <aff id="Aff2">
     <label>
      2
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/02zhqgq86
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.194645.b
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0001 2174 2757
      </institution-id>
      <institution content-type="org-division">
       Department of Electrical and Electronic Engineering
      </institution>
      <institution content-type="org-name">
       The University of Hong Kong
      </institution>
     </institution-wrap>
     <addr-line content-type="city">
      Hong Kong
     </addr-line>
     <country country="CN">
      China
     </country>
    </aff>
    <aff id="Aff3">
     <label>
      3
     </label>
     <institution-wrap>
      <institution-id institution-id-type="ROR">
       https://ror.org/03jdj4y14
      </institution-id>
      <institution-id institution-id-type="GRID">
       grid.451133.1
      </institution-id>
      <institution-id institution-id-type="ISNI">
       0000 0004 0458 4453
      </institution-id>
      <institution content-type="org-name">
       NVIDIA
      </institution>
     </institution-wrap>
     <addr-line content-type="city">
      Santa Clara
     </addr-line>
     <addr-line content-type="state">
      CA
     </addr-line>
     <country country="US">
      USA
     </country>
    </aff>
   </contrib-group>
   <author-notes>
    <fn fn-type="equal" id="fn1">
     <p>
      These authors contributed equally: Manu Gopakumar, Gun-Yeal Lee
     </p>
    </fn>
    <corresp id="IDs41586024073860_cor7">
     <label>
      g
     </label>
     <email>
      gordon.wetzstein@stanford.edu
     </email>
    </corresp>
   </author-notes>
   <pub-date date-type="pub" publication-format="electronic">
    <day>
     8
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <pub-date date-type="pub" publication-format="print">
    <day>
     23
    </day>
    <month>
     5
    </month>
    <year>
     2024
    </year>
   </pub-date>
   <volume>
    629
   </volume>
   <issue seq="40">
    8013
   </issue>
   <fpage>
    791
   </fpage>
   <lpage>
    797
   </lpage>
   <history>
    <date date-type="registration">
     <day>
      4
     </day>
     <month>
      4
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="received">
     <day>
      2
     </day>
     <month>
      7
     </month>
     <year>
      2023
     </year>
    </date>
    <date date-type="accepted">
     <day>
      4
     </day>
     <month>
      4
     </month>
     <year>
      2024
     </year>
    </date>
    <date date-type="online">
     <day>
      8
     </day>
     <month>
      5
     </month>
     <year>
      2024
     </year>
    </date>
   </history>
   <permissions>
    <copyright-statement content-type="compact">
     © The Author(s) 2024
    </copyright-statement>
    <copyright-year>
     2024
    </copyright-year>
    <copyright-holder>
     The Author(s)
    </copyright-holder>
    <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
     <license-p>
      <bold>
       Open Access
      </bold>
      This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
      <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">
       http://creativecommons.org/licenses/by/4.0/
      </ext-link>
      .
     </license-p>
    </license>
   </permissions>
   <abstract id="Abs1" xml:lang="en">
    <title>
     Abstract
    </title>
    <p id="Par1">
     Emerging spatial computing systems seamlessly superimpose digital information on the physical environment observed by a user, enabling transformative experiences across various domains, such as entertainment, education, communication and training
     <sup>
      <xref ref-type="bibr" rid="CR1">
       1
      </xref>
      ,
      <xref ref-type="bibr" rid="CR2">
       2
      </xref>
      –
      <xref ref-type="bibr" rid="CR3">
       3
      </xref>
     </sup>
     . However, the widespread adoption of augmented-reality (AR) displays has been limited due to the bulky projection optics of their light engines and their inability to accurately portray three-dimensional (3D) depth cues for virtual content, among other factors
     <sup>
      <xref ref-type="bibr" rid="CR4">
       4
      </xref>
      ,
      <xref ref-type="bibr" rid="CR5">
       5
      </xref>
     </sup>
     . Here we introduce a holographic AR system that overcomes these challenges using a unique combination of inverse-designed full-colour metasurface gratings, a compact dispersion-compensating waveguide geometry and artificial-intelligence-driven holography algorithms. These elements are co-designed to eliminate the need for bulky collimation optics between the spatial light modulator and the waveguide and to present vibrant, full-colour, 3D AR content in a compact device form factor. To deliver unprecedented visual quality with our prototype, we develop an innovative image formation model that combines a physically accurate waveguide model with learned components that are automatically calibrated using camera feedback. Our unique co-design of a nanophotonic metasurface waveguide and artificial-intelligence-driven holographic algorithms represents a significant advancement in creating visually compelling 3D AR experiences in a compact wearable device.
    </p>
   </abstract>
   <abstract abstract-type="ShortSummary" id="Abs2" xml:lang="en">
    <p id="Par2">
     We develop a method for providing high-quality, holographic, three-dimensional augmented-reality images in a small form factor suitable for incorporation in eyeglass-scale wearables, using high-refraction-index glass waveguides with nanoscale metasurfaces, and incorporating artificial intelligence.
    </p>
   </abstract>
   <kwd-group kwd-group-type="hierarchical" vocab="FoR" vocab-identifier="ANZSRC 2008">
    <kwd content-type="term" vocab-term-identifier="08">
     Information and Computing Sciences
    </kwd>
    <nested-kwd>
     <kwd content-type="term" vocab-term-identifier="0801">
      Artificial Intelligence and Image Processing
     </kwd>
     <kwd content-type="term" vocab-term-identifier="0806">
      Information Systems
     </kwd>
    </nested-kwd>
   </kwd-group>
   <custom-meta-group>
    <custom-meta>
     <meta-name>
      publisher-imprint-name
     </meta-name>
     <meta-value>
      Nature Portfolio
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-issue-count
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-article-count
     </meta-name>
     <meta-value>
      64
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-pricelist-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-holder
     </meta-name>
     <meta-value>
      Springer Nature Limited
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-copyright-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-contains-esm
     </meta-name>
     <meta-value>
      Yes
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-month
     </meta-name>
     <meta-value>
      4
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-registration-date-day
     </meta-name>
     <meta-value>
      4
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      toc-levels
     </meta-name>
     <meta-value>
      0
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      volume-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-product
     </meta-name>
     <meta-value>
      NonStandardArchiveJournal
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      numbering-style
     </meta-name>
     <meta-value>
      Unnumbered
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-grants-type
     </meta-name>
     <meta-value>
      OpenChoice
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      metadata-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      abstract-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodypdf-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bodyhtml-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      bibliography-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      esm-grant
     </meta-name>
     <meta-value>
      OpenAccess
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      online-first
     </meta-name>
     <meta-value>
      false
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-file-reference
     </meta-name>
     <meta-value>
      BodyRef/PDF/41586_2024_Article_7386.pdf
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      pdf-type
     </meta-name>
     <meta-value>
      Typeset
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      target-type
     </meta-name>
     <meta-value>
      OnlinePDF
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-online-date-year
     </meta-name>
     <meta-value>
      2024
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-online-date-month
     </meta-name>
     <meta-value>
      5
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-online-date-day
     </meta-name>
     <meta-value>
      22
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      issue-type
     </meta-name>
     <meta-value>
      Regular
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      article-type
     </meta-name>
     <meta-value>
      OriginalPaper
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-primary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, Humanities and Social Sciences, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-secondary
     </meta-name>
     <meta-value>
      Science, multidisciplinary
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      journal-subject-collection
     </meta-name>
     <meta-value>
      Science (multidisciplinary)
     </meta-value>
    </custom-meta>
    <custom-meta>
     <meta-name>
      open-access
     </meta-name>
     <meta-value>
      true
     </meta-value>
    </custom-meta>
   </custom-meta-group>
  </article-meta>
 </front>
 <body>
  <sec id="Sec1">
   <title>
    Main
   </title>
   <p id="Par3">
    Emerging augmented-reality (AR) systems offer new experiences to users and have far-reaching implications for applications that span entertainment, education, communication, training, behavioural therapy and basic vision research
    <sup>
     <xref ref-type="bibr" rid="CR1">
      1
     </xref>
     ,
     <xref ref-type="bibr" rid="CR2">
      2
     </xref>
     –
     <xref ref-type="bibr" rid="CR3">
      3
     </xref>
    </sup>
    . To unlock their full potential in consumer applications, however, AR display systems must be compact—ideally no larger than conventional eyeglasses—to enable comfort and style for all-day use. Among the plethora of optical designs proposed for such near-eye displays
    <sup>
     <xref ref-type="bibr" rid="CR6">
      6
     </xref>
     ,
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
    </sup>
    , waveguide image combiners are the most promising solution for AR glasses because of their compact form factors. Current waveguide designs, however, require projection optics with a thickness proportional to the focal length of the projection lens (Fig.
    <xref ref-type="fig" rid="Fig1">
     1a
    </xref>
    ), introducing optical bulk, and they are limited to displaying two-dimensional (2D) images at a fixed distance to the user. These limitations result in reduced perceptual realism and visual discomfort due to the vergence–accommodation conflict
    <sup>
     <xref ref-type="bibr" rid="CR4">
      4
     </xref>
     ,
     <xref ref-type="bibr" rid="CR5">
      5
     </xref>
    </sup>
    and, even with small projector optics, it is challenging to achieve a device form factor that matches the style of common eyeglasses.
    <fig id="Fig1" position="float">
     <label>
      Fig. 1
     </label>
     <caption xml:lang="en">
      <title>
       Illustration of the optical principle of waveguide-based AR displays.
      </title>
      <p>
       <bold>
        a
       </bold>
       , Conventional AR glasses use amplitude SLMs, such as organic light-emitting diodes or micro light-emitting diodes, which require a projector-based light engine that is typically at least as thick as the focal length
       <italic>
        f
       </italic>
       of the projection lens.
       <bold>
        b
       </bold>
       , The design of our holographic AR glasses uses a phase-only SLM that can be mounted very close to the in-coupling grating, thereby minimizing the device form factor. Additionally, unlike conventional AR glasses, our holographic design can provide full 3D depth cues for virtual content, as illustrated by the bunny (adapted from the Stanford Computer Graphics Laboratory).
       <bold>
        c
       </bold>
       , Compact 3D-printed prototype illustrating the components of our holographic AR glasses in a wearable form factor.
      </p>
     </caption>
     <graphic mime-subtype="PNG" specific-use="web" xlink:href="/ProjectMundo/MediaObjects/10X1038_s41586-024-07386-0/41586_2024_7386_Fig1_HTML.png"/>
    </fig>
   </p>
   <p id="Par4">
    Holographic principles
    <sup>
     <xref ref-type="bibr" rid="CR8">
      8
     </xref>
    </sup>
    could enable the ‘ultimate display’
    <sup>
     <xref ref-type="bibr" rid="CR9">
      9
     </xref>
    </sup>
    using their ability to produce perceptually realistic 3D content using ultrathin optical films
    <sup>
     <xref ref-type="bibr" rid="CR10">
      10
     </xref>
     ,
     <xref ref-type="bibr" rid="CR11">
      11
     </xref>
    </sup>
    . This ability motivated previous attempts to adapt digital holography to AR display configurations
    <sup>
     <xref ref-type="bibr" rid="CR12">
      12
     </xref>
     ,
     <xref ref-type="bibr" rid="CR13">
      13
     </xref>
    </sup>
    ; though promising, these methods failed to achieve the compact form factors and high 3D image quality required to unlock future spatial computing applications.
   </p>
   <p id="Par5">
    Here we develop a new AR display system that pairs a lensless holographic light engine with a metasurface waveguide optimized for full-colour optical-see-through (OST) AR display applications in a compact form factor (Fig.
    <xref ref-type="fig" rid="Fig1">
     1b
    </xref>
    ). Compared with other waveguides, our optical system is unique in enabling the relay of full-colour 3D holographic images with high uniformity and see-through efficiency. This remarkable capability is enabled by the use of inverse-designed metasurface
    <sup>
     <xref ref-type="bibr" rid="CR14">
      14
     </xref>
     ,
     <xref ref-type="bibr" rid="CR15">
      15
     </xref>
     –
     <xref ref-type="bibr" rid="CR16">
      16
     </xref>
    </sup>
    grating couplers. Metasurfaces
    <sup>
     <xref ref-type="bibr" rid="CR17">
      17
     </xref>
     ,
     <xref ref-type="bibr" rid="CR18">
      18
     </xref>
    </sup>
    have been demonstrated to offer higher diffraction efficiency
    <sup>
     <xref ref-type="bibr" rid="CR19">
      19
     </xref>
    </sup>
    , spectral selectivity
    <sup>
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
    </sup>
    ,
    <italic>
     Q
    </italic>
    -factor
    <sup>
     <xref ref-type="bibr" rid="CR21">
      21
     </xref>
    </sup>
    and transmittance
    <sup>
     <xref ref-type="bibr" rid="CR22">
      22
     </xref>
    </sup>
    than conventional refractive and diffractive optical elements in applications, including AR
    <sup>
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
    </sup>
    , virtual reality
    <sup>
     <xref ref-type="bibr" rid="CR24">
      24
     </xref>
    </sup>
    and wearable devices
    <sup>
     <xref ref-type="bibr" rid="CR20">
      20
     </xref>
    </sup>
    . Unlike these approaches, ours not only optimizes the devices and demonstrates novel applications of metasurfaces, but also co-designs the entire optical system, including the geometry of a high-index glass waveguide and the metasurface grating couplers, to enable compatability with holographic AR display systems. Waveguide holography has been described in recent work for non-see-through virtual reality settings
    <sup>
     <xref ref-type="bibr" rid="CR25">
      25
     </xref>
    </sup>
    , but it has seen limited adoption because of its poor image quality. To address this challenge, we develop a mathematical model that describes the propagation of coherent waves in a waveguide using a combination of physically accurate modelling techniques and artificial intelligence. The learnable parts of this model are automatically calibrated using camera feedback with our prototype. This approach significantly advances recent artificial-intelligence-driven holography algorithms
    <sup>
     <xref ref-type="bibr" rid="CR26">
      26
     </xref>
     ,
     <xref ref-type="bibr" rid="CR27">
      27
     </xref>
     ,
     <xref ref-type="bibr" rid="CR28">
      28
     </xref>
     –
     <xref ref-type="bibr" rid="CR29">
      29
     </xref>
    </sup>
    by making them suitable for compact waveguides in see-through AR configurations. With our system, we obtained high-quality, full-colour multiplane 3D holographic images using a single OST AR waveguide. Compared with related optical designs
    <sup>
     <xref ref-type="bibr" rid="CR30">
      30
     </xref>
     ,
     <xref ref-type="bibr" rid="CR31">
      31
     </xref>
     ,
     <xref ref-type="bibr" rid="CR32">
      32
     </xref>
     –
     <xref ref-type="bibr" rid="CR33">
      33
     </xref>
    </sup>
    , our system provides unprecedented full-colour image quality in a compact form factor, enabling a path towards true 3D holographic AR glasses.
   </p>
  </sec>
  <sec id="Sec2">
   <title>
    Inverse-designed metasurface waveguide
   </title>
   <p id="Par6">
    For OST AR displays, it is critical to provide the user with an unobstructed view of the physical environment while overlaying digital information on their vision of the world. Waveguide image combiners are thin transparent optical systems that have become the industry norm for these applications
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
    </sup>
    , enabling the aforementioned capabilities. Our metasurface waveguide system design optimizes compactness, dispersion correction, transmission efficiency and angular uniformity to meet the high demands of 3D-capable AR applications.
   </p>
   <p id="Par7">
    Precise manipulation of coherent wavefronts in a waveguide system is crucial for holographic displays, but is very challenging due to the interfering nature of coherent light. We address this challenge using a high-index glass material with a homogeneous design of all-glass metasurfaces (Fig.
    <xref ref-type="fig" rid="Fig2">
     2
    </xref>
    ). For a compact waveguide system to minimize boundary reflection and interference, a single-layer coupler is necessary. This coupler must guide broadband visible light through the waveguide at a high diffraction angle, ensuring total internal reflection (TIR). The critical angle, represented as
    <inline-formula id="IEq1">
     <alternatives>
      <math id="IEq1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mrow>
        <msub>
         <mrow>
          <mi>
           θ
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           c
          </mi>
         </mrow>
        </msub>
        <mrow>
         <mo>
          (
         </mo>
         <mrow>
          <mi>
           λ
          </mi>
         </mrow>
         <mo>
          )
         </mo>
        </mrow>
        <mo>
         =
        </mo>
        <msup>
         <mrow>
          <mi>
           sin
          </mi>
         </mrow>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           1
          </mn>
         </mrow>
        </msup>
        <mrow>
         <mrow>
          <mfenced close=")" open="(">
           <mrow>
            <mfrac>
             <mrow>
              <mn>
               1
              </mn>
             </mrow>
             <mrow>
              <mi>
               n
              </mi>
              <mrow>
               <mo>
                (
               </mo>
               <mrow>
                <mi>
                 λ
                </mi>
               </mrow>
               <mo>
                )
               </mo>
              </mrow>
             </mrow>
            </mfrac>
           </mrow>
          </mfenced>
         </mrow>
        </mrow>
       </mrow>
      </math>
      <tex-math id="IEq1_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{{\rm{c}}}(\lambda )={\sin }^{-1}\left(\frac{1}{n(\lambda )}\right)$$\end{document}
      </tex-math>
      <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_IEq1.gif"/>
     </alternatives>
    </inline-formula>
    , dictates that shorter wavelengths
    <italic>
     λ
    </italic>
    require a higher refractive index
    <italic>
     n
    </italic>
    to achieve TIR. Our numerical analysis indicates that a refractive index of 1.8 or higher is necessary to transmit all red, green and blue wavelengths through a single coupler, with a higher index expanding the field of view. This underscores the importance of employing a high-index material in our system design. In addition, the high-index glass (
    <italic>
     n
    </italic>
    &gt; 1.8), with a complex refractive index denoted as
    <inline-formula id="IEq2">
     <alternatives>
      <math id="IEq2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mrow>
        <mover accent="true">
         <mrow>
          <mi>
           n
          </mi>
         </mrow>
         <mrow>
          <mo>
           ̃
          </mo>
         </mrow>
        </mover>
        <mo>
         =
        </mo>
        <mi>
         n
        </mi>
        <mo>
         +
        </mo>
        <mi>
         i
        </mi>
        <mi>
         k
        </mi>
       </mrow>
      </math>
      <tex-math id="IEq2_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{n}=n+ik$$\end{document}
      </tex-math>
      <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_IEq2.gif"/>
     </alternatives>
    </inline-formula>
    , assures minimal absorption loss (
    <italic>
     k
    </italic>
    ≈ 0) and provides sufficient light–matter interaction, while typical glass (
    <italic>
     n
    </italic>
    &lt; 1.5) is insufficient to locally manipulate electromagnetic waves due to weak light–matter interaction. As a result, the high-index glass metasurface attains a balance between high see-through efficiency and diffraction efficiency, surpassing the capabilities of typical glass metasurfaces.
    <fig id="Fig2" position="float">
     <label>
      Fig. 2
     </label>
     <caption xml:lang="en">
      <title>
       Design and evaluation of our inverse-designed metasurfaces.
      </title>
      <p>
       <bold>
        a
       </bold>
       , Visualization of the waveguide geometry for full-colour operation.
       <bold>
        b
       </bold>
       , Electric field maps at red (638 nm), green (521 nm) and blue (445 nm) wavelengths for light passing through the metasurface out-coupler towards the user’s eye. The black arrows illustrate the wave vectors of the incident and diffracted light.
       <bold>
        c
       </bold>
       , Visualization of the inverse-designed metasurfaces optimized for waveguide couplers. The period (
       <italic>
        Λ
       </italic>
       ) and height (
       <italic>
        H
       </italic>
       ) of the metasurfaces are 384 nm and 220 nm, respectively.
       <bold>
        d
       </bold>
       , Scanning electron microscope images of the fabricated metasurfaces.
       <bold>
        e
       </bold>
       , The simulated and experimentally measured transmittance spectra of unpolarized light for the inverse-designed metasurfaces in the visible range, corresponding to see-through efficiency for real-world scenes.
       <bold>
        f
       </bold>
       , The simulated (dashed lines) transfer functions along the
       <italic>
        x
       </italic>
       axis for the conventional single-lined gratings and the simulated (solid lines) and experimentally measured (circles) transfer functions for our inverse-designed metasurfaces. The colour of the plots corresponds to the red, green and blue wavelengths. The designed metasurfaces are much more efficient than conventional gratings in green and blue, but, due to the very large diffraction angle of red, further improvement of the efficiency of the red channel is more difficult.
       <bold>
        g
       </bold>
       , Uniformities of the transfer functions for the conventional gratings without optimization and the inverse-designed metasurfaces with optimization. Scale bars, 400 nm (
       <bold>
        b
       </bold>
       ), 2 μm (
       <bold>
        d
       </bold>
       , left), 200 nm (
       <bold>
        d
       </bold>
       , right).
       <italic>
        E
       </italic>
       , electromagnetic field.
      </p>
     </caption>
     <graphic mime-subtype="PNG" specific-use="web" xlink:href="/ProjectMundo/MediaObjects/10X1038_s41586-024-07386-0/41586_2024_7386_Fig2_HTML.png"/>
    </fig>
   </p>
   <p id="Par8">
    Although the high-index glass enables propagation of broadband light with TIR, dispersion correction is further required for full-colour operation. Dispersion-engineered metasurfaces could be an option
    <sup>
     <xref ref-type="bibr" rid="CR34">
      34
     </xref>
     ,
     <xref ref-type="bibr" rid="CR35">
      35
     </xref>
    </sup>
    , as a device-level solution, but they often have insufficient degrees-of-freedom to meet the system performance required for AR applications (namely, high uniformity and see-through efficiency). To this end, we correct the chromatic dispersion at the system level through geometric design of the metasurface waveguide system and k-vector matching of the input and output couplers. The in- and out-couplers are designed to have the same momentum but with an opposite direction, so they can couple the incident light in and out without observable dispersion.
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
    </sup>
    Additionally, to spatially match the couplers, we design a dispersion-compensating waveguide geometry by precisely engineering the waveguide thickness and the dimensions and distances of the symmetric metasurface couplers. The lateral displacement of a replicated pupil inside the waveguide can be expressed as
    <inline-formula id="IEq3">
     <alternatives>
      <math id="IEq3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mi>
        l
       </mi>
       <mo>
        (
       </mo>
       <mi>
        λ
       </mi>
       <mo>
        )
       </mo>
       <mo>
        =
       </mo>
       <mn>
        2
       </mn>
       <msub>
        <mrow>
         <mi>
          d
         </mi>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            w
           </mi>
           <mi mathvariant="normal">
            g
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </msub>
       <mi>
        tan
       </mi>
       <mfenced close=")" open="(">
        <mrow>
         <msup>
          <mrow>
           <mi>
            sin
           </mi>
          </mrow>
          <mrow>
           <mo>
            −
           </mo>
           <mn>
            1
           </mn>
          </mrow>
         </msup>
         <mrow>
          <mo>
           (
          </mo>
          <mfrac>
           <mi>
            λ
           </mi>
           <mrow>
            <mi>
             n
            </mi>
            <mo>
             (
            </mo>
            <mi>
             λ
            </mi>
            <mo>
             )
            </mo>
            <mrow>
             <mi>
              Λ
             </mi>
            </mrow>
           </mrow>
          </mfrac>
          <mo>
           )
          </mo>
         </mrow>
        </mrow>
       </mfenced>
      </math>
      <tex-math id="IEq3_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l(\lambda )=2{d}_{{\rm{w}}{\rm{g}}}\tan \left({\sin }^{-1}(\frac{\lambda }{n(\lambda )\varLambda })\right)$$\end{document}
      </tex-math>
      <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_IEq3.gif"/>
     </alternatives>
    </inline-formula>
    , where
    <italic>
     d
    </italic>
    <sub>
     wg
    </sub>
    ,
    <italic>
     λ
    </italic>
    and
    <italic>
     Λ
    </italic>
    are the waveguide thickness, the wavelength of light in free space and the grating period, respectively. Our idea is to design the waveguide geometry to have a suitable least common multiple of the
    <inline-formula id="IEq4">
     <alternatives>
      <math id="IEq4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mrow>
        <mi>
         l
        </mi>
        <mfenced close=")" open="(">
         <mrow>
          <mrow>
           <mrow>
            <mi>
             λ
            </mi>
           </mrow>
          </mrow>
         </mrow>
        </mfenced>
       </mrow>
      </math>
      <tex-math id="IEq4_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l\left(\lambda \right)$$\end{document}
      </tex-math>
      <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_IEq4.gif"/>
     </alternatives>
    </inline-formula>
    function for red, green and blue wavelengths, which can be described by ∃
    <italic>
     d
    </italic>
    <sub>
     wg
    </sub>
    ,
    <italic>
     Λ
    </italic>
    : LCM(
    <italic>
     l
    </italic>
    (
    <italic>
     λ
    </italic>
    <sub>
     R
    </sub>
    ),
    <italic>
     l
    </italic>
    (
    <italic>
     λ
    </italic>
    <sub>
     G
    </sub>
    ),
    <italic>
     l
    </italic>
    (
    <italic>
     λ
    </italic>
    <sub>
     B
    </sub>
    ) ) &lt;
    <italic>
     L
    </italic>
    <sub>
     wg
    </sub>
    , where
    <italic>
     L
    </italic>
    <sub>
     wg
    </sub>
    is the maximum length between in- and out-couplers for a compact near-eye display and LCM is the least common multiple function. Specifically, we set
    <italic>
     d
    </italic>
    <sub>
     wg
    </sub>
    and
    <italic>
     Λ
    </italic>
    to 5 mm and 384 nm, respectively; with these parameters, the red, green and blue wavefronts from the in-coupler propagate through the waveguide through one, three and five internal reflections, respectively, before meeting at the out-coupler, as illustrated in Fig.
    <xref ref-type="fig" rid="Fig2">
     2a
    </xref>
    .
   </p>
   <p id="Par9">
    To optimize the geometry of the metasurface gratings for maximum diffraction efficiency and uniformity of angular response, we employ a rigorous-coupled-wave-analysis solver
    <sup>
     <xref ref-type="bibr" rid="CR36">
      36
     </xref>
    </sup>
    . Our metasurface couplers operate in transverse electric polarization mode to provide a more uniform optical response. The optimization process uses the gradient descent method, starting from a randomly initialized geometry in the 2D spatial domain and utilizing the Adam solver
    <sup>
     <xref ref-type="bibr" rid="CR37">
      37
     </xref>
    </sup>
    to refine the profiles of the metasurface gratings. The loss function in the optimization loop maximizes the sum of the first diffraction order efficiencies for red, green and blue wavelengths (638 nm, 521 nm and 445 nm), while minimizing the standard deviations of efficiencies for different incident angles, ranging from −5° to 5°, for these three wavelengths. We simplify the design process to one dimension by assuming
    <italic>
     x
    </italic>
    axis symmetry and account for fabrication tolerances of these large-area metasurfaces by adding Gaussian blur. The resulting design converged to a double-lined metasurface grating, as shown in Fig.
    <xref ref-type="fig" rid="Fig2">
     2c
    </xref>
    . This geometry yields metasurface couplers that steer the incident wave to high diffraction angles for red, green and blue wavelengths, as confirmed by the electric field profiles and overlaid Poynting vectors (Fig.
    <xref ref-type="fig" rid="Fig2">
     2b
    </xref>
    ). Importantly, the optimized asymmetric nanostructure not only enhances the diffraction efficiency in one direction but also improves uniformity over the angle of incidence.
   </p>
   <p id="Par10">
    Figure
    <xref ref-type="fig" rid="Fig2">
     2e
    </xref>
    shows the high see-through efficiency our inverse-designed metasurface couplers achieve, reaching approximately 78.4% in the visible spectrum. Figure
    <xref ref-type="fig" rid="Fig2">
     2f
    </xref>
    contains the transfer functions of our inverse-designed metasurfaces and typical gratings for red, green and blue wavelengths (full 2D transfer functions are shown in the
    <xref ref-type="supplementary-material" rid="MOESM1">
     Supplementary Information
    </xref>
    ). As opposed to conventional gratings, our metasurfaces exhibit uniform transmittance regardless of the angle of incidence, thanks to the optimized electromagnetic resonances in the nanostructures. Figure
    <xref ref-type="fig" rid="Fig2">
     2g
    </xref>
    quantifies the uniformity of the transfer function that is defined as the ratio of the minimum and maximum amplitudes within the viewing angle range. The inverse-designed metasurface has high uniformities of 61.7%, 91.2% and 98.3% for red, green and blue, respectively, whereas conventional gratings achieve much lower uniformities of 58.9%, 47.7% and 88.8%. These findings confirm that our inverse-designed all-glass metasurface couplers provide excellent angular uniformity and high see-through efficiency for full-colour operation.
   </p>
   <p id="Par11">
    A key challenge for the fabrication of holographic waveguides is a high sensitivity to surface irregularities or particle contamination, which directly affects the observed image quality. For this reason, we fabricate our metasurface system directly on lead-containing high-index glass (SF6 glass, SCHOTT), without any other composing materials, using electron beam (e-beam) lithography. To avoid residue particle contamination or surface damage of the lift-off process or surface irregularities introduced by physical etching, we avoid commonly used lithography processes for metasurface fabrication, including positive e-beam resist with metal lift-off or negative e-beam resist to make an etching mask. Instead, our method is based on reverse patterning with a positive e-beam resist (polymethyl methacrylate (PMMA)) using multiple dry etching methods, thus avoiding lift-off hard masks and ensuring the glass surface remains protected throughout the fabrication process (
    <xref ref-type="sec" rid="Sec6">
     Methods
    </xref>
    ). Note that this method can also be applied to photolithography or nanoimprint lithography for mass production
    <sup>
     <xref ref-type="bibr" rid="CR38">
      38
     </xref>
     ,
     <xref ref-type="bibr" rid="CR39">
      39
     </xref>
    </sup>
    .
   </p>
  </sec>
  <sec id="Sec3">
   <title>
    Waveguide propagation model
   </title>
   <p id="Par12">
    To simulate the propagation of coherent light through our metasurface waveguide, we first derive a physically motivated model. We then show how this model can be parameterized by neural network components that can be automatically learned from camera feedback. As shown by our experiments, the unique combination of physical and artificial-intelligence components is crucial for accurately modelling the physical optics of such a waveguide and synthesizing high-quality holograms with it.
   </p>
   <p id="Par13">
    The wavefront
    <italic>
     u
    </italic>
    <sub>
     IC
    </sub>
    coupled into the waveguide can be computed as the product of the phase-only spatial light modulator (SLM) pattern, e
    <sup>
     i
     <italic>
      ϕ
     </italic>
    </sup>
    , the incident illumination and the in-coupler aperture
    <italic>
     a
    </italic>
    <sub>
     IC
    </sub>
    . Since we use a converging wavefront for illumination with focal length
    <italic>
     f
    </italic>
    <sub>
     illum
    </sub>
    , the in-coupled wavefront is expressed as
    <disp-formula id="Equ1">
     <label>
      1
     </label>
     <alternatives>
      <math display="block" id="Equ1_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <msub>
        <mrow>
         <mi>
          u
         </mi>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            I
           </mi>
           <mi mathvariant="normal">
            C
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </msub>
       <mo>
        (
       </mo>
       <msup>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            e
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            i
           </mi>
          </mrow>
         </mrow>
         <mi>
          ϕ
         </mi>
        </mrow>
       </msup>
       <mo>
        )
       </mo>
       <mo>
        =
       </mo>
       <msup>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            e
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mo>
          −
         </mo>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            i
           </mi>
          </mrow>
         </mrow>
         <mfrac>
          <mrow>
           <mn>
            2
           </mn>
           <mrow>
            <mrow>
             <mi>
              π
             </mi>
            </mrow>
           </mrow>
          </mrow>
          <mi>
           λ
          </mi>
         </mfrac>
         <msqrt>
          <msup>
           <mrow>
            <mi>
             x
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mo>
           +
          </mo>
          <msup>
           <mrow>
            <mi>
             y
            </mi>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msup>
          <mo>
           +
          </mo>
          <msubsup>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               i
              </mi>
              <mi mathvariant="normal">
               l
              </mi>
              <mi mathvariant="normal">
               l
              </mi>
              <mi mathvariant="normal">
               u
              </mi>
              <mi mathvariant="normal">
               m
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mn>
             2
            </mn>
           </mrow>
          </msubsup>
         </msqrt>
        </mrow>
       </msup>
       <msup>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            e
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            i
           </mi>
          </mrow>
         </mrow>
         <mi>
          ϕ
         </mi>
        </mrow>
       </msup>
       <msub>
        <mrow>
         <mi>
          a
         </mi>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            I
           </mi>
           <mi mathvariant="normal">
            C
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </msub>
       <mo>
        ,
       </mo>
      </math>
      <tex-math id="Equ1_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{{\rm{I}}{\rm{C}}}({{\rm{e}}}^{{\rm{i}}\phi })={{\rm{e}}}^{-{\rm{i}}\frac{2\pi }{\lambda }\sqrt{{x}^{2}+{y}^{2}+{f}_{{\rm{i}}{\rm{l}}{\rm{l}}{\rm{u}}{\rm{m}}}^{2}}}{{\rm{e}}}^{{\rm{i}}\phi }{a}_{{\rm{I}}{\rm{C}}},$$\end{document}
      </tex-math>
      <graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_Equ1.gif"/>
     </alternatives>
    </disp-formula>
    where and
    <italic>
     x
    </italic>
    and
    <italic>
     y
    </italic>
    are the transverse coordinates.
   </p>
   <p id="Par14">
    Next, this wavefront is propagated through the waveguide to compute the out-coupled field,
    <italic>
     u
    </italic>
    <sub>
     OC
    </sub>
    . A physically motivated model of the waveguide is adequately described by its frequency-dependent transfer function,
    <italic>
     H
    </italic>
    <sub>
     WG
    </sub>
    and the aperture
    <italic>
     a
    </italic>
    <sub>
     OC
    </sub>
    of the out-coupler:
    <disp-formula id="Equ2">
     <label>
      2
     </label>
     <alternatives>
      <math display="block" id="Equ2_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <msub>
        <mrow>
         <mi>
          u
         </mi>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            O
           </mi>
           <mi mathvariant="normal">
            C
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </msub>
       <mo>
        (
       </mo>
       <msup>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            e
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            i
           </mi>
          </mrow>
         </mrow>
         <mi>
          ϕ
         </mi>
        </mrow>
       </msup>
       <mo>
        )
       </mo>
       <mo>
        =
       </mo>
       <msub>
        <mrow>
         <mi>
          a
         </mi>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            O
           </mi>
           <mi mathvariant="normal">
            C
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </msub>
       <mo>
        ∬
       </mo>
       <mrow>
        <mrow>
         <mi class="MJX-tex-caligraphic" mathvariant="script">
          F
         </mi>
        </mrow>
       </mrow>
       <mrow>
        <mo>
         (
        </mo>
        <msub>
         <mrow>
          <mi>
           u
          </mi>
         </mrow>
         <mrow>
          <mrow>
           <mrow>
            <mi mathvariant="normal">
             I
            </mi>
            <mi mathvariant="normal">
             C
            </mi>
           </mrow>
          </mrow>
         </mrow>
        </msub>
        <mo>
         (
        </mo>
        <msup>
         <mrow>
          <mrow>
           <mrow>
            <mi mathvariant="normal">
             e
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <mrow>
            <mi mathvariant="normal">
             i
            </mi>
           </mrow>
          </mrow>
          <mi>
           ϕ
          </mi>
         </mrow>
        </msup>
        <mo>
         )
        </mo>
        <mo>
         )
        </mo>
       </mrow>
       <msub>
        <mrow>
         <mi>
          H
         </mi>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            W
           </mi>
           <mi mathvariant="normal">
            G
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </msub>
       <msup>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            e
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mrow>
          <mrow>
           <mi mathvariant="normal">
            i
           </mi>
          </mrow>
         </mrow>
         <mn>
          2
         </mn>
         <mrow>
          <mrow>
           <mi>
            π
           </mi>
          </mrow>
         </mrow>
         <mo>
          (
         </mo>
         <msub>
          <mrow>
           <mi>
            f
           </mi>
          </mrow>
          <mrow>
           <mi>
            x
           </mi>
          </mrow>
         </msub>
         <mi>
          x
         </mi>
         <mo>
          +
         </mo>
         <msub>
          <mrow>
           <mi>
            f
           </mi>
          </mrow>
          <mrow>
           <mi>
            y
           </mi>
          </mrow>
         </msub>
         <mi>
          y
         </mi>
         <mo>
          )
         </mo>
        </mrow>
       </msup>
       <mrow>
        <mrow>
         <mi mathvariant="normal">
          d
         </mi>
        </mrow>
       </mrow>
       <msub>
        <mrow>
         <mi>
          f
         </mi>
        </mrow>
        <mrow>
         <mi>
          x
         </mi>
        </mrow>
       </msub>
       <mrow>
        <mrow>
         <mi mathvariant="normal">
          d
         </mi>
        </mrow>
       </mrow>
       <msub>
        <mrow>
         <mi>
          f
         </mi>
        </mrow>
        <mrow>
         <mi>
          y
         </mi>
        </mrow>
       </msub>
       <mo>
        ,
       </mo>
      </math>
      <tex-math id="Equ2_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{{\rm{O}}{\rm{C}}}({{\rm{e}}}^{{\rm{i}}\phi })={a}_{{\rm{O}}{\rm{C}}}\iint {\mathcal{F}}({u}_{{\rm{I}}{\rm{C}}}({{\rm{e}}}^{{\rm{i}}\phi })){H}_{{\rm{W}}{\rm{G}}}{{\rm{e}}}^{{\rm{i}}2\pi ({f}_{x}x+{f}_{y}y)}{\rm{d}}{f}_{x}{\rm{d}}{f}_{y},$$\end{document}
      </tex-math>
      <graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_Equ2.gif"/>
     </alternatives>
    </disp-formula>
    where
    <inline-formula id="IEq5">
     <alternatives>
      <math id="IEq5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mi class="MJX-tex-caligraphic" mathvariant="script">
        F
       </mi>
      </math>
      <tex-math id="IEq5_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{F}}$$\end{document}
      </tex-math>
      <inline-graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_IEq5.gif"/>
     </alternatives>
    </inline-formula>
    is the Fourier transform and
    <italic>
     f
    </italic>
    <sub>
     x
    </sub>
    and
    <italic>
     f
    </italic>
    <sub>
     y
    </sub>
    are the frequency coordinates. The transfer function
    <italic>
     H
    </italic>
    <sub>
     WG
    </sub>
    incorporates the reflection coefficients within the waveguide, coupling efficiencies, the propagation of the first diffracted order and the translation between the in- and out-coupler. The contributions of each of these components are used to derive the full expression for
    <italic>
     H
    </italic>
    <sub>
     WG
    </sub>
    in our
    <xref ref-type="supplementary-material" rid="MOESM1">
     Supplementary Information
    </xref>
    . Note that we can set
    <italic>
     H
    </italic>
    <sub>
     WG
    </sub>
    to the identity operator, ignoring the transfer function, as a naive, non-physical baseline.
   </p>
   <p id="Par15">
    Finally, the 3D images observed by a user looking through the holographic AR glasses can be simulated by propagating the out-coupled field with a model of free-space propagation,
    <italic>
     f
    </italic>
    <sub>
     free
    </sub>
    , to different target distances,
    <italic>
     d
    </italic>
    <sub>
     target
    </sub>
    , in front of the viewer:
    <disp-formula id="Equ3">
     <label>
      3
     </label>
     <alternatives>
      <math display="block" id="Equ3_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mrow>
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           WG
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mrow>
           <mrow>
            <msup>
             <mrow>
              <mi mathvariant="normal">
               e
              </mi>
             </mrow>
             <mrow>
              <mi mathvariant="normal">
               i
              </mi>
              <mi>
               ϕ
              </mi>
             </mrow>
            </msup>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               d
              </mi>
             </mrow>
             <mrow>
              <mi mathvariant="normal">
               target
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mrow>
         </mrow>
        </mfenced>
        <mo>
         =
        </mo>
        <msub>
         <mrow>
          <mi>
           f
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           free
          </mi>
         </mrow>
        </msub>
        <mfenced close=")" open="(">
         <mrow>
          <mrow>
           <mrow>
            <msub>
             <mrow>
              <mi>
               u
              </mi>
             </mrow>
             <mrow>
              <mi mathvariant="normal">
               OC
              </mi>
             </mrow>
            </msub>
            <mrow>
             <mo>
              (
             </mo>
             <mrow>
              <msup>
               <mrow>
                <mi mathvariant="normal">
                 e
                </mi>
               </mrow>
               <mrow>
                <mi mathvariant="normal">
                 i
                </mi>
                <mi>
                 ϕ
                </mi>
               </mrow>
              </msup>
             </mrow>
             <mo>
              )
             </mo>
            </mrow>
            <mo>
             ,
            </mo>
            <msub>
             <mrow>
              <mi>
               d
              </mi>
             </mrow>
             <mrow>
              <mi mathvariant="normal">
               target
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mrow>
         </mrow>
        </mfenced>
        <mo>
         .
        </mo>
       </mrow>
      </math>
      <tex-math id="Equ3_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{\rm{WG}}}\left({{\rm{e}}}^{{\rm{i}}\phi },{d}_{{\rm{target}}}\right)={f}_{{\rm{free}}}\left({u}_{{\rm{OC}}}({{\rm{e}}}^{{\rm{i}}\phi }),{d}_{{\rm{target}}}\right).$$\end{document}
      </tex-math>
      <graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_Equ3.gif"/>
     </alternatives>
    </disp-formula>
   </p>
   <p id="Par16">
    With these equations,
    <italic>
     f
    </italic>
    <sub>
     WG
    </sub>
    maps phase patterns shown on the SLM to the image that a user would see while focusing at a particular depth,
    <italic>
     d
    </italic>
    <sub>
     target
    </sub>
    , through the waveguide, and
    <italic>
     f
    </italic>
    <sub>
     free
    </sub>
    maps the wavefront in front of the user’s eye to the image that a user would see while focusing at a particular depth,
    <italic>
     d
    </italic>
    <sub>
     target
    </sub>
    .
   </p>
   <p id="Par17">
    Although a physical model, such as
    <italic>
     f
    </italic>
    <sub>
     WG
    </sub>
    , should accurately describe the wave propagation in a waveguide, in practice it is challenging to model all aspects of such a physical optical system at the required accuracy. Nanoscopic differences, on the order of the wavelength of light, between the simulated model and the optical aberrations, fabrication errors, source beam, or electro-optical effect of the SLM strongly degrade the observed holographic image quality. To account for these small differences between the simulated model and physical optics, we add learnable components in the form of convolutional neural networks (CNNs) to our model. Although related approaches have recently been proposed for bulky benchtop holographic virtual reality displays
    <sup>
     <xref ref-type="bibr" rid="CR26">
      26
     </xref>
     ,
     <xref ref-type="bibr" rid="CR40">
      40
     </xref>
     ,
     <xref ref-type="bibr" rid="CR41">
      41
     </xref>
     –
     <xref ref-type="bibr" rid="CR42">
      42
     </xref>
    </sup>
    , ours characterizes the propagation of full-colour coherent wavefronts through an OST waveguide using this emerging paradigm. Specifically, we propose to learn parameters
    <italic>
     a
    </italic>
    <sub>
     IC
    </sub>
    and
    <italic>
     a
    </italic>
    <sub>
     OC
    </sub>
    as complex-valued fields, the spatially varying diffraction efficiencies and the CNNs at the in-coupler and target planes to account for a mismatch between simulated model and physical optics. These learned components, which are illustrated with our full waveguide model in Fig.
    <xref ref-type="fig" rid="Fig3">
     3
    </xref>
    , result in the following learnable physical waveguide model:
    <disp-formula id="Equ4">
     <label>
      4
     </label>
     <alternatives>
      <math display="block" id="Equ4_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mtable columnalign="left" columnspacing="1em" rowspacing="4pt">
        <mtr>
         <mtd>
          <mspace width="thinmathspace"/>
          <mspace width="thinmathspace"/>
          <msub>
           <mrow>
            <mi>
             u
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               I
              </mi>
              <mi mathvariant="normal">
               C
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           (
          </mo>
          <msup>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               e
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               i
              </mi>
             </mrow>
            </mrow>
            <mi>
             ϕ
            </mi>
           </mrow>
          </msup>
          <mo>
           )
          </mo>
          <mo>
           =
          </mo>
          <msub>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               C
              </mi>
              <mi mathvariant="normal">
               N
              </mi>
              <mi mathvariant="normal">
               N
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               I
              </mi>
              <mi mathvariant="normal">
               C
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mrow>
           <mo>
            (
           </mo>
           <msup>
            <mrow>
             <mrow>
              <mrow>
               <mi mathvariant="normal">
                e
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mo>
              −
             </mo>
             <mrow>
              <mrow>
               <mi mathvariant="normal">
                i
               </mi>
              </mrow>
             </mrow>
             <mfrac>
              <mrow>
               <mn>
                2
               </mn>
               <mrow>
                <mrow>
                 <mi>
                  π
                 </mi>
                </mrow>
               </mrow>
              </mrow>
              <mi>
               λ
              </mi>
             </mfrac>
             <msqrt>
              <msup>
               <mrow>
                <mi>
                 x
                </mi>
               </mrow>
               <mrow>
                <mn>
                 2
                </mn>
               </mrow>
              </msup>
              <mo>
               +
              </mo>
              <msup>
               <mrow>
                <mi>
                 y
                </mi>
               </mrow>
               <mrow>
                <mn>
                 2
                </mn>
               </mrow>
              </msup>
              <mo>
               +
              </mo>
              <msubsup>
               <mrow>
                <mi>
                 f
                </mi>
               </mrow>
               <mrow>
                <mrow>
                 <mrow>
                  <mi mathvariant="normal">
                   i
                  </mi>
                  <mi mathvariant="normal">
                   l
                  </mi>
                  <mi mathvariant="normal">
                   l
                  </mi>
                  <mi mathvariant="normal">
                   u
                  </mi>
                  <mi mathvariant="normal">
                   m
                  </mi>
                 </mrow>
                </mrow>
               </mrow>
               <mrow>
                <mn>
                 2
                </mn>
               </mrow>
              </msubsup>
             </msqrt>
            </mrow>
           </msup>
           <msup>
            <mrow>
             <mrow>
              <mrow>
               <mi mathvariant="normal">
                e
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mrow>
              <mrow>
               <mi mathvariant="normal">
                i
               </mi>
              </mrow>
             </mrow>
             <mi>
              ϕ
             </mi>
            </mrow>
           </msup>
           <msub>
            <mrow>
             <mi>
              a
             </mi>
            </mrow>
            <mrow>
             <mrow>
              <mrow>
               <mi mathvariant="normal">
                I
               </mi>
               <mi mathvariant="normal">
                C
               </mi>
              </mrow>
             </mrow>
            </mrow>
           </msub>
           <mo>
            )
           </mo>
          </mrow>
         </mtd>
        </mtr>
        <mtr>
         <mtd>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               W
              </mi>
              <mi mathvariant="normal">
               G
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           (
          </mo>
          <msup>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               e
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               i
              </mi>
             </mrow>
            </mrow>
            <mi>
             ϕ
            </mi>
           </mrow>
          </msup>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             d
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               t
              </mi>
              <mi mathvariant="normal">
               a
              </mi>
              <mi mathvariant="normal">
               r
              </mi>
              <mi mathvariant="normal">
               g
              </mi>
              <mi mathvariant="normal">
               e
              </mi>
              <mi mathvariant="normal">
               t
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           )
          </mo>
          <mo>
           =
          </mo>
          <msub>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               C
              </mi>
              <mi mathvariant="normal">
               N
              </mi>
              <mi mathvariant="normal">
               N
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               t
              </mi>
              <mi mathvariant="normal">
               a
              </mi>
              <mi mathvariant="normal">
               r
              </mi>
              <mi mathvariant="normal">
               g
              </mi>
              <mi mathvariant="normal">
               e
              </mi>
              <mi mathvariant="normal">
               t
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           (
          </mo>
          <msub>
           <mrow>
            <mi>
             f
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               f
              </mi>
              <mi mathvariant="normal">
               r
              </mi>
              <mi mathvariant="normal">
               e
              </mi>
              <mi mathvariant="normal">
               e
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           (
          </mo>
          <msub>
           <mrow>
            <mi>
             u
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               O
              </mi>
              <mi mathvariant="normal">
               C
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           (
          </mo>
          <msup>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               e
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               i
              </mi>
             </mrow>
            </mrow>
            <mi>
             ϕ
            </mi>
           </mrow>
          </msup>
          <mo>
           )
          </mo>
          <mo>
           ,
          </mo>
          <msub>
           <mrow>
            <mi>
             d
            </mi>
           </mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi mathvariant="normal">
               t
              </mi>
              <mi mathvariant="normal">
               a
              </mi>
              <mi mathvariant="normal">
               r
              </mi>
              <mi mathvariant="normal">
               g
              </mi>
              <mi mathvariant="normal">
               e
              </mi>
              <mi mathvariant="normal">
               t
              </mi>
             </mrow>
            </mrow>
           </mrow>
          </msub>
          <mo>
           )
          </mo>
          <mo>
           )
          </mo>
          <mo>
           .
          </mo>
         </mtd>
        </mtr>
       </mtable>
      </math>
      <tex-math id="Equ4_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{c}\,\,{u}_{{\rm{I}}{\rm{C}}}({{\rm{e}}}^{{\rm{i}}\phi })={{\rm{C}}{\rm{N}}{\rm{N}}}_{{\rm{I}}{\rm{C}}}({{\rm{e}}}^{-{\rm{i}}\frac{2\pi }{\lambda }\sqrt{{x}^{2}+{y}^{2}+{f}_{{\rm{i}}{\rm{l}}{\rm{l}}{\rm{u}}{\rm{m}}}^{2}}}{{\rm{e}}}^{{\rm{i}}\phi }{a}_{{\rm{I}}{\rm{C}}})\\ {f}_{{\rm{W}}{\rm{G}}}({{\rm{e}}}^{{\rm{i}}\phi },{d}_{{\rm{t}}{\rm{a}}{\rm{r}}{\rm{g}}{\rm{e}}{\rm{t}}})={{\rm{C}}{\rm{N}}{\rm{N}}}_{{\rm{t}}{\rm{a}}{\rm{r}}{\rm{g}}{\rm{e}}{\rm{t}}}({f}_{{\rm{f}}{\rm{r}}{\rm{e}}{\rm{e}}}({u}_{{\rm{O}}{\rm{C}}}({{\rm{e}}}^{{\rm{i}}\phi }),{d}_{{\rm{t}}{\rm{a}}{\rm{r}}{\rm{g}}{\rm{e}}{\rm{t}}})).\end{array}$$\end{document}
      </tex-math>
      <graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_Equ4.gif"/>
     </alternatives>
    </disp-formula>
    In
    <xref ref-type="sec" rid="Sec6">
     Methods
    </xref>
    , we detail our training procedure and CNN architecture.
    <fig id="Fig3" position="float">
     <label>
      Fig. 3
     </label>
     <caption xml:lang="en">
      <title>
       Illustration of the proposed wave propagation model.
      </title>
      <p>
       We combine physical aspects of the waveguide (highlighted in green) with artificial-intelligence components that are learned from camera feedback (highlighted in orange). In our model, the input phase pattern (left) applies a per-pixel phase delay, from 0 to 2π, to the converging illumination before the wavefront is modulated by the learned in-coupler efficiency. This wavefront is then sent through a CNN at the in-coupler plane and propagated through the waveguide, using its physically motivated transfer function, before an additional learned out-coupler efficiency is used to determine the out-coupled wavefront (centre). The latter is propagated to the target scene at various distances from the user where a CNN is applied, converting the complex-valued field into observed intensities (right). When trained on a captured dataset, the learned parameters of the CNNs, the coupler efficiencies and the waveguide propagation enable this model to accurately predict the output of our holographic AR glasses. The model is fully differentiable, enabling simple gradient descent CGH algorithms to compute the phase pattern for a target scene at runtime. The bunny scene is from
       <italic>
        Big Buck Bunny
       </italic>
       , © 2008 Blender Foundation/
       <ext-link ext-link-type="uri" xlink:href="http://www.bigbuckbunny.org">
        www.bigbuckbunny.org
       </ext-link>
       , under a Creative Commons licence
       <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/3.0/">
        CC BY 3.0
       </ext-link>
       .
      </p>
     </caption>
     <graphic mime-subtype="PNG" specific-use="web" xlink:href="/ProjectMundo/MediaObjects/10X1038_s41586-024-07386-0/41586_2024_7386_Fig3_HTML.png"/>
    </fig>
   </p>
  </sec>
  <sec id="Sec4">
   <title>
    Experimental results
   </title>
   <p id="Par18">
    Our prototype AR display combines the fabricated metasurface waveguide with a HOLOEYE LETO-3 phase-only SLM. This SLM has a resolution of 1080 × 1920 pixels with a pitch of 6.4 μm. A FISBA READYBeam fibre-coupled module with optically aligned red, green and blue laser diodes with wavelengths of 638, 521 and 445 nm is used as the light source. Since our illumination comes through the back of our waveguide, we slightly tilt our SLM and illumination, so that our digital content is not obscured by any unwanted light that is coupled into the waveguide before reaching the SLM. We capture calibration data for our artificial-intelligence-based wave propagation model and also capture results of using a FLIR Grasshopper3 12.3 MP colour USB3 sensor through a Canon EF 35 mm lens with an Arduino controlling the focus of the lens. Following recent work
    <sup>
     <xref ref-type="bibr" rid="CR42">
      42
     </xref>
    </sup>
    , our experimental setup operates in a partially coherent setting where a few coherent modes are multiplexed in time to achieve optimal 3D holographic image quality with realistic depth-of-field effects. All holograms are computed using a gradient descent computer-generated holography (CGH) algorithm
    <sup>
     <xref ref-type="bibr" rid="CR26">
      26
     </xref>
    </sup>
    that incorporates our camera-calibrated wave propagation model.
   </p>
   <p id="Par19">
    We show experimentally captured results from our prototype in Fig.
    <xref ref-type="fig" rid="Fig4">
     4
    </xref>
    . In Fig.
    <xref ref-type="fig" rid="Fig4">
     4a
    </xref>
    , we qualitatively and quantitatively assess the 2D image quality and compare a naive free-space propagation model, a physically motivated wave propagation model using the rigorous-coupled-wave-analysis-simulated transfer functions and the proposed artificial-intelligence-based variant combining the physical model with camera-calibrated learnable parameters. In all examples, the artificial-intelligence-based wave propagation model outperforms the baselines by a large margin of 3–5 dB peak signal-to-noise ratio. The full-colour 3D results shown in Fig.
    <xref ref-type="fig" rid="Fig4">
     4b
    </xref>
    validate the high image quality our system achieves for both in- and out-of-focus regions of the presented digital content. The accurate depiction of 3D defocus behaviour can mitigate the vergence–accommodation conflict and associated discomfort for users of our display system. To our knowledge, no existing waveguide-based AR display has demonstrated full-colour 3D results with a comparable quality
    <sup>
     <xref ref-type="bibr" rid="CR25">
      25
     </xref>
     ,
     <xref ref-type="bibr" rid="CR43">
      43
     </xref>
    </sup>
    . Finally, we also show experimental full-colour 3D results in Fig.
    <xref ref-type="fig" rid="Fig4">
     4c
    </xref>
    where we optically combine a physical scene with digitally overlaid content and capture the scene using different focus settings of the camera. Again, our approach outperforms baseline models by a large margin.
    <fig id="Fig4" position="float">
     <label>
      Fig. 4
     </label>
     <caption xml:lang="en">
      <title>
       Experimental results captured through our compact holographic display prototype.
      </title>
      <p>
       <bold>
        a
       </bold>
       , Comparison of 2D holograms synthesized using several different wave propagation models, including free-space propagation, a physically motivated model and our proposed model combining physics and learnable parameters that are calibrated using camera feedback.
       <bold>
        b
       </bold>
       , Comparison of two 3D holograms. Zoomed-in crops show the scene with the camera focused at different depths. Blue boxes highlight content that the camera is focused on while white boxes emphasize camera defocus.
       <bold>
        c
       </bold>
       , Comparison of a 3D hologram captured in an optical-see-through AR mode. The bird, fish and butterfly are digitally superimposed objects, and the elephant and letters are part of the physical environment. In all examples, the proposed wave propagation model represents the physical optics much more accurately, resulting in significant image quality improvements over alternative models. In
       <bold>
        a
       </bold>
       , the squirrel scene is from
       <italic>
        Big Buck Bunny
       </italic>
       , © 2008 Blender Foundation/
       <ext-link ext-link-type="uri" xlink:href="http://www.bigbuckbunny.org">
        www.bigbuckbunny.org
       </ext-link>
       , under a Creative Commons licence CC BY 3.0. In
       <bold>
        b
       </bold>
       , couch and market target scenes are, respectively, from the High Spatio-Angular Light Field dataset
       <sup>
        <xref ref-type="bibr" rid="CR49">
         49
        </xref>
       </sup>
       and the Durian Open Movie project (© copyright Blender Foundation/
       <ext-link ext-link-type="uri" xlink:href="http://durian.blender.org">
        durian.blender.org
       </ext-link>
       ) under a Creative Commons licence
       <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/3.0/">
        CC BY 3.0
       </ext-link>
       .
      </p>
     </caption>
     <graphic mime-subtype="PNG" specific-use="web" xlink:href="/ProjectMundo/MediaObjects/10X1038_s41586-024-07386-0/41586_2024_7386_Fig4_HTML.png"/>
    </fig>
   </p>
  </sec>
  <sec id="Sec5" sec-type="discussion">
   <title>
    Discussion
   </title>
   <p id="Par20">
    The co-design of a metasurface waveguide and artificial-intelligence-based holography algorithms facilitates a compact full-colour 3D holographic OST AR display system. To our knowledge, no system with comparable characteristics has previously been described and our experimental image quality far exceeds that demonstrated by related waveguide designs for non-see-through applications
    <sup>
     <xref ref-type="bibr" rid="CR25">
      25
     </xref>
    </sup>
    .
   </p>
   <p id="Par21">
    The field of view of our waveguide design is currently limited to 11.7°. While this is comparable to many commercial AR systems, it would be desirable to enlarge it. This could be achieved using higher refractive index materials for the waveguide or by engineering an additional metasurface eyepiece into the out-coupler. Related ideas have recently been explored for other optical AR system designs
    <sup>
     <xref ref-type="bibr" rid="CR23">
      23
     </xref>
    </sup>
    , which could be adapted to ours. Our waveguide is compact, but it would be interesting to further reduce its thickness
    <italic>
     d
    </italic>
    <sub>
     wg
    </sub>
    . In our
    <xref ref-type="supplementary-material" rid="MOESM1">
     Supplementary Information
    </xref>
    , we derive the relationship between waveguide thickness, SLM size
    <italic>
     L
    </italic>
    <sub>
     slm
    </sub>
    and nasal field of view
    <italic>
     θ
    </italic>
    <sub>
     −
    </sub>
    as
    <disp-formula id="Equ5">
     <label>
      5
     </label>
     <alternatives>
      <math display="block" id="Equ5_Math" xmlns="http://www.w3.org/1998/Math/MathML">
       <mrow>
        <msub>
         <mrow>
          <mi>
           d
          </mi>
         </mrow>
         <mrow>
          <mi mathvariant="normal">
           wg
          </mi>
         </mrow>
        </msub>
        <mo>
         ≥
        </mo>
        <mfrac>
         <mrow>
          <msub>
           <mrow>
            <mi>
             L
            </mi>
           </mrow>
           <mrow>
            <mi mathvariant="normal">
             slm
            </mi>
           </mrow>
          </msub>
         </mrow>
         <mrow>
          <mn>
           2
          </mn>
          <mi>
           tan
          </mi>
          <mrow>
           <mrow>
            <mfenced close=")" open="(">
             <mrow>
              <msup>
               <mrow>
                <mi>
                 sin
                </mi>
               </mrow>
               <mrow>
                <mo>
                 −
                </mo>
                <mn>
                 1
                </mn>
               </mrow>
              </msup>
              <mrow>
               <mrow>
                <mfenced close="]" open="[">
                 <mrow>
                  <mrow>
                   <mrow>
                    <mfenced close=")" open="(">
                     <mrow>
                      <mfrac>
                       <mrow>
                        <msub>
                         <mrow>
                          <mi>
                           λ
                          </mi>
                         </mrow>
                         <mrow>
                          <mi mathvariant="normal">
                           B
                          </mi>
                         </mrow>
                        </msub>
                       </mrow>
                       <mrow>
                        <mi mathvariant="normal">
                         Λ
                        </mi>
                       </mrow>
                      </mfrac>
                      <mo>
                       −
                      </mo>
                      <mi>
                       sin
                      </mi>
                      <mrow>
                       <mo>
                        (
                       </mo>
                       <mrow>
                        <msub>
                         <mrow>
                          <mi>
                           θ
                          </mi>
                         </mrow>
                         <mrow>
                          <mo>
                           −
                          </mo>
                         </mrow>
                        </msub>
                       </mrow>
                       <mo>
                        )
                       </mo>
                      </mrow>
                     </mrow>
                    </mfenced>
                   </mrow>
                  </mrow>
                  <mfrac>
                   <mrow>
                    <mn>
                     1
                    </mn>
                   </mrow>
                   <mrow>
                    <mi>
                     n
                    </mi>
                    <mrow>
                     <mo>
                      (
                     </mo>
                     <mrow>
                      <msub>
                       <mrow>
                        <mi>
                         λ
                        </mi>
                       </mrow>
                       <mrow>
                        <mi mathvariant="normal">
                         B
                        </mi>
                       </mrow>
                      </msub>
                     </mrow>
                     <mo>
                      )
                     </mo>
                    </mrow>
                   </mrow>
                  </mfrac>
                 </mrow>
                </mfenced>
               </mrow>
              </mrow>
             </mrow>
            </mfenced>
           </mrow>
          </mrow>
         </mrow>
        </mfrac>
        <mo>
         .
        </mo>
       </mrow>
      </math>
      <tex-math id="Equ5_TeX">
       \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{{\rm{wg}}}\ge \frac{{L}_{{\rm{slm}}}}{2\tan \left({\sin }^{-1}\left[\left(\frac{{\lambda }_{{\rm{B}}}}{\Lambda }-\sin ({\theta }_{-})\right)\frac{1}{n({\lambda }_{{\rm{B}}})}\right]\right)}.$$\end{document}
      </tex-math>
      <graphic mime-subtype="GIF" specific-use="web" xlink:href="41586_2024_7386_Article_Equ5.gif"/>
     </alternatives>
    </disp-formula>
    This equation shows that the thickness of the waveguide is directly proportional to the SLM size, among other factors. Therefore, the most promising path to reducing the thickness of the waveguide is to use a smaller SLM. There is a clear path to achieving this with emerging SLMs that provide very small pixel pitches, down to 1 μm (ref.
    <sup>
     <xref ref-type="bibr" rid="CR44">
      44
     </xref>
    </sup>
    ), compared with the 6.4 μm of our SLM. Although not commercially available yet, these SLMs would enable ultrathin waveguides using our approach.
   </p>
   <p id="Par22">
    Similar to all holographic displays, the étendue of our display is limited by the space–bandwidth product of the SLM. Étendue expansion techniques
    <sup>
     <xref ref-type="bibr" rid="CR7">
      7
     </xref>
     ,
     <xref ref-type="bibr" rid="CR43">
      43
     </xref>
     ,
     <xref ref-type="bibr" rid="CR45">
      45
     </xref>
     ,
     <xref ref-type="bibr" rid="CR46">
      46
     </xref>
     –
     <xref ref-type="bibr" rid="CR47">
      47
     </xref>
    </sup>
    could be adapted to our settings, although no such technique has been demonstrated to support full-colour 3D waveguide holography. Another potential direction for future work would be to combine our design with an illumination waveguide as shown in prior work for a compact illumination path
    <sup>
     <xref ref-type="bibr" rid="CR25">
      25
     </xref>
    </sup>
    . Finally, we have not attempted to optimize the efficiency of our CGH algorithm at runtime. While hologram generation currently takes several minutes per phase pattern, recent methods have shown that real-time inversion of wave propagation models for hologram synthesis can be achieved using machine-learning approaches
    <sup>
     <xref ref-type="bibr" rid="CR26">
      26
     </xref>
     ,
     <xref ref-type="bibr" rid="CR27">
      27
     </xref>
     ,
     <xref ref-type="bibr" rid="CR29">
      29
     </xref>
     ,
     <xref ref-type="bibr" rid="CR48">
      48
     </xref>
    </sup>
    .
   </p>
   <p id="Par23">
    The proposed co-design of nanophotonic hardware and artificial-intelligence-driven algorithms enables optical-see-through AR display modes in smaller form factors and with higher 3D image quality than any existing approach of which we are aware, enabling a path towards true 3D holographic AR glasses.
   </p>
  </sec>
  <sec id="Sec6" sec-type="materials|methods" specific-use="web-only">
   <title>
    Methods
   </title>
   <sec id="Sec7">
    <title>
     Fabrication details
    </title>
    <p id="Par24">
     The fabrication procedure begins by coating the substrate with a 30-nm-thick Chromium (Cr) film through e-beam evaporation (Kurt J. Lesker Company). We then proceed to an e-beam lithography process (Raith Voyager) using a 50 kV e-beam to accurately create the metasurface patterns with a dimension of 6.5 mm by 6.5 mm for the in-coupler and 6.5 mm by 7.1 mm for the out-coupler, after spin-coating a positive-tone e-beam resist layer (950 PMMA a4, 1000 rpm for 60 s), post-backing the PMMA layer (180 °C for 5 min) and spin-coating a charge dissipation layer (e-spacer, Showa Denko). Then the patterns are transferred onto the high-index glass substrate using multiple dry etching steps. These steps involve an inductively coupled plasma reactive ion etcher (ICP-RIE, PlasmaTherm Metal Etcher) for Cr etching with the PMMA mask and a reactive ion etcher (RIE, Oxford Dielectric Etcher) for glass etching with the Cr mask, with a specific gas mixture of Cl
     <sub>
      2
     </sub>
     , O
     <sub>
      2
     </sub>
     , CHF
     <sub>
      3
     </sub>
     , CF
     <sub>
      4
     </sub>
     and Ar, and further aided by helium backside cooling. The remaining Cr mask is eliminated by an additional ICP-RIE process. Figure
     <xref ref-type="fig" rid="Fig2">
      2d
     </xref>
     presents the scanning electron microscope images of the precisely fabricated all-glass metasurface couplers.
    </p>
    <p id="Par25">
     Metasurface sample images are taken by a scanning electron microscope (FEI Nova NanoSEM 450). The representative samples are coated with a thin 3 nm film of gold/palladium to reduce charing in the images. Images are acquired with an accelerating voltage of 10 kV.
    </p>
   </sec>
   <sec id="Sec8">
    <title>
     CNN network architecture
    </title>
    <p id="Par26">
     Our CNNs, CNN
     <sub>
      IC
     </sub>
     and CNN
     <sub>
      target
     </sub>
     , use a modified UNet architecture
     <sup>
      <xref ref-type="bibr" rid="CR50">
       50
      </xref>
     </sup>
     to efficiently learn the residual aberrations in a physical optical system. The input wavefront is augmented by concatenating its real and imaginary values with their corresponding amplitude and phase components. After the input layer, both CNNs use 32 feature channels and perform five downsampling operations using strided convolutions, as well as five upsampling operations using transposed convolutions. The networks use instance normalization
     <sup>
      <xref ref-type="bibr" rid="CR51">
       51
      </xref>
     </sup>
     , leaky rectified linear unit activation (slope −0.2) for the down blocks, rectified linear unit nonlinearities for the up blocks and skip connections. CNN
     <sub>
      IC
     </sub>
     has two-channel outputs representing the real and imaginary values, while CNN
     <sub>
      target
     </sub>
     directly outputs a single-channel amplitude.
     <italic>
      a
     </italic>
     <sub>
      IC
     </sub>
     and
     <italic>
      a
     </italic>
     <sub>
      OC
     </sub>
     are the binary aperture functions of the grating couplers for the physically motivated wave propagation model. When using the artificial-intelligence-augmented model, these quantities are complex-valued fields that are learned per colour channel.
    </p>
   </sec>
   <sec id="Sec9">
    <title>
     Training the waveguide model
    </title>
    <p id="Par27">
     We train our neural-network-parameterized wave propagation model using a dataset comprising a large number of pairs of SLM phase patterns and corresponding intensity images captured by a camera focusing at different depths at the output of our prototype holographic display. The SLM phase patterns in our dataset are generated using our physical waveguide model to produce images from the DIV2K dataset, at different virtual distances through the waveguide. The model is trained over four intensity planes, corresponding to 0 D (
     <italic>
      ∞
     </italic>
     m), 0.33 D (3 m), 0.67 D (1.5 m), 1.0 D (1 m) in the physical space. We perform our model training on a 48 GB NVIDIA RTX A6000 with a batch size of 1 and a learning rate of 3 × 10
     <sup>
      −4
     </sup>
     . We note that the diversity of phase patterns is important for the model training. A dataset generated using the gradient descent CGH algorithm
     <sup>
      <xref ref-type="bibr" rid="CR26">
       26
      </xref>
     </sup>
     typically consists of holographic images that primarily cover a narrow angular spectrum. Thus, we generate phase patterns with a set of random parameters, including learning rates, initial phase distribution and propagation distances. We generate 10,000 patterns for each channel and capture the corresponding intensities. The dataset is divided into training, validation and test sets with a ratio of 8:1:1. The initially trained model can be used to synthesize an additional phase dataset that is used to refine the model. Such a refinement stage improves the experimental quality. We perform this refinement procedure twice for the best quality. After this training procedure, we use our learned waveguide propagation model to synthesize holograms for new 2D and 3D scenes enabling our holographic AR glasses to operate without any additional camera feedback.
    </p>
   </sec>
  </sec>
  <sec id="Sec10" sec-type="materials|methods" specific-use="print-only">
   <title>
    Online content
   </title>
   <p id="Par28">
    Any methods, additional references, Nature Portfolio reporting summaries, source data, extended data, supplementary information, acknowledgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41586-024-07386-0">
     https://doi.org/10.1038/s41586-024-07386-0
    </ext-link>
    .
   </p>
  </sec>
 </body>
 <back>
  <ack>
   <title>
    Acknowledgements
   </title>
   <p>
    M.G. is supported by a Stanford Graduate Fellowship in Science and Engineering. G.-Y.L. is supported by a Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (2022R1A6A3A03073823). S.C. is supported by a Kwanjeong Scholarship and a Meta Research PhD Fellowship. B.C. is supported by a Stanford Graduate Fellowship in Science and Engineering and a National Science Foundation Graduate Research Fellowship. G.W. is supported by the ARO (PECASE Award W911NF-19-1-0120), Samsung and the Sony Research Award Program. Part of this work was performed at the Stanford Nano Shared Facilities (SNSF) and Stanford Nanofabrication Facility (SNF), supported by the National Science Foundation and the National Nanotechnology Coordinated Infrastructure under award ECCS-2026822. We also thank Y. Park for her ongoing support.
   </p>
  </ack>
  <sec sec-type="author-contribution">
   <title>
    Author contributions
   </title>
   <p>
    M.G. developed the experimental setup and captured the measurements. G.-Y.L. designed and fabricated the metasurface waveguide and performed the theoretical analysis, numerical simulations and experimental measurements on metasurfaces. M.G. and S.C. developed and implemented the algorithmic procedures with input from G.-Y.L., B.C., Y.P. and J.K. G.W. conceived the method and supervised all aspects of the project. All authors took part in designing the experiments and writing the paper and the
    <xref ref-type="supplementary-material" rid="MOESM1">
     Supplementary Information
    </xref>
    .
   </p>
  </sec>
  <sec sec-type="peer-review">
   <title>
    Peer review
   </title>
   <sec id="FPar1">
    <title>
     Peer review information
    </title>
    <p id="Par29">
     <italic>
      Nature
     </italic>
     thanks Ni Chen, Lingling Huang and Tim Wilkinson for their contribution to the peer review of this work.
    </p>
   </sec>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Data availability
   </title>
   <p>
    A full-colour captured dataset specific to our holographic AR glasses prototype is available upon request.
   </p>
  </sec>
  <sec sec-type="data-availability">
   <title>
    Code availability
   </title>
   <p>
    Computer code supporting the findings of this study is available online at
    <ext-link ext-link-type="uri" xlink:href="https://github.com/computational-imaging/holographic-AR-glasses.git">
     https://github.com/computational-imaging/holographic-AR-glasses.git
    </ext-link>
    .
   </p>
  </sec>
  <sec sec-type="ethics-statement">
   <sec id="FPar2" sec-type="COI-statement">
    <title>
     Competing interests
    </title>
    <p id="Par30">
     The authors declare no competing interests.
    </p>
   </sec>
  </sec>
  <ref-list id="Bib1">
   <title>
    References
   </title>
   <ref-list>
    <ref id="CR1">
     <label>
      1.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Azuma
        </surname>
        <given-names>
         RT
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       A survey of augmented reality
      </article-title>
      <source>
       Presence: Teleoperators Virtual Environ.
      </source>
      <year>
       1997
      </year>
      <volume>
       6
      </volume>
      <fpage>
       355
      </fpage>
      <lpage>
       385
      </lpage>
      <pub-id pub-id-type="doi">
       10.1162/pres.1997.6.4.355
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR2">
     <label>
      2.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Xiong
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Hsiang
        </surname>
        <given-names>
         E-L
        </given-names>
       </name>
       <name>
        <surname>
         He
        </surname>
        <given-names>
         Z
        </given-names>
       </name>
       <name>
        <surname>
         Zhan
        </surname>
        <given-names>
         T
        </given-names>
       </name>
       <name>
        <surname>
         Wu
        </surname>
        <given-names>
         S-T
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Augmented reality and virtual reality displays: emerging technologies and future perspectives
      </article-title>
      <source>
       Light: Sci. Appl.
      </source>
      <year>
       2021
      </year>
      <volume>
       10
      </volume>
      <fpage>
       216
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021LSA....10..216X
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitlamt77M
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41377-021-00658-8
      </pub-id>
      <pub-id pub-id-type="pmid">
       34697292
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR3">
     <label>
      3.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chang
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Bang
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Wetzstein
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <name>
        <surname>
         Lee
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <name>
        <surname>
         Gao
        </surname>
        <given-names>
         L
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Toward the next-generation VR/AR optics: a review of holographic near-eye displays from a human-centric perspective
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2020
      </year>
      <volume>
       7
      </volume>
      <fpage>
       1563
      </fpage>
      <lpage>
       1578
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020Optic...7.1563C
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.406004
      </pub-id>
      <pub-id pub-id-type="pmid">
       34141829
      </pub-id>
      <pub-id pub-id-type="pmcid">
       8208705
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR4">
     <label>
      4.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Kooi
        </surname>
        <given-names>
         FL
        </given-names>
       </name>
       <name>
        <surname>
         Toet
        </surname>
        <given-names>
         A
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Visual comfort of binocular and 3D displays
      </article-title>
      <source>
       Displays
      </source>
      <year>
       2004
      </year>
      <volume>
       25
      </volume>
      <fpage>
       99
      </fpage>
      <lpage>
       108
      </lpage>
      <pub-id pub-id-type="doi">
       10.1016/j.displa.2004.07.004
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR5">
     <label>
      5.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shibata
        </surname>
        <given-names>
         T
        </given-names>
       </name>
       <name>
        <surname>
         Kim
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Hoffman
        </surname>
        <given-names>
         DM
        </given-names>
       </name>
       <name>
        <surname>
         Banks
        </surname>
        <given-names>
         MS
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       The zone of comfort: predicting visual discomfort with stereo displays
      </article-title>
      <source>
       J. Vis.
      </source>
      <year>
       2011
      </year>
      <volume>
       11
      </volume>
      <fpage>
       11
      </fpage>
      <lpage>
       11
      </lpage>
      <pub-id pub-id-type="doi">
       10.1167/11.8.11
      </pub-id>
      <pub-id pub-id-type="pmid">
       21778252
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR6">
     <label>
      6.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Cakmakci
        </surname>
        <given-names>
         O
        </given-names>
       </name>
       <name>
        <surname>
         Rolland
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Head-worn displays: a review
      </article-title>
      <source>
       J. Disp. Technol.
      </source>
      <year>
       2006
      </year>
      <volume>
       2
      </volume>
      <fpage>
       199
      </fpage>
      <lpage>
       216
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2006JDisT...2..199C
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1109/JDT.2006.879846
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR7">
     <label>
      7.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Kress
        </surname>
        <given-names>
         BC
        </given-names>
       </name>
       <name>
        <surname>
         Chatterjee
        </surname>
        <given-names>
         I
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Waveguide combiners for mixed reality headsets: a nanophotonics design perspective
      </article-title>
      <source>
       Nanophotonics
      </source>
      <year>
       2021
      </year>
      <volume>
       10
      </volume>
      <fpage>
       41
      </fpage>
      <lpage>
       74
      </lpage>
      <pub-id pub-id-type="doi">
       10.1515/nanoph-2020-0410
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR8">
     <label>
      8.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Gabor
        </surname>
        <given-names>
         D
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       A new microscopic principle
      </article-title>
      <source>
       Nature
      </source>
      <year>
       1949
      </year>
      <volume>
       161
      </volume>
      <fpage>
       777
      </fpage>
      <lpage>
       778
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       1948Natur.161..777G
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/161777a0
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR9">
     <label>
      9.
     </label>
     <mixed-citation publication-type="other">
      Sutherland, I. E. The ultimate display. In
      <italic>
       Proc. of the IFIP Congress
      </italic>
      (ed. Kalenich, W. A.)
      <bold>
       2
      </bold>
      , 506–508 (Spartan, 1965).
     </mixed-citation>
    </ref>
    <ref id="CR10">
     <label>
      10.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Tay
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       An updatable holographic three-dimensional display
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2008
      </year>
      <volume>
       451
      </volume>
      <fpage>
       694
      </fpage>
      <lpage>
       698
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2008Natur.451..694T
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BD1cXhs1Kns70%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature06596
      </pub-id>
      <pub-id pub-id-type="pmid">
       18256667
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR11">
     <label>
      11.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Blanche
        </surname>
        <given-names>
         P-A
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Holographic three-dimensional telepresence using large-area photorefractive polymer
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2010
      </year>
      <volume>
       468
      </volume>
      <fpage>
       80
      </fpage>
      <lpage>
       83
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2010Natur.468...80B
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3cXhtlOht7nN
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature09521
      </pub-id>
      <pub-id pub-id-type="pmid">
       21048763
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR12">
     <label>
      12.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Smalley
        </surname>
        <given-names>
         DE
        </given-names>
       </name>
       <name>
        <surname>
         Smithwick
        </surname>
        <given-names>
         Q
        </given-names>
       </name>
       <name>
        <surname>
         Bove
        </surname>
        <given-names>
         V
        </given-names>
       </name>
       <name>
        <surname>
         Barabas
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Jolly
        </surname>
        <given-names>
         S
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Anisotropic leaky-mode modulator for holographic video displays
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2013
      </year>
      <volume>
       498
      </volume>
      <fpage>
       313
      </fpage>
      <lpage>
       317
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2013Natur.498..313S
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC3sXpslGht7k%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/nature12217
      </pub-id>
      <pub-id pub-id-type="pmid">
       23783627
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR13">
     <label>
      13.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Maimone
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Georgiou
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Kollin
        </surname>
        <given-names>
         JS
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Holographic near-eye displays for virtual and augmented reality
      </article-title>
      <source>
       ACM Trans. Graph.
      </source>
      <year>
       2017
      </year>
      <volume>
       36
      </volume>
      <fpage>
       85
      </fpage>
      <pub-id pub-id-type="doi">
       10.1145/3072959.3073624
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR14">
     <label>
      14.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Molesky
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Inverse design in nanophotonics
      </article-title>
      <source>
       Nat. Photon.
      </source>
      <year>
       2018
      </year>
      <volume>
       12
      </volume>
      <fpage>
       659
      </fpage>
      <lpage>
       670
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2018NaPho..12..659M
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXitVent7zI
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41566-018-0246-9
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR15">
     <label>
      15.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Z
        </given-names>
       </name>
       <name>
        <surname>
         Pestourie
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Lin
        </surname>
        <given-names>
         Z
        </given-names>
       </name>
       <name>
        <surname>
         Johnson
        </surname>
        <given-names>
         SG
        </given-names>
       </name>
       <name>
        <surname>
         Capasso
        </surname>
        <given-names>
         F
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Empowering metasurfaces with inverse design: principles and applications
      </article-title>
      <source>
       ACS Photonics
      </source>
      <year>
       2022
      </year>
      <volume>
       9
      </volume>
      <fpage>
       2178
      </fpage>
      <lpage>
       2192
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XhsVOgt7rF
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1021/acsphotonics.1c01850
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR16">
     <label>
      16.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jiang
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Fan
        </surname>
        <given-names>
         JA
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep neural networks for the evaluation and design of photonic devices
      </article-title>
      <source>
       Nat. Rev. Mater.
      </source>
      <year>
       2021
      </year>
      <volume>
       6
      </volume>
      <fpage>
       679
      </fpage>
      <lpage>
       700
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021NatRM...6..679J
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41578-020-00260-1
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR17">
     <label>
      17.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Genevet
        </surname>
        <given-names>
         P
        </given-names>
       </name>
       <name>
        <surname>
         Capasso
        </surname>
        <given-names>
         F
        </given-names>
       </name>
       <name>
        <surname>
         Aieta
        </surname>
        <given-names>
         F
        </given-names>
       </name>
       <name>
        <surname>
         Khorasaninejad
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <name>
        <surname>
         Devlin
        </surname>
        <given-names>
         R
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Recent advances in planar optics: from plasmonic to dielectric metasurfaces
      </article-title>
      <source>
       Optica
      </source>
      <year>
       2017
      </year>
      <volume>
       4
      </volume>
      <fpage>
       139
      </fpage>
      <lpage>
       152
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017Optic...4..139G
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXjsFGisLw%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OPTICA.4.000139
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR18">
     <label>
      18.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lee
        </surname>
        <given-names>
         G-Y
        </given-names>
       </name>
       <name>
        <surname>
         Sung
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Lee
        </surname>
        <given-names>
         B
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Metasurface optics for imaging applications
      </article-title>
      <source>
       MRS Bull.
      </source>
      <year>
       2020
      </year>
      <volume>
       45
      </volume>
      <fpage>
       202
      </fpage>
      <lpage>
       209
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020MRSBu..45..202R
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1557/mrs.2020.64
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR19">
     <label>
      19.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lin
        </surname>
        <given-names>
         D
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Optical metasurfaces for high angle steering at visible wavelengths
      </article-title>
      <source>
       Sci. Rep.
      </source>
      <year>
       2017
      </year>
      <volume>
       7
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2017NatSR...7.2286L
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41598-017-02167-4
      </pub-id>
      <pub-id pub-id-type="pmid">
       28536465
      </pub-id>
      <pub-id pub-id-type="pmcid">
       5442109
      </pub-id>
      <elocation-id>
       2286
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR20">
     <label>
      20.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Song
        </surname>
        <given-names>
         J-H
        </given-names>
       </name>
       <name>
        <surname>
         van de Groep
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Kim
        </surname>
        <given-names>
         SJ
        </given-names>
       </name>
       <name>
        <surname>
         Brongersma
        </surname>
        <given-names>
         ML
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Non-local metasurfaces for spectrally decoupled wavefront manipulation and eye tracking
      </article-title>
      <source>
       Nat. Nanotechnol.
      </source>
      <year>
       2021
      </year>
      <volume>
       16
      </volume>
      <fpage>
       1224
      </fpage>
      <lpage>
       1230
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021NatNa..16.1224S
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXitFGru7fP
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41565-021-00967-4
      </pub-id>
      <pub-id pub-id-type="pmid">
       34594006
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR21">
     <label>
      21.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Lawrence
        </surname>
        <given-names>
         M
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       High quality factor phase gradient metasurfaces
      </article-title>
      <source>
       Nat. Nanotechnol.
      </source>
      <year>
       2020
      </year>
      <volume>
       15
      </volume>
      <fpage>
       956
      </fpage>
      <lpage>
       961
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2020NatNa..15..956L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXhs1aqt7bK
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41565-020-0754-x
      </pub-id>
      <pub-id pub-id-type="pmid">
       32807879
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR22">
     <label>
      22.
     </label>
     <mixed-citation publication-type="other">
      Cordaro, A. et al. Solving integral equations in free space with inverse-designed ultrathin optical metagratings.
      <italic>
       Nat. Nanotechnol.
      </italic>
      <bold>
       18
      </bold>
      , 365–372 (2023).
     </mixed-citation>
    </ref>
    <ref id="CR23">
     <label>
      23.
     </label>
     <mixed-citation publication-type="other">
      Lee, G.-Y. et al. Metasurface eyepiece for augmented reality.
      <italic>
       Nat. Commun.
      </italic>
      <bold>
       9
      </bold>
      , 4562 (2018).
     </mixed-citation>
    </ref>
    <ref id="CR24">
     <label>
      24.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Joo
        </surname>
        <given-names>
         W-J
        </given-names>
       </name>
       <name>
        <surname>
         Brongersma
        </surname>
        <given-names>
         ML
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Creating the ultimate virtual reality display
      </article-title>
      <source>
       Science
      </source>
      <year>
       2022
      </year>
      <volume>
       377
      </volume>
      <fpage>
       1376
      </fpage>
      <lpage>
       1378
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022Sci...377.1376J
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFOrurnI
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/science.abq7011
      </pub-id>
      <pub-id pub-id-type="pmid">
       36137048
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR25">
     <label>
      25.
     </label>
     <mixed-citation publication-type="other">
      Kim, J. et al. Holographic glasses for virtual reality. In
      <italic>
       ACM SIGGRAPH 2022 Conference Proc.
      </italic>
      (eds Nandigjav, M. et al.) 33 (ACM, 2022).
     </mixed-citation>
    </ref>
    <ref id="CR26">
     <label>
      26.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Peng
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Choi
        </surname>
        <given-names>
         S
        </given-names>
       </name>
       <name>
        <surname>
         Padmanaban
        </surname>
        <given-names>
         N
        </given-names>
       </name>
       <name>
        <surname>
         Wetzstein
        </surname>
        <given-names>
         G
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Neural holography with camera-in-the-loop training
      </article-title>
      <source>
       ACM Trans. Graph.
      </source>
      <year>
       2020
      </year>
      <volume>
       39
      </volume>
      <fpage>
       185
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisVGgs7vL
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1145/3414685.3417802
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR27">
     <label>
      27.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Shi
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         B
        </given-names>
       </name>
       <name>
        <surname>
         Kim
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Kellnhofer
        </surname>
        <given-names>
         P
        </given-names>
       </name>
       <name>
        <surname>
         Matusik
        </surname>
        <given-names>
         W
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Towards real-time photorealistic 3D holography with deep neural networks
      </article-title>
      <source>
       Nature
      </source>
      <year>
       2021
      </year>
      <volume>
       591
      </volume>
      <fpage>
       234
      </fpage>
      <lpage>
       239
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021Natur.591..234S
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXmt1emsLo%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41586-020-03152-0
      </pub-id>
      <pub-id pub-id-type="pmid">
       33692557
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR28">
     <label>
      28.
     </label>
     <mixed-citation publication-type="other">
      Peng, Y., Choi, S., Kim, J. &amp; Wetzstein, G. Speckle-free holography with partially coherent light sources and camera-in-the-loop calibration.
      <italic>
       Sci. Adv.
      </italic>
      <bold>
       7
      </bold>
      , eabg5040 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR29">
     <label>
      29.
     </label>
     <mixed-citation publication-type="other">
      Shi, L., Li, B. &amp; Matusik, W. End-to-end learning of 3D phase-only holograms for holographic display.
      <italic>
       Light Sci. Appl.
      </italic>
      <bold>
       11
      </bold>
      , 247 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR30">
     <label>
      30.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Yeom
        </surname>
        <given-names>
         H-J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       3d holographic head mounted display using holographic optical elements with astigmatism aberration compensation
      </article-title>
      <source>
       Opt, Express
      </source>
      <year>
       2015
      </year>
      <volume>
       23
      </volume>
      <fpage>
       32025
      </fpage>
      <lpage>
       32034
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2015OExpr..2332025Y
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OE.23.032025
      </pub-id>
      <pub-id pub-id-type="pmid">
       26698993
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR31">
     <label>
      31.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jeong
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Holographically customized optical combiner for eye-box extended near-eye display
      </article-title>
      <source>
       Opt. Express
      </source>
      <year>
       2019
      </year>
      <volume>
       27
      </volume>
      <fpage>
       38006
      </fpage>
      <lpage>
       38018
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2019OExpr..2738006J
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OE.382190
      </pub-id>
      <pub-id pub-id-type="pmid">
       31878572
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR32">
     <label>
      32.
     </label>
     <mixed-citation publication-type="other">
      Yeom, J., Son, Y. &amp; Choi, K. Crosstalk reduction in voxels for a see-through holographic waveguide by using integral imaging with compensated elemental images.
      <italic>
       Photonics
      </italic>
      <bold>
       8
      </bold>
      , 217 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR33">
     <label>
      33.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Choi
        </surname>
        <given-names>
         M-H
        </given-names>
       </name>
       <name>
        <surname>
         Shin
        </surname>
        <given-names>
         K-S
        </given-names>
       </name>
       <name>
        <surname>
         Jang
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Han
        </surname>
        <given-names>
         W
        </given-names>
       </name>
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         J-H
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Waveguide-type Maxwellian near-eye display using a pin-mirror holographic optical element array
      </article-title>
      <source>
       Opt. Lett.
      </source>
      <year>
       2022
      </year>
      <volume>
       47
      </volume>
      <fpage>
       405
      </fpage>
      <lpage>
       408
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2022OptL...47..405C
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/OL.443004
      </pub-id>
      <pub-id pub-id-type="pmid">
       35030617
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR34">
     <label>
      34.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chen
        </surname>
        <given-names>
         WT
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       A broadband achromatic metalens for focusing and imaging in the visible
      </article-title>
      <source>
       Nat. Nanotechnol.
      </source>
      <year>
       2018
      </year>
      <volume>
       13
      </volume>
      <fpage>
       220
      </fpage>
      <lpage>
       226
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2018NatNa..13..220C
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1cXis1OitQ%3D%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41565-017-0034-6
      </pub-id>
      <pub-id pub-id-type="pmid">
       29292382
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR35">
     <label>
      35.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         Z
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Meta-optics achieves RGB-achromatic focusing for virtual reality
      </article-title>
      <source>
       Sci. Adv.
      </source>
      <year>
       2021
      </year>
      <volume>
       7
      </volume>
      <fpage>
       eabe4458
      </fpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2021SciA....7.4458L
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3MXlsFCltr4%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1126/sciadv.abe4458
      </pub-id>
      <pub-id pub-id-type="pmid">
       33571130
      </pub-id>
      <pub-id pub-id-type="pmcid">
       7840120
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR36">
     <label>
      36.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Kim
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Lee
        </surname>
        <given-names>
         B
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Torcwa: GPU-accelerated Fourier modal method and gradient-based optimization for metasurface design
      </article-title>
      <source>
       Comput. Phys. Comm.
      </source>
      <year>
       2023
      </year>
      <volume>
       282
      </volume>
      <fpage>
       108552
      </fpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB38XisFSrurrM
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1016/j.cpc.2022.108552
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR37">
     <label>
      37.
     </label>
     <mixed-citation publication-type="other">
      Kingma, D. P. &amp; Ba, J. Adam: A method for stochastic optimization. In
      <italic>
       Proceedings of the 3rd International Conference on Learning Representations
      </italic>
      (2015).
     </mixed-citation>
    </ref>
    <ref id="CR38">
     <label>
      38.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         J-S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       All-glass, large metalens at visible wavelength using deep-ultraviolet projection lithography
      </article-title>
      <source>
       Nano Lett.
      </source>
      <year>
       2019
      </year>
      <volume>
       19
      </volume>
      <fpage>
       8673
      </fpage>
      <lpage>
       8682
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2019NanoL..19.8673P
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BC1MXitFGrsL%2FE
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1021/acs.nanolett.9b03333
      </pub-id>
      <pub-id pub-id-type="pmid">
       31726010
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR39">
     <label>
      39.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Kim
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       Scalable manufacturing of high-index atomic layer–polymer hybrid metasurfaces for metaphotonics in the visible
      </article-title>
      <source>
       Nat. Mater.
      </source>
      <year>
       2023
      </year>
      <volume>
       22
      </volume>
      <fpage>
       474
      </fpage>
      <lpage>
       481
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2023NatMa..22..474K
      </pub-id>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3sXmtVagtb8%3D
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41563-023-01485-5
      </pub-id>
      <pub-id pub-id-type="pmid">
       36959502
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR40">
     <label>
      40.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Chakravarthula
        </surname>
        <given-names>
         P
        </given-names>
       </name>
       <name>
        <surname>
         Tseng
        </surname>
        <given-names>
         E
        </given-names>
       </name>
       <name>
        <surname>
         Srivastava
        </surname>
        <given-names>
         T
        </given-names>
       </name>
       <name>
        <surname>
         Fuchs
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Heide
        </surname>
        <given-names>
         F
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Learned hardware-in-the-loop phase retrieval for holographic near-eye displays
      </article-title>
      <source>
       ACM Trans. Graph.
      </source>
      <year>
       2020
      </year>
      <volume>
       39
      </volume>
      <fpage>
       186
      </fpage>
      <pub-id pub-id-type="doi">
       10.1145/3414685.3417846
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR41">
     <label>
      41.
     </label>
     <mixed-citation publication-type="other">
      Choi, S., Gopakumar, M., Peng, Y., Kim, J. &amp; Wetzstein, G. Neural 3D holography: learning accurate wave propagation models for 3D holographic virtual and augmented reality displays.
      <italic>
       ACM Trans. Graph.
      </italic>
      <bold>
       40
      </bold>
      , 240 (2021).
     </mixed-citation>
    </ref>
    <ref id="CR42">
     <label>
      42.
     </label>
     <mixed-citation publication-type="other">
      Choi, S. et al. Time-multiplexed neural holography: a flexible framework for holographic near-eye displays with fast heavily-quantized spatial light modulators. In
      <italic>
       ACM SIGGRAPH 2022 Conference Proc.
      </italic>
      (eds Nandigjav, M. et al.) 32 (2022).
     </mixed-citation>
    </ref>
    <ref id="CR43">
     <label>
      43.
     </label>
     <mixed-citation publication-type="other">
      Jang, C., Bang, K., Chae, M., Lee, B. &amp; Lanman, D. Waveguide holography for 3D augmented reality glasses.
      <italic>
       Nat. Commun.
      </italic>
      <bold>
       15
      </bold>
      , 66 (2024).
     </mixed-citation>
    </ref>
    <ref id="CR44">
     <label>
      44.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Hwang
        </surname>
        <given-names>
         C-S
        </given-names>
       </name>
       <etal/>
      </person-group>
      <article-title xml:lang="en">
       21-2: Invited paper: 1µm pixel pitch spatial light modulator panel for digital holography
      </article-title>
      <source>
       Dig. Tech. Pap. SID Int. Symp.
      </source>
      <year>
       2020
      </year>
      <volume>
       51
      </volume>
      <fpage>
       297
      </fpage>
      <lpage>
       300
      </lpage>
      <pub-id assigning-authority="ChemPort ( Chemical Abstract Service )" pub-id-type="other">
       1:CAS:528:DC%2BB3cXhvFWntrfJ
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1002/sdtp.13862
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR45">
     <label>
      45.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         J
        </given-names>
       </name>
       <name>
        <surname>
         Lee
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Park
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Ultrathin wide-angle large-area digital 3D holographic display using a non-periodic photon sieve
      </article-title>
      <source>
       Nat. Commun.
      </source>
      <year>
       2019
      </year>
      <volume>
       10
      </volume>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2019NatCo..10.1304P
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1038/s41467-019-09126-9
      </pub-id>
      <pub-id pub-id-type="pmid">
       30898998
      </pub-id>
      <pub-id pub-id-type="pmcid">
       6428928
      </pub-id>
      <elocation-id>
       1304
      </elocation-id>
     </mixed-citation>
    </ref>
    <ref id="CR46">
     <label>
      46.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Kuo
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <name>
        <surname>
         Waller
        </surname>
        <given-names>
         L
        </given-names>
       </name>
       <name>
        <surname>
         Ng
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Maimone
        </surname>
        <given-names>
         A
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       High resolution étendue expansion for holographic displays
      </article-title>
      <source>
       ACM Trans. Graph.
      </source>
      <year>
       2020
      </year>
      <volume>
       39
      </volume>
      <fpage>
       66
      </fpage>
      <pub-id pub-id-type="doi">
       10.1145/3386569.3392414
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR47">
     <label>
      47.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Jang
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Bang
        </surname>
        <given-names>
         K
        </given-names>
       </name>
       <name>
        <surname>
         Li
        </surname>
        <given-names>
         G
        </given-names>
       </name>
       <name>
        <surname>
         Lee
        </surname>
        <given-names>
         B
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Holographic near-eye display with expanded eye-box
      </article-title>
      <source>
       ACM Trans. Graph.
      </source>
      <year>
       2018
      </year>
      <volume>
       37
      </volume>
      <fpage>
       195
      </fpage>
      <pub-id pub-id-type="doi">
       10.1145/3272127.3275069
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR48">
     <label>
      48.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Horisaki
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Takagi
        </surname>
        <given-names>
         R
        </given-names>
       </name>
       <name>
        <surname>
         Tanida
        </surname>
        <given-names>
         J
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Deep-learning-generated holography
      </article-title>
      <source>
       Appl. Optics
      </source>
      <year>
       2018
      </year>
      <volume>
       57
      </volume>
      <fpage>
       3859
      </fpage>
      <lpage>
       3863
      </lpage>
      <pub-id assigning-authority="NASA Astrophysics Data System" pub-id-type="other">
       2018ApOpt..57.3859H
      </pub-id>
      <pub-id pub-id-type="doi">
       10.1364/AO.57.003859
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR49">
     <label>
      49.
     </label>
     <mixed-citation publication-type="journal">
      <person-group person-group-type="author">
       <name>
        <surname>
         Kim
        </surname>
        <given-names>
         C
        </given-names>
       </name>
       <name>
        <surname>
         Zimmer
        </surname>
        <given-names>
         H
        </given-names>
       </name>
       <name>
        <surname>
         Pritch
        </surname>
        <given-names>
         Y
        </given-names>
       </name>
       <name>
        <surname>
         Sorkine-Hornung
        </surname>
        <given-names>
         A
        </given-names>
       </name>
       <name>
        <surname>
         Gross
        </surname>
        <given-names>
         M
        </given-names>
       </name>
      </person-group>
      <article-title xml:lang="en">
       Scene reconstruction from high spatio-angular resolution light fields
      </article-title>
      <source>
       ACM Trans. Graph.
      </source>
      <year>
       2013
      </year>
      <volume>
       32
      </volume>
      <fpage>
       73
      </fpage>
      <pub-id pub-id-type="doi">
       10.1145/2461912.2461926
      </pub-id>
     </mixed-citation>
    </ref>
    <ref id="CR50">
     <label>
      50.
     </label>
     <mixed-citation publication-type="other">
      Ronneberger, O., Fischer, P. &amp; Brox, T. U-net: convolutional networks for biomedical image segmentation. In
      <italic>
       Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015
      </italic>
      (eds Navab, N., Hornegger, J., Wells, W. &amp; Frangi, A.) 234–241 (Springer, 2015).
     </mixed-citation>
    </ref>
    <ref id="CR51">
     <label>
      51.
     </label>
     <mixed-citation publication-type="other">
      Ulyanov, D., Vedaldi, A. &amp; Lempitsky, V. Improved texture networks: maximizing quality and diversity in feed-forward stylization and texture synthesis. In
      <italic>
       Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
      </italic>
      6924–6932 (2017).
     </mixed-citation>
    </ref>
   </ref-list>
  </ref-list>
  <app-group>
   <app id="App1" specific-use="web-only">
    <sec id="Sec11">
     <title>
      Supplementary information
     </title>
     <p id="Par31">
      <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information">
       <media mime-subtype="pdf" mimetype="application" xlink:href="MediaObjects/41586_2024_7386_MOESM1_ESM.pdf">
        <label>
         Supplementary Information
        </label>
        <caption xml:lang="en">
         <p>
          This file contains Supplementary Notes 1–5, Figs. 1–18, Table 1 and References.
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41586_2024_7386_MOESM2_ESM.mp4">
        <label>
         Supplementary Video 1
        </label>
        <caption xml:lang="en">
         <p>
          Laser-synchronized 2D video results, 3D video results, 2D AR video results and 3D AR video results.
         </p>
        </caption>
       </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3" xlink:title="Supplementary information">
       <media mime-subtype="mp4" mimetype="video" xlink:href="MediaObjects/41586_2024_7386_MOESM3_ESM.mp4">
        <label>
         Supplementary Video 2
        </label>
        <caption xml:lang="en">
         <p>
          Metasurface optimization animation.
         </p>
        </caption>
       </media>
      </supplementary-material>
     </p>
    </sec>
   </app>
  </app-group>
  <notes notes-type="ESMHint">
   <title>
    Supplementary information
   </title>
   <p>
    The online version contains supplementary material available at
    <ext-link ext-link-type="doi" xlink:href="10.1038/s41586-024-07386-0">
     https://doi.org/10.1038/s41586-024-07386-0
    </ext-link>
    .
   </p>
  </notes>
  <notes notes-type="Misc">
   <p>
    <bold>
     Publisher’s note
    </bold>
    Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
   </p>
  </notes>
 </back>
</article>
