{
    "1": {
        "question": "文章中提出的對比主成分分析 (cPCA) 的主要目的是什麼？",
        "options": {
            "A": "執行線性變換以最大化數據集的方差。",
            "B": "識別相對於比較數據集在一個數據集中富集的低維結構。",
            "C": "應用非線性數據投影以更好地識別模式。",
            "D": "在所有當前應用中完全取代PCA。",
            "E": "自動化數據分類以進行監督學習任務。"
        }
    },
    "2": {
        "question": "根據文章，傳統PCA在處理多個數據集時的限制是什麼？",
        "options": {
            "A": "PCA只能用於數值數據。",
            "B": "PCA計算密集且速度慢。",
            "C": "PCA不允許直接比較不同的數據集。",
            "D": "PCA需要大型數據集才能有效運行。",
            "E": "PCA生成過多的主成分。"
        }
    },
    "3": {
        "question": "cPCA如何確定數據投影的感興趣方向？",
        "options": {
            "A": "通過找到來自兩個數據集的協方差矩陣之和的特徵向量。",
            "B": "通過考慮直接從目標數據集導出的協方差矩陣的特徵向量。",
            "C": "通過計算目標和背景數據集組合的方差。",
            "D": "通過計算目標和背景數據集的協方差矩陣加權差異的奇異向量。",
            "E": "通過使用用戶預定義的任意方向集。"
        }
    },
    "4": {
        "question": "對比參數α在cPCA方法中起什麼作用？",
        "options": {
            "A": "它決定了PCA方差計算的規模。",
            "B": "它量化了高目標方差和低背景方差之間的權衡。",
            "C": "它確定要提取的主成分數量。",
            "D": "它控制cPCA算法的速度。",
            "E": "它指導數據集的標準化過程。"
        }
    },
    "5": {
        "question": "在文章的背景下，使用cPCA而非傳統PCA分析癌症患者的基因表達數據的主要好處是什麼？",
        "options": {
            "A": "它微調數據以更好地與監督學習模型集成。",
            "B": "它專注於由癌症亞型引起的基因變異，而不是人口統計變異。",
            "C": "它消除了對原始基因表達水平進行預處理的需要。",
            "D": "它自動識別所有可能的癌症亞型。",
            "E": "它顯著提高了大型數據集的分析速度。"
        }
    },
    "6": {
        "question": "當cPCA應用於覆蓋在複雜背景上的手寫數字的合成圖像時，注意到了什麼實驗結果？",
        "options": {
            "A": "未識別出明顯的聚類。",
            "B": "背景特徵比數字特徵更突出。",
            "C": "出現了對應於不同數字的兩個明顯聚類。",
            "D": "引入了顯著的噪音，掩蓋了主要模式。",
            "E": "合成圖像與其背景完全分離。"
        }
    },
    "7": {
        "question": "文章強調了以下哪一項關於cPCA的陳述？",
        "options": {
            "A": "它主要是一種用於數據集分類的監督學習方法。",
            "B": "它取代了跨領域的特定數據集的專用算法。",
            "C": "它通過其對比主成分實現幾何解釋。",
            "D": "它的應用需要顯著的領域知識。",
            "E": "它增加了數據集的複雜性而不是減少。"
        }
    },
    "8": {
        "question": "cPCA如何比傳統PCA更能發現生物數據集中的重要子群？",
        "options": {
            "A": "通過完全忽略人口統計變異。",
            "B": "通過增強普遍變異的突出性。",
            "C": "通過使用背景數據集抵消普遍但不感興趣的變異。",
            "D": "通過放大主要信號而不參考數據集。",
            "E": "僅關注數據集的平均值。"
        }
    },
    "9": {
        "question": "在給定的研究中，cPCA如何在唐氏綜合症蛋白表達數據集中優於其他降維技術？",
        "options": {
            "A": "通過識別蛋白表達最高的特定年齡組。",
            "B": "通過有效地將震驚的小鼠分為有和沒有唐氏綜合症的小鼠。",
            "C": "通過生成比分類所需更多的成分。",
            "D": "通過確定最突出的性別特徵。",
            "E": "通過將數據簡化為單一變量表示。"
        }
    },
    "10": {
        "question": "文章對於cPCA的背景數據集選擇有什麼建議？",
        "options": {
            "A": "它應該具有最小的方差以不影響目標數據投影。",
            "B": "它應該是隨機的以確保無偏的方法。",
            "C": "它應該包含我們希望從目標數據中消除的結構。",
            "D": "它必須與目標數據集的協方差結構精確匹配。",
            "E": "它應始終與目標數據集大小相同。"
        }
    },
    "11": {
        "question": "文章建議在什麼情況下使用cPCA？",
        "options": {
            "A": "具有良好標記數據集的監督分類任務。",
            "B": "使用PCA在相關數據集上進行探索性任務。",
            "C": "預期沒有顯著數據集差異的情況。",
            "D": "純理論模型構建項目。",
            "E": "線性回歸模型增強。"
        }
    },
    "12": {
        "question": "cPCA在分析墨西哥人口的基因數據時產生了什麼樣的可視化？",
        "options": {
            "A": "均勻分佈的視覺模式，沒有明顯的結構。",
            "B": "主要反映歐洲血統比例的地圖。",
            "C": "對應於墨西哥境內地理起源的明顯聚類。",
            "D": "混亂的重疊，沒有明顯的意義。",
            "E": "基因變異的簡單線性表示。"
        }
    },
    "13": {
        "question": "根據文章，cPCA的哪個算法特性使其與LDA和QUADRO等方法區分開來？",
        "options": {
            "A": "其整合多個數據集信息的能力。",
            "B": "其在運行並行計算方面的效率。",
            "C": "其無監督的性質，專注於數據集特定模式而不進行分類。",
            "D": "其依賴於標記數據以獲得最佳性能。",
            "E": "其需要領域特定的調整參數。"
        }
    },
    "14": {
        "question": "在白血病患者數據集的例子中，使用cPCA與PCA相比觀察到了什麼？",
        "options": {
            "A": "PCA提供了更清晰的移植前後樣本分離。",
            "B": "cPCA無法有效分離樣本。",
            "C": "cPCA結果中患者內樣本變異最小化。",
            "D": "cPCA顯示出更強的亞群分離。",
            "E": "PCA和cPCA輸出之間沒有明顯差異。"
        }
    },
    "15": {
        "question": "文章中提到cPCA提供了什麼計算優勢？",
        "options": {
            "A": "減少計算的特徵向量數量。",
            "B": "比其他降維方法快得多。",
            "C": "計算效率類似於常規PCA。",
            "D": "減少數據標準化的計算需求。",
            "E": "消除了對額外數據預處理的需求。"
        }
    },
    "16": {
        "question": "使用cPCA時選擇不同α值的主要目的是什麼？",
        "options": {
            "A": "確保數據點在各維度上的均勻分佈。",
            "B": "通過投影到不同的子空間來探索各種數據趨勢。",
            "C": "優化算法的計算速度。",
            "D": "保證兩個數據集的方差最大化。",
            "E": "在分析前標準化數據集。"
        }
    },
    "17": {
        "question": "在cPCA分析中，為什麼背景數據集的結構很重要？",
        "options": {
            "A": "它影響目標數據子空間中捕獲的方差。",
            "B": "它直接增強目標數據集中的感興趣特徵。",
            "C": "它決定提取的主成分數量。",
            "D": "它自動與目標數據集的協方差矩陣對齊。",
            "E": "它標準化特徵向量計算。"
        }
    },
    "18": {
        "question": "根據文章，選擇cPCA背景數據集時通常不考慮哪個因素？",
        "options": {
            "A": "它應該與目標數據中的噪音相關成分形成強烈對比。",
            "B": "它需要與目標數據集樣本一一對應。",
            "C": "它受益於與目標數據中不需要的變異相似的結構。",
            "D": "它應該捕獲不需要的系統變異以便去除。",
            "E": "它可以在樣本數量上與目標數據集不同。"
        }
    },
    "19": {
        "question": "cPCA如何增強探索性數據分析？",
        "options": {
            "A": "通過自動化數據分類和標記過程。",
            "B": "通過基於目標特定方差的特徵選擇精煉。",
            "C": "通過從歷史數據中預測未來數據趨勢。",
            "D": "通過專注於減少數據集維度。",
            "E": "通過生成統計顯著性的p值。"
        }
    },
    "20": {
        "question": "根據文章，哪種類型的數據集最能從cPCA中受益？",
        "options": {
            "A": "具有顯著標記數據點的數據集。",
            "B": "需要精確異常檢測的數據集。",
            "C": "具有明確先前分類的數據集。",
            "D": "具有重疊的時間或空間變異的數據集。",
            "E": "具有明確現有邊界的數據集。"
        }
    },
    "21": {
        "question": "cPCA解決了傳統PCA在揭示子類方面的哪個限制？",
        "options": {
            "A": "它主要檢測標籤而不是連續模式。",
            "B": "它專注於最廣泛而不是最精細的結構。",
            "C": "它標準化所有變異，使異常值更突出。",
            "D": "它缺乏生物數據分析的理論基礎。",
            "E": "它不提供數據集屬性的精確複製。"
        }
    },
    "22": {
        "question": "文章對cPCA實施中的對比參數α有什麼建議？",
        "options": {
            "A": "對所有數據集始終建議使用固定的α。",
            "B": "自動生成的α值通常足以應用於許多應用。",
            "C": "對所有數據集而言，較小的α更適合最佳方差。",
            "D": "手動調整對於有意義的結果是必須的。",
            "E": "線性增加α會增強對比選擇性。"
        }
    },
    "23": {
        "question": "從文章推斷，cPCA的一個常見應用是什麼？",
        "options": {
            "A": "設計複雜的監督學習結構。",
            "B": "高效分析靜態時間序列數據。",
            "C": "揭示各種條件下數據集的對比。",
            "D": "取代所有降維技術。",
            "E": "啟動數據集分段以進行批處理。"
        }
    },
    "24": {
        "question": "cPCA的方法如何與文章中提到的帕累托前沿概念相關？",
        "options": {
            "A": "cPCA為不同數據集構建各種帕累托前沿。",
            "B": "它選擇對應於方差對下右邊界的方向。",
            "C": "帕累托前沿有助於擴展cPCA的維度覆蓋範圍。",
            "D": "它以帕累托原則的方向強調初始化PCA。",
            "E": "帕累托前沿與cPCA實施無關。"
        }
    },
    "25": {
        "question": "cPCA在單細胞RNA-Seq數據實驗中的應用揭示了什麼？",
        "options": {
            "A": "cPCA減少了不同RNA樣本之間的差異。",
            "B": "從cPCA投影中無法得出顯著模式。",
            "C": "移植前後樣本之間的顯著分離。",
            "D": "儘管處理不同，RNA序列仍然均勻。",
            "E": "實驗數據中引入了更多噪音。"
        }
    },
    "26": {
        "question": "哪個因素主要影響cPCA中對比分析的最佳方向？",
        "options": {
            "A": "僅目標數據集的大小。",
            "B": "背景方差與目標方差的比較。",
            "C": "數據集間的普遍方差一致性。",
            "D": "協方差結構的線性。",
            "E": "數據集中的成分數量。"
        }
    },
    "27": {
        "question": "在討論墨西哥基因數據的例子中，文章建議如何處理普遍變異？",
        "options": {
            "A": "在分析前修剪所有SNP。",
            "B": "像處理大型單一數據集一樣應用PCA。",
            "C": "使用cPCA與更廣泛的背景數據集以專注於墨西哥內部變異。",
            "D": "隨機選擇樣本的子集。",
            "E": "完全忽略普遍變異以簡化。"
        }
    },
    "28": {
        "question": "文章中強調cPCA在計算效率方面的優勢是什麼？",
        "options": {
            "A": "比標準PCA需要更多時間但提供更好的結果。",
            "B": "提供與PCA相比的完整算法改進。",
            "C": "需要與PCA基本相同的計算努力。",
            "D": "以更少的迭代更快地降低維度。",
            "E": "自動並行化數據分析過程。"
        }
    },
    "29": {
        "question": "以下哪種情況不建議作為cPCA的對比背景？",
        "options": {
            "A": "使用對照組數據對比患病受試者。",
            "B": "對比歷史和現代建築的圖像。",
            "C": "初始時間點與結束時間點的數據。",
            "D": "同質人口對比多樣化混合。",
            "E": "治療前數據與治療後數據對比。"
        }
    },
    "30": {
        "question": "文章對於使用cPCA發現子類別有什麼看法？",
        "options": {
            "A": "只有在預先標記時才能檢測到子類別。",
            "B": "即使子類別未事先標記也有效。",
            "C": "PCA通常比cPCA更適合發現。",
            "D": "僅在緊密聚集的數據集情況下有用。",
            "E": "需要明確的特徵選擇才能有效。"
        }
    },
    "31": {
        "question": "根據文章，cPCA打算如何處理數據集中的噪音？",
        "options": {
            "A": "默認忽略任何噪音成分。",
            "B": "放大噪音以更好地突出主要特徵。",
            "C": "通過使用無信號的背景記錄來消除噪音。",
            "D": "將噪音作為協方差矩陣的一部分進行整合。",
            "E": "通過監督學習調整過濾噪音。"
        }
    },
    "32": {
        "question": "計算cPCA中的對比方向需要哪一步驟？",
        "options": {
            "A": "從數據集中提取均值中心值。",
            "B": "從協方差矩陣差異中定義對比矩陣。",
            "C": "在分析前隨機化數據集樣本。",
            "D": "確保數據集具有相同的樣本大小。",
            "E": "將所有數據集成分對齊到單一維度閾值。"
        }
    },
    "33": {
        "question": "使用cPCA在小鼠蛋白表達數據集中顯著實現了什麼類型的視覺分離？",
        "options": {
            "A": "基於對照與實驗受試者的分離。",
            "B": "樣本內的性別分離。",
            "C": "分離有和沒有唐氏綜合症的小鼠。",
            "D": "小鼠的年齡依賴性聚類。",
            "E": "隨機分佈，沒有特定模式。"
        }
    },
    "34": {
        "question": "cPCA選擇最佳對比方向的原則是什麼？",
        "options": {
            "A": "專注於最大化所有方向的方差總和。",
            "B": "尋找數據集間低相關的方向。",
            "C": "均勻地最小化目標和背景方差。",
            "D": "最大化目標方差，同時最小化背景方差。",
            "E": "最大化與目標數據無關的背景方差。"
        }
    },
    "35": {
        "question": "在cPCA中，使用不同的α值意味著什麼？",
        "options": {
            "A": "它調整算法對更高背景方差的偏差。",
            "B": "它使探索不同趨勢的各種子空間成為可能。",
            "C": "它直接修改數據集間的維度。",
            "D": "它影響數據集樣本分析的順序。",
            "E": "它標準化整個數據集的方差結構。"
        }
    },
    "36": {
        "question": "文章中的圖5描述了關於cPCA的什麼？",
        "options": {
            "A": "數據集間方差的隨機波動。",
            "B": "選擇與目標方差最大值重合的方向。",
            "C": "幾何解釋和最佳對比方向選擇。",
            "D": "協方差結構中的目標-背景對不匹配。",
            "E": "目標和背景數據集的完全對齊。"
        }
    },
    "37": {
        "question": "cPCA中的對比方向與特徵向量有什麼關係？",
        "options": {
            "A": "對比方向與特徵向量無關。",
            "B": "它們在維度上總是與真實特徵向量不同。",
            "C": "它們對應於對比矩陣的特徵向量。",
            "D": "它們僅與最小特徵值的特徵向量相關。",
            "E": "它們僅與背景數據的特徵向量對齊。"
        }
    },
    "38": {
        "question": "文章強調cPCA的初始要求是什麼？",
        "options": {
            "A": "手動預處理數據集以消除所有噪音。",
            "B": "預先分配特定維度進行分析。",
            "C": "提供目標和背景數據集的協方差矩陣。",
            "D": "為所有投影設置固定的方差閾值。",
            "E": "全面標記所有數據組件。"
        }
    },
    "39": {
        "question": "為什麼cPCA對於專注於遺產和祖先模式的遺傳研究特別有用？",
        "options": {
            "A": "它增強了主導祖先變異的重要性。",
            "B": "它自動解釋遺傳背景數據。",
            "C": "它突出了群體內指標的微妙變異。",
            "D": "它主要利用普遍的遺傳相似性。",
            "E": "它提出了民族起源的自動分類。"
        }
    },
    "40": {
        "question": "文章詳細說明了cPCA相對於多維尺度分析 (MDS) 的優勢是什麼？",
        "options": {
            "A": "對固有非線性數據結構的優越可視化。",
            "B": "能夠使用背景數據集增強對比。",
            "C": "在各種數據集上的計算時間更快。",
            "D": "內置的數據聚類傾向校正。",
            "E": "對數據過擬合預防的內在偏見。"
        }
    },
    "41": {
        "question": "在典型的cPCA分析中，改變α參數如何影響結果？",
        "options": {
            "A": "增加的維度超過目標允許的範圍。",
            "B": "實現目標和背景方差之間的平衡。",
            "C": "自然減少特徵分解的複雜性。",
            "D": "指數減少數據集的交叉相關性。",
            "E": "改善異常檢測的標準化。"
        }
    },
    "42": {
        "question": "cPCA在統計方法上與PCA有何不同？",
        "options": {
            "A": "cPCA相互依賴地計算數據集方差。",
            "B": "cPCA在兩個數據集中獨立優化方差。",
            "C": "cPCA完全忽略方差信息。",
            "D": "cPCA假設數據集之間的直接線性依賴性。",
            "E": "cPCA默認最大化兩個方差。"
        }
    },
    "43": {
        "question": "根據文章，哪些實驗結果顯示cPCA相對於其他8種降維方法的優勢？",
        "options": {
            "A": "在所有數據集和方法中表現相似。",
            "B": "其他方法無法將唐氏綜合症小鼠單獨聚類。",
            "C": "運行時間更快但錯誤率更高。",
            "D": "在精度上被監督方法掩蓋。",
            "E": "比其他方法的方差分析信息量少。"
        }
    },
    "44": {
        "question": "文章對於cPCA中數據的隨機性效應有什麼看法？",
        "options": {
            "A": "樣本cPC以類似於標準PCA特徵向量的速度收斂到群體cPC。",
            "B": "隨機變化不影響cPCA的協方差結構。",
            "C": "cPCA引入了平衡的模式隨機性。",
            "D": "cPCA自動考慮隨機異常值。",
            "E": "它不依賴於穩定的數據協方差矩陣。"
        }
    },
    "45": {
        "question": "在cPCA收斂速度中，維度d起什麼作用？",
        "options": {
            "A": "顯著限制收斂潛力。",
            "B": "導致低d值的恆定收斂速度。",
            "C": "影響樣本cPC接近群體cPC的速度。",
            "D": "決定數據集的總特徵向量數量。",
            "E": "指導計算努力的比例增加。"
        }
    },
    "46": {
        "question": "cPCA在計算上如何與補充信息中演示的核化版本相關？",
        "options": {
            "A": "用額外的核層補充核心PCA。",
            "B": "固有地忽略非線性模式。",
            "C": "cPCA可以核化以揭示非線性模式。",
            "D": "cPCA在所有情況下排除核應用。",
            "E": "它要求增加數據預處理以支持核。"
        }
    },
    "47": {
        "question": "cPCA處理的哪個計算任務在探索性數據科學項目中通常很重要？",
        "options": {
            "A": "計算普遍方差成分。",
            "B": "在探索之前應用監督模型。",
            "C": "確定相對於背景數據集在目標數據中富集的模式。",
            "D": "標準化維度方差閾值。",
            "E": "自動複製稀疏數據集以增加深度。"
        }
    },
    "48": {
        "question": "哪個特徵使cPCA與監督PCA和QDA區分開來？",
        "options": {
            "A": "其專注於基於標籤的分類結果。",
            "B": "其區分標記子群的能力。",
            "C": "其無監督策略以澄清數據集特定模式。",
            "D": "其偏好較小的數據集而非較大的數據集。",
            "E": "內置需要精確的用戶輸入參數。"
        }
    },
    "49": {
        "question": "在執行cPCA時，對比主成分 (cPCs) 與常規PCs有何區別？",
        "options": {
            "A": "cPCs專注於最大化背景方差。",
            "B": "cPCs通過重新縮放分析與PCs相同的維度。",
            "C": "cPCs基於目標特定方差固有地降低維度。",
            "D": "cPCs不可避免地使用非正交方向。",
            "E": "cPCs忽略目標數據而偏重背景協方差。"
        }
    },
    "50": {
        "question": "根據文章中提到的幾何解釋，cPCA旨在實現什麼？",
        "options": {
            "A": "基於軸上的固定指標對齊數據集。",
            "B": "最大化目標方差朝向方差對邊界的左上端。",
            "C": "選擇沿方差對下右邊界的方向。",
            "D": "整合超出普遍趨勢的方差例外。",
            "E": "在數據集中標準化幾何方差配置。"
        }
    }
}