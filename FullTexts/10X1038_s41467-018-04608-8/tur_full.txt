Kontrastif Temel Bileşen Analizi ile Bir Veri Kümesinde Zenginleştirilmiş Desenlerin Keşfi

Özet: Yüksek boyutlu verilerin görselleştirilmesi ve keşfi, disiplinler arasında yaygın bir zorluktur. Temel bileşen analizi (PCA) gibi yaygın olarak kullanılan teknikler, bir veri kümesindeki baskın eğilimleri belirlemeyi amaçlar. Ancak, birçok durumda farklı koşullar altında toplanmış veri kümelerine sahibiz, örneğin bir tedavi ve bir kontrol deneyi, ve belirli bir veri kümesine özgü desenleri görselleştirmek ve keşfetmekle ilgileniyoruz. Bu makale, karşılaştırma verilerine göre bir veri kümesinde zenginleştirilmiş düşük boyutlu yapıları tanımlayan bir yöntem, kontrastif temel bileşen analizi (cPCA) önermektedir. Çeşitli deneylerde, cPCA'nın bir arka plan veri kümesi ile birlikte, PCA ve diğer standart yöntemler tarafından kaçırılan veri kümesine özgü desenleri görselleştirmemizi sağladığını gösteriyoruz. Ayrıca, cPCA'nın geometrik bir yorumunu ve güçlü matematiksel garantiler sunuyoruz. cPCA'nın bir uygulaması kamuya açıktır ve PCA'nın şu anda kullanıldığı birçok uygulamada keşifsel veri analizi için kullanılabilir.

Temel bileşen analizi (PCA), veri keşfi ve görselleştirme için en yaygın kullanılan yöntemlerden biridir. PCA, veriyi düşük boyutlu bir uzaya yansıtır ve özellikle bir veri kümesindeki kümeler, eğilimler ve aykırı değerler gibi desenleri görselleştirmek için güçlü bir yaklaşımdır. İlgili birçok görselleştirme yöntemi vardır; örneğin, t-SNE ve çok boyutlu ölçekleme (MDS), doğrusal olmayan veri yansıtmalara izin verir ve doğrusal olmayan desenleri PCA'dan daha iyi yakalayabilir. Ancak, bu yöntemlerin tümü bir seferde bir veri kümesini keşfetmek için tasarlanmıştır. Analist birden fazla veri kümesine (veya karşılaştırmak için bir veri kümesinde birden fazla koşula) sahip olduğunda, mevcut uygulama durumu, her veri kümesine ayrı ayrı PCA (veya t-SNE, MDS, vb.) uygulamak ve ardından veri kümeleri arasında ilginç benzerlikler ve farklılıklar olup olmadığını keşfetmek için çeşitli yansıtmalara manuel olarak bakmaktır,. Karşıt PCA (cPCA), veri keşfi ve görselleştirmedeki bu boşluğu, veri kümeleri arasında en ilginç farklılıkları sergileyen yansıtmalara otomatik olarak tanımlayarak doldurmak için tasarlanmıştır. Şekil[1], cPCA'nın genel bir görünümünü sağlar ve bunu daha ayrıntılı olarak açıklayacağız.

cPCA, disiplinler arası geniş bir problem yelpazesi tarafından motive edilmiştir. Örnek olarak, burada iki böyle problemi belirtip, makalenin ilerleyen bölümlerinde deneylerle diğerlerini göstereceğiz. İlk olarak, farklı etnik kökenlerden ve cinsiyetlerden bireylerin gen ekspresyon ölçümlerinden oluşan bir veri kümesini düşünün. Bu veri, analiz etmekle ilgilendiğimiz kanser hastalarının gen ekspresyon seviyelerini {x i} içerir. Ayrıca, benzer demografik geçmişe sahip sağlıklı hastaların gen ekspresyon seviyelerine karşılık gelen kontrol verilerimiz de vardır {y i}. Amacımız, kanser hastaları içinde eğilimleri ve varyasyonları bulmaktır (örneğin, kanserin moleküler alt tiplerini tanımlamak için). Ancak, doğrudan {x i} üzerine PCA uygularsak, en üstteki temel bileşenler, kanser alt tipleri yerine bireylerin demografik varyasyonlarına karşılık gelebilir çünkü genetik varyasyonlar muhtemelen daha büyük olacaktır. Bu soruna, sağlıklı hastaların da demografik farklılıklarla ilişkili varyasyonu içerdiğini, ancak kanser alt tiplerine karşılık gelen varyasyonu içermediğini belirterek yaklaşıyoruz. Böylece, {x i}'nin yüksek varyansa sahip olduğu ancak {y i}’nin düşük varyansa sahip olduğu bileşenleri arayabiliriz.

İlgili bir örnek olarak, karmaşık bir arka planda el yazısı rakamlar içeren bir veri kümesini düşünün {x i}, örneğin farklı çim görüntüleri (bkz. Fig.[2(a), üst]). Tipik bir denetimsiz öğrenme görevinin amacı, veriyi kümeleyerek görüntüdeki farklı rakamları ortaya çıkarmak olabilir. Ancak, bu görüntülere standart PCA uygularsak, en üstteki temel bileşenlerin el yazısı rakamlarla ilgili özellikleri temsil etmediğini, ancak görüntü arka planıyla ilgili özelliklerdeki baskın varyasyonu yansıttığını buluruz (Fig.[2(b)], üst). Bunun, yalnızca çim görüntülerinden oluşan bir referans veri kümesi {y i} kullanılarak düzeltilebileceğini gösteriyoruz (Fig.[2(a)], alt kısmında gösterildiği gibi, {x i}’de kullanılanlarla aynı olmayan ancak özellikler arasında benzer kovaryansa sahip görüntüler), ve {x i}’de {y i}’ye kıyasla daha yüksek varyansa sahip alt uzayı arayarak. Bu alt uzaya yansıtma yaparak, aslında görüntüleri el yazısı rakamın değerine göre görsel olarak ayırabiliriz (Fig. 2(b), alt). PCA tarafından keşfedilen temel bileşenlerle cPCA tarafından keşfedilenleri karşılaştırarak, cPCA'nın daha ilgili özellikleri tanımladığını görüyoruz (Fig.[2(c)]), bu da cPCA'yı özellik seçimi ve gürültü giderme gibi uygulamalar için kullanmamıza olanak tanır.

Karşıt PCA, boyut azaltmayı verimli bir şekilde gerçekleştirerek görselleştirme ve keşifsel veri analizi yapmayı sağlayan bir denetimsiz öğrenme aracıdır. Bu, cPCA'yı, birincil amacı çeşitli veri kümeleri arasında sınıflandırma veya ayırt etme olan doğrusal ayırt edici analiz (LDA), kuadratik ayırt edici analiz (QDA), denetimli PCA ve QUADRO gibi geniş bir denetimli öğrenme yöntemleri sınıfından ayırır. Bu aynı zamanda cPCA'yı, birden fazla veri kümesini entegre eden ve her bir veri kümesine özgü olanlar yerine iki veya daha fazla veri kümesi arasında ilişkili desenleri tanımlamayı amaçlayan yöntemlerden ayırır. PCA dışında boyut azaltma için zengin bir denetimsiz yöntem ailesi de vardır. Örneğin, çok boyutlu ölçekleme (MDS), yüksek boyutlu uzaydaki mesafeyi koruyan düşük boyutlu bir gömme bulur; temel bileşen arayışı, küçük giriş bazında gürültüye ve büyük seyrek hatalara karşı dayanıklı düşük dereceli bir alt uzay bulur. Ancak hiçbiri, cPCA'nın yaptığı gibi, ikinci bir veri kümesinden ilgili bilgileri kullanmak için tasarlanmamıştır. Ek'te, cPCA'yı temsilci veri kümeleri üzerinde daha önce bahsedilen birçok teknikle karşılaştırdık (bkz. Ek Şekiller[3]ve[4]), , ,.

Belirli bir uygulama alanında, cPCA ile benzer hedeflere sahip uzmanlaşmış araçlar olabilir, ,. Örneğin, sonuçlarda, cPCA'nın genotip verilerine uygulandığında Meksika içindeki coğrafi soyları nasıl görselleştirdiğini gösteriyoruz. Genetik soyların ince taneli kümelerini keşfetmek, popülasyon genetiğinde önemli bir problemdir ve araştırmacılar yakın zamanda bu tür soy kümelerini özel olarak görselleştirmek için bir algoritma geliştirdiler. cPCA burada iyi performans gösterse de, uzman tarafından hazırlanmış algoritma belirli bir veri kümesi için daha iyi performans gösterebilir. Ancak, uzmanlaşmış algoritma, tasarım için önemli ölçüde alan bilgisi gerektirir, daha fazla hesaplama maliyetine sahiptir ve kullanımı zor olabilir. cPCA'nın amacı, her bir alandaki bu uzmanlaşmış en son yöntemlerin tümünü değiştirmek değil, rastgele veri kümelerini keşfetmek için genel bir yöntem sağlamaktır.

Bu makalede cPCA için somut ve verimli bir algoritma öneriyoruz. Yöntem, görselleştirmek veya içinde desenler tanımlamakla ilgilendiğimiz bir hedef veri kümesi {x i} alır. İkincil bir girdi olarak, cPCA, ilgi çekici desenleri içermeyen bir arka plan veri kümesi {y i} alır. cPCA algoritması, hedef veride {x i} büyük miktarda varyasyonu, ancak arka planda {y i} az miktarda varyasyonu yakalayan alt uzayları döndürür (daha fazla ayrıntı için bkz. Şekil[1], Yöntemler ve Ek Yöntemler). Bu alt uzay, {x i}’ye özgü yapıyı içeren özelliklere karşılık gelir. Dolayısıyla, hedef veri bu alt uzaya yansıtıldığında, arka plana göre hedef verideki ek yapıyı görselleştirebilir ve keşfedebiliriz. Temel bileşenlere (PC'ler) benzer şekilde, cPCA tarafından bulunan yönlere karşıt temel bileşenler (cPC'ler) diyoruz. cPCA'nın temelde bir denetimsiz teknik olduğunu, arka plan veri kümesini bir karşıtlık olarak kullanarak bir veri kümesindeki desenleri daha net çözmek için tasarlandığını vurguluyoruz. Özellikle, cPCA, hedef ve arka plan veri kümeleri arasında ayrım yapmayı amaçlamaz; hedef veri kümesinde zenginleştirilmiş eğilimleri içeren alt uzay, veri kümeleri arasında sınıflandırma için en uygun alt uzayla aynı olmak zorunda değildir.

Araştırmacılar, standart PCA'nın biyolojik verilerde alt grupları keşfetmede genellikle etkisiz olduğunu, en azından kısmen, "baskın temel bileşenlerin... artefaktlarla ilişkilendiğini" ve araştırmacının ilgisini çeken özelliklerle değil, belirttiler. cPCA, bu ortamlarda daha önemli alt grupları tespit etmek için nasıl kullanılabilir? Hedefteki evrensel ancak ilginç olmayan varyasyonu iptal etmek için bir arka plan veri kümesi kullanarak, hedef veri kümesine özgü yapıyı arayabiliriz.

İlk deneyimiz, şok terapisi almış farelerin protein ekspresyon ölçümlerinden oluşan bir veri kümesi kullanır,. Bazı fareler Down Sendromu (DS) geliştirmiştir. Yöntemleri değerlendirmek için gerçek bilgiye sahip olduğumuz bir denetimsiz öğrenme görevi oluşturmak için, bu DS bilgisinin analist tarafından bilinmediğini varsayıyoruz ve yalnızca algoritma değerlendirmesi için kullanıyoruz. Şoklanmış fare popülasyonu içinde denetimsiz bir şekilde herhangi bir önemli fark tespit edip edemeyeceğimizi görmek istiyoruz (Down Sendromu varlığı veya yokluğu önemli bir örnek olarak). Şekil [3a] (üst) hedef veri kümesine PCA uygulamanın sonucunu gösteriyoruz: dönüştürülmüş veri, fare popülasyonu içinde herhangi bir önemli kümeleşme ortaya çıkarmıyor. Fareler içindeki ana varyasyon kaynakları, cinsiyet veya yaş gibi doğal olabilir.

Bu veri kümesine, şok terapisine maruz kalmamış bir fare grubunun protein ekspresyon ölçümlerinden oluşan bir arka plan kullanarak cPCA uygularız. Bunlar, muhtemelen deney fareleriyle benzer doğal varyasyona sahip olan, ancak şok terapisinden kaynaklanan farklılıkları olmayan kontrol fareleridir. Bu veri kümesi bir arka plan olarak kullanıldığında, cPCA, dönüştürülmüş hedef veride iki farklı grubu çözebilir, biri Down Sendromu olmayan farelere ve diğeri (çoğunlukla) Down Sendromu olan farelere karşılık gelir, Şekil [3a] (alt) olarak gösterilmiştir. Karşılaştırma olarak, hedef ve arka plan veri kümeleri arasında farklılık gösteren yönleri tanımlamak için 8 başka boyut azaltma tekniği de uyguladık, ancak hiçbiri fareleri cPCA kadar iyi ayıramadı (ayrıntılar için bkz. Ek Şekil [4] ).

Sonraki olarak, bir lösemi hastasından kök hücre nakli öncesi alınan kemik iliği mononükleer hücrelerinin (BMMC'ler) ve aynı hastadan kök hücre nakli sonrası alınan BMMC'lerin tek hücreli RNA ekspresyon seviyelerinden oluşan daha yüksek boyutlu bir kamu veri kümesini analiz ediyoruz. Tüm tek hücreli RNA-Seq verileri, yazarlar tarafından tanımlanan benzer yöntemler kullanılarak ön işleme tabi tutulur. Özellikle, PCA veya cPCA uygulamadan önce, tüm veri kümeleri, hedef veri içindeki en yüksek dağılıma [varyansın ortalamaya bölünmesi] dayalı olarak seçilen 500 gene indirgenir. Yine, dönüştürülmüş veride iki örneği görsel olarak keşfedip keşfedemeyeceğimizi görmek için PCA uygularız. Şekil [3b] (sol üst) gösterildiği gibi, her iki hücre türü de ilk iki PC tarafından kapsanan uzayda benzer bir dağılım izler. Bu muhtemelen örnekler arasındaki farkların küçük olması ve PC'lerin bunun yerine her bir örnek içindeki çeşitli hücre türlerinin heterojenliğini veya hatta deneysel koşullardaki varyasyonları yansıtması nedeniyle olabilir, bu da tek hücreli RNA-Seq ölçümleri üzerinde önemli bir etkiye sahip olabilir.

cPCA'yı, sağlıklı bir bireyin BMMC hücrelerinden alınan RNA-Seq ölçümlerinden oluşan bir arka plan veri kümesi kullanarak uygularız. Bu arka plan veri kümesinin, hücrelerin heterojen popülasyonundan kaynaklanan varyasyonu ve deneysel koşullardaki varyasyonları içermesini bekleriz. Bu nedenle, cPCA'nın hedef verilerde zenginleştirilmiş yönleri, nakil öncesi ve sonrası farklılıklarına karşılık gelen yönleri kurtarabileceğini umabiliriz. Gerçekten de, Fig. [3b] (sol alt) gösterildiği gibi, bulduğumuz şey budur.

Hedef veri kümemizi, ikinci bir lösemi hastasından alınan BMMC örnekleriyle, yine kök hücre nakli öncesi ve sonrası olmak üzere genişletiyoruz. Böylece toplamda dört hücre alt popülasyonu vardır. Bu veriler üzerinde PCA uygulaması, dört alt popülasyonun, Fig. [3b] (sağ üst) gösterildiği gibi, en üst iki ana bileşen (PC) tarafından kapsanan alt uzayda ayrılmadığını gösterir. Ancak, aynı arka plan veri kümesi ile cPCA uygulandığında, en az üç alt popülasyonun çok daha güçlü bir ayrım gösterdiği görülür, Fig. [3b] (sağ alt) gösterildiği gibi. cPCA yerleştirmesi ayrıca, kök hücre nakli sonrası hücre örneklerinin (camgöbeği ve yeşil noktalar) nakil öncesine (altın ve pembe noktalar) göre birbirine daha benzer olduğunu öne sürer, bu makul bir hipotezdir ve araştırmacı tarafından test edilebilir. Bu deneyin daha fazla ayrıntısı için Ek Fig. [5] 'e bakılabilir. cPCA'nın alt popülasyonlar arasındaki ilişkiyi çıkarmak için yararlı bir araç olabileceğini görüyoruz, bu konuyu daha sonra daha fazla araştıracağız.

Önceki örneklerde, cPCA'nın kullanıcıya önceden etiketlenmemiş bir hedef veri kümesi içinde alt sınıfları keşfetme imkanı sağladığını gördük. Ancak, alt sınıflar önceden bilindiğinde bile, boyut azaltma, gruplar içindeki ilişkiyi görselleştirmek için yararlı bir yol olabilir. Örneğin, PCA genellikle genetik varyantlara dayalı olarak etnik popülasyonlar arasındaki ilişkiyi görselleştirmek için kullanılır, çünkü genetik varyantları iki boyuta yansıtmak genellikle coğrafi ve tarihi eğilimlerin çarpıcı görselleştirmelerini sunan haritalar üretir,. Ancak yine de, PCA en baskın yapıyı tanımlamakla sınırlıdır; bu evrensel veya ilgi çekici olmayan bir varyasyonu temsil ettiğinde, cPCA eğilimleri görselleştirmede daha etkili olabilir.

Bu örnek için kullandığımız veri kümesi, daha önceki bir çalışmada toplanan, Meksika'nın beş eyaletinden bireylerin genomlarından tek nükleotid polimorfizmleri (SNP'ler) içermektedir. Meksika kökenini PCA kullanarak analiz etmek zordur çünkü PC'ler genellikle Meksika içindeki coğrafi kökeni yansıtmaz; bunun yerine, her Meksikalı bireyin Avrupa/Yerli Amerikalı mirasının oranını yansıtır, bu da Meksika içindeki coğrafi kökene bağlı farklılıkları baskılar ve gizler (bkz. Fig. [4a] ). Bu sorunu aşmak için, popülasyon genetikçileri, PCA uygulamadan önce, Avrupa kökenli olduğu bilinen SNP'leri manuel olarak budar. Ancak, bu prosedür sınırlı bir uygulanabilirliğe sahiptir çünkü SNP'lerin kökenini ve arka plan varyasyonunun kaynağının ilgi çekici varyasyondan çok farklı olmasını gerektirir, ki bu genellikle böyle değildir.

Alternatif olarak, Meksika ve Avrupa'dan bireylerden oluşan bir arka plan veri kümesi ile cPCA kullanıyoruz. Bu arka plan, Yerli Amerikalı/Avrupalı varyasyonu ile baskın olup, hedef veri kümesindeki Meksika içi varyasyonu izole etmemizi sağlar. cPCA uygulamasının sonuçları Fig. [4b] 'de gösterilmiştir. Meksika'daki aynı eyaletten bireylerin daha yakın yerleştirildiğini buluyoruz. Ayrıca, en farklı olan iki grup, Meksika içinde coğrafi olarak da en uzak olan Sonorans ve Yucatan'dan Mayalar'dır, diğer üç eyaletten Meksikalılar ise hem coğrafi olarak hem de cPCA tarafından yakalanan yerleştirmede birbirine yakındır (bkz. Fig. [4c] ). Daha fazla ayrıntı için Ek Fig. [6] 'ya da bakınız.

Birçok veri bilimi ortamında, bir veri kümesinde diğer verilere göre zenginleştirilmiş desenleri görselleştirmek ve keşfetmekle ilgileniyoruz. Bu tür karşılaştırmalı keşifler yapmak için genel bir araç olarak cPCA'yı sunduk ve çeşitli uygulama alanlarında faydasını gösterdik. cPCA'nın başlıca avantajları, genelliği ve kullanım kolaylığıdır. Belirli bir cPCA'nın hesaplanması, normal bir PCA'nın hesaplanmasıyla esasen aynı süreyi alır. Bu hesaplama verimliliği, cPCA'nın etkileşimli veri keşfi için yararlı olmasını sağlar, burada her işlem ideal olarak neredeyse anında olmalıdır. Bu nedenle, PCA'nın ilgili veri kümeleri üzerinde uygulandığı herhangi bir ortamda, cPCA da uygulanabilir. Ek Not[3]ve Ek Fig.[8]'de, cPCA'nın veri kümelerinde doğrusal olmayan karşılaştırmalı desenleri ortaya çıkarmak için nasıl çekirdeklenebileceğini gösteriyoruz.

Karşılaştırmalı PCA'nın tek serbest parametresi, karşılaştırma gücüα 'dır. Varsayılan algoritmamızda, en bilgilendiriciα değerlerini seçmek için alt uzayların kümelemelerine dayanan otomatik bir şema geliştirdik (bkz. Yöntemler). Bu makale için gerçekleştirilen tüm deneyler, otomatik olarak üretilenα değerlerini kullanır ve bu varsayılanın cPCA'nın birçok uygulamasında yeterli olacağına inanıyoruz. Kullanıcı, daha ayrıntılı bir keşif istenirse,α için belirli değerler de girebilir.

cPCA, normal PCA ve diğer boyut azaltma yöntemleri gibi,p -değerleri veya diğer istatistiksel anlamlılık ölçümleri vermez. cPCA aracılığıyla keşfedilen desenler, hipotez testi veya ilgili alan bilgisi kullanılarak ek analizlerle doğrulanmalıdır. cPCA'nın kodunu bir python paketi olarak, belgeler ve örneklerle birlikte yayınladık.

d -boyutlu hedef verixi ∈ Rd ve arka plan veriyi ∈ Rd , onların karşılık gelen ampirik kovaryans matrisleriC X,C Yolsun. Birim vektörlerin kümesiR unit d = def v ∈ Rd :v2 = 1 olsun. Herhangi bir yön içinv ∈ R unit d , hedef veride ve arka plan veride hesapladığı varyans şu şekilde yazılabilir: Hedef veri varyansı :λX ( v ) =defvTCXv , Arka plan veri varyansı :λY ( v ) =defvTCYv.Yüksek hedef varyansı ve düşük arka plan varyansı arasında dengeyi belirleyen bir karşılaştırma parametresiα ≥ 0 verildiğinde, cPCA,v * karşılaştırmalı yönünü optimize ederek hesaplar 1 v * = argmax v ∈ Runitd λ X(v)- α λ Y(v).  Bu problem şu şekilde yeniden yazılabilirv * = argmax v ∈ Runitd v T CX - α CY v ,  bu dav *'ninC = def CX - α CY matrisinin ilk özvektörüne karşılık geldiğini ima eder. Bu nedenle, karşılaştırmalı yönler özdeğer ayrışımı kullanılarak verimli bir şekilde hesaplanabilir. PCA'ya benzer şekilde,C 'nin önde gelen özvektörlerine karşılaştırmalı ana bileşenler (cPC'ler) diyoruz. cPC'lerinC matrisinin özvektörleri olduğunu ve dolayısıyla birbirine dik olduklarını not ediyoruz. Sabit birα için, ( [1] ) hesaplar ve ilk birkaç (genellikle iki) cPC tarafından kapsanan alt uzayı döndürürüz.

Karşılaştırma parametresiα , yüksek hedef varyansı ve düşük arka plan varyansı arasında dengeyi temsil eder.α = 0 olduğunda, cPCA yalnızca hedef varyansı maksimize eden yönleri seçer ve dolayısıyla hedef veri {x i} üzerinde uygulanan PCA'ya indirgenir.α arttıkça, daha küçük arka plan varyansına sahip yönler daha önemli hale gelir ve cPC'ler arka plan verinin {y i} null uzayına yönlendirilir. Sınır durumundaα = ∞, {y i} null uzayında olmayan herhangi bir yön sonsuz bir ceza alır. Bu durumda, cPCA, hedef veriyi önce arka plan verinin null uzayına yansıtmak ve ardından yansıtılan veri üzerinde PCA yapmak anlamına gelir.

Tek birα seçmek ve onun alt uzayını döndürmek yerine, cPCA birα listesi için alt uzayları hesaplar ve ana açı açısından birbirinden uzak olan birkaç alt uzayı döndürür. Verilerin bu alt uzaylara yansıtılması, hedef veri içinde farklı eğilimleri ortaya çıkaracak ve döndürülen dağılım grafikleri görsel olarak incelenerek, kullanıcı analizine uygun alt uzayı (ve karşılık gelenα değerini) hızla belirleyebilir. Ayrıntılı bir örnek için Ek Fig. [1] 'e bakınız.

cPCA'nın tam algoritması Algoritma 2'de (Ek Yöntemler) açıklanmıştır. Genellikle, potansiyelα değerlerinin listesini 0.1 ile 1000 arasında logaritmik olarak aralıklı 40 değer olarak ayarlarız ve bu, makaledeki tüm deneyler için kullanılır. Temsilci alt uzayları seçmek için, cPCA alt uzayları kümelemek için spektral kümeleme kullanır, burada yakınlık, alt uzaylar arasındaki ana açıların kosinüsünün çarpımı olarak tanımlanır. Daha sonra, her kümenin medoidleri (temsilcileri) kullanıcı tarafından görülen dağılım grafikleri oluşturmak içinα değerleri olarak kullanılır.

Arka plan veri kümesinin seçimi, cPCA'nın sonucunu büyük ölçüde etkiler. Genel olarak, arka plan verileri, hedef verilerden çıkarmak istediğimiz yapıya sahip olmalıdır. Bu tür bir yapı genellikle hedefte yüksek varyansa sahip yönlere karşılık gelir, ancak analist için ilgi çekici değildir.

Hedef verilere faydalı karşıtlıklar sağlayabilecek birkaç genel arka plan veri kümesi örneği sunuyoruz: (1) Bir kontrol grubu {y i} ile hastalıklı bir popülasyon {x i} karşılaştırılır çünkü kontrol grubu benzer popülasyon düzeyinde varyasyon içerir ancak hastalığın farklı alt tiplerinden kaynaklanan ince varyasyonu içermez. (2) Sıfır zamanındaki veriler {y i} daha sonraki bir zaman noktasındaki verilerle {x i} karşılaştırılır. Bu, zaman içindeki en belirgin değişikliklerin görselleştirilmesini sağlar. (3) Homojen bir grup {y i} ile karışık bir grup {x i} karşılaştırılır çünkü her ikisi de popülasyon içi varyasyon ve ölçüm gürültüsü içerir, ancak ilki popülasyonlar arası varyasyon içermez. (4) Tedavi öncesi bir veri kümesi {y i} tedavi sonrası verilerle {x i} karşılaştırılır, ölçüm gürültüsünü kaldırmak ancak tedaviden kaynaklanan varyasyonları korumak için. (5) Sadece gürültü içeren sinyalsiz kayıtlar {y i} veya görüntüler, hem sinyal hem de gürültü içeren ölçümlerle {x i} karşılaştırılır.

Eklemek gerekir ki, arka plan verilerinin, hedef veri kümesinden çıkarmak istediğimizle tam olarak aynı kovaryans yapısına sahip olması gerekmez. Örneğin, Fig. [2] 'de gösterilen deneyde, çimen görüntülerinden oluşan bir arka plan veri kümesi kullanmamıza gerek olmadığı ortaya çıkıyor. Aslında, çimen görüntüleri yerine gökyüzü görüntüleri arka plan veri kümesi olarak kullanılsa bile benzer sonuçlar elde edilir. Kovaryans matrislerinin yapısı yeterince benzer olduğundan, cPCA hedef verilerden arka plan yapısını çıkarır. Ayrıca, cPCA'nın hedef veriler ve arka plan verilerinin benzer sayıda örneğe sahip olmasını gerektirmediğini belirtmek gerekir. Kovaryans matrisleri bağımsız olarak hesaplandığından, cPCA yalnızca ampirik kovaryans matrislerinin altta yatan popülasyon kovaryans matrislerinin iyi tahminleri olmasını gerektirir, bu da esasen PCA ile aynı gereksinimdir.

Burada, cPCA'nın geometrik yorumunu ve istatistiksel özelliklerini tartışıyoruz. İlk olarak, karşıt analiz amacıyla hangi yönlerin "daha iyi" olduğunu düşünmek ilginçtir. Bir yön içinv ∈ R unit d , cPCA'daki önemi, hedef-arka plan varyans çifti (λ X(v ),λ Y(v )) ile tamamen belirlenir; daha yüksek bir hedef varyansı ve daha düşük bir arka plan varyansı olması arzu edilir. Bu sezgiye dayanarak, çeşitli yönler için kısmi bir karşıtlık sırası daha tanımlayabiliriz: iki yön içinv1 vev2 ,v1 daha yüksek bir hedef varyansı ve daha düşük bir arka plan varyansı varsa daha iyi bir karşıt yön olduğunu söyleyebiliriz. Bu durumda,v1 'in hedef-arka plan varyans çifti, hedef-arka plan varyans çiftlerinin grafiğinde (λ X(v ),λ Y(v ))v2 'nin sağ alt tarafında yer alır, örneğin Fig. [5]. Bu kısmi sıraya dayanarak, en karşıt yönlerin kümesi, Pareto sınırının tanımına benzer bir şekilde tanımlanabilir.U  tüm yönler için hedef-arka plan varyans çiftlerinin kümesi olsun, yaniU = def  ( λX ( v ) ,λY ( v ))v ∈Runitd. En karşıt yönlerin kümesi, hedef-arka plan varyans çiftlerinin grafiğindeU 'nin sağ alt sınırına karşılık gelir, Fig.[5]'de gösterildiği gibi. (Eşzamanlı olarak köşegenleştirilebilir arka plan ve hedef matrisler için özel durum için, Ek Fig.[7]'ye bakınız.)

cPCA ile ilgili olarak,α 'yı değiştirerek, en üst cPC'lerin kümesinin en karşıt yönlerin kümesiyle aynı olduğunu kanıtlayabiliriz (bkz. Ek Not [2] ). Ayrıca,α kontrast parametresi ile cPCA tarafından seçilenv yönü için, varyans çifti (λ X(v ),λ Y(v ))U  'nin sağ alt sınırının bir eğim-1/α çizgisi ile teğet noktasına karşılık gelir. Sonuç olarak,α 'yı sıfırdan sonsuza kadar değiştirerek, cPCA,U  'nin sağ alt sınırının sol alt ucundan sağ üst ucuna doğru hareket eden varyans çiftleri ile yönleri seçer.

Verilerin rastgeleliği ile ilgili olarak, örnek cPC'nin popülasyon cPC'ye yakınsama oranınınO p  dmin ( n,m ) olduğu belirtilmelidir, buradad boyut ven ,m hedef ve arka plan verilerinin boyutlarıdır. Bu oran, bir kovaryans matrisi için örnek özvektörün standart yakınsama oranına benzerdir. Ek Not [2] 'ye bakınız.

Karşıt PCA'nın bir Python uygulamasını GitHub'da yayınladık (https://github.com/abidlabs/contrastive ). GitHub deposu ayrıca bu makaledeki ve Ek Bilgilerdeki figürlerin çoğunu yeniden üreten Python defterleri ve veri kümelerini de içerir.

Bu makalede karşıt PCA'yı değerlendirmek için kullanılan veri kümeleri ya bizden ya da orijinal çalışmaların yazarlarından temin edilebilir. Yayınladığımız veri kümeleri için lütfen önceki bölümde listelenen GitHub deposuna bakınız.

Fig. 1: cPCA'nın Şematik Genel Görünümü. cPCA'yı gerçekleştirmek için, hedef ve arka plan veri kümelerinin kovaryans matrislerini C X, C Yhesaplayın. Kovaryans matrislerinin ağırlıklı farkının tekil vektörleri, C X− α · C Y, cPCA tarafından döndürülen yönlerdir. Sağdaki dağılım grafiğinde gösterildiği gibi, PCA (hedef veri üzerinde) hedef veride en yüksek varyansa sahip yönü tanımlar, oysa cPCA, hedef veride arka plan verisine kıyasla daha yüksek varyansa sahip yönü tanımlar. Hedef veriyi bu son yöne projelendirmek, hedef veriye özgü desenler verir ve genellikle PCA tarafından kaçırılan yapıyı ortaya çıkarır. Özellikle, bu örnekte, cPCA ile hedef verinin boyutunu azaltmak, iki farklı küme ortaya çıkaracaktır

Fig. 2: Gürültülü Rakamlar Üzerinde Karşıt PCA.a, Üst: MNIST veri setinden el yazısı rakamları 0 ve 1'in görüntülerini, ImageNet veri setinden alınan çimen görüntülerinin üzerine rastgele bindirerek 5.000 sentetik görüntüden oluşan bir hedef veri seti oluşturuyoruz. Çimen görüntüleri gri tonlamaya dönüştürülür, 100 × 100 boyutuna yeniden boyutlandırılır ve ardından MNIST rakamlarıyla aynı boyutta, 28 × 28 olacak şekilde rastgele kırpılır.b, Üst: Burada, sentetik görüntülerin standart PCA kullanılarak ilk iki ana bileşene gömülmesinin sonucunu çiziyoruz. 0'ların ve 1'lerin olduğu görüntülere karşılık gelen noktaların ayırt edilmesinin zor olduğunu görüyoruz.a, Alt: Ardından, aynı synset'e ait yalnızca çimen görüntülerinden oluşan bir arka plan veri seti tanıtılır, ancak hedef veri setini oluşturmak için kullanılanlardan farklı görüntüler kullanılır.b, Alt: Hedef ve arka plan veri setlerinde cPCA kullanarak (karşıtlık parametresi α değeri 2.0 olarak ayarlanmış), hedef veri setinin daha düşük boyutlu temsilinde iki küme ortaya çıkar, biri 0 rakamı olan görüntülerden, diğeri 1 rakamı olan görüntülerden oluşur.cHer pikselin ilk ana bileşene (PC) ve ilk karşıt ana bileşene (cPC) olan göreceli katkısını inceliyoruz. Daha beyaz pikseller daha pozitif bir ağırlık taşırken, daha koyu olanlar negatif ağırlık taşıyan pikselleri belirtir. PCA, görüntünün çevresindeki piksellere vurgu yapma eğilimindedir ve görüntünün merkezindeki ve altındaki piksellere biraz daha az vurgu yapar, bu da varyansın çoğunun arka plan özelliklerinden kaynaklandığını gösterir. Öte yandan, cPCA, el yazısı 1'lerin bulunduğu piksellere ağırlık verme, el yazısı 0'ların bulunduğu piksellere negatif ağırlık verme ve diğer piksellerin çoğunu ihmal etme eğilimindedir, bu da üst üste bindirilmiş rakamları ayırt etmek için yararlı olan özellikleri etkili bir şekilde keşfeder

Fig. 3: Biyolojik verilerde alt grupların keşfi. a Down Sendromlu (DS) ve Down Sendromsuz farelerin protein ekspresyon veri setini ilk iki bileşene projelendirmek için PCA kullanıyoruz. DS'li ve DS'siz farelerden alınan protein ekspresyon ölçümlerinin daha düşük boyutlu temsili benzer şekilde dağıtılmış olarak görülmektedir (üst). Ancak, veri setini ilk iki cPC'ye projelendirmek için cPCA kullandığımızda, DS'li ve DS'siz fareleri ayrı ayrı kümelendiren daha düşük boyutlu bir temsil keşfederiz (alt). b Ayrıca, yüksek boyutlu tek hücreli RNA-Seq veri setini iki boyutta görselleştirmek için PCA ve cPCA kullanıyoruz. Veri seti, iki lösemi hastasından dört hücre örneğinden oluşur: hasta 1'den bir nakil öncesi örnek, hasta 1'den bir nakil sonrası örnek, hasta 2'den bir nakil öncesi örnek ve hasta 2'den bir nakil sonrası örnek. b , sol: Sadece hasta 1'den alınan örnekleri kullanarak elde edilen sonuçlar, cPCA'nın (alt) örnekleri PCA'dan (üst) daha etkili bir şekilde ayırdığını gösterir. İkinci hastadan alınan örnekler dahil edildiğinde, b , sağda, yine cPCA (alt) örnekleri ayırmada PCA'dan (üst) daha etkilidir, ancak her iki hastadan nakil sonrası hücreler benzer şekilde dağıtılmıştır. Her örneğin ayrı ayrı çizimlerini Supplementary Fig.[5] 'te gösteriyoruz, burada farklı örnekler arasındaki örtüşmeyi görmek daha kolaydır

Fig. 4: Meksika köken grupları arasındaki ilişki. a 5 Meksika eyaletinden bireylerin genetik verilerine uygulanan PCA, gömülü verilerde görsel olarak ayırt edilebilir herhangi bir desen ortaya çıkarmaz. b Aynı veri setine uygulanan cPCA, verilerdeki desenleri ortaya çıkarır: aynı eyaletten bireyler, cPCA gömülmesinde birbirine daha yakın kümelenmiştir. c Ayrıca, noktaların dağılımı, gruplar arasındaki ilişkileri, farklı eyaletlerin coğrafi konumuyla eşleşen bir şekilde ortaya çıkarır: örneğin, coğrafi olarak bitişik eyaletlerden bireyler, gömülmede bitişiktir. c Meksika haritasından uyarlanmıştır, orijinal olarak Wikipedia'da User:Allstrak tarafından yapılmış, CC-BY-SA lisansı altında yayımlanmış, https://commons.wikimedia.org/wiki/File:Mexico_Map.svg adresinden alınmıştır

Fig. 5: cPCA'nın Geometrik Yorumu. Hedef-arka plan varyans çiftlerinin kümesiU, bazı rastgele üretilmiş hedef ve arka plan verileri için teal bölge olarak çizilmiştir. Alt-sağ sınır, altın renkte renklendirilmiş, en karşıt yönlerin kümesine karşılık gelirSλ. Mavi üçgenler, sırasıyla α değerleri 0.92 ve 0.29 ile seçilen cPC'ler için varyans çiftleridir. Altın eğri ve eğim1α= 1.08, 3.37 olan teğet çizgilerin teğet noktalarına karşılık geldiklerini not ediyoruz

