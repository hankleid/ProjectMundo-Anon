Meneroka corak yang diperkaya dalam set data dengan analisis komponen utama kontras

Abstrak: Visualisasi dan penerokaan data berdimensi tinggi adalah cabaran yang meluas merentasi disiplin. Teknik yang digunakan secara meluas seperti analisis komponen utama (PCA) bertujuan untuk mengenal pasti trend dominan dalam satu set data. Walau bagaimanapun, dalam banyak keadaan, kita mempunyai set data yang dikumpulkan di bawah keadaan yang berbeza, contohnya, eksperimen rawatan dan kawalan, dan kita berminat untuk memvisualisasikan dan meneroka corak yang khusus untuk satu set data. Kertas ini mencadangkan satu kaedah, analisis komponen utama kontras (cPCA), yang mengenal pasti struktur berdimensi rendah yang diperkaya dalam satu set data berbanding data perbandingan. Dalam pelbagai eksperimen, kami menunjukkan bahawa cPCA dengan set data latar belakang membolehkan kami memvisualisasikan corak khusus set data yang terlepas oleh PCA dan kaedah standard lain. Kami juga menyediakan tafsiran geometri cPCA dan jaminan matematik yang kukuh. Pelaksanaan cPCA tersedia secara umum, dan boleh digunakan untuk analisis data eksploratori dalam banyak aplikasi di mana PCA kini digunakan.

Analisis komponen utama (PCA) adalah salah satu kaedah yang paling banyak digunakan untuk penerokaan dan visualisasi data. PCA memproyeksikan data ke ruang berdimensi rendah dan sangat berkuasa sebagai pendekatan untuk memvisualisasikan corak, seperti kelompok, garis, dan pencilan dalam satu set data. Terdapat banyak kaedah visualisasi berkaitan; sebagai contoh, t-SNE dan penskalaan berbilang dimensi (MDS) membenarkan unjuran data tak linear dan mungkin lebih baik menangkap corak tak linear berbanding PCA. Namun, semua kaedah ini direka untuk meneroka satu set data pada satu masa. Apabila penganalisis mempunyai pelbagai set data (atau pelbagai keadaan dalam satu set data untuk dibandingkan), amalan semasa adalah untuk melaksanakan PCA (atau t-SNE, MDS, dll.) pada setiap set data secara berasingan, dan kemudian membandingkan secara manual pelbagai unjuran untuk meneroka jika terdapat persamaan dan perbezaan yang menarik di antara set data,. PCA kontras (cPCA) direka untuk mengisi jurang ini dalam penerokaan dan visualisasi data dengan secara automatik mengenal pasti unjuran yang menunjukkan perbezaan paling menarik di antara set data. Rajah[1]memberikan gambaran keseluruhan cPCA yang akan kami jelaskan dengan lebih terperinci di hadapan.

cPCA didorong oleh pelbagai masalah merentasi disiplin. Sebagai ilustrasi, kami menyebut dua masalah sedemikian di sini dan menunjukkan yang lain melalui eksperimen kemudian dalam kertas ini. Pertama, pertimbangkan satu set data pengukuran ekspresi gen daripada individu pelbagai etnik dan jantina. Data ini termasuk tahap ekspresi gen pesakit kanser {x i}, yang kami berminat untuk menganalisis. Kami juga mempunyai data kawalan, yang sepadan dengan tahap ekspresi gen pesakit sihat {y i} dari latar belakang demografi yang serupa. Matlamat kami adalah untuk mencari tren dan variasi dalam kalangan pesakit kanser (contohnya, untuk mengenal pasti subjenis molekul kanser). Jika kami terus menggunakan PCA pada {x i}, bagaimanapun, komponen utama teratas mungkin sepadan dengan variasi demografi individu dan bukannya subjenis kanser kerana variasi genetik disebabkan oleh yang pertama mungkin lebih besar daripada yang kedua. Kami mendekati masalah ini dengan menyedari bahawa pesakit sihat juga mengandungi variasi yang berkaitan dengan perbezaan demografi, tetapi tidak variasi yang sepadan dengan subjenis kanser. Oleh itu, kami boleh mencari komponen di mana {x i} mempunyai varians tinggi tetapi {y i} mempunyai varians rendah.

Sebagai contoh berkaitan, pertimbangkan satu set data {x i} yang terdiri daripada digit tulisan tangan pada latar belakang yang kompleks, seperti pelbagai imej rumput (lihat Fig.[2(a), atas]). Matlamat tugas pembelajaran tanpa pengawasan tipikal mungkin untuk mengelompokkan data, mendedahkan digit yang berbeza dalam imej. Walau bagaimanapun, jika kita menggunakan PCA standard pada imej-imej ini, kita mendapati bahawa komponen utama teratas tidak mewakili ciri-ciri berkaitan dengan digit tulisan tangan, tetapi mencerminkan variasi dominan dalam ciri-ciri berkaitan dengan latar belakang imej (Fig.[2(b)], atas). Kami menunjukkan bahawa adalah mungkin untuk membetulkan ini dengan menggunakan satu set data rujukan {y i} yang terdiri semata-mata daripada imej rumput (tidak semestinya imej yang sama digunakan dalam {x i} tetapi mempunyai kovarians yang serupa antara ciri-ciri, seperti yang ditunjukkan dalam Fig.[2(a)], bawah), dan mencari subruang varians yang lebih tinggi dalam {x i} berbanding {y i}. Dengan memproyeksikan ke subruang ini, kita sebenarnya boleh memisahkan imej secara visual berdasarkan nilai digit tulisan tangan (Fig. 2(b), bawah). Dengan membandingkan komponen utama yang ditemui oleh PCA dengan yang ditemui oleh cPCA, kita melihat bahawa cPCA mengenal pasti ciri-ciri yang lebih relevan (Fig.[2(c)]), yang membolehkan kita menggunakan cPCA untuk aplikasi seperti pemilihan ciri dan pengurangan bunyi.

PCA kontras adalah alat untuk pembelajaran tanpa pengawasan, yang mengurangkan dimensi dengan cekap untuk membolehkan visualisasi dan analisis data penerokaan. Ini memisahkan cPCA daripada kelas besar kaedah pembelajaran berpengawasan yang matlamat utamanya adalah untuk mengklasifikasikan atau membezakan antara pelbagai set data, seperti analisis diskriminan linear (LDA), analisis diskriminan kuadratik (QDA), PCA berpengawasan, dan QUADRO. Ini juga membezakan cPCA daripada kaedah yang mengintegrasikan pelbagai set data, dengan matlamat untuk mengenal pasti corak berkorelasi antara dua atau lebih set data, dan bukannya yang unik untuk setiap set data individu. Terdapat juga keluarga kaya kaedah tanpa pengawasan untuk pengurangan dimensi selain PCA. Sebagai contoh, penskalaan berbilang dimensi (MDS) mencari penanaman berdimensi rendah yang mengekalkan jarak dalam ruang berdimensi tinggi; pengejaran komponen utama mencari subruang pangkat rendah yang tahan terhadap bunyi kecil pada setiap entri dan kesalahan jarang yang besar. Tetapi tiada satu pun direka untuk menggunakan maklumat yang relevan dari set data kedua, seperti yang dilakukan oleh cPCA. Dalam suplemen, kami telah membandingkan cPCA dengan banyak teknik yang disebutkan sebelumnya pada set data perwakilan (lihat Rajah Tambahan[3]dan[4]), , ,.

Dalam domain aplikasi tertentu, mungkin terdapat alat khusus dalam domain tersebut dengan matlamat yang serupa dengan cPCA, ,. Sebagai contoh, dalam hasil, kami menunjukkan bagaimana cPCA yang diterapkan pada data genotip memvisualisasikan keturunan geografi dalam Mexico. Meneroka kelompok keturunan genetik yang terperinci adalah masalah penting dalam genetik populasi, dan penyelidik baru-baru ini telah membangunkan algoritma untuk secara khusus memvisualisasikan kelompok keturunan sedemikian. Walaupun cPCA berfungsi dengan baik di sini, algoritma yang direka oleh pakar mungkin berfungsi lebih baik untuk set data tertentu. Walau bagaimanapun, algoritma khusus memerlukan pengetahuan domain yang besar untuk direka, lebih mahal dari segi pengiraan, dan boleh mencabar untuk digunakan. Matlamat cPCA bukan untuk menggantikan semua kaedah canggih khusus ini dalam setiap domain mereka, tetapi untuk menyediakan kaedah umum untuk meneroka set data sewenang-wenangnya.

Kami mencadangkan algoritma konkrit dan cekap untuk cPCA dalam kertas ini. Kaedah ini mengambil sebagai input satu set data sasaran {x i} yang kami berminat untuk memvisualisasikan atau mengenal pasti corak di dalamnya. Sebagai input sekunder, cPCA mengambil satu set data latar belakang {y i}, yang tidak mengandungi corak yang diminati. Algoritma cPCA mengembalikan subruang yang menangkap sejumlah besar variasi dalam data sasaran {x i}, tetapi sedikit dalam latar belakang {y i} (lihat Fig.[1], Kaedah, dan Kaedah Tambahan untuk lebih terperinci). Subruang ini sepadan dengan ciri-ciri yang mengandungi struktur khusus untuk {x i}. Oleh itu, apabila data sasaran diproyeksikan ke subruang ini, kami dapat memvisualisasikan dan menemui struktur tambahan dalam data sasaran berbanding latar belakang. Seperti komponen utama (PC), kami memanggil arah yang ditemui oleh cPCA sebagai komponen utama kontras (cPC). Kami menekankan bahawa cPCA pada dasarnya adalah teknik tanpa pengawasan, direka untuk menyelesaikan corak dalam satu set data dengan lebih jelas dengan menggunakan set data latar belakang sebagai kontras. Khususnya, cPCA tidak bertujuan untuk membezakan antara set data sasaran dan latar belakang; subruang yang mengandungi tren yang diperkaya dalam set data sasaran tidak semestinya subruang yang optimum untuk klasifikasi antara set data.

Penyelidik telah menyatakan bahawa PCA standard sering tidak berkesan dalam menemui subkumpulan dalam data biologi, sekurang-kurangnya sebahagiannya kerana "komponen utama dominan...berkorelasi dengan artifak," dan bukannya dengan ciri-ciri yang menarik minat penyelidik. Bagaimana cPCA boleh digunakan dalam tetapan ini untuk mengesan subkumpulan yang lebih signifikan? Dengan menggunakan set data latar belakang untuk membatalkan variasi universal tetapi tidak menarik dalam sasaran, kita boleh mencari struktur yang unik untuk set data sasaran.

Eksperimen pertama kami menggunakan satu set data yang terdiri daripada pengukuran ekspresi protein tikus yang telah menerima terapi kejutan,. Beberapa tikus telah mengembangkan Sindrom Down (DS). Untuk mencipta tugas pembelajaran tanpa pengawasan di mana kami mempunyai maklumat kebenaran asas untuk menilai kaedah, kami menganggap maklumat DS ini tidak diketahui oleh penganalisis dan hanya menggunakannya untuk penilaian algoritma. Kami ingin melihat jika kami mengesan sebarang perbezaan yang signifikan dalam populasi tikus yang terkejut secara tanpa pengawasan (kehadiran atau ketiadaan Sindrom Down menjadi contoh utama). Dalam Fig. [3a] (atas), kami menunjukkan hasil penggunaan PCA pada set data sasaran: data yang ditransformasikan tidak mendedahkan sebarang pengelompokan yang signifikan dalam populasi tikus. Sumber utama variasi dalam tikus mungkin semula jadi, seperti jantina atau umur.

Kami menggunakan cPCA pada set data ini menggunakan latar belakang yang terdiri daripada pengukuran ekspresi protein dari satu set tikus yang tidak terdedah kepada terapi kejutan. Mereka adalah tikus kawalan yang mungkin mempunyai variasi semula jadi yang serupa dengan tikus eksperimen, tetapi tanpa perbezaan yang dihasilkan daripada terapi kejutan. Dengan set data ini sebagai latar belakang, cPCA dapat menyelesaikan dua kumpulan berbeza dalam data sasaran yang ditransformasikan, satu sepadan dengan tikus yang tidak mempunyai Sindrom Down dan satu sepadan (kebanyakannya) dengan tikus yang mempunyai Sindrom Down, seperti yang digambarkan dalam Fig. [3a] (bawah). Sebagai perbandingan, kami juga menggunakan 8 teknik pengurangan dimensi lain untuk mengenal pasti arah yang membezakan antara set data sasaran dan latar belakang, tiada satu pun yang dapat memisahkan tikus sebaik cPCA (lihat Rajah Tambahan [4] untuk butiran).

Seterusnya, kami menganalisis satu set data awam berdimensi tinggi yang terdiri daripada tahap ekspresi RNA sel tunggal dari campuran sel mononuklear sumsum tulang (BMMCs) yang diambil dari pesakit leukemia sebelum pemindahan sel stem dan BMMCs dari pesakit yang sama selepas pemindahan sel stem. Semua data RNA-Seq sel tunggal diproses menggunakan kaedah serupa seperti yang diterangkan oleh penulis. Khususnya, sebelum menggunakan PCA atau cPCA, semua set data dikurangkan kepada 500 gen, yang dipilih berdasarkan penyebaran tertinggi [varians dibahagi dengan purata] dalam data sasaran. Sekali lagi, kami melaksanakan PCA untuk melihat jika kami dapat secara visual menemui dua sampel dalam data yang ditransformasikan. Seperti yang ditunjukkan dalam Fig. [3b] (kiri atas), kedua-dua jenis sel mengikuti pengedaran yang serupa dalam ruang yang direntangi oleh dua PC pertama. Ini mungkin kerana perbezaan antara sampel adalah kecil dan PC sebaliknya mencerminkan heterogenitas pelbagai jenis sel dalam setiap sampel atau bahkan variasi dalam keadaan eksperimen, yang boleh mempunyai kesan yang signifikan pada pengukuran RNA-Seq sel tunggal.

Kami menggunakan cPCA dengan dataset latar belakang yang terdiri daripada pengukuran RNA-Seq dari sel BMMC individu yang sihat. Kami menjangkakan dataset latar belakang ini mengandungi variasi disebabkan oleh populasi sel yang heterogen serta variasi dalam keadaan eksperimen. Kami berharap, cPCA dapat memulihkan arah yang diperkaya dalam data sasaran, yang sepadan dengan perbezaan pra dan pasca-transplantasi. Memang, itulah yang kami dapati, seperti yang ditunjukkan dalam Fig. [3b] (bawah kiri).

Kami seterusnya menambah dataset sasaran kami dengan sampel BMMC dari pesakit leukemia kedua, sekali lagi sebelum dan selepas transplantasi sel stem. Oleh itu, terdapat sejumlah empat subpopulasi sel. Aplikasi PCA pada data ini menunjukkan bahawa keempat-empat subpopulasi tidak dapat dipisahkan dalam subruang yang direntangi oleh dua komponen utama (PCs) teratas, seperti yang ditunjukkan dalam Fig. [3b] (atas kanan). Sekali lagi, apabila cPCA digunakan dengan dataset latar belakang yang sama, sekurang-kurangnya tiga daripada subpopulasi menunjukkan pemisahan yang lebih kuat, seperti yang ditunjukkan dalam Fig. [3b] (bawah kanan). Pembenaman cPCA juga mencadangkan bahawa sampel sel dari kedua-dua pesakit lebih serupa antara satu sama lain selepas transplantasi sel stem (titik sian dan hijau) berbanding sebelum transplantasi (titik emas dan merah jambu), satu hipotesis yang munasabah yang boleh diuji oleh penyelidik. Seseorang boleh merujuk kepada Fig. Tambahan [5] untuk maklumat lanjut mengenai eksperimen ini. Kami melihat bahawa cPCA boleh menjadi alat berguna untuk menyimpulkan hubungan antara subpopulasi, satu topik yang kami terokai lebih lanjut seterusnya.

Dalam contoh-contoh sebelumnya, kami telah melihat bahawa cPCA membolehkan pengguna menemui subkelas dalam dataset sasaran yang tidak dilabelkan terlebih dahulu. Walau bagaimanapun, walaupun subkelas diketahui lebih awal, pengurangan dimensi boleh menjadi cara berguna untuk menggambarkan hubungan dalam kumpulan. Sebagai contoh, PCA sering digunakan untuk menggambarkan hubungan antara populasi etnik berdasarkan varian genetik, kerana memproyeksikan varian genetik ke dalam dua dimensi sering menghasilkan peta yang menawarkan visualisasi yang menarik tentang tren geografi dan sejarah,. Tetapi sekali lagi, PCA terhad kepada mengenal pasti struktur yang paling dominan; apabila ini mewakili variasi universal atau tidak menarik, cPCA boleh lebih berkesan dalam menggambarkan tren.

Dataset yang kami gunakan untuk contoh ini terdiri daripada polimorfisme nukleotida tunggal (SNPs) dari genom individu dari lima negeri di Mexico, yang dikumpulkan dalam kajian sebelumnya. Keturunan Mexico sukar untuk dianalisis menggunakan PCA kerana PCs biasanya tidak mencerminkan asal geografi dalam Mexico; sebaliknya, mereka mencerminkan perkadaran warisan Eropah/Asli Amerika setiap individu Mexico, yang mendominasi dan mengaburkan perbezaan disebabkan oleh asal geografi dalam Mexico (lihat Fig. [4a] ). Untuk mengatasi masalah ini, ahli genetik populasi secara manual memangkas SNPs, mengeluarkan yang diketahui berasal dari keturunan Eropah, sebelum menggunakan PCA. Walau bagaimanapun, prosedur ini mempunyai keterbatasan kerana ia memerlukan pengetahuan tentang asal SNPs dan bahawa sumber variasi latar belakang sangat berbeza dari variasi yang diminati, yang sering tidak berlaku.

Sebagai alternatif, kami menggunakan cPCA dengan dataset latar belakang yang terdiri daripada individu dari Mexico dan dari Eropah. Latar belakang ini didominasi oleh variasi Asli Amerika/Eropah, membolehkan kami mengasingkan variasi intra-Mexico dalam dataset sasaran. Hasil penggunaan cPCA ditunjukkan dalam Fig. [4b]. Kami mendapati bahawa individu dari negeri yang sama di Mexico tertanam lebih dekat antara satu sama lain. Tambahan pula, dua kumpulan yang paling berbeza adalah Sonorans dan Mayans dari Yucatan, yang juga paling jauh secara geografi dalam Mexico, manakala orang Mexico dari tiga negeri lain berdekatan antara satu sama lain, baik secara geografi mahupun dalam pembenaman yang ditangkap oleh cPCA (lihat Fig. [4c] ). Lihat juga Fig. Tambahan [6] untuk maklumat lanjut.

Dalam banyak tetapan sains data, kami berminat untuk menggambarkan dan meneroka corak yang diperkaya dalam satu dataset berbanding data lain. Kami telah membentangkan cPCA sebagai alat umum untuk melakukan penerokaan kontras seperti itu, dan kami telah menggambarkan kegunaannya dalam pelbagai aplikasi. Kelebihan utama cPCA adalah keumuman dan kemudahan penggunaannya. Mengira cPCA tertentu mengambil masa yang sama dengan mengira PCA biasa. Kecekapan pengiraan ini membolehkan cPCA berguna untuk penerokaan data interaktif, di mana setiap operasi seharusnya hampir serta-merta. Oleh itu, dalam mana-mana tetapan di mana PCA digunakan pada dataset berkaitan, cPCA juga boleh digunakan. Dalam Nota Tambahan[3]dan Fig. Tambahan[8], kami menunjukkan bagaimana cPCA boleh dikernelkan untuk mendedahkan corak kontras bukan linear dalam dataset.

Satu-satunya parameter bebas dalam cPCA kontras adalah kekuatan kontrasα. Dalam algoritma lalai kami, kami membangunkan skema automatik berdasarkan pengelompokan subruang untuk memilih nilaiα yang paling bermaklumat (lihat Kaedah). Semua eksperimen yang dilakukan untuk kertas ini menggunakan nilaiα yang dihasilkan secara automatik, dan kami percaya lalai ini akan mencukupi dalam banyak aplikasi cPCA. Pengguna juga boleh memasukkan nilai khusus untukα jika penerokaan yang lebih terperinci diinginkan.

cPCA, seperti PCA biasa dan kaedah pengurangan dimensi lain, tidak memberikan nilaip atau kuantifikasi kepentingan statistik lain. Corak yang ditemui melalui cPCA perlu disahkan melalui ujian hipotesis atau analisis tambahan menggunakan pengetahuan domain yang relevan. Kami telah melepaskan kod untuk cPCA sebagai pakej python bersama dengan dokumentasi dan contoh.

Untuk data sasaran berdimensidxi ∈ Rd dan data latar belakangyi ∈ Rd , biarkanC X,C Ymenjadi matriks kovarians empirik yang sepadan. BiarkanR unit d = def v ∈ Rd :v2 = 1 menjadi set vektor unit. Untuk sebarang arahv ∈ R unit d , varians yang diambil kira dalam data sasaran dan dalam data latar belakang boleh ditulis sebagai: Target data variance :λX ( v ) =defvTCXv , Background data variance :λY ( v ) =defvTCYv.Diberi parameter kontrasα ≥ 0 yang mengkuantifikasi pertukaran antara mempunyai varians sasaran tinggi dan varians latar belakang rendah, cPCA mengira arah kontrasv * dengan mengoptimumkan 1 v * = argmax v ∈ Runitd λ X(v)- α λ Y(v).  Masalah ini boleh ditulis semula sebagaiv * = argmax v ∈ Runitd v T CX - α CY v ,  yang menyiratkan bahawav * sepadan dengan eigenvektor pertama matriksC = def CX - α CY. Oleh itu, arah kontras boleh dikira dengan cekap menggunakan penguraian nilai eigen. Seperti PCA, kami memanggil eigenvektor utamaC sebagai komponen utama kontras (cPCs). Kami perhatikan bahawa cPCs adalah eigenvektor matriksC dan oleh itu ortogonal antara satu sama lain. Untukα yang tetap, kami mengira ( [1] ) dan mengembalikan subruang yang direntangi oleh beberapa cPCs pertama (biasanya dua).

Parameter kontrasα mewakili pertukaran antara mempunyai varians sasaran tinggi dan varians latar belakang rendah. Apabilaα = 0, cPCA memilih arah yang hanya memaksimumkan varians sasaran, dan oleh itu berkurang kepada PCA yang digunakan pada data sasaran {x i}. Apabilaα meningkat, arah dengan varians latar belakang yang lebih kecil menjadi lebih penting dan cPCs didorong ke arah ruang null data latar belakang {y i}. Dalam kes hadα = ∞, sebarang arah yang tidak berada dalam ruang null {y i} menerima penalti tak terhingga. Dalam kes ini, cPCA sepadan dengan pertama memproyeksikan data sasaran ke ruang null data latar belakang, dan kemudian melakukan PCA pada data yang diproyeksikan.

Daripada memilih satuα dan mengembalikan subruangnya, cPCA mengira subruang dari senaraiα dan mengembalikan beberapa subruang yang jauh antara satu sama lain dari segi sudut utama. Memproyeksikan data ke setiap subruang ini akan mendedahkan trend yang berbeza dalam data sasaran, dan dengan memeriksa plot serakan yang dikembalikan, pengguna dapat dengan cepat mengenal pasti subruang yang relevan (dan nilaiα yang sepadan) untuk analisisnya. Lihat Supplementary Fig. [1] untuk contoh terperinci.

Algoritma lengkap cPCA diterangkan dalam Algoritma 2 (Kaedah Tambahan). Kami biasanya menetapkan senarai nilai potensiα kepada 40 nilai yang dijarakkan secara logaritma antara 0.1 dan 1000 dan ini digunakan untuk semua eksperimen dalam kertas ini. Untuk memilih subruang wakil, cPCA menggunakan pengelompokan spektrum untuk mengelompokkan subruang, di mana afiniti ditakrifkan sebagai hasil darab kosinus sudut utama antara subruang. Kemudian medoid (wakil) setiap kelompok digunakan sebagai nilaiα untuk menjana plot serakan yang dilihat oleh pengguna.

Pemilihan set data latar belakang mempunyai pengaruh besar terhadap hasil cPCA. Secara umum, data latar belakang harus mempunyai struktur yang ingin kita keluarkan dari data sasaran. Struktur sedemikian biasanya sepadan dengan arah dalam sasaran dengan varians tinggi, tetapi tidak menarik minat penganalisis.

Kami menyediakan beberapa contoh umum set data latar belakang yang mungkin memberikan kontras berguna kepada data sasaran: (1) Kumpulan kawalan {y i} dibandingkan dengan populasi berpenyakit {x i} kerana kumpulan kawalan mengandungi variasi peringkat populasi yang serupa tetapi tidak variasi halus disebabkan oleh subtipe penyakit yang berbeza. (2) Data pada masa sifar {y i} digunakan untuk dibandingkan dengan data pada titik masa kemudian {x i}. Ini membolehkan visualisasi perubahan paling ketara dari masa ke masa. (3) Kumpulan homogen {y i} dibandingkan dengan kumpulan campuran {x i} kerana kedua-duanya mempunyai variasi intra-populasi dan bunyi pengukuran, tetapi yang pertama tidak mempunyai variasi antara populasi. (4) Set data pra-rawatan {y i} dibandingkan dengan data pasca-rawatan {x i} untuk mengeluarkan bunyi pengukuran tetapi mengekalkan variasi yang disebabkan oleh rawatan. (5) Satu set rakaman bebas isyarat {y i} atau imej yang hanya mengandungi bunyi, dibandingkan dengan pengukuran {x i} yang terdiri daripada kedua-dua isyarat dan bunyi.

Perlu ditambah bahawa data latar belakang tidak perlu mempunyai struktur kovarians yang sama seperti yang ingin kita keluarkan dari set data sasaran. Sebagai contoh, dalam eksperimen yang ditunjukkan dalam Fig. [2] , ternyata kita tidak perlu menggunakan set data latar belakang yang terdiri daripada imej rumput. Malah, hasil yang serupa diperoleh walaupun sebaliknya imej rumput, imej langit digunakan sebagai set data latar belakang. Oleh kerana struktur matriks kovarians cukup serupa, cPCA mengeluarkan struktur latar belakang dari data sasaran. Selain itu, cPCA tidak memerlukan data sasaran dan data latar belakang mempunyai bilangan sampel yang serupa. Oleh kerana matriks kovarians dikira secara bebas, cPCA hanya memerlukan bahawa matriks kovarians empirik adalah anggaran yang baik bagi matriks kovarians populasi yang mendasari, pada dasarnya keperluan yang sama seperti PCA.

Di sini, kami membincangkan tafsiran geometri cPCA serta sifat statistiknya. Pertama, adalah menarik untuk mempertimbangkan arah mana yang "lebih baik" untuk tujuan analisis kontras. Untuk arahv ∈ R unit d , kepentingannya dalam cPCA ditentukan sepenuhnya oleh pasangan varians sasaran-latar belakangnya (λ X(v ),λ Y(v )); adalah diingini untuk mempunyai varians sasaran yang lebih tinggi dan varians latar belakang yang lebih rendah. Berdasarkan intuisi ini, kita boleh mendefinisikan susunan separa kontras untuk pelbagai arah: untuk dua arahv1 danv2 , kita mungkin mengatakanv1 adalah arah kontras yang lebih baik jika ia mempunyai varians sasaran yang lebih tinggi dan varians latar belakang yang lebih rendah. Dalam kes ini, pasangan varians sasaran-latar belakangv1 akan terletak di sebelah kanan bawahv2 dalam plot pasangan varians sasaran-latar belakang (λ X(v ),λ Y(v )), contohnya, Fig. [5]. Berdasarkan susunan separa ini, set arah yang paling kontras boleh ditakrifkan dengan cara yang sama seperti definisi sempadan Pareto. BiarkanU  menjadi set pasangan varians sasaran-latar belakang untuk semua arah, iaituU = def  ( λX ( v ) ,λY ( v ))v ∈Runitd. Set arah yang paling kontras sepadan dengan sempadan kanan bawahU dalam plot pasangan varians sasaran-latar belakang, seperti yang ditunjukkan dalam Fig.[5]. (Untuk kes tertentu matriks latar belakang dan sasaran yang boleh didiagonalkan serentak, lihat Supplementary Fig.[7].)

Mengenai cPCA, kita boleh membuktikan (lihat Nota Tambahan [2] ) bahawa dengan memvariasikanα , set cPC teratas adalah sama dengan set arah yang paling kontras. Selain itu, untuk arahv yang dipilih oleh cPCA dengan parameter kontras ditetapkan kepadaα , pasangan variansnya (λ X(v ),λ Y(v )) sepadan dengan titik singgung sempadan kanan bawahU  dengan garis cerun-1/α. Akibatnya, dengan memvariasikanα dari sifar hingga infiniti, cPCA memilih arah dengan pasangan varians yang bergerak dari hujung kiri bawah ke hujung kanan atas sempadan kanan bawahU .

Kami juga ingin menyatakan bahawa berkaitan dengan kebolehubahan data, kadar penumpuan sampel cPC kepada populasi cPC adalahO p  dmin ( n,m ) di bawah andaian ringan, di manad adalah dimensi dann ,m adalah saiz data sasaran dan latar belakang. Kadar ini adalah serupa dengan kadar penumpuan standard bagi vektor eigen sampel untuk matriks kovarians. Lihat Nota Tambahan [2].

Kami telah mengeluarkan pelaksanaan Python bagi PCA kontras di GitHub (https://github.com/abidlabs/contrastive ). Repositori GitHub juga termasuk buku nota Python dan set data yang menghasilkan semula kebanyakan angka dalam kertas ini dan dalam Maklumat Tambahan.

Set data yang telah digunakan untuk menilai PCA kontras dalam kertas ini sama ada tersedia daripada kami atau daripada pengarang kajian asal. Sila lihat repositori GitHub yang disenaraikan dalam seksyen sebelumnya untuk set data yang telah kami keluarkan.

Fig. 1: Gambaran Skematik cPCA. Untuk melaksanakan cPCA, hitung matriks kovarians C X, C Ybagi set data sasaran dan latar belakang. Vektor tunggal bagi perbezaan berwajaran matriks kovarians, C X− α · C Y, adalah arah yang dikembalikan oleh cPCA. Seperti yang ditunjukkan dalam plot serakan di sebelah kanan, PCA (pada data sasaran) mengenal pasti arah yang mempunyai varians tertinggi dalam data sasaran, manakala cPCA mengenal pasti arah yang mempunyai varians lebih tinggi dalam data sasaran berbanding data latar belakang. Memproyeksikan data sasaran ke arah yang terakhir memberikan corak unik kepada data sasaran dan sering mendedahkan struktur yang terlepas oleh PCA. Khususnya, dalam contoh ini, pengurangan dimensi data sasaran oleh cPCA akan mendedahkan dua kelompok yang berbeza

Fig. 2: cPCA Kontrastif pada Digit Bising.a, Atas: Kami mencipta set data sasaran sebanyak 5,000 imej sintetik dengan menyusun secara rawak imej digit tulisan tangan 0 dan 1 dari set data MNIST di atas imej rumput yang diambil dari set data ImageNet yang tergolong dalam sinset rumput. Imej rumput ditukar kepada skala kelabu, diubah saiz menjadi 100 × 100, dan kemudian dipotong secara rawak untuk menjadi saiz yang sama dengan digit MNIST, 28 × 28.b, Atas: Di sini, kami memplot hasil pemetaan imej sintetik ke atas dua komponen utama pertama menggunakan PCA standard. Kami melihat bahawa titik yang sepadan dengan imej dengan 0 dan imej dengan 1 sukar dibezakan.a, Bawah: Satu set data latar belakang kemudian diperkenalkan yang hanya terdiri daripada imej rumput yang tergolong dalam sinset yang sama, tetapi kami menggunakan imej yang berbeza daripada yang digunakan untuk mencipta set data sasaran.b, Bawah: Menggunakan cPCA pada set data sasaran dan latar belakang (dengan nilai parameter kontras α ditetapkan kepada 2.0), dua kelompok muncul dalam perwakilan berdimensi rendah set data sasaran, satu terdiri daripada imej dengan digit 0 dan satu lagi dengan digit 1.cKami melihat sumbangan relatif setiap piksel kepada komponen utama pertama (PC) dan komponen utama kontrasif pertama (cPC). Piksel yang lebih putih adalah yang membawa berat lebih positif, manakala yang lebih gelap menunjukkan piksel yang membawa berat negatif. PCA cenderung menekankan piksel di pinggir imej dan sedikit mengurangkan penekanan pada piksel di tengah dan bawah imej, menunjukkan bahawa kebanyakan varians adalah disebabkan oleh ciri latar belakang. Sebaliknya, cPCA cenderung menambah berat pada piksel yang berada di lokasi digit tulisan tangan 1, mengurangkan berat piksel di lokasi digit tulisan tangan 0, dan mengabaikan kebanyakan piksel lain, secara efektif menemui ciri-ciri yang berguna untuk membezakan antara digit yang disusun

Fig. 3: Menemui subkumpulan dalam data biologi. a Kami menggunakan PCA untuk memproyeksikan set data ekspresi protein tikus dengan dan tanpa Sindrom Down (DS) ke atas dua komponen pertama. Perwakilan berdimensi rendah bagi ukuran ekspresi protein dari tikus dengan dan tanpa DS dilihat diedarkan secara serupa (atas). Tetapi, apabila kami menggunakan cPCA untuk memproyeksikan set data ke atas dua cPC pertama, kami menemui perwakilan berdimensi rendah yang mengelompokkan tikus dengan dan tanpa DS secara berasingan (bawah). b Selain itu, kami menggunakan PCA dan cPCA untuk memvisualisasikan set data RNA-Seq sel tunggal berdimensi tinggi dalam dua dimensi. Set data ini terdiri daripada empat sampel sel dari dua pesakit leukemia: sampel pra-transplantasi dari pesakit 1, sampel pasca-transplantasi dari pesakit 1, sampel pra-transplantasi dari pesakit 2, dan sampel pasca-transplantasi dari pesakit 2. b , kiri: Hasil menggunakan hanya sampel dari pesakit 1, yang menunjukkan bahawa cPCA (bawah) lebih berkesan memisahkan sampel daripada PCA (atas). Apabila sampel dari pesakit kedua dimasukkan, dalam b , kanan, sekali lagi cPCA (bawah) lebih berkesan daripada PCA (atas) dalam memisahkan sampel, walaupun sel pasca-transplantasi dari kedua-dua pesakit diedarkan secara serupa. Kami menunjukkan plot setiap sampel secara berasingan dalam Supplementary Fig.[5] , di mana lebih mudah untuk melihat pertindihan antara sampel yang berbeza

Fig. 4: Hubungan antara kumpulan keturunan Mexico. a PCA yang digunakan pada data genetik dari individu dari 5 negeri di Mexico tidak mendedahkan sebarang corak yang dapat dilihat secara visual dalam data tertanam. b cPCA yang digunakan pada set data yang sama mendedahkan corak dalam data: individu dari negeri yang sama dikelompokkan lebih rapat dalam penanaman cPCA. c Selain itu, taburan titik mendedahkan hubungan antara kumpulan yang sepadan dengan lokasi geografi negeri yang berbeza: sebagai contoh, individu dari negeri yang bersebelahan secara geografi adalah bersebelahan dalam penanaman. c Diadaptasi dari peta Mexico yang asalnya adalah karya Pengguna:Allstrak di Wikipedia, diterbitkan di bawah lesen CC-BY-SA, bersumber dari https://commons.wikimedia.org/wiki/File:Mexico_Map.svg

Fig. 5: Tafsiran Geometri cPCA. Set pasangan varians sasaran–latar belakangUdiplotkan sebagai kawasan teal untuk beberapa data sasaran dan latar belakang yang dijana secara rawak. Sempadan bawah-kanan, yang diwarnakan dengan emas, sepadan dengan set arah paling kontrasifSλ. Segitiga biru adalah pasangan varians untuk cPC yang dipilih dengan nilai α masing-masing 0.92 dan 0.29. Kami perhatikan bahawa mereka sepadan dengan titik singgung lengkung emas dan garis singgung dengan cerun1α= 1.08, 3.37, masing-masing

