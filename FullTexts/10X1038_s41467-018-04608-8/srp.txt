Istraživanje obrazaca obogaćenih u skupu podataka pomoću kontrastivne analize glavnih komponenti 

ApstraktVizualizacija i istraživanje podataka visoke dimenzionalnosti je sveprisutan izazov u različitim disciplinama. Široko korišćene tehnike kao što je analiza glavnih komponenti (PCA) imaju za cilj identifikaciju dominantnih trendova u jednom skupu podataka. Međutim, u mnogim situacijama imamo skupove podataka prikupljene pod različitim uslovima, npr. tretman i kontrolni eksperiment, i zainteresovani smo za vizualizaciju i istraživanje obrazaca specifičnih za jedan skup podataka. Ovaj rad predlaže metodu, kontrastivnu analizu glavnih komponenti (cPCA), koja identifikuje niskodimenzionalne strukture koje su obogaćene u skupu podataka u odnosu na uporedne podatke. U širokom spektru eksperimenata, pokazujemo da cPCA sa pozadinskim skupom podataka omogućava vizualizaciju obrazaca specifičnih za skup podataka koji su propušteni od strane PCA i drugih standardnih metoda. Dalje pružamo geometrijsku interpretaciju cPCA i snažne matematičke garancije. Implementacija cPCA je javno dostupna i može se koristiti za istraživačku analizu podataka u mnogim aplikacijama gde se trenutno koristi PCA. 

 Analiza glavnih komponenti (PCA) je jedna od najčešće korišćenih metoda za istraživanje i vizualizaciju podataka. PCA projektuje podatke na prostor niske dimenzionalnosti i posebno je moćna kao pristup za vizualizaciju obrazaca, kao što su klasteri, klini i izuzeci u skupu podataka. Postoji veliki broj srodnih metoda za vizualizaciju; na primer, t-SNE i višedimenzionalno skaliranje (MDS) omogućavaju nelinearne projekcije podataka i mogu bolje uhvatiti nelinearne obrasce nego PCA. Ipak, sve ove metode su dizajnirane da istražuju jedan skup podataka u isto vreme. Kada analitičar ima više skupova podataka (ili više uslova u jednom skupu podataka za poređenje), trenutna praksa je da se PCA (ili t-SNE, MDS, itd.) primeni na svaki skup podataka zasebno, a zatim ručno uporede različite projekcije kako bi se istražilo da li postoje zanimljive sličnosti i razlike između skupova podataka. Kontrastivna PCA (cPCA) je dizajnirana da popuni ovu prazninu u istraživanju i vizualizaciji podataka automatskim identifikovanjem projekcija koje pokazuju najzanimljivije razlike između skupova podataka. Fig.1 pruža pregled cPCA koji ćemo detaljnije objasniti kasnije. Fig. 1 Shema pregleda cPCA. Da biste izvršili cPCA, izračunajte kovarijacione matrice CX , CY ciljnog i pozadinskog skupa podataka. Singularni vektori ponderisane razlike kovarijacionih matrica, CX − α· CY , su pravci koje vraća cPCA. Kao što je prikazano na dijagramu raspršenja desno, PCA (na ciljnim podacima) identifikuje pravac koji ima najveću varijansu u ciljnim podacima, dok cPCA identifikuje pravac koji ima veću varijansu u ciljnim podacima u poređenju sa pozadinskim podacima. Projektovanje ciljnog skupa podataka na ovaj pravac daje obrasce jedinstvene za ciljne podatke i često otkriva strukturu koja je propuštena od strane PCA. Konkretno, u ovom primeru, smanjenje dimenzionalnosti ciljnog skupa podataka pomoću cPCA bi otkrilo dva različita klastera 

 cPCA je motivisana širokim spektrom problema u različitim disciplinama. Za ilustraciju, ovde pominjemo dva takva problema i demonstriramo druge kroz eksperimente kasnije u radu. Prvo, razmotrimo skup podataka merenja ekspresije gena kod pojedinaca različitih etničkih pripadnosti i polova. Ovi podaci uključuju nivoe ekspresije gena kod pacijenata sa rakom {x i}, koje smo zainteresovani da analiziramo. Takođe imamo kontrolne podatke, koji odgovaraju nivoima ekspresije gena kod zdravih pacijenata {y i} iz slične demografske pozadine. Naš cilj je da pronađemo trendove i varijacije unutar pacijenata sa rakom (npr. da identifikujemo molekularne podtipove raka). Ako direktno primenimo PCA na {x i}, međutim, glavne komponente mogu odgovarati demografskim varijacijama pojedinaca umesto podtipovima raka jer su genetske varijacije zbog prvog verovatno veće od onih zbog drugog. Pristupamo ovom problemu primećujući da zdravi pacijenti takođe sadrže varijacije povezane sa demografskim razlikama, ali ne i varijacije koje odgovaraju podtipovima raka. Tako možemo tražiti komponente u kojima {x i} ima visoku varijansu, ali {y i} ima nisku varijansu.

 Kao srodni primer, razmotrimo skup podataka {x i} koji se sastoji od rukom pisanih cifara na složenoj pozadini, kao što su različite slike trave (vidi Fig.2(a), top ). Cilj tipičnog zadatka nenadziranog učenja može biti grupisanje podataka, otkrivajući različite cifre na slici. Međutim, ako primenimo standardnu PCA na ove slike, otkrivamo da glavne komponente ne predstavljaju karakteristike povezane sa rukom pisanim ciframa, već odražavaju dominantnu varijaciju u karakteristikama povezanim sa pozadinom slike (Fig.2(b) , top). Pokazujemo da je moguće ispraviti ovo korišćenjem referentnog skupa podataka {y i} koji se sastoji isključivo od slika trave (ne nužno istih slika korišćenih u {x i} ali sa sličnom kovarijansom između karakteristika, kao što je prikazano u Fig.2(a) , bottom), i traženjem podprostora veće varijanse u {x i} u poređenju sa {y i}. Projektovanjem na ovaj podprostor, možemo vizuelno razdvojiti slike na osnovu vrednosti rukom pisane cifre (Fig. 2(b), bottom). Poređenjem glavnih komponenti otkrivenih pomoću PCA sa onima otkrivenim pomoću cPCA, vidimo da cPCA identifikuje relevantnije karakteristike (Fig.2(c) ), što nam omogućava da koristimo cPCA za takve primene kao što su selekcija karakteristika i uklanjanje šuma. Fig. 2 Kontrastivna PCA na bučnim ciframa. a, Vrh: Kreiramo ciljni skup podataka od 5.000 sintetičkih slika nasumičnim preklapanjem slika rukom pisanih cifara 0 i 1 iz MNIST skupa podatakana slike trave preuzete iz ImageNet skupa podatakakoje pripadaju sinsetu trave. Slike trave su konvertovane u sivu skalu, promenjene veličine na 100 × 100, a zatim nasumično isečene na istu veličinu kao MNIST cifre, 28 × 28. b, Vrh: Ovde prikazujemo rezultat ugrađivanja sintetičkih slika na njihove prve dve glavne komponente koristeći standardnu PCA. Vidimo da su tačke koje odgovaraju slikama sa 0 i slikama sa 1 teško razlikovati. a, Dno: Zatim se uvodi pozadinski skup podataka koji se sastoji isključivo od slika trave koje pripadaju istom sinsetu, ali koristimo slike koje su različite od onih korišćenih za kreiranje ciljnog skupa podataka. b, Dno: Koristeći cPCA na ciljnim i pozadinskim skupovima podataka (sa vrednošću kontrastnog parametra αpostavljenom na 2.0), dva klastera se pojavljuju u nižedimenzionalnoj reprezentaciji ciljnog skupa podataka, jedan koji se sastoji od slika sa cifrom 0 i drugi od slika sa cifrom 1. cPosmatramo relativni doprinos svakog piksela prvoj glavnoj komponenti (PC) i prvoj kontrastivnoj glavnoj komponenti (cPC). Beli pikseli su oni koji nose pozitivniju težinu, dok tamniji označavaju piksele koji nose negativne težine. PCA ima tendenciju da naglašava piksele na periferiji slike i blago smanjuje naglasak na piksele u centru i dnu slike, što ukazuje da je većina varijanse zbog pozadinskih karakteristika. S druge strane, cPCA ima tendenciju da povećava težinu piksela koji se nalaze na lokaciji rukom pisanih 1, negativno teži piksele na lokaciji rukom pisanih 0 i zanemaruje većinu drugih piksela, efikasno otkrivajući one karakteristike korisne za razlikovanje preklopljenih cifara 

 Kontrastivna PCA je alat za nenadzirano učenje, koji efikasno smanjuje dimenzionalnost kako bi omogućio vizualizaciju i istraživačku analizu podataka. Ovo odvaja cPCA od velike klase nadziranih metoda učenja čiji je primarni cilj klasifikacija ili razlikovanje između različitih skupova podataka, kao što su linearna diskriminantna analiza (LDA), kvadratna diskriminantna analiza (QDA), nadzirana PCA i QUADRO. Ovo takođe razlikuje cPCA od metoda koje integrišu više skupova podataka, sa ciljem identifikacije korelisanih obrazaca među dva ili više skupova podataka, umesto onih jedinstvenih za svaki pojedinačni skup podataka. Postoji i bogata porodica nenadziranih metoda za smanjenje dimenzionalnosti pored PCA. Na primer, višedimenzionalno skaliranje (MDS) pronalazi ugrađivanje niske dimenzionalnosti koje čuva udaljenost u prostoru visoke dimenzionalnosti; potraga za glavnim komponentama pronalazi podprostor niskog ranga koji je robustan na male šumove po unosu i velike retke greške. Ali nijedna nije dizajnirana da koristi relevantne informacije iz drugog skupa podataka, kao što to čini cPCA. U dodatku, uporedili smo cPCA sa mnogim prethodno pomenutim tehnikama na reprezentativnim skupovima podataka (vidi Dodatne Fig.3 i4 ).

 U specifičnoj oblasti primene, mogu postojati specijalizovani alati u toj oblasti sa sličnim ciljevima kao cPCA. Na primer, u rezultatima, pokazujemo kako cPCA primenjena na podatke o genotipu vizualizuje geografsko poreklo unutar Meksika. Istraživanje fino-granularnih klastera genetskih porekla je važan problem u populacionoj genetici, i istraživači su nedavno razvili algoritam za specifičnu vizualizaciju takvih klastera porekla. Dok cPCA ovde dobro funkcioniše, algoritam kreiran od strane stručnjaka može još bolje funkcionisati za specifičan skup podataka. Međutim, specijalizovani algoritam zahteva značajno znanje iz oblasti za dizajn, skuplji je u pogledu računarskih resursa i može biti izazovan za korišćenje. Cilj cPCA nije da zameni sve ove specijalizovane metode najnovije tehnologije u svakoj od njihovih oblasti, već da pruži opštu metodu za istraživanje proizvoljnih skupova podataka.

 Predlažemo konkretan i efikasan algoritam za cPCA u ovom radu. Metoda uzima kao ulaz ciljni skup podataka {x i} koji smo zainteresovani da vizualizujemo ili identifikujemo obrasce unutar njega. Kao sekundarni ulaz, cPCA uzima pozadinski skup podataka {y i}, koji ne sadrži obrasce od interesa. Algoritam cPCA vraća podprostore koji hvataju veliku količinu varijacije u ciljnim podacima {x i}, ali malo u pozadini {y i} (vidi Fig.1 , Metode, i Dodatne Metode za više detalja). Ovaj podprostor odgovara karakteristikama koje sadrže strukturu specifičnu za {x i}. Stoga, kada se ciljni podaci projektuju na ovaj podprostor, možemo vizualizovati i otkriti dodatnu strukturu u ciljnim podacima u odnosu na pozadinu. Analogno glavnim komponentama (PCs), pravce pronađene pomoću cPCA nazivamo kontrastivnim glavnim komponentama (cPCs). Naglašavamo da je cPCA fundamentalno nenadzirana tehnika, dizajnirana da jasnije razreši obrasce u jednom skupu podataka korišćenjem pozadinskog skupa podataka kao kontrasta. Konkretno, cPCA ne teži da razlikuje ciljne i pozadinske skupove podataka; podprostor koji sadrži trendove koji su obogaćeni u ciljnim podacima nije nužno isti podprostor koji je optimalan za klasifikaciju između skupova podataka.

Istraživači su primetili da je standardna PCA često neefikasna u otkrivanju podgrupa unutar bioloških podataka, barem delimično zato što se "dominantne glavne komponente...korališu sa artefaktima," umesto sa karakteristikama koje su od interesa istraživaču. Kako se cPCA može koristiti u ovim postavkama za otkrivanje značajnijih podgrupa? Korišćenjem pozadinskog skupa podataka da se poništi univerzalna, ali nezanimljiva varijacija u cilju, možemo tražiti strukturu koja je jedinstvena za ciljni skup podataka. 

Naš prvi eksperiment koristi skup podataka koji se sastoji od merenja ekspresije proteina kod miševa koji su primili terapiju šokom. Neki od miševa su razvili Daunov sindrom (DS). Da bismo kreirali zadatak nenadziranog učenja gde imamo istinite informacije za evaluaciju metoda, pretpostavljamo da ove informacije o DS nisu poznate analitičaru i koristimo ih samo za evaluaciju algoritma. Želeli bismo da vidimo da li možemo otkriti bilo kakve značajne razlike unutar populacije miševa podvrgnutih šoku na nenadzirani način (prisustvo ili odsustvo Daunovog sindroma kao ključni primer). U Fig.3a (top), prikazujemo rezultat primene PCA na ciljni skup podataka: transformisani podaci ne otkrivaju nikakvo značajno grupisanje unutar populacije miševa. Glavni izvori varijacije unutar miševa mogu biti prirodni, kao što su pol ili starost. Fig. 3Otkrivanje podgrupa u biološkim podacima. aKoristimo PCA da projektujemo skup podataka o ekspresiji proteina miševa sa i bez Daunovog sindroma (DS) na prve dve komponente. Nižedimenzionalna reprezentacija merenja ekspresije proteina miševa sa i bez DS se vidi da je slično raspoređena (gore). Ali, kada koristimo cPCA da projektujemo skup podataka na njegove prve dve cPC, otkrivamo nižedimenzionalnu reprezentaciju koja klasteriše miševe sa i bez DS odvojeno (dole). bNadalje, koristimo PCA i cPCA da vizualizujemo visokodimenzionalni skup podataka jednoćelijskog RNA-Seq u dve dimenzije. Skup podataka se sastoji od četiri uzorka ćelija od dva pacijenta sa leukemijom: uzorak pre transplantacije od pacijenta 1, uzorak posle transplantacije od pacijenta 1, uzorak pre transplantacije od pacijenta 2 i uzorak posle transplantacije od pacijenta 2. b, levo: Rezultati koristeći samo uzorke od pacijenta 1, koji pokazuju da cPCA (dole) efikasnije razdvaja uzorke nego PCA (gore). Kada su uključeni uzorci od drugog pacijenta, u b, desno, ponovo cPCA (dole) je efikasniji od PCA (gore) u razdvajanju uzoraka, iako su ćelije posle transplantacije od oba pacijenta slično raspoređene. Prikazujemo grafikone svakog uzorka posebno u Dodatnoj Fig. 5, gde je lakše videti preklapanje između različitih uzoraka

Primenićemo cPCA na ovaj skup podataka koristeći pozadinu koja se sastoji od merenja ekspresije proteina kod skupa miševa koji nisu bili izloženi terapiji šokom. Oni su kontrolni miševi koji verovatno imaju sličnu prirodnu varijaciju kao eksperimentalni miševi, ali bez razlika koje proizlaze iz terapije šokom. Sa ovim skupom podataka kao pozadinom, cPCA je u stanju da razreši dve različite grupe u transformisanim ciljnim podacima, jedna koja odgovara miševima koji nemaju Daunov sindrom i jedna koja (uglavnom) odgovara miševima koji imaju Daunov sindrom, kao što je ilustrovano u Fig.3a (bottom). Kao poređenje, primenili smo i 8 drugih tehnika za smanjenje dimenzionalnosti kako bismo identifikovali pravce koji razlikuju ciljne i pozadinske skupove podataka, od kojih nijedna nije bila u stanju da razdvoji miševe tako dobro kao cPCA (vidi Dodatnu Fig.4 za detalje). 

Zatim analiziramo javni skup podataka više dimenzionalnosti koji se sastoji od nivoa ekspresije RNA na nivou jedne ćelije mešavine mononuklearnih ćelija koštane srži (BMMCs) uzetih od pacijenta sa leukemijom pre transplantacije matičnih ćelija i BMMCs od istog pacijenta nakon transplantacije matičnih ćelija. Svi podaci RNA-Seq na nivou jedne ćelije su unapred obrađeni korišćenjem sličnih metoda kao što su opisali autori. Konkretno, pre primene PCA ili cPCA, svi skupovi podataka su smanjeni na 500 gena, koji su odabrani na osnovu najveće disperzije [varijansa podeljena sa srednjom vrednošću] unutar ciljnog skupa podataka. Ponovo primenjujemo PCA da vidimo da li možemo vizuelno otkriti dva uzorka u transformisanim podacima. Kao što je prikazano u Fig.3b (top left), oba tipa ćelija prate sličnu distribuciju u prostoru koji obuhvataju prve dve glavne komponente. Ovo je verovatno zato što su razlike između uzoraka male i glavne komponente umesto toga odražavaju heterogenost različitih vrsta ćelija unutar svakog uzorka ili čak varijacije u eksperimentalnim uslovima, što može imati značajan efekat na merenja RNA-Seq na nivou jedne ćelije. 

Primenićemo cPCA koristeći pozadinski skup podataka koji se sastoji od RNA-Seq merenja iz BMMC ćelija zdravog pojedinca. Očekujemo da ovaj pozadinski skup podataka sadrži varijacije zbog heterogene populacije ćelija kao i varijacije u eksperimentalnim uslovima. Možemo se nadati da će cPCA moći da povrati pravce koji su obogaćeni u ciljnim podacima, a koji odgovaraju razlikama pre i posle transplantacije. Zaista, to je ono što nalazimo, kao što je prikazano na Fig.3b (dole levo). 

Dalje proširujemo naš ciljni skup podataka sa BMMC uzorcima od drugog pacijenta sa leukemijom, ponovo pre i posle transplantacije matičnih ćelija. Tako postoje ukupno četiri subpopulacije ćelija. Primena PCA na ove podatke pokazuje da četiri subpopulacije nisu odvojive u podprostoru koji obuhvataju prva dva glavna komponente (PCs), kao što je prikazano na Fig.3b (gore desno). Međutim, kada se cPCA primeni sa istim pozadinskim skupom podataka, najmanje tri subpopulacije pokazuju mnogo jaču separaciju, kao što je prikazano na Fig.3b (dole desno). cPCA ugradnja takođe sugeriše da su uzorci ćelija od oba pacijenta sličniji jedni drugima nakon transplantacije matičnih ćelija (cijan i zeleni tačkice) nego pre transplantacije (zlatne i roze tačkice), što je razumna hipoteza koju istraživač može testirati. Može se pogledati Dodatna Fig.5 za više detalja o ovom eksperimentu. Vidimo da cPCA može biti koristan alat za zaključivanje odnosa između subpopulacija, temu koju dalje istražujemo. 

U prethodnim primerima, videli smo da cPCA omogućava korisniku da otkrije podklase unutar ciljnog skupa podataka koje nisu unapred označene. Međutim, čak i kada su podklase poznate unapred, redukcija dimenzionalnosti može biti koristan način za vizualizaciju odnosa unutar grupa. Na primer, PCA se često koristi za vizualizaciju odnosa između etničkih populacija na osnovu genetskih varijanti, jer projektovanje genetskih varijanti na dve dimenzije često proizvodi mape koje nude upečatljive vizualizacije geografskih i istorijskih trendova. Ali opet, PCA je ograničen na identifikaciju najdominantnije strukture; kada ovo predstavlja univerzalnu ili nezanimljivu varijaciju, cPCA može biti efikasniji u vizualizaciji trendova. 

Skup podataka koji koristimo za ovaj primer sastoji se od polimorfizama jednog nukleotida (SNPs) iz genoma pojedinaca iz pet država u Meksiku, prikupljenih u prethodnoj studiji. Meksičko poreklo je izazovno analizirati koristeći PCA jer PCs obično ne odražavaju geografsko poreklo unutar Meksika; umesto toga, odražavaju proporciju evropskog/američkog domorodačkog nasleđa svakog meksičkog pojedinca, što dominira i prikriva razlike zbog geografskog porekla unutar Meksika (vidi Fig.4a ). Da bi se prevazišao ovaj problem, genetičari populacije ručno uklanjaju SNPs, uklanjajući one za koje se zna da potiču iz evropskog porekla, pre primene PCA. Međutim, ovaj postupak je ograničene primenljivosti jer zahteva poznavanje porekla SNPs i da izvor pozadinske varijacije bude veoma različit od varijacije od interesa, što često nije slučaj. Fig. 4Odnos između grupa meksičkog porekla. aPCA primenjena na genetske podatke pojedinaca iz 5 meksičkih država ne otkriva nikakve vizuelno prepoznatljive obrasce u ugrađenim podacima. bcPCA primenjena na isti skup podataka otkriva obrasce u podacima: pojedinci iz iste države su grupisani bliže zajedno u cPCA ugrađivanju. cNadalje, raspodela tačaka otkriva odnose između grupa koji odgovaraju geografskom položaju različitih država: na primer, pojedinci iz geografski susednih država su susedni u ugrađivanju. cPrilagođeno sa mape Meksika koja je originalno delo korisnika: Allstrak na Wikipediji, objavljeno pod CC-BY-SA licencom, preuzeto sa https://commons.wikimedia.org/wiki/File:Mexico_Map.svg 

Kao alternativu, koristimo cPCA sa pozadinskim skupom podataka koji se sastoji od pojedinaca iz Meksika i iz Evrope. Ova pozadina je dominirana varijacijom američkih domorodaca/evropskom, što nam omogućava da izolujemo unutar-meksičku varijaciju u ciljnim podacima. Rezultati primene cPCA prikazani su na Fig.4b. Nalazimo da su pojedinci iz iste države u Meksiku bliže ugrađeni. Štaviše, dve grupe koje su najrazličitije su Sonoranci i Maje iz Jukatana, koji su takođe geografski najudaljeniji unutar Meksika, dok su Meksikanci iz ostale tri države blizu jedni drugima, kako geografski tako i u ugradnji koju je uhvatio cPCA (vidi Fig.4c ). Pogledajte i Dodatnu Fig.6 za više detalja. 

 U mnogim postavkama nauke o podacima, zainteresovani smo za vizualizaciju i istraživanje obrazaca koji su obogaćeni u jednom skupu podataka u odnosu na druge podatke. Predstavili smo cPCA kao opšti alat za izvođenje takvog kontrastnog istraživanja i ilustrovali smo njegovu korisnost u raznovrsnom spektru primena. Glavne prednosti cPCA su njegova opštost i jednostavnost upotrebe. Računanje određenog cPCA zahteva suštinski isto vreme kao i računanje regularnog PCA. Ova računarska efikasnost omogućava cPCA da bude koristan za interaktivno istraživanje podataka, gde bi svaka operacija idealno trebala biti gotovo trenutna. Kao takav, u bilo kojim postavkama gde se PCA primenjuje na povezane skupove podataka, cPCA se takođe može primeniti. U Dodatnoj Napomeni3 i Dodatnoj Fig.8 , pokazujemo kako se cPCA može kernelizovati da otkrije nelinearne kontrastne obrasce u skupovima podataka.

 Jedini slobodni parametar kontrastne PCA je jačina kontrastaα. U našem podrazumevanom algoritmu, razvili smo automatsku šemu zasnovanu na klasterizaciji podprostora za odabir najinformativnijih vrednostiα (vidi Metode). Svi eksperimenti izvedeni za ovaj rad koriste automatski generisane vrednostiα , i verujemo da će ovaj podrazumevani biti dovoljan u mnogim primenama cPCA. Korisnik takođe može uneti specifične vrednosti zaα ako je potrebna detaljnija istraživanja.

 cPCA, kao i regularna PCA i druge metode redukcije dimenzionalnosti, ne dajep -vrednosti ili druge kvantifikacije statističke značajnosti. Obrasci otkriveni kroz cPCA moraju biti validirani kroz testiranje hipoteza ili dodatnu analizu koristeći relevantno domen znanje. Objavili smo kod za cPCA kao python paket zajedno sa dokumentacijom i primerima.

Za ciljne podatke dimenzijed (equation) i pozadinske podatke (equation) , nekaC X,C Ybudu njihovi odgovarajući empirijski kovarijacioni matrice. Neka (equation) bude skup jedinicnih vektora. Za bilo koji pravac (equation) , varijansa koju obuhvata u ciljnim podacima i u pozadinskim podacima može se napisati kao: (equation) Uzimajući u obzir parametar kontrastaα ≥ 0 koji kvantifikuje kompromis između visoke ciljne varijanse i niske pozadinske varijanse, cPCA izračunava kontrastni pravacv * optimizacijom (equation) Ovaj problem se može prepisati kao (equation) što implicira dav * odgovara prvom sopstvenom vektoru matrice (equation). Stoga se kontrastni pravci mogu efikasno izračunati koristeći dekompoziciju sopstvenih vrednosti. Analogno PCA, vodeći sopstveni vektori matriceC nazivaju se kontrastne glavne komponente (cPCs). Napominjemo da su cPCs sopstveni vektori matriceC i stoga su ortogonalni jedni drugima. Za fiksniα , izračunavamo (1 ) i vraćamo podprostor koji obuhvata prvih nekoliko (obično dve) cPCs. 

Parametar kontrastaα predstavlja kompromis između visoke ciljne varijanse i niske pozadinske varijanse. Kada jeα = 0, cPCA bira pravce koji samo maksimiziraju ciljne varijanse, i stoga se svodi na PCA primenjen na ciljne podatke {x i}. Kakoα raste, pravci sa manjom pozadinskom varijansom postaju važniji i cPCs se usmeravaju ka nultom prostoru pozadinskih podataka {y i}. U graničnom slučajuα = ∞, bilo koji pravac koji nije u nultom prostoru {y i} dobija beskonačnu kaznu. U ovom slučaju, cPCA odgovara prvom projektovanju ciljnog skupa podataka na nulti prostor pozadinskih podataka, a zatim izvođenju PCA na projektovanim podacima. 

Umesto da se bira jedanα i vraća njegov podprostor, cPCA izračunava podprostore listeα i vraća nekoliko podprostora koji su daleko jedan od drugog u smislu glavnog ugla. Projektovanjem podataka na svaki od ovih podprostora otkrivaju se različiti trendovi unutar ciljanih podataka, a vizuelnim pregledom dobijenih dijagrama raspršenja, korisnik može brzo uočiti relevantan podprostor (i odgovarajuću vrednostα ) za svoju analizu. Pogledajte Dodatnu Fig.1 za detaljan primer. 

Kompletan algoritam cPCA je opisan u Algoritmu 2 (Dodatne Metode). Obično postavljamo listu potencijalnih vrednostiα na 40 vrednosti logaritamski raspoređenih između 0.1 i 1000 i to se koristi za sve eksperimente u radu. Da bismo izabrali reprezentativne podprostore, cPCA koristi spektralno grupisanje za grupisanje podprostora, gde je afinitet definisan kao proizvod kosinusa glavnih uglova između podprostora. Zatim se medijani (reprezentativni) svake grupe koriste kao vrednostiα za generisanje dijagrama raspršenja koje korisnik vidi. 

Izbor pozadinskog skupa podataka ima veliki uticaj na rezultat cPCA. Uopšteno, pozadinski podaci treba da imaju strukturu koju bismo želeli da uklonimo iz ciljanih podataka. Takva struktura obično odgovara pravcima u cilju sa velikom varijansom, ali koji nisu od interesa za analitičara. 

Dajemo nekoliko opštih primera pozadinskih skupova podataka koji mogu pružiti korisne kontraste ciljnim podacima: (1) Kontrolna grupa {y i} u kontrastu sa obolelom populacijom {x i} jer kontrolna grupa sadrži slične varijacije na nivou populacije, ali ne i suptilne varijacije zbog različitih podtipova bolesti. (2) Podaci u vremenu nula {y i} korišćeni za kontrast sa podacima u kasnijem vremenskom trenutku {x i}. Ovo omogućava vizualizacije najupečatljivijih promena tokom vremena. (3) Homogena grupa {y i} u kontrastu sa mešanom grupom {x i} jer obe imaju varijacije unutar populacije i šum merenja, ali prva nema varijacije između populacija. (4) Skup podataka pre tretmana {y i} u kontrastu sa podacima posle tretmana {x i} da bi se uklonio šum merenja, ali sačuvale varijacije izazvane tretmanom. (5) Skup snimaka bez signala {y i} ili slike koje sadrže samo šum, u kontrastu sa merenjima {x i} koja se sastoje od signala i šuma. 

Vredi dodati da pozadinski podaci ne moraju imati potpuno istu strukturu kovarijanse kao ono što bismo želeli da uklonimo iz ciljanog skupa podataka. Kao primer, u eksperimentu prikazanom u Fig.2 , ispostavlja se da ne moramo koristiti pozadinski skup podataka koji se sastoji od slika trave. U stvari, slični rezultati se dobijaju čak i ako se umesto slika trave koriste slike neba kao pozadinski skup podataka. Kako su strukture matrica kovarijanse dovoljno slične, cPCA uklanja pozadinsku strukturu iz ciljanih podataka. Pored toga, cPCA ne zahteva da ciljani podaci i pozadinski podaci imaju sličan broj uzoraka. Pošto se matrice kovarijanse izračunavaju nezavisno, cPCA samo zahteva da empirijske matrice kovarijanse budu dobre procene osnovnih populacionih matrica kovarijanse, što je u suštini isti zahtev kao i za PCA. 

Ovde diskutujemo o geometrijskoj interpretaciji cPCA kao i o njenim statističkim svojstvima. Prvo, zanimljivo je razmotriti koji su pravci "bolji" za svrhu kontrastivne analize. Za pravac (equation) , njegova značajnost u cPCA je u potpunosti određena njegovim parom varijansi cilj-pozadina (λ X(v ),λ Y(v )); poželjno je imati veću ciljnu varijansu i manju pozadinsku varijansu. Na osnovu ove intuicije, možemo dalje definisati delimičan redosled kontrastivnosti za različite pravce: za dva pravcav1 iv2 , mogli bismo reći da jev1 bolji kontrastivni pravac ako ima veću ciljnu varijansu i manju pozadinsku varijansu. U tom slučaju, par varijansi cilj-pozadina zav1 bi ležao na donjoj-desnoj strani od onog zav2 u grafiku parova varijansi cilj-pozadina (λ X(v ),λ Y(v )), npr., Fig.5. Na osnovu ovog delimičnog reda, skup najkontrastivnijih pravaca može se definisati na sličan način kao definicija Pareto granice. Neka (equation) bude skup parova varijansi cilj-pozadina za sve pravce, tj. (equation) Fig. 5Geometrijska interpretacija cPCA. Skup parova varijansi cilj-pozadina(equation)je prikazan kao tirkizna oblast za neke nasumično generisane ciljne i pozadinske podatke. Donja-desna granica, obojena zlatnom bojom, odgovara skupu najkontrastivnijih pravaca(equation). Plavi trouglovi su parovi varijansi za cPC izabrane sa αvrednostima 0.92 i 0.29 respektivno. Napominjemo da oni odgovaraju tačkama tangente zlatne krive i tangencijalnih linija sa nagibom(equation)= 1.08, 3.37, respektivno

Što se tiče cPCA, možemo dokazati (vidi Dodatnu Napomenu2 ) da promenomα , skup vrhunskih cPC-a je identičan skupu najkontrastivnijih pravaca. Štaviše, za pravacv izabran od strane cPCA sa kontrastnim parametrom postavljenim naα , njegov par varijansi (λ X(v ),λ Y(v )) odgovara tački tangente donje-desne granice (equation) sa linijom nagiba-1/α. Kao rezultat, promenomα od nule do beskonačnosti, cPCA bira pravce sa parovima varijansi koji putuju od donjeg-levog kraja do gornjeg-desnog kraja donje-desne granice (equation). 

Takođe napominjemo da u vezi sa slučajnom prirodom podataka, stopa konvergencije uzorka cPC ka populacionom cPC je (equation) pod blagim pretpostavkama, gde jed dimenzija, an ,m su veličine ciljanih i pozadinskih podataka. Ova stopa je slična standardnoj stopi konvergencije uzorka sopstvenog vektora za matricu kovarijanse. Pogledajte Dodatnu Napomenu2. 

Objavili smo Python implementaciju kontrastivne PCA na GitHub-u (https://github.com/abidlabs/contrastive ). GitHub repozitorijum takođe uključuje Python beležnice i skupove podataka koji reprodukuju većinu figura u ovom radu i u Dodatnim Informacijama. 

Skupovi podataka koji su korišćeni za evaluaciju kontrastivne PCA u ovom radu su ili dostupni od nas ili od autora originalnih studija. Molimo pogledajte GitHub repozitorijum naveden u prethodnom odeljku za skupove podataka koje smo objavili. 

