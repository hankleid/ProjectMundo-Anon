Исследование обогащенных паттернов в наборе данных с помощью контрастного анализа главных компонент

Аннотация: Визуализация и исследование высокоразмерных данных является повсеместной задачей в различных дисциплинах. Широко используемые методы, такие как анализ главных компонент (PCA), направлены на выявление доминирующих тенденций в одном наборе данных. Однако во многих случаях у нас есть наборы данных, собранные в разных условиях, например, эксперимент с лечением и контрольный эксперимент, и нас интересует визуализация и исследование паттернов, специфичных для одного набора данных. В этой статье предлагается метод, контрастный анализ главных компонент (cPCA), который выявляет низкоразмерные структуры, обогащенные в наборе данных относительно сравнительных данных. В широком спектре экспериментов мы демонстрируем, что cPCA с фоновым набором данных позволяет визуализировать специфические для набора данных паттерны, которые не выявляются с помощью PCA и других стандартных методов. Мы также предоставляем геометрическую интерпретацию cPCA и сильные математические гарантии. Реализация cPCA доступна в открытом доступе и может быть использована для исследовательского анализа данных во многих приложениях, где в настоящее время используется PCA.

Анализ главных компонент (PCA) является одним из наиболее широко используемых методов для исследования и визуализации данных. PCA проецирует данные в пространство низкой размерности и особенно мощен как подход для визуализации паттернов, таких как кластеры, градиенты и выбросы в наборе данных. Существует множество связанных методов визуализации; например, t-SNE и многомерное шкалирование (MDS) позволяют выполнять нелинейные проекции данных и могут лучше захватывать нелинейные паттерны, чем PCA. Однако все эти методы предназначены для исследования одного набора данных за раз. Когда у аналитика есть несколько наборов данных (или несколько условий в одном наборе данных для сравнения), то текущая практика заключается в выполнении PCA (или t-SNE, MDS и т.д.) на каждом наборе данных отдельно, а затем в ручном сравнении различных проекций для изучения, есть ли интересные сходства и различия между наборами данных,. Контрастный PCA (cPCA) разработан для заполнения этого пробела в исследовании и визуализации данных, автоматически идентифицируя проекции, которые демонстрируют наиболее интересные различия между наборами данных. Рисунок[1]предоставляет обзор cPCA, который мы объясним более подробно далее.

cPCA мотивирован широким спектром проблем в различных дисциплинах. Для иллюстрации мы упоминаем здесь две такие проблемы и демонстрируем другие через эксперименты позже в статье. Во-первых, рассмотрим набор данных измерений экспрессии генов от индивидов разных этнических групп и полов. Эти данные включают уровни экспрессии генов у пациентов с раком {x i}, которые мы заинтересованы анализировать. У нас также есть контрольные данные, которые соответствуют уровням экспрессии генов у здоровых пациентов {y i} из аналогичного демографического фона. Наша цель - найти тренды и вариации среди пациентов с раком (например, для идентификации молекулярных подтипов рака). Если мы напрямую применим PCA к {x i}, однако, главные компоненты могут соответствовать демографическим вариациям индивидов, а не подтипам рака, потому что генетические вариации из-за первых, вероятно, больше, чем из-за вторых. Мы подходим к этой проблеме, отмечая, что здоровые пациенты также содержат вариации, связанные с демографическими различиями, но не вариации, соответствующие подтипам рака. Таким образом, мы можем искать компоненты, в которых {x i} имеет высокую дисперсию, но {y i} имеет низкую дисперсию.

Как связанный пример, рассмотрим набор данных {x i}, который состоит из рукописных цифр на сложном фоне, таких как различные изображения травы (см. Рис.[2(a), top]). Целью типичной задачи обучения без учителя может быть кластеризация данных, выявляющая различные цифры на изображении. Однако, если мы применим стандартный PCA к этим изображениям, мы обнаружим, что главные компоненты не представляют особенности, связанные с рукописными цифрами, а отражают доминирующую вариацию в особенностях, связанных с фоном изображения (Рис.[2(b)], top). Мы показываем, что можно исправить это, используя эталонный набор данных {y i}, который состоит исключительно из изображений травы (не обязательно тех же изображений, что используются в {x i}, но имеющих аналогичную ковариацию между особенностями, как показано на Рис.[2(a)], bottom), и ищем подпространство с более высокой дисперсией в {x i} по сравнению с {y i}. Проецируя на это подпространство, мы можем визуально разделить изображения на основе значения рукописной цифры (Рис. 2(b), bottom). Сравнивая главные компоненты, обнаруженные PCA, с теми, что обнаружены cPCA, мы видим, что cPCA идентифицирует более релевантные особенности (Рис.[2(c)]), что позволяет нам использовать cPCA для таких приложений, как выбор особенностей и удаление шума.

Контрастный PCA - это инструмент для обучения без учителя, который эффективно уменьшает размерность, чтобы обеспечить визуализацию и исследовательский анализ данных. Это отличает cPCA от большого класса методов обучения с учителем, основная цель которых - классифицировать или различать различные наборы данных, такие как линейный дискриминантный анализ (LDA), квадратичный дискриминантный анализ (QDA), супервизорный PCA и QUADRO. Это также отличает cPCA от методов, которые интегрируют несколько наборов данных, с целью идентификации коррелированных паттернов среди двух или более наборов данных, а не тех, что уникальны для каждого отдельного набора данных. Существует также богатое семейство методов уменьшения размерности без учителя, кроме PCA. Например, многомерное шкалирование (MDS) находит низкоразмерное встраивание, которое сохраняет расстояние в высокоразмерном пространстве; поиск главных компонентов находит подпространство низкого ранга, которое устойчиво к небольшому шуму и грубым разреженным ошибкам. Но ни один из них не предназначен для использования релевантной информации из второго набора данных, как это делает cPCA. В приложении мы сравнили cPCA с многими из ранее упомянутых техник на репрезентативных наборах данных (см. Дополнительные Рис.[3]и[4]), , ,.

В конкретной области применения могут существовать специализированные инструменты с аналогичными целями, как у cPCA, ,. Например, в результатах мы показываем, как cPCA, примененный к данным генотипа, визуализирует географическое происхождение в пределах Мексики. Исследование тонких кластеров генетических предков является важной проблемой в популяционной генетике, и исследователи недавно разработали алгоритм для специфической визуализации таких кластеров предков. Хотя cPCA хорошо работает здесь, алгоритм, созданный экспертами, может работать даже лучше для конкретного набора данных. Однако специализированный алгоритм требует значительных знаний в области для разработки, более затратен в вычислительном плане и может быть сложным в использовании. Цель cPCA не в том, чтобы заменить все эти специализированные передовые методы в каждой из их областей, а в том, чтобы предоставить общий метод для исследования произвольных наборов данных.

Мы предлагаем конкретный и эффективный алгоритм для cPCA в этой статье. Метод принимает на вход целевой набор данных {x i}, который мы заинтересованы визуализировать или идентифицировать паттерны внутри. В качестве вторичного входа cPCA принимает фоновый набор данных {y i}, который не содержит интересующих паттернов. Алгоритм cPCA возвращает подпространства, которые захватывают большое количество вариаций в целевых данных {x i}, но мало в фоновых {y i} (см. Рис.[1], Методы и Дополнительные Методы для более подробной информации). Это подпространство соответствует особенностям, содержащим структуру, специфичную для {x i}. Следовательно, когда целевые данные проецируются на это подпространство, мы можем визуализировать и обнаруживать дополнительную структуру в целевых данных относительно фона. Аналогично главным компонентам (PCs), мы называем направления, найденные cPCA, контрастными главными компонентами (cPCs). Мы подчеркиваем, что cPCA является фундаментально методом без учителя, разработанным для более четкого разрешения паттернов в одном наборе данных, используя фоновый набор данных как контраст. В частности, cPCA не стремится различать целевые и фоновые наборы данных; подпространство, содержащее тренды, обогащенные в целевом наборе данных, не обязательно является тем же подпространством, которое оптимально для классификации между наборами данных.

Исследователи отметили, что стандартный PCA часто неэффективен в обнаружении подгрупп в биологических данных, по крайней мере отчасти потому, что "доминирующие главные компоненты...коррелируют с артефактами", а не с особенностями, представляющими интерес для исследователя. Как можно использовать cPCA в этих условиях для обнаружения более значительных подгрупп? Используя фоновый набор данных для отмены универсальной, но неинтересной вариации в целевом, мы можем искать структуру, уникальную для целевого набора данных.

Наш первый эксперимент использует набор данных, состоящий из измерений экспрессии белков у мышей, которые получили шоковую терапию,. У некоторых мышей развился синдром Дауна (DS). Чтобы создать задачу обучения без учителя, где у нас есть информация о реальном положении дел для оценки методов, мы предполагаем, что эта информация о DS неизвестна аналитику и используется только для оценки алгоритма. Мы хотели бы увидеть, обнаружим ли мы какие-либо значительные различия в популяции мышей, подвергшихся шоковой терапии, в режиме без учителя (наличие или отсутствие синдрома Дауна является ключевым примером). На Рис. [3a] (вверху) мы показываем результат применения PCA к целевому набору данных: преобразованные данные не выявляют значительных кластеров в популяции мышей. Основные источники вариации среди мышей могут быть естественными, такими как пол или возраст.

Мы применяем cPCA к этому набору данных, используя фоновый набор, состоящий из измерений экспрессии белков у группы мышей, которые не подвергались шоковой терапии. Это контрольные мыши, которые, вероятно, имеют аналогичную естественную вариацию, как и экспериментальные мыши, но без различий, вызванных шоковой терапией. С этим набором данных в качестве фона, cPCA может разрешить две разные группы в преобразованных целевых данных, одна из которых соответствует мышам, не имеющим синдрома Дауна, и одна (в основном) мышам, имеющим синдром Дауна, как показано на Рис. [3a] (внизу). В качестве сравнения, мы также применили 8 других техник уменьшения размерности для идентификации направлений, которые различают целевые и фоновые наборы данных, ни одна из которых не смогла разделить мышей так же хорошо, как cPCA (см. Дополнительный Рис. [4] для подробностей).

Далее мы анализируем более высокоразмерный публичный набор данных, состоящий из уровней экспрессии РНК на уровне одной клетки смеси мононуклеарных клеток костного мозга (BMMCs), взятых у пациента с лейкемией до трансплантации стволовых клеток и BMMCs от того же пациента после трансплантации стволовых клеток. Все данные РНК-Seq на уровне одной клетки предварительно обрабатываются с использованием аналогичных методов, описанных авторами. В частности, перед применением PCA или cPCA все наборы данных сокращаются до 500 генов, которые выбираются на основе наибольшей дисперсии [дисперсия, деленная на среднее] в целевых данных. Снова мы выполняем PCA, чтобы увидеть, можем ли мы визуально обнаружить два образца в преобразованных данных. Как показано на Рис. [3b] (вверху слева), оба типа клеток следуют аналогичному распределению в пространстве, охваченном первыми двумя PCs. Это, вероятно, потому, что различия между образцами малы, и PCs вместо этого отражают гетерогенность различных типов клеток в каждом образце или даже вариации в экспериментальных условиях, которые могут иметь значительное влияние на измерения РНК-Seq на уровне одной клетки.

Мы применяем cPCA, используя фоновый набор данных, который состоит из измерений RNA-Seq клеток BMMC здорового человека. Мы ожидаем, что этот фоновый набор данных будет содержать вариации, связанные с гетерогенной популяцией клеток, а также вариации в экспериментальных условиях. Мы можем надеяться, что cPCA сможет восстановить направления, обогащенные в целевых данных, соответствующие различиям до и после трансплантации. Действительно, это то, что мы обнаруживаем, как показано на рис. [3b] (внизу слева).

Мы дополнительно расширяем наш целевой набор данных образцами BMMC от второго пациента с лейкемией, снова до и после трансплантации стволовых клеток. Таким образом, в общей сложности имеется четыре субпопуляции клеток. Применение PCA к этим данным показывает, что четыре субпопуляции неразделимы в подпространстве, охватываемом двумя главными компонентами (PCs), как показано на рис. [3b] (вверху справа). Однако, когда cPCA применяется с тем же фоновым набором данных, по крайней мере три из субпопуляций показывают гораздо более сильное разделение, как показано на рис. [3b] (внизу справа). Встраивание cPCA также предполагает, что образцы клеток от обоих пациентов более похожи друг на друга после трансплантации стволовых клеток (циановые и зеленые точки), чем до трансплантации (золотые и розовые точки), что является разумной гипотезой, которую может проверить исследователь. Дополнительную информацию об этом эксперименте можно найти в Дополнительном рис. [5]. Мы видим, что cPCA может быть полезным инструментом для определения отношений между субпопуляциями, тему, которую мы исследуем далее.

В предыдущих примерах мы видели, что cPCA позволяет пользователю обнаруживать подклассы в целевом наборе данных, которые не маркированы заранее. Однако даже когда подклассы известны заранее, уменьшение размерности может быть полезным способом визуализации отношений внутри групп. Например, PCA часто используется для визуализации отношений между этническими популяциями на основе генетических вариантов, поскольку проекция генетических вариантов на две размерности часто создает карты, которые предлагают поразительные визуализации географических и исторических тенденций,. Но опять же, PCA ограничен в выявлении наиболее доминирующей структуры; когда это представляет собой универсальную или неинтересную вариацию, cPCA может быть более эффективным в визуализации тенденций.

Набор данных, который мы используем для этого примера, состоит из однонуклеотидных полиморфизмов (SNPs) из геномов людей из пяти штатов Мексики, собранных в предыдущем исследовании. Мексиканское происхождение сложно анализировать с помощью PCA, поскольку PCs обычно не отражают географическое происхождение в пределах Мексики; вместо этого они отражают долю европейского/коренного американского наследия каждого мексиканца, что доминирует и скрывает различия, обусловленные географическим происхождением в пределах Мексики (см. рис. [4a] ). Чтобы преодолеть эту проблему, популяционные генетики вручную удаляют SNPs, известные как происходящие от европейского наследия, перед применением PCA. Однако эта процедура имеет ограниченное применение, так как требует знания происхождения SNPs и того, что источник фоновой вариации сильно отличается от интересующей вариации, что часто не так.

В качестве альтернативы мы используем cPCA с фоновым набором данных, который состоит из людей из Мексики и Европы. Этот фон доминирует вариацией коренных американцев/европейцев, что позволяет нам изолировать внутримексиканскую вариацию в целевом наборе данных. Результаты применения cPCA показаны на рис. [4b]. Мы обнаруживаем, что люди из одного и того же штата в Мексике расположены ближе друг к другу. Более того, две группы, которые наиболее различны, это сонорцы и майя из Юкатана, которые также являются наиболее географически удаленными в пределах Мексики, в то время как мексиканцы из других трех штатов близки друг к другу как географически, так и в встраивании, захваченном cPCA (см. рис. [4c] ). См. также Дополнительный рис. [6] для получения более подробной информации.

Во многих областях науки о данных нас интересует визуализация и исследование паттернов, обогащенных в одном наборе данных по сравнению с другими данными. Мы представили cPCA как общий инструмент для выполнения такого контрастного исследования и продемонстрировали его полезность в различных приложениях. Основные преимущества cPCA - это его универсальность и простота использования. Вычисление конкретного cPCA занимает по сути столько же времени, сколько и вычисление обычного PCA. Эта вычислительная эффективность позволяет cPCA быть полезным для интерактивного исследования данных, где каждая операция должна быть почти мгновенной. Таким образом, в любых условиях, где PCA применяется к связанным наборам данных, также может быть применен cPCA. В Дополнительной заметке[3]и Дополнительном рис.[8]мы показываем, как cPCA может быть ядронизирован для выявления нелинейных контрастных паттернов в наборах данных.

Единственный свободный параметр контрастного PCA - это сила контрастаα. В нашем стандартном алгоритме мы разработали автоматическую схему на основе кластеризации подпространств для выбора наиболее информативных значенийα (см. Методы). Все эксперименты, проведенные для этой статьи, используют автоматически сгенерированные значенияα , и мы считаем, что этот стандарт будет достаточен во многих приложениях cPCA. Пользователь также может ввести конкретные значения дляα , если требуется более детальное исследование.

cPCA, как и обычный PCA и другие методы уменьшения размерности, не даетp -значений или других количественных оценок статистической значимости. Паттерны, обнаруженные с помощью cPCA, необходимо проверять с помощью тестирования гипотез или дополнительного анализа с использованием соответствующих знаний в области. Мы выпустили код для cPCA в виде пакета Python вместе с документацией и примерами.

Дляd -мерных целевых данныхxi ∈ Rd и фоновых данныхyi ∈ Rd , пустьC X,C Yбудут их соответствующими эмпирическими ковариационными матрицами. ПустьR unit d = def v ∈ Rd :v2 = 1 будет множеством единичных векторов. Для любого направленияv ∈ R unit d , дисперсия, которую оно объясняет в целевых данных и в фоновых данных, может быть записана как: Целевые данные дисперсия :λX ( v ) =defvTCXv , Фоновые данные дисперсия :λY ( v ) =defvTCYv.Учитывая параметр контрастаα ≥ 0, который количественно определяет компромисс между высокой дисперсией целевых данных и низкой дисперсией фоновых данных, cPCA вычисляет контрастное направлениеv * путем оптимизации 1 v * = argmax v ∈ Runitd λ X(v)- α λ Y(v).  Эта задача может быть переписана какv * = argmax v ∈ Runitd v T CX - α CY v ,  что подразумевает, чтоv * соответствует первому собственному вектору матрицыC = def CX - α CY. Таким образом, контрастные направления могут быть эффективно вычислены с использованием разложения на собственные значения. Аналогично PCA, мы называем ведущие собственные векторыC контрастными главными компонентами (cPCs). Мы отмечаем, что cPCs являются собственными векторами матрицыC и, следовательно, ортогональны друг другу. Для фиксированногоα мы вычисляем ( [1] ) и возвращаем подпространство, охватываемое первыми несколькими (обычно двумя) cPCs.

Параметр контрастаα представляет собой компромисс между высокой дисперсией целевых данных и низкой дисперсией фоновых данных. Когдаα = 0, cPCA выбирает направления, которые только максимизируют дисперсию целевых данных, и, следовательно, сводится к PCA, примененному к целевым данным {x i}. По мере увеличенияα направления с меньшей дисперсией фоновых данных становятся более важными, и cPCs направляются к нулевому пространству фоновых данных {y i}. В предельном случаеα = ∞ любое направление, не находящееся в нулевом пространстве {y i}, получает бесконечное наказание. В этом случае cPCA соответствует сначала проекции целевых данных на нулевое пространство фоновых данных, а затем выполнению PCA на проецированных данных.

Вместо выбора одногоα и возврата его подпространства, cPCA вычисляет подпространства для списка значенийα и возвращает несколько подпространств, которые находятся далеко друг от друга с точки зрения главного угла. Проецирование данных на каждое из этих подпространств выявит различные тенденции в целевых данных, и, визуально изучая возвращаемые диаграммы рассеяния, пользователь может быстро определить соответствующее подпространство (и соответствующее значениеα ) для своего анализа. Подробный пример см. в Дополнительной рис. [1].

Полный алгоритм cPCA описан в Алгоритме 2 (Дополнительные методы). Мы обычно устанавливаем список потенциальных значенийα в 40 значений, логарифмически распределенных между 0.1 и 1000, и это используется для всех экспериментов в статье. Для выбора представительных подпространств cPCA использует спектральную кластеризацию для кластеризации подпространств, где аффинность определяется как произведение косинусов главных углов между подпространствами. Затем медианы (представители) каждого кластера используются в качестве значенийα для генерации диаграмм рассеяния, видимых пользователю.

Выбор фонового набора данных оказывает большое влияние на результат cPCA. В общем, фоновая информация должна иметь структуру, которую мы хотели бы удалить из целевых данных. Такая структура обычно соответствует направлениям в целевых данных с высокой дисперсией, но которые не представляют интереса для аналитика.

Мы предоставляем несколько общих примеров фоновых наборов данных, которые могут обеспечить полезные контрасты для целевых данных: (1) Контрольная группа {y i} в сравнении с больной популяцией {x i}, поскольку контрольная группа содержит аналогичную популяционную вариацию, но не тонкую вариацию, связанную с различными подтипами болезни. (2) Данные в момент времени ноль {y i} используются для контраста с данными в более поздний момент времени {x i}. Это позволяет визуализировать наиболее заметные изменения со временем. (3) Однородная группа {y i} в сравнении с смешанной группой {x i}, поскольку обе имеют внутрипопуляционную вариацию и шум измерений, но первая не имеет межпопуляционной вариации. (4) Набор данных до лечения {y i} в сравнении с данными после лечения {x i} для удаления шума измерений, но сохранения вариаций, вызванных лечением. (5) Набор записей без сигнала {y i} или изображений, содержащих только шум, в сравнении с измерениями {x i}, состоящими из сигнала и шума.

Стоит добавить, что фоновая информация не обязательно должна иметь точно такую же ковариационную структуру, которую мы хотели бы удалить из целевого набора данных. Например, в эксперименте, показанном на рис. [2] , оказывается, что нам не нужно использовать фоновый набор данных, состоящий из изображений травы. На самом деле, аналогичные результаты получаются, даже если вместо изображений травы используются изображения неба в качестве фонового набора данных. Поскольку структура ковариационных матриц достаточно схожа, cPCA удаляет фоновую структуру из целевых данных. Кроме того, cPCA не требует, чтобы целевые данные и фоновая информация имели одинаковое количество образцов. Поскольку ковариационные матрицы вычисляются независимо, cPCA требует только, чтобы эмпирические ковариационные матрицы были хорошими оценками ковариационных матриц популяции, что по сути является тем же требованием, что и для PCA.

Здесь мы обсуждаем геометрическую интерпретацию cPCA, а также его статистические свойства. Во-первых, интересно рассмотреть, какие направления являются "лучше" для целей контрастного анализа. Для направленияv ∈ R unit d , его значимость в cPCA полностью определяется его парой дисперсий целевого и фонового данных (λ X(v ),λ Y(v )); желательно иметь более высокую дисперсию целевого и более низкую дисперсию фонового данных. Основываясь на этой интуиции, мы можем далее определить частичный порядок контрастности для различных направлений: для двух направленийv1 иv2 , мы можем сказать, чтоv1 является лучшим контрастным направлением, если оно имеет более высокую дисперсию целевого и более низкую дисперсию фонового данных. В этом случае пара дисперсий целевого и фонового данныхv1 будет находиться в нижней правой части отv2 на графике пар дисперсий целевого и фонового данных (λ X(v ),λ Y(v )), например, рис. [5]. Основываясь на этом частичном порядке, множество наиболее контрастных направлений можно определить аналогично определению фронта Парето. ПустьU  будет множеством пар дисперсий целевого и фонового данных для всех направлений, т.е.U = def  ( λX ( v ) ,λY ( v ))  v ∈ Runitd. Множество наиболее контрастных направлений соответствует нижней правой границеU  на графике пар дисперсий целевого и фонового данных, как показано на рис. [5]. (Для конкретного случая одновременно диагонализируемых фоновых и целевых матриц см. Дополнительную рис. [7].)

Что касается cPCA, мы можем доказать (см. Дополнительную заметку [2] ), что, изменяяα , множество верхних cPC совпадает с множеством наиболее контрастных направлений. Более того, для направленияv , выбранного cPCA с параметром контраста, установленным наα , его пара дисперсий (λ X(v ),λ Y(v )) соответствует точке касания нижней правой границыU  с линией наклона-1/α. В результате, изменяяα от нуля до бесконечности, cPCA выбирает направления с парами дисперсий, перемещающимися от нижнего левого конца к верхнему правому концу нижней правой границыU .

Мы также отмечаем, что в отношении случайности данных скорость сходимости выборочного cPC к популяционному cPC составляетO p  dmin ( n,m ) при мягких предположениях, гдеd — это размерность, аn ,m — размеры целевых и фоновых данных. Эта скорость аналогична стандартной скорости сходимости выборочного собственного вектора для ковариационной матрицы. См. Дополнительную заметку [2].

Мы выпустили реализацию contrastive PCA на Python на GitHub (https://github.com/abidlabs/contrastive ). Репозиторий GitHub также включает в себя Python-ноутбуки и наборы данных, которые воспроизводят большинство рисунков в этой статье и в Дополнительной информации.

Наборы данных, которые использовались для оценки contrastive PCA в этой статье, доступны либо у нас, либо у авторов оригинальных исследований. Пожалуйста, смотрите репозиторий GitHub, указанный в предыдущем разделе, для наборов данных, которые мы выпустили.

Fig. 1: Схематический обзор cPCA. Для выполнения cPCA вычислите ковариационные матрицы C X, C Yцелевого и фонового наборов данных. Сингулярные векторы взвешенной разности ковариационных матриц, C X− α · C Y, являются направлениями, возвращаемыми cPCA. Как показано на диаграмме рассеяния справа, PCA (на целевых данных) определяет направление с наибольшей дисперсией в целевых данных, в то время как cPCA определяет направление с более высокой дисперсией в целевых данных по сравнению с фоновыми данными. Проецирование целевых данных на последнее направление дает уникальные для целевых данных паттерны и часто выявляет структуру, которую пропускает PCA. В частности, в этом примере уменьшение размерности целевых данных с помощью cPCA выявит два различных кластера

Fig. 2: Контрастный PCA на зашумленных цифрах.a, Верх: Мы создаем целевой набор данных из 5000 синтетических изображений, случайно накладывая изображения рукописных цифр 0 и 1 из набора данных MNIST на изображения травы, взятые из набора данных ImageNet , принадлежащие синсету травы. Изображения травы преобразуются в градации серого, изменяются до размера 100 × 100, а затем случайным образом обрезаются до размера, совпадающего с размером цифр MNIST, 28 × 28.b, Верх: Здесь мы отображаем результат встраивания синтетических изображений на их первые две главные компоненты, используя стандартный PCA. Мы видим, что точки, соответствующие изображениям с 0 и изображениями с 1, трудно различимы.a, Низ: Затем вводится фоновый набор данных, состоящий исключительно из изображений травы, принадлежащих тому же синсету, но мы используем изображения, отличные от тех, которые использовались для создания целевого набора данных.b, Низ: Используя cPCA на целевых и фоновых наборах данных (с параметром контраста α , установленным на 2.0), в низкоразмерном представлении целевого набора данных появляются два кластера, один из которых состоит из изображений с цифрой 0, а другой — из изображений с цифрой 1.cМы рассматриваем относительный вклад каждого пикселя в первую главную компоненту (PC) и первую контрастную главную компоненту (cPC). Более светлые пиксели — это те, которые имеют более положительный вес, в то время как более темные обозначают пиксели с отрицательными весами. PCA склонен подчеркивать пиксели на периферии изображения и слегка уменьшать акцент на пикселях в центре и внизу изображения, указывая на то, что большая часть дисперсии обусловлена фоновыми особенностями. С другой стороны, cPCA склонен увеличивать вес пикселей, находящихся в месте расположения рукописных 1, уменьшать вес пикселей в месте расположения рукописных 0 и игнорировать большинство других пикселей, эффективно обнаруживая те особенности, которые полезны для различения наложенных цифр

Fig. 3: Обнаружение подгрупп в биологических данных. a Мы используем PCA для проецирования набора данных экспрессии белков у мышей с синдромом Дауна (DS) и без него на первые две компоненты. Низкоразмерное представление измерений экспрессии белков у мышей с DS и без него распределено схожим образом (верх). Однако, когда мы используем cPCA для проецирования набора данных на его первые две cPC, мы обнаруживаем низкоразмерное представление, которое группирует мышей с DS и без него отдельно (низ). b Кроме того, мы используем PCA и cPCA для визуализации высокоразмерного набора данных одноядерной РНК-секвенирования в двух измерениях. Набор данных состоит из четырех образцов клеток от двух пациентов с лейкемией: образец до трансплантации от пациента 1, образец после трансплантации от пациента 1, образец до трансплантации от пациента 2 и образец после трансплантации от пациента 2. b , слева: Результаты, используя только образцы от пациента 1, которые демонстрируют, что cPCA (низ) более эффективно разделяет образцы, чем PCA (верх). Когда включены образцы от второго пациента, в b , справа, снова cPCA (низ) более эффективно, чем PCA (верх), разделяет образцы, хотя клетки после трансплантации от обоих пациентов распределены схожим образом. Мы показываем графики каждого образца отдельно в Дополнительном рис.[5] , где легче увидеть перекрытие между различными образцами

Fig. 4: Взаимоотношения между группами мексиканского происхождения. a PCA, примененный к генетическим данным от индивидов из 5 мексиканских штатов, не выявляет никаких визуально различимых паттернов в встроенных данных. b cPCA, примененный к тому же набору данных, выявляет паттерны в данных: индивиды из одного и того же штата сгруппированы ближе друг к другу в встраивании cPCA. c Кроме того, распределение точек выявляет взаимоотношения между группами, которые соответствуют географическому расположению различных штатов: например, индивиды из географически соседних штатов соседствуют во встраивании. c Адаптировано из карты Мексики, которая изначально является работой пользователя Allstrak на Википедии, опубликованной под лицензией CC-BY-SA, источник https://commons.wikimedia.org/wiki/File:Mexico_Map.svg

Fig. 5: Геометрическая интерпретация cPCA. Набор пар дисперсий целевых и фоновых данныхUизображен как бирюзовая область для некоторых случайно сгенерированных целевых и фоновых данных. Нижняя правая граница, окрашенная в золотой цвет, соответствует набору наиболее контрастных направленийSλ. Синие треугольники — это пары дисперсий для cPC, выбранных с α значениями 0.92 и 0.29 соответственно. Мы отмечаем, что они соответствуют точкам касания золотой кривой и касательных линий с наклоном1α= 1.08, 3.37, соответственно

